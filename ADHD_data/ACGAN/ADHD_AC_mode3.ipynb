{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_AC_mode3.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","GI_kANkKEnmQ","_lIT_ZxfE1mZ","xaIOGJ22LzA6","cLWWWfE6L20n","fK7NGsGKL5Ts","Zm7qDbXsMJcD"],"authorship_tag":"ABX9TyMnco5Q5EC5ZpcuQCdxEWqQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621398063258,"user_tz":-480,"elapsed":19785,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"841d1d1a-a581-4b31-80ce-5e9aa5295047"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'BrainNet',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621398075971,"user_tz":-480,"elapsed":912,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"38d4d776-38bc-4c10-f58d-ef7624c4d931"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621398076357,"user_tz":-480,"elapsed":1294,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"28a3778b-b8e7-4f00-a57f-3e5e1c0a2801"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.32763208 1.        ]\n"," [2.         0.46256176 0.        ]\n"," [0.         0.71493729 1.        ]\n"," [0.         0.53895857 0.        ]\n"," [2.         0.50057013 1.        ]\n"," [1.         0.39376663 1.        ]\n"," [1.         0.48080578 0.        ]\n"," [1.         0.33890789 1.        ]\n"," [0.         0.33903459 0.        ]\n"," [1.         0.52489548 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621398076359,"user_tz":-480,"elapsed":1291,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"fab36d6b-1260-42e3-dac9-29cda4ad7b06"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[1.         0.         0.         0.32763208 1.        ]\n"," [0.         0.         1.         0.46256176 0.        ]\n"," [1.         0.         0.         0.71493729 1.        ]\n"," [1.         0.         0.         0.53895857 0.        ]\n"," [0.         0.         1.         0.50057013 1.        ]\n"," [0.         1.         0.         0.39376663 1.        ]\n"," [0.         1.         0.         0.48080578 0.        ]\n"," [0.         1.         0.         0.33890789 1.        ]\n"," [1.         0.         0.         0.33903459 0.        ]\n"," [0.         1.         0.         0.52489548 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621398078298,"user_tz":-480,"elapsed":660,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"1ee2c419-b5d5-40c7-b0ce-f1b96b2cff06"},"source":["# Discriminator\n","DECAY = 0.0005\n","ALPHA = 0.33\n","LR_D = 0.0001\n","BETA_D = 0.5\n","FE_CHANNEL = 128\n","CODE_CHANNEL = 16\n","MERGE_CHANNEL = 64\n","\n","# Generator\n","D = 10\n","STD = 0.02\n","\n","# GAN\n","LR_G = 0.0001\n","BETA_G = 0.5\n","\n","# Loss weights\n","LOSS_WEIGHTS = [1.0, 1.0]\n","\n","# Train function\n","LATENT_DIM = 50\n","BATCH_SIZE = 64\n","\n","'''\n","The number of E2E layers\n","Channel size of E2E layers\n","Dropout\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\nChannel size of E2E layers\\nDropout\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"_lIT_ZxfE1mZ"},"source":["#Model function"]},{"cell_type":"code","metadata":{"id":"kYW-Fke9E5tT"},"source":["# define E2E layer\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.utils import conv_utils\n","\n","class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaIOGJ22LzA6"},"source":["# define D"]},{"cell_type":"code","metadata":{"id":"ySQCRi_RFACM"},"source":["# define the standalone discriminator model\n","def define_discriminator(image_shape=(190,190,1), n_classes=3):\n","  # weight regularization\n","  reg = regularizers.l2(DECAY)\n","  # weight initialization\n","  kernel_init = initializers.he_uniform()\n","  # image input\n","  in_image = Input(shape=image_shape, name='in_image')\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(in_image)  \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 64, (2, 190), kernel_regularizer=reg)(fe)     \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(128, (1, 190), kernel_regularizer=reg, name='row')(fe)  \n","  temp2 = Conv2D(128, (190, 1), kernel_regularizer=reg, name='column')(fe)\n","  temp2 = Reshape((190, 1, 128))(temp2)\n","  fe = Add()([temp1, temp2])\n","  fe = BatchNormalization()(fe)                          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(256, (190, 1), kernel_regularizer=reg)(fe) \n","  fe = BatchNormalization()(fe)          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(0.5)(merge)\n","\n","  # real/fake output\n","  out1 = Dense(1, activation='sigmoid', name='valid')(merge)\n","  # class label output\n","  out2 = Dense(n_classes, activation='softmax', name='class')(merge)\n","  # define model\n","  model = Model(in_image, [out1, out2], name=\"Discriminator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLWWWfE6L20n"},"source":["# define G"]},{"cell_type":"code","metadata":{"id":"feTOreTCFQEr"},"source":["# define the standalone generator model\n","def define_generator(latent_dim=50, n_classes=3, d=D):\n","  #Initailize Weights\n","  init = RandomNormal(stddev=STD)\n","    \n","  #Take in noise as input\n","  in_z = keras.Input(shape=(latent_dim,))\n","  print(f\"Shape of Noise Vector: {in_z.shape}\")\n","  \n","  #Create a dense layer\n","  dense = keras.layers.Dense(190*d, activation=\"relu\", kernel_initializer = init)\n","  \n","  X = dense(in_z)\n","  X = keras.layers.Reshape((190,d))(X)\n","  print(f\"Shape of X: {X.shape}\")\n","\n","  A = keras.layers.Dot(axes=(2, 2))([X,X])\n","  A = keras.backend.expand_dims(A, axis = -1)\n","\n","  A = Activation('tanh')(A)\n","  print(f\"Shape of A: {A.shape}\")\n","  \n","  # define model\n","  model = Model(in_z, A, name=\"Generator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK7NGsGKL5Ts"},"source":["#define GAN"]},{"cell_type":"code","metadata":{"id":"bzf_8DlyHJGD"},"source":["def all_model(latent_dim=50):\n","  # define D & G\n","  d_model = define_discriminator()\n","  g_model = define_generator(latent_dim)\n","\n","  # compile D\n","  opt = optimizers.Adam(lr=LR_D, beta_1=BETA_D)\n","  d_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  # define GAN\n","  d_model.trainable = False\n"," \n","  in_noise = keras.Input(shape=(latent_dim,))\n","  img = g_model(in_noise)\n","\n","  valid, label = d_model(img)\n","  gan_model = Model(in_noise, [valid, label], name=\"GAN\")\n","\n","  opt = optimizers.Adam(lr=LR_G, beta_1=BETA_G)\n","  gan_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  return d_model, g_model, gan_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8CEB6VkKsQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621398092414,"user_tz":-480,"elapsed":7052,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"fd10ee15-e77e-46b4-9d70-1363af0dac1e"},"source":["d_model, g_model, gan_model = all_model(LATENT_DIM)\n","d_model.summary()\n","g_model.summary()\n","gan_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","in_image (InputLayer)           [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 32) 12160       in_image[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 190, 190, 32) 128         e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 64) 778240      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 190, 190, 64) 256         e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 190, 190, 64) 0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 128)  0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 128)  0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 190, 1, 128)  512         add[0][0]                        \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 190, 1, 128)  0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 256)    6226176     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 1, 1, 256)    1024        conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 256)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1, 1, 256)    0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 256)          0           dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          32896       flatten[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 64)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 64)           0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","valid (Dense)                   (None, 1)            65          dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 3)            195         dropout_4[0][0]                  \n","==================================================================================================\n","Total params: 10,173,124\n","Trainable params: 0\n","Non-trainable params: 10,173,124\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1900)         96900       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 190, 10)      0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 190, 190)     0           reshape_1[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","tf.expand_dims (TFOpLambda)     (None, 190, 190, 1)  0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 190, 190, 1)  0           tf.expand_dims[0][0]             \n","==================================================================================================\n","Total params: 96,900\n","Trainable params: 96,900\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 50)]              0         \n","_________________________________________________________________\n","Generator (Functional)       (None, 190, 190, 1)       96900     \n","_________________________________________________________________\n","Discriminator (Functional)   [(None, 1), (None, 3)]    10173124  \n","=================================================================\n","Total params: 10,270,024\n","Trainable params: 96,900\n","Non-trainable params: 10,173,124\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zm7qDbXsMJcD"},"source":["#Auxiliary function"]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","\n","  y_train = combine_train[:, 0]\n","  y_remain = combine_remain[:, 0]\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, y_val, y_test = train_test_split(X_remain, y_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}\")\n","\n","  return [X_train, y_train],[X_val, y_val],[X_test, y_test]\n","     \n","# select real samples\n","def generate_real_samples(dataset, n_samples):\n","\t# split into images and labels\n","\timages, labels = dataset\n","\t# choose random instances\n","\tix = np.random.randint(0, images.shape[0], n_samples)\n","\t# select images and labels\n","\tX, labels = images[ix], labels[ix] \n","\ty = np.ones((n_samples, 1))              \n","\treturn X, [y, labels]\n","\n","def generate_random_ecodings(n_samples):\n","  enc_idx = np.arange(0,len(encoded_data))\n","  sample_idx = np.random.choice(enc_idx, size = n_samples)\n","  samples = []\n","  labels = []\n","  #print(sample_idx)\n","  for idx in sample_idx:\n","    samples.append(encoded_data[idx][:3])\n","    label = encoded_data[idx][:3]\n","    if label[0]==1:\n","      labels.append(0)\n","    elif label[1]==1:\n","      labels.append(1)\n","    else:\n","      labels.append(2)\n","  return np.array(samples), np.array(labels)\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, n_classes=3):\n","  #Generate noise, 3 dimensions short of latent_dim\n","  z_noise = np.random.normal(0, 1, size=[n_samples,latent_dim-3])   # Gaussian distribution\n","  #Generate encoding of 3 dimensions\n","  z_encoding, labels = generate_random_ecodings(n_samples)\n","  #Concatenate z_noise and z_encoding to create input of latent_dim\n","  z_input = np.concatenate((z_noise, z_encoding), axis = 1)\n","  return [z_input, labels]\n","\n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","  # generate points in latent space\n","  z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n","  # predict outputs\n","  images = generator.predict(z_input)\n","  y = np.zeros((n_samples, 1))           \n","  return images, [y, labels_input]\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, d_model):\n","  path = 'ACGAN/mode3'\n","  filename1 = path + '/weights/d_model_%04d.h5' % (step+1)\n","  d_model.save_weights(filename1)\n","  print('>Saved: %s' % filename1)\n","\n","# create a line plot of loss for the gan and save to file\n","def plot_history(train_hist, validation_hist):\n","  path = 'ACGAN/mode3'\n","  # dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = train_hist\n","  # # plot train_data loss\n","  # pyplot.plot(dr_v_loss1, label='D-validity-real')\n","  # pyplot.plot(df_v_loss1, label='D-validity-fake')\n","  # pyplot.plot(g_v_loss1, label='G-validity')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_loss.pdf')\n","  # pyplot.close()\n"," \n","  # plot train_datad accuracy\n","  # pyplot.plot(dr_v_acc1, label='validity-real')\n","  # pyplot.plot(df_v_acc1, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_valid_acc.pdf')\n","  # pyplot.close()\n","\n","  # pyplot.plot(dr_c_acc1, label='class-real')\n","  # pyplot.plot(df_c_acc1, label='class-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_class_acc.pdf')\n","  # pyplot.close()\n"," \n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = validation_hist\n","  # # plot validation_data loss\n","  # pyplot.plot(dr_v_loss2, label='validity-real')\n","  # pyplot.plot(df_v_loss2, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_validation_loss.pdf')\n","  # pyplot.close()\n","\n","  # plot validation_data accuracy\n","  pyplot.plot(dr_v_acc2, label='validity-real')\n","  pyplot.plot(df_v_acc2, label='validity-fake')\n","  pyplot.plot(dr_c_acc2, label='class-real')\n","  pyplot.legend()\n","  pyplot.savefig(path + '/plot_validation_acc.pdf')\n","  pyplot.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i4q7BrEyjTh2"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"ad0hvdDOjO96"},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, val_dataset, n_epochs=300, latent_dim=LATENT_DIM, n_batch=BATCH_SIZE):\n","  epoch=0\n","  # calculate the number of batches per training epoch\n","  bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","  # calculate the number of training iterations\n","  n_steps = bat_per_epo * n_epochs\n","  # calculate the real/fake batch_size\n","  half_batch = int(n_batch / 2)\n","  # prepare lists for train_data hist\n","  dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = list(), list(), list(), list(), list(), list(), list()\n","  # prepare lists for validation_data hist\n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = list(), list(), list(), list(), list()\n","\n","  # manually enumerate epochs\n","  for i in range(n_steps):\n","    #----------------------------------------\n","    # update discriminator model weights\n","    #----------------------------------------\n","\n","    # get randomly selected 'real' samples\n","    X_real, [y_real, labels_real] = generate_real_samples(dataset, half_batch)\n","    dr_metrics = d_model.train_on_batch(X_real, [y_real, labels_real])\n","    # generate 'fake' \n","    X_fake, [y_fake, labels_fake] = generate_fake_samples(g_model, latent_dim, half_batch)\n","    df_metrics = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n","\n","    # summarize the loss and accuracy\n","    d_metrics = 0.5 * np.add(dr_metrics, df_metrics)\n","\n","    #----------------------------------------\n","    # update the generator via the discriminator's error\n","    #----------------------------------------\n","\n","    # prepare points in latent space as input for the generator\n","    [z_input, z_labels] = generate_latent_points(latent_dim, n_batch)   \n","    y_gan = np.ones((n_batch, 1)) \n","    g_metrics = gan_model.train_on_batch(z_input, [y_gan, z_labels])\n","\n","    # summarize loss on this batch\n","    print('STEP:%d, D{v_l: %.3f, v_acc: [%.1f| %.1f| %.1f], c_acc: [%.1f| %.1f]}  G{v_l: %.3f, v_acc: %.1f, c_acc: %.1f}'\n","        % (i+1, d_metrics[1], 100*dr_metrics[3], 100*df_metrics[3], 100*d_metrics[3], 100*dr_metrics[4], 100*df_metrics[4], \n","          g_metrics[1], 100*g_metrics[3], 100*g_metrics[4]))\n","    # metrics[0]: loss, metrics[1]: validity_loss, metrics[2]: classification_loss, metrics[3]: validity_accuracy, metrics[4]: classification_accuracy\n","\n","    # record history\n","    dr_v_loss1.append(dr_metrics[1])\n","    df_v_loss1.append(df_metrics[1])\n","    g_v_loss1.append(g_metrics[1])\n","    dr_v_acc1.append(dr_metrics[3])\n","    df_v_acc1.append(df_metrics[3])\n","    dr_c_acc1.append(dr_metrics[4])\n","    df_c_acc1.append(df_metrics[4])\n","\n","    #----------------------------------------\n","    # evaluation\n","    #----------------------------------------\n","    if (i+1) % (bat_per_epo) == 0:\n","      epoch+=1\n","      # generate real validation data\n","      X_r_val, labels_r_val = val_dataset\n","      num_test = X_r_val.shape[0]\n","      # generate fake validation data\n","      y_r_val = ones((num_test, 1))\n","      X_f_val, [y_f_val, labels_f_val] = generate_fake_samples(g_model, latent_dim, num_test)\n","\n","      print(f\"\\nValidation Metrics of Discriminator:\")\n","      # evaluate both real and fake valid_dataset\n","      valid_metrics_r = d_model.evaluate(X_r_val, [y_r_val, labels_r_val], verbose=1)\n","      valid_metrics_f = d_model.evaluate(X_f_val, [y_f_val, labels_f_val], verbose=1)\n","\n","      v_acc = 50 * (valid_metrics_r[3] + valid_metrics_f[3])  \n","      three_c_acc = 100 * valid_metrics_r[4]   \n","\n","      # two class accuracy\n","      _, labels_pred = d_model.predict(X_r_val)\n","      labels_pred = np.argmax(labels_pred, axis=1)\n","      # print('val {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_r_val==0), np.sum(labels_r_val==1), np.sum(labels_r_val==2)))\n","      # print('pred {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_pred==0), np.sum(labels_pred==1), np.sum(labels_pred==2)))\n","      labels_2_val, labels_2_pred = labels_r_val.copy(), labels_pred.copy()\n","      # classify 2 as 1\n","      labels_2_val[labels_2_val==2] = 1\n","      labels_2_pred[labels_2_pred==2] = 1\n","      # calculate the accuracy \n","      correct = np.sum(labels_2_val==labels_2_pred)\n","      two_c_acc = correct / num_test * 100\n","           \n","      print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","      print(\"=\"*100)\n","      # save good models\n","      if three_c_acc > 64 or two_c_acc > 67:\n","      # if three_c_acc > 65:\n","        summarize_performance(i, d_model)\n","\n","      # record history\n","      dr_v_loss2.append(valid_metrics_r[1])\n","      df_v_loss2.append(valid_metrics_f[1])\n","      dr_v_acc2.append(valid_metrics_r[3])\n","      df_v_acc2.append(valid_metrics_f[3])\n","      dr_c_acc2.append(valid_metrics_r[4])\n","\n","    # print epoch\n","    if (i+1) % (bat_per_epo * 10) == 0:\n","      print(f\"Epoch: {epoch}\")\n","      print(\"=\"*100)\n","   \n","      # plot history\n","      train_hist = [dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1]\n","      validation_hist = [dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      plot_history(train_hist, validation_hist)\n","      point = [dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      np.save('ACGAN/mode3/point_3', point)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FvIIOPHvqBse","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621398099833,"user_tz":-480,"elapsed":747,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"3ea19950-c176-4da9-d108-b7ff759b9a44"},"source":["# load image data\n","train_data, val_data, test_data = load_real_samples(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d7SzbdH3qCS2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621399328517,"user_tz":-480,"elapsed":1229427,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"76904dc2-0f81-4a46-ec2e-9a52e6792a89"},"source":["epochs = 100\n","\n","# define model\n","discriminator, generator, gan_model = all_model(LATENT_DIM)\n","# train model\n","train(generator, discriminator, gan_model, train_data, val_data, n_epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","STEP:1, D{v_l: 1.048, v_acc: [53.1| 46.9| 50.0], c_acc: [15.6| 46.9]}  G{v_l: 0.692, v_acc: 53.1, c_acc: 40.6}\n","STEP:2, D{v_l: 0.870, v_acc: [68.8| 71.9| 70.3], c_acc: [40.6| 25.0]}  G{v_l: 0.696, v_acc: 54.7, c_acc: 29.7}\n","STEP:3, D{v_l: 1.327, v_acc: [53.1| 28.1| 40.6], c_acc: [40.6| 31.2]}  G{v_l: 0.702, v_acc: 42.2, c_acc: 42.2}\n","STEP:4, D{v_l: 1.499, v_acc: [53.1| 40.6| 46.9], c_acc: [43.8| 28.1]}  G{v_l: 0.696, v_acc: 53.1, c_acc: 39.1}\n","STEP:5, D{v_l: 1.106, v_acc: [65.6| 53.1| 59.4], c_acc: [34.4| 56.2]}  G{v_l: 0.695, v_acc: 50.0, c_acc: 42.2}\n","STEP:6, D{v_l: 1.042, v_acc: [53.1| 56.2| 54.7], c_acc: [62.5| 31.2]}  G{v_l: 0.700, v_acc: 39.1, c_acc: 46.9}\n","STEP:7, D{v_l: 1.232, v_acc: [56.2| 43.8| 50.0], c_acc: [43.8| 43.8]}  G{v_l: 0.698, v_acc: 42.2, c_acc: 42.2}\n","STEP:8, D{v_l: 1.373, v_acc: [43.8| 50.0| 46.9], c_acc: [56.2| 37.5]}  G{v_l: 0.701, v_acc: 51.6, c_acc: 35.9}\n","STEP:9, D{v_l: 1.472, v_acc: [50.0| 37.5| 43.8], c_acc: [46.9| 56.2]}  G{v_l: 0.698, v_acc: 48.4, c_acc: 43.8}\n","STEP:10, D{v_l: 1.652, v_acc: [40.6| 46.9| 43.8], c_acc: [28.1| 43.8]}  G{v_l: 0.709, v_acc: 40.6, c_acc: 45.3}\n","STEP:11, D{v_l: 0.968, v_acc: [56.2| 62.5| 59.4], c_acc: [43.8| 50.0]}  G{v_l: 0.713, v_acc: 43.8, c_acc: 42.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 294ms/step - loss: 2.1689 - valid_loss: 0.6918 - class_loss: 1.0918 - valid_acc: 0.6235 - class_acc: 0.4941\n","3/3 [==============================] - 1s 45ms/step - loss: 2.1621 - valid_loss: 0.6932 - class_loss: 1.0837 - valid_acc: 0.4471 - class_acc: 0.6000\n","average v_acc: 53.529, three class acc: 49.412, two class acc: 54.118\n","====================================================================================================\n","STEP:12, D{v_l: 1.119, v_acc: [43.6| 59.4| 51.5], c_acc: [53.0| 37.5]}  G{v_l: 0.699, v_acc: 45.3, c_acc: 40.6}\n","STEP:13, D{v_l: 1.249, v_acc: [56.2| 50.0| 53.1], c_acc: [65.6| 53.1]}  G{v_l: 0.711, v_acc: 40.6, c_acc: 34.4}\n","STEP:14, D{v_l: 1.375, v_acc: [56.2| 46.9| 51.6], c_acc: [43.8| 46.9]}  G{v_l: 0.692, v_acc: 56.2, c_acc: 40.6}\n","STEP:15, D{v_l: 1.135, v_acc: [59.4| 62.5| 60.9], c_acc: [53.1| 40.6]}  G{v_l: 0.698, v_acc: 46.9, c_acc: 53.1}\n","STEP:16, D{v_l: 1.256, v_acc: [46.9| 53.1| 50.0], c_acc: [50.0| 46.9]}  G{v_l: 0.696, v_acc: 45.3, c_acc: 48.4}\n","STEP:17, D{v_l: 1.214, v_acc: [53.1| 50.0| 51.6], c_acc: [46.9| 46.9]}  G{v_l: 0.694, v_acc: 51.6, c_acc: 45.3}\n","STEP:18, D{v_l: 1.220, v_acc: [59.4| 46.9| 53.1], c_acc: [40.6| 56.2]}  G{v_l: 0.689, v_acc: 56.2, c_acc: 40.6}\n","STEP:19, D{v_l: 1.406, v_acc: [53.1| 43.8| 48.4], c_acc: [43.8| 56.2]}  G{v_l: 0.744, v_acc: 37.5, c_acc: 40.6}\n","STEP:20, D{v_l: 1.335, v_acc: [40.6| 56.2| 48.4], c_acc: [50.0| 31.2]}  G{v_l: 0.723, v_acc: 42.2, c_acc: 37.5}\n","STEP:21, D{v_l: 0.930, v_acc: [68.8| 56.2| 62.5], c_acc: [37.5| 37.5]}  G{v_l: 0.675, v_acc: 62.5, c_acc: 48.4}\n","STEP:22, D{v_l: 1.204, v_acc: [43.8| 59.4| 51.6], c_acc: [25.0| 50.0]}  G{v_l: 0.703, v_acc: 46.9, c_acc: 48.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.1399 - valid_loss: 0.6866 - class_loss: 1.0674 - valid_acc: 0.8588 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.1616 - valid_loss: 0.6999 - class_loss: 1.0758 - valid_acc: 0.0824 - class_acc: 0.5647\n","average v_acc: 47.059, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:23, D{v_l: 1.140, v_acc: [19.7| 50.0| 34.8], c_acc: [55.6| 59.4]}  G{v_l: 0.714, v_acc: 46.9, c_acc: 39.1}\n","STEP:24, D{v_l: 1.138, v_acc: [59.4| 40.6| 50.0], c_acc: [21.9| 34.4]}  G{v_l: 0.689, v_acc: 54.7, c_acc: 45.3}\n","STEP:25, D{v_l: 1.207, v_acc: [46.9| 65.6| 56.2], c_acc: [40.6| 46.9]}  G{v_l: 0.695, v_acc: 56.2, c_acc: 45.3}\n","STEP:26, D{v_l: 1.177, v_acc: [53.1| 59.4| 56.2], c_acc: [50.0| 53.1]}  G{v_l: 0.743, v_acc: 37.5, c_acc: 37.5}\n","STEP:27, D{v_l: 1.381, v_acc: [31.2| 46.9| 39.1], c_acc: [37.5| 43.8]}  G{v_l: 0.745, v_acc: 39.1, c_acc: 48.4}\n","STEP:28, D{v_l: 1.081, v_acc: [50.0| 53.1| 51.6], c_acc: [43.8| 56.2]}  G{v_l: 0.714, v_acc: 46.9, c_acc: 34.4}\n","STEP:29, D{v_l: 0.924, v_acc: [50.0| 65.6| 57.8], c_acc: [62.5| 37.5]}  G{v_l: 0.727, v_acc: 48.4, c_acc: 40.6}\n","STEP:30, D{v_l: 1.742, v_acc: [28.1| 43.8| 35.9], c_acc: [43.8| 56.2]}  G{v_l: 0.748, v_acc: 43.8, c_acc: 50.0}\n","STEP:31, D{v_l: 1.048, v_acc: [53.1| 62.5| 57.8], c_acc: [59.4| 62.5]}  G{v_l: 0.670, v_acc: 57.8, c_acc: 60.9}\n","STEP:32, D{v_l: 1.419, v_acc: [46.9| 34.4| 40.6], c_acc: [56.2| 65.6]}  G{v_l: 0.699, v_acc: 53.1, c_acc: 39.1}\n","STEP:33, D{v_l: 1.389, v_acc: [34.4| 46.9| 40.6], c_acc: [40.6| 59.4]}  G{v_l: 0.694, v_acc: 50.0, c_acc: 48.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.1345 - valid_loss: 0.7130 - class_loss: 1.0351 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 2.1023 - valid_loss: 0.7137 - class_loss: 1.0022 - valid_acc: 0.0000e+00 - class_acc: 0.6235\n","average v_acc: 0.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:34, D{v_l: 0.804, v_acc: [14.5| 65.6| 40.1], c_acc: [59.0| 56.2]}  G{v_l: 0.718, v_acc: 50.0, c_acc: 59.4}\n","STEP:35, D{v_l: 1.413, v_acc: [59.4| 53.1| 56.2], c_acc: [68.8| 40.6]}  G{v_l: 0.733, v_acc: 45.3, c_acc: 48.4}\n","STEP:36, D{v_l: 1.074, v_acc: [56.2| 37.5| 46.9], c_acc: [40.6| 37.5]}  G{v_l: 0.786, v_acc: 35.9, c_acc: 40.6}\n","STEP:37, D{v_l: 0.880, v_acc: [59.4| 78.1| 68.8], c_acc: [50.0| 62.5]}  G{v_l: 0.710, v_acc: 57.8, c_acc: 48.4}\n","STEP:38, D{v_l: 1.692, v_acc: [40.6| 40.6| 40.6], c_acc: [43.8| 62.5]}  G{v_l: 0.674, v_acc: 62.5, c_acc: 54.7}\n","STEP:39, D{v_l: 1.180, v_acc: [53.1| 59.4| 56.2], c_acc: [65.6| 68.8]}  G{v_l: 0.698, v_acc: 54.7, c_acc: 54.7}\n","STEP:40, D{v_l: 1.202, v_acc: [59.4| 50.0| 54.7], c_acc: [59.4| 62.5]}  G{v_l: 0.661, v_acc: 57.8, c_acc: 60.9}\n","STEP:41, D{v_l: 1.152, v_acc: [46.9| 62.5| 54.7], c_acc: [56.2| 53.1]}  G{v_l: 0.638, v_acc: 67.2, c_acc: 50.0}\n","STEP:42, D{v_l: 1.586, v_acc: [21.9| 62.5| 42.2], c_acc: [40.6| 56.2]}  G{v_l: 0.712, v_acc: 56.2, c_acc: 48.4}\n","STEP:43, D{v_l: 1.124, v_acc: [59.4| 43.8| 51.6], c_acc: [40.6| 59.4]}  G{v_l: 0.737, v_acc: 48.4, c_acc: 57.8}\n","STEP:44, D{v_l: 0.990, v_acc: [50.0| 50.0| 50.0], c_acc: [43.8| 37.5]}  G{v_l: 0.719, v_acc: 54.7, c_acc: 51.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.1150 - valid_loss: 0.6976 - class_loss: 1.0306 - valid_acc: 0.3294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.1528 - valid_loss: 0.7505 - class_loss: 1.0155 - valid_acc: 0.0000e+00 - class_acc: 0.5412\n","average v_acc: 16.471, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:45, D{v_l: 0.920, v_acc: [11.1| 62.5| 36.8], c_acc: [50.4| 50.0]}  G{v_l: 0.706, v_acc: 51.6, c_acc: 56.2}\n","STEP:46, D{v_l: 1.297, v_acc: [43.8| 53.1| 48.4], c_acc: [34.4| 53.1]}  G{v_l: 0.712, v_acc: 51.6, c_acc: 60.9}\n","STEP:47, D{v_l: 0.912, v_acc: [59.4| 50.0| 54.7], c_acc: [50.0| 78.1]}  G{v_l: 0.714, v_acc: 46.9, c_acc: 57.8}\n","STEP:48, D{v_l: 1.175, v_acc: [43.8| 59.4| 51.6], c_acc: [53.1| 53.1]}  G{v_l: 0.748, v_acc: 48.4, c_acc: 45.3}\n","STEP:49, D{v_l: 0.985, v_acc: [62.5| 53.1| 57.8], c_acc: [56.2| 50.0]}  G{v_l: 0.660, v_acc: 64.1, c_acc: 34.4}\n","STEP:50, D{v_l: 1.121, v_acc: [56.2| 46.9| 51.6], c_acc: [34.4| 62.5]}  G{v_l: 0.746, v_acc: 42.2, c_acc: 37.5}\n","STEP:51, D{v_l: 1.019, v_acc: [59.4| 59.4| 59.4], c_acc: [53.1| 84.4]}  G{v_l: 0.686, v_acc: 53.1, c_acc: 39.1}\n","STEP:52, D{v_l: 1.142, v_acc: [46.9| 59.4| 53.1], c_acc: [28.1| 68.8]}  G{v_l: 0.715, v_acc: 62.5, c_acc: 50.0}\n","STEP:53, D{v_l: 0.919, v_acc: [53.1| 59.4| 56.2], c_acc: [46.9| 78.1]}  G{v_l: 0.761, v_acc: 46.9, c_acc: 43.8}\n","STEP:54, D{v_l: 1.420, v_acc: [59.4| 43.8| 51.6], c_acc: [53.1| 71.9]}  G{v_l: 0.786, v_acc: 50.0, c_acc: 56.2}\n","STEP:55, D{v_l: 1.160, v_acc: [43.8| 62.5| 53.1], c_acc: [43.8| 68.8]}  G{v_l: 0.769, v_acc: 50.0, c_acc: 51.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 2.0936 - valid_loss: 0.6920 - class_loss: 1.0144 - valid_acc: 0.5294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.1297 - valid_loss: 0.7578 - class_loss: 0.9847 - valid_acc: 0.0000e+00 - class_acc: 0.5412\n","average v_acc: 26.471, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:56, D{v_l: 1.050, v_acc: [10.3| 53.1| 31.7], c_acc: [51.3| 71.9]}  G{v_l: 0.682, v_acc: 54.7, c_acc: 53.1}\n","STEP:57, D{v_l: 1.005, v_acc: [71.9| 53.1| 62.5], c_acc: [46.9| 62.5]}  G{v_l: 0.712, v_acc: 56.2, c_acc: 45.3}\n","STEP:58, D{v_l: 1.192, v_acc: [50.0| 43.8| 46.9], c_acc: [56.2| 37.5]}  G{v_l: 0.657, v_acc: 68.8, c_acc: 51.6}\n","STEP:59, D{v_l: 1.138, v_acc: [56.2| 40.6| 48.4], c_acc: [59.4| 65.6]}  G{v_l: 0.632, v_acc: 60.9, c_acc: 40.6}\n","STEP:60, D{v_l: 1.280, v_acc: [53.1| 53.1| 53.1], c_acc: [34.4| 75.0]}  G{v_l: 0.624, v_acc: 59.4, c_acc: 46.9}\n","STEP:61, D{v_l: 1.220, v_acc: [40.6| 50.0| 45.3], c_acc: [50.0| 71.9]}  G{v_l: 0.656, v_acc: 62.5, c_acc: 50.0}\n","STEP:62, D{v_l: 1.200, v_acc: [40.6| 56.2| 48.4], c_acc: [34.4| 71.9]}  G{v_l: 0.662, v_acc: 51.6, c_acc: 48.4}\n","STEP:63, D{v_l: 1.251, v_acc: [50.0| 50.0| 50.0], c_acc: [50.0| 71.9]}  G{v_l: 0.638, v_acc: 60.9, c_acc: 59.4}\n","STEP:64, D{v_l: 1.011, v_acc: [40.6| 68.8| 54.7], c_acc: [43.8| 71.9]}  G{v_l: 0.713, v_acc: 51.6, c_acc: 48.4}\n","STEP:65, D{v_l: 1.188, v_acc: [43.8| 46.9| 45.3], c_acc: [46.9| 68.8]}  G{v_l: 0.677, v_acc: 60.9, c_acc: 51.6}\n","STEP:66, D{v_l: 1.270, v_acc: [34.4| 40.6| 37.5], c_acc: [37.5| 62.5]}  G{v_l: 0.697, v_acc: 59.4, c_acc: 56.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0329 - valid_loss: 0.6413 - class_loss: 1.0041 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 2.1642 - valid_loss: 0.8122 - class_loss: 0.9646 - valid_acc: 0.0000e+00 - class_acc: 0.6588\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:67, D{v_l: 0.896, v_acc: [13.7| 50.0| 31.8], c_acc: [61.5| 81.2]}  G{v_l: 0.679, v_acc: 56.2, c_acc: 54.7}\n","STEP:68, D{v_l: 1.171, v_acc: [40.6| 68.8| 54.7], c_acc: [59.4| 56.2]}  G{v_l: 0.658, v_acc: 54.7, c_acc: 53.1}\n","STEP:69, D{v_l: 0.961, v_acc: [53.1| 46.9| 50.0], c_acc: [56.2| 75.0]}  G{v_l: 0.666, v_acc: 62.5, c_acc: 54.7}\n","STEP:70, D{v_l: 1.154, v_acc: [56.2| 59.4| 57.8], c_acc: [56.2| 71.9]}  G{v_l: 0.631, v_acc: 60.9, c_acc: 57.8}\n","STEP:71, D{v_l: 1.267, v_acc: [46.9| 50.0| 48.4], c_acc: [65.6| 78.1]}  G{v_l: 0.755, v_acc: 42.2, c_acc: 50.0}\n","STEP:72, D{v_l: 1.397, v_acc: [53.1| 43.8| 48.4], c_acc: [46.9| 78.1]}  G{v_l: 0.673, v_acc: 57.8, c_acc: 45.3}\n","STEP:73, D{v_l: 1.395, v_acc: [37.5| 50.0| 43.8], c_acc: [53.1| 68.8]}  G{v_l: 0.727, v_acc: 51.6, c_acc: 50.0}\n","STEP:74, D{v_l: 0.911, v_acc: [50.0| 62.5| 56.2], c_acc: [43.8| 84.4]}  G{v_l: 0.773, v_acc: 40.6, c_acc: 54.7}\n","STEP:75, D{v_l: 1.122, v_acc: [40.6| 56.2| 48.4], c_acc: [56.2| 78.1]}  G{v_l: 0.657, v_acc: 59.4, c_acc: 57.8}\n","STEP:76, D{v_l: 1.347, v_acc: [50.0| 50.0| 50.0], c_acc: [56.2| 78.1]}  G{v_l: 0.671, v_acc: 60.9, c_acc: 51.6}\n","STEP:77, D{v_l: 1.281, v_acc: [53.1| 56.2| 54.7], c_acc: [59.4| 68.8]}  G{v_l: 0.722, v_acc: 57.8, c_acc: 48.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.0171 - valid_loss: 0.6189 - class_loss: 1.0106 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 2.1383 - valid_loss: 0.8343 - class_loss: 0.9164 - valid_acc: 0.0000e+00 - class_acc: 0.6118\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:78, D{v_l: 0.878, v_acc: [12.0| 59.4| 35.7], c_acc: [57.3| 78.1]}  G{v_l: 0.650, v_acc: 60.9, c_acc: 54.7}\n","STEP:79, D{v_l: 1.243, v_acc: [46.9| 53.1| 50.0], c_acc: [43.8| 68.8]}  G{v_l: 0.598, v_acc: 68.8, c_acc: 59.4}\n","STEP:80, D{v_l: 0.907, v_acc: [37.5| 65.6| 51.6], c_acc: [53.1| 75.0]}  G{v_l: 0.740, v_acc: 53.1, c_acc: 48.4}\n","STEP:81, D{v_l: 1.324, v_acc: [43.8| 56.2| 50.0], c_acc: [59.4| 68.8]}  G{v_l: 0.675, v_acc: 59.4, c_acc: 54.7}\n","STEP:82, D{v_l: 0.933, v_acc: [40.6| 65.6| 53.1], c_acc: [46.9| 75.0]}  G{v_l: 0.715, v_acc: 53.1, c_acc: 53.1}\n","STEP:83, D{v_l: 0.898, v_acc: [53.1| 75.0| 64.1], c_acc: [62.5| 75.0]}  G{v_l: 0.688, v_acc: 57.8, c_acc: 51.6}\n","STEP:84, D{v_l: 1.082, v_acc: [37.5| 62.5| 50.0], c_acc: [81.2| 65.6]}  G{v_l: 0.727, v_acc: 48.4, c_acc: 57.8}\n","STEP:85, D{v_l: 1.069, v_acc: [37.5| 59.4| 48.4], c_acc: [50.0| 75.0]}  G{v_l: 0.674, v_acc: 60.9, c_acc: 53.1}\n","STEP:86, D{v_l: 0.977, v_acc: [53.1| 46.9| 50.0], c_acc: [43.8| 75.0]}  G{v_l: 0.647, v_acc: 59.4, c_acc: 43.8}\n","STEP:87, D{v_l: 1.035, v_acc: [53.1| 62.5| 57.8], c_acc: [50.0| 75.0]}  G{v_l: 0.601, v_acc: 67.2, c_acc: 54.7}\n","STEP:88, D{v_l: 1.232, v_acc: [40.6| 50.0| 45.3], c_acc: [56.2| 90.6]}  G{v_l: 0.673, v_acc: 57.8, c_acc: 54.7}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 1.9643 - valid_loss: 0.5495 - class_loss: 1.0270 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.1901 - valid_loss: 0.9325 - class_loss: 0.8699 - valid_acc: 0.0000e+00 - class_acc: 0.7529\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:89, D{v_l: 1.067, v_acc: [16.2| 53.1| 34.7], c_acc: [68.4| 78.1]}  G{v_l: 0.692, v_acc: 56.2, c_acc: 40.6}\n","STEP:90, D{v_l: 1.200, v_acc: [50.0| 62.5| 56.2], c_acc: [40.6| 71.9]}  G{v_l: 0.675, v_acc: 62.5, c_acc: 43.8}\n","STEP:91, D{v_l: 0.781, v_acc: [53.1| 62.5| 57.8], c_acc: [53.1| 84.4]}  G{v_l: 0.651, v_acc: 68.8, c_acc: 54.7}\n","STEP:92, D{v_l: 0.912, v_acc: [53.1| 43.8| 48.4], c_acc: [56.2| 84.4]}  G{v_l: 0.665, v_acc: 57.8, c_acc: 62.5}\n","STEP:93, D{v_l: 0.886, v_acc: [62.5| 43.8| 53.1], c_acc: [43.8| 75.0]}  G{v_l: 0.616, v_acc: 68.8, c_acc: 45.3}\n","STEP:94, D{v_l: 0.870, v_acc: [46.9| 59.4| 53.1], c_acc: [46.9| 87.5]}  G{v_l: 0.640, v_acc: 57.8, c_acc: 60.9}\n","STEP:95, D{v_l: 0.760, v_acc: [65.6| 68.8| 67.2], c_acc: [62.5| 87.5]}  G{v_l: 0.582, v_acc: 70.3, c_acc: 65.6}\n","STEP:96, D{v_l: 0.755, v_acc: [53.1| 78.1| 65.6], c_acc: [59.4| 75.0]}  G{v_l: 0.789, v_acc: 51.6, c_acc: 57.8}\n","STEP:97, D{v_l: 1.207, v_acc: [56.2| 37.5| 46.9], c_acc: [62.5| 84.4]}  G{v_l: 0.642, v_acc: 62.5, c_acc: 51.6}\n","STEP:98, D{v_l: 0.993, v_acc: [56.2| 75.0| 65.6], c_acc: [59.4| 75.0]}  G{v_l: 0.692, v_acc: 60.9, c_acc: 53.1}\n","STEP:99, D{v_l: 1.122, v_acc: [43.8| 59.4| 51.6], c_acc: [59.4| 84.4]}  G{v_l: 0.591, v_acc: 67.2, c_acc: 53.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8949 - valid_loss: 0.5016 - class_loss: 1.0056 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 2.2087 - valid_loss: 0.9301 - class_loss: 0.8908 - valid_acc: 0.0000e+00 - class_acc: 0.5647\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:100, D{v_l: 0.813, v_acc: [15.4| 68.8| 42.1], c_acc: [53.8| 81.2]}  G{v_l: 0.705, v_acc: 56.2, c_acc: 50.0}\n","STEP:101, D{v_l: 1.129, v_acc: [62.5| 50.0| 56.2], c_acc: [53.1| 65.6]}  G{v_l: 0.613, v_acc: 67.2, c_acc: 57.8}\n","STEP:102, D{v_l: 1.239, v_acc: [65.6| 56.2| 60.9], c_acc: [59.4| 71.9]}  G{v_l: 0.660, v_acc: 68.8, c_acc: 65.6}\n","STEP:103, D{v_l: 0.988, v_acc: [46.9| 50.0| 48.4], c_acc: [62.5| 84.4]}  G{v_l: 0.663, v_acc: 62.5, c_acc: 53.1}\n","STEP:104, D{v_l: 1.025, v_acc: [43.8| 59.4| 51.6], c_acc: [53.1| 65.6]}  G{v_l: 0.656, v_acc: 65.6, c_acc: 56.2}\n","STEP:105, D{v_l: 1.089, v_acc: [34.4| 56.2| 45.3], c_acc: [53.1| 81.2]}  G{v_l: 0.687, v_acc: 59.4, c_acc: 53.1}\n","STEP:106, D{v_l: 0.920, v_acc: [71.9| 56.2| 64.1], c_acc: [68.8| 87.5]}  G{v_l: 0.708, v_acc: 57.8, c_acc: 59.4}\n","STEP:107, D{v_l: 1.306, v_acc: [37.5| 37.5| 37.5], c_acc: [71.9| 71.9]}  G{v_l: 0.635, v_acc: 59.4, c_acc: 56.2}\n","STEP:108, D{v_l: 0.989, v_acc: [43.8| 65.6| 54.7], c_acc: [43.8| 84.4]}  G{v_l: 0.600, v_acc: 62.5, c_acc: 50.0}\n","STEP:109, D{v_l: 0.798, v_acc: [50.0| 59.4| 54.7], c_acc: [75.0| 84.4]}  G{v_l: 0.574, v_acc: 67.2, c_acc: 62.5}\n","STEP:110, D{v_l: 0.853, v_acc: [50.0| 62.5| 56.2], c_acc: [62.5| 87.5]}  G{v_l: 0.640, v_acc: 64.1, c_acc: 57.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8797 - valid_loss: 0.4697 - class_loss: 1.0222 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.9338 - valid_loss: 0.9210 - class_loss: 0.6249 - valid_acc: 0.0000e+00 - class_acc: 0.7294\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 10\n","====================================================================================================\n","STEP:111, D{v_l: 0.993, v_acc: [10.3| 56.2| 33.3], c_acc: [67.5| 87.5]}  G{v_l: 0.650, v_acc: 70.3, c_acc: 65.6}\n","STEP:112, D{v_l: 0.639, v_acc: [68.8| 71.9| 70.3], c_acc: [56.2| 87.5]}  G{v_l: 0.721, v_acc: 57.8, c_acc: 64.1}\n","STEP:113, D{v_l: 0.913, v_acc: [50.0| 62.5| 56.2], c_acc: [59.4| 81.2]}  G{v_l: 0.662, v_acc: 60.9, c_acc: 51.6}\n","STEP:114, D{v_l: 0.962, v_acc: [43.8| 71.9| 57.8], c_acc: [62.5| 93.8]}  G{v_l: 0.737, v_acc: 50.0, c_acc: 53.1}\n","STEP:115, D{v_l: 0.766, v_acc: [53.1| 65.6| 59.4], c_acc: [50.0| 81.2]}  G{v_l: 0.757, v_acc: 51.6, c_acc: 56.2}\n","STEP:116, D{v_l: 1.307, v_acc: [53.1| 50.0| 51.6], c_acc: [50.0| 78.1]}  G{v_l: 0.733, v_acc: 57.8, c_acc: 54.7}\n","STEP:117, D{v_l: 0.919, v_acc: [37.5| 71.9| 54.7], c_acc: [62.5| 87.5]}  G{v_l: 0.647, v_acc: 62.5, c_acc: 53.1}\n","STEP:118, D{v_l: 1.068, v_acc: [46.9| 53.1| 50.0], c_acc: [53.1| 78.1]}  G{v_l: 0.672, v_acc: 57.8, c_acc: 56.2}\n","STEP:119, D{v_l: 0.931, v_acc: [50.0| 59.4| 54.7], c_acc: [62.5| 84.4]}  G{v_l: 0.790, v_acc: 54.7, c_acc: 51.6}\n","STEP:120, D{v_l: 0.790, v_acc: [43.8| 75.0| 59.4], c_acc: [68.8| 81.2]}  G{v_l: 0.604, v_acc: 71.9, c_acc: 50.0}\n","STEP:121, D{v_l: 0.954, v_acc: [50.0| 53.1| 51.6], c_acc: [62.5| 78.1]}  G{v_l: 0.719, v_acc: 57.8, c_acc: 62.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 1.9219 - valid_loss: 0.5035 - class_loss: 1.0306 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 2.0012 - valid_loss: 0.8872 - class_loss: 0.7261 - valid_acc: 0.0000e+00 - class_acc: 0.7294\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:122, D{v_l: 0.946, v_acc: [14.5| 62.5| 38.5], c_acc: [70.9| 87.5]}  G{v_l: 0.803, v_acc: 53.1, c_acc: 64.1}\n","STEP:123, D{v_l: 1.228, v_acc: [50.0| 59.4| 54.7], c_acc: [68.8| 90.6]}  G{v_l: 0.692, v_acc: 65.6, c_acc: 46.9}\n","STEP:124, D{v_l: 0.818, v_acc: [43.8| 71.9| 57.8], c_acc: [59.4| 87.5]}  G{v_l: 0.625, v_acc: 62.5, c_acc: 56.2}\n","STEP:125, D{v_l: 0.823, v_acc: [62.5| 59.4| 60.9], c_acc: [68.8| 84.4]}  G{v_l: 0.713, v_acc: 53.1, c_acc: 54.7}\n","STEP:126, D{v_l: 0.806, v_acc: [50.0| 56.2| 53.1], c_acc: [59.4| 84.4]}  G{v_l: 0.738, v_acc: 51.6, c_acc: 59.4}\n","STEP:127, D{v_l: 0.788, v_acc: [62.5| 62.5| 62.5], c_acc: [46.9| 75.0]}  G{v_l: 0.792, v_acc: 51.6, c_acc: 57.8}\n","STEP:128, D{v_l: 0.809, v_acc: [56.2| 56.2| 56.2], c_acc: [59.4| 81.2]}  G{v_l: 0.740, v_acc: 60.9, c_acc: 65.6}\n","STEP:129, D{v_l: 0.775, v_acc: [56.2| 62.5| 59.4], c_acc: [65.6| 81.2]}  G{v_l: 0.743, v_acc: 45.3, c_acc: 75.0}\n","STEP:130, D{v_l: 1.079, v_acc: [37.5| 56.2| 46.9], c_acc: [53.1| 78.1]}  G{v_l: 0.796, v_acc: 53.1, c_acc: 68.8}\n","STEP:131, D{v_l: 1.156, v_acc: [50.0| 53.1| 51.6], c_acc: [59.4| 84.4]}  G{v_l: 0.684, v_acc: 62.5, c_acc: 70.3}\n","STEP:132, D{v_l: 0.660, v_acc: [68.8| 59.4| 64.1], c_acc: [50.0| 71.9]}  G{v_l: 0.743, v_acc: 54.7, c_acc: 54.7}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 1.9119 - valid_loss: 0.4917 - class_loss: 1.0323 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.9213 - valid_loss: 0.8765 - class_loss: 0.6570 - valid_acc: 0.0000e+00 - class_acc: 0.7294\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:133, D{v_l: 0.941, v_acc: [12.8| 62.5| 37.7], c_acc: [68.4| 90.6]}  G{v_l: 0.916, v_acc: 40.6, c_acc: 62.5}\n","STEP:134, D{v_l: 0.832, v_acc: [56.2| 50.0| 53.1], c_acc: [62.5| 87.5]}  G{v_l: 0.814, v_acc: 46.9, c_acc: 67.2}\n","STEP:135, D{v_l: 0.790, v_acc: [56.2| 62.5| 59.4], c_acc: [59.4| 84.4]}  G{v_l: 0.738, v_acc: 56.2, c_acc: 53.1}\n","STEP:136, D{v_l: 1.001, v_acc: [46.9| 65.6| 56.2], c_acc: [62.5| 90.6]}  G{v_l: 0.822, v_acc: 42.2, c_acc: 68.8}\n","STEP:137, D{v_l: 0.818, v_acc: [75.0| 53.1| 64.1], c_acc: [56.2| 84.4]}  G{v_l: 0.708, v_acc: 60.9, c_acc: 60.9}\n","STEP:138, D{v_l: 0.870, v_acc: [65.6| 68.8| 67.2], c_acc: [56.2| 93.8]}  G{v_l: 0.619, v_acc: 65.6, c_acc: 60.9}\n","STEP:139, D{v_l: 0.698, v_acc: [59.4| 62.5| 60.9], c_acc: [62.5| 81.2]}  G{v_l: 0.740, v_acc: 57.8, c_acc: 62.5}\n","STEP:140, D{v_l: 0.755, v_acc: [50.0| 71.9| 60.9], c_acc: [65.6| 93.8]}  G{v_l: 0.709, v_acc: 67.2, c_acc: 65.6}\n","STEP:141, D{v_l: 0.734, v_acc: [46.9| 78.1| 62.5], c_acc: [50.0| 90.6]}  G{v_l: 0.736, v_acc: 64.1, c_acc: 73.4}\n","STEP:142, D{v_l: 1.153, v_acc: [43.8| 59.4| 51.6], c_acc: [68.8| 87.5]}  G{v_l: 0.734, v_acc: 60.9, c_acc: 62.5}\n","STEP:143, D{v_l: 0.842, v_acc: [59.4| 56.2| 57.8], c_acc: [53.1| 93.8]}  G{v_l: 0.786, v_acc: 59.4, c_acc: 68.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 1.9415 - valid_loss: 0.5321 - class_loss: 1.0215 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.8414 - valid_loss: 0.8520 - class_loss: 0.6015 - valid_acc: 0.0000e+00 - class_acc: 0.6706\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:144, D{v_l: 0.845, v_acc: [11.1| 50.0| 30.6], c_acc: [65.0| 87.5]}  G{v_l: 0.755, v_acc: 51.6, c_acc: 75.0}\n","STEP:145, D{v_l: 0.858, v_acc: [46.9| 53.1| 50.0], c_acc: [68.8| 84.4]}  G{v_l: 0.902, v_acc: 51.6, c_acc: 59.4}\n","STEP:146, D{v_l: 0.857, v_acc: [43.8| 62.5| 53.1], c_acc: [65.6| 84.4]}  G{v_l: 0.910, v_acc: 43.8, c_acc: 60.9}\n","STEP:147, D{v_l: 0.811, v_acc: [62.5| 62.5| 62.5], c_acc: [65.6| 84.4]}  G{v_l: 0.908, v_acc: 46.9, c_acc: 68.8}\n","STEP:148, D{v_l: 0.991, v_acc: [50.0| 56.2| 53.1], c_acc: [62.5| 87.5]}  G{v_l: 0.869, v_acc: 48.4, c_acc: 67.2}\n","STEP:149, D{v_l: 0.754, v_acc: [43.8| 78.1| 60.9], c_acc: [59.4| 84.4]}  G{v_l: 0.746, v_acc: 60.9, c_acc: 67.2}\n","STEP:150, D{v_l: 0.900, v_acc: [50.0| 56.2| 53.1], c_acc: [62.5| 96.9]}  G{v_l: 0.799, v_acc: 62.5, c_acc: 67.2}\n","STEP:151, D{v_l: 0.728, v_acc: [59.4| 75.0| 67.2], c_acc: [53.1| 93.8]}  G{v_l: 0.818, v_acc: 48.4, c_acc: 56.2}\n","STEP:152, D{v_l: 0.974, v_acc: [59.4| 62.5| 60.9], c_acc: [62.5| 87.5]}  G{v_l: 0.895, v_acc: 51.6, c_acc: 65.6}\n","STEP:153, D{v_l: 0.701, v_acc: [50.0| 81.2| 65.6], c_acc: [56.2| 84.4]}  G{v_l: 0.642, v_acc: 75.0, c_acc: 64.1}\n","STEP:154, D{v_l: 0.706, v_acc: [50.0| 68.8| 59.4], c_acc: [65.6| 87.5]}  G{v_l: 0.829, v_acc: 51.6, c_acc: 70.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.0990 - valid_loss: 0.6025 - class_loss: 1.1086 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.7495 - valid_loss: 0.8295 - class_loss: 0.5321 - valid_acc: 0.0000e+00 - class_acc: 0.7059\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:155, D{v_l: 0.884, v_acc: [11.1| 68.8| 39.9], c_acc: [65.8| 90.6]}  G{v_l: 0.778, v_acc: 53.1, c_acc: 57.8}\n","STEP:156, D{v_l: 1.067, v_acc: [40.6| 62.5| 51.6], c_acc: [65.6| 87.5]}  G{v_l: 0.747, v_acc: 57.8, c_acc: 62.5}\n","STEP:157, D{v_l: 0.820, v_acc: [40.6| 65.6| 53.1], c_acc: [62.5| 90.6]}  G{v_l: 0.844, v_acc: 56.2, c_acc: 67.2}\n","STEP:158, D{v_l: 0.935, v_acc: [53.1| 71.9| 62.5], c_acc: [53.1| 87.5]}  G{v_l: 0.938, v_acc: 51.6, c_acc: 59.4}\n","STEP:159, D{v_l: 0.676, v_acc: [46.9| 75.0| 60.9], c_acc: [65.6| 90.6]}  G{v_l: 0.934, v_acc: 46.9, c_acc: 67.2}\n","STEP:160, D{v_l: 1.043, v_acc: [43.8| 56.2| 50.0], c_acc: [71.9| 87.5]}  G{v_l: 0.807, v_acc: 59.4, c_acc: 57.8}\n","STEP:161, D{v_l: 0.720, v_acc: [40.6| 68.8| 54.7], c_acc: [68.8| 81.2]}  G{v_l: 0.900, v_acc: 56.2, c_acc: 71.9}\n","STEP:162, D{v_l: 0.824, v_acc: [65.6| 71.9| 68.8], c_acc: [62.5| 93.8]}  G{v_l: 0.844, v_acc: 53.1, c_acc: 68.8}\n","STEP:163, D{v_l: 0.835, v_acc: [53.1| 65.6| 59.4], c_acc: [71.9| 81.2]}  G{v_l: 0.701, v_acc: 59.4, c_acc: 68.8}\n","STEP:164, D{v_l: 1.034, v_acc: [37.5| 78.1| 57.8], c_acc: [56.2| 84.4]}  G{v_l: 0.826, v_acc: 50.0, c_acc: 56.2}\n","STEP:165, D{v_l: 0.705, v_acc: [59.4| 81.2| 70.3], c_acc: [53.1| 84.4]}  G{v_l: 0.928, v_acc: 48.4, c_acc: 75.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.1339 - valid_loss: 0.6677 - class_loss: 1.0783 - valid_acc: 0.7882 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.5896 - valid_loss: 0.7357 - class_loss: 0.4660 - valid_acc: 0.3059 - class_acc: 0.7647\n","average v_acc: 54.706, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:166, D{v_l: 0.725, v_acc: [34.2| 68.8| 51.5], c_acc: [73.5| 87.5]}  G{v_l: 0.741, v_acc: 56.2, c_acc: 70.3}\n","STEP:167, D{v_l: 0.724, v_acc: [59.4| 65.6| 62.5], c_acc: [56.2| 90.6]}  G{v_l: 0.825, v_acc: 45.3, c_acc: 75.0}\n","STEP:168, D{v_l: 0.981, v_acc: [34.4| 68.8| 51.6], c_acc: [59.4| 90.6]}  G{v_l: 0.905, v_acc: 48.4, c_acc: 60.9}\n","STEP:169, D{v_l: 0.720, v_acc: [56.2| 68.8| 62.5], c_acc: [37.5| 93.8]}  G{v_l: 1.055, v_acc: 42.2, c_acc: 67.2}\n","STEP:170, D{v_l: 0.614, v_acc: [50.0| 75.0| 62.5], c_acc: [43.8| 93.8]}  G{v_l: 0.869, v_acc: 48.4, c_acc: 67.2}\n","STEP:171, D{v_l: 0.742, v_acc: [50.0| 75.0| 62.5], c_acc: [62.5| 96.9]}  G{v_l: 0.687, v_acc: 53.1, c_acc: 73.4}\n","STEP:172, D{v_l: 0.784, v_acc: [71.9| 71.9| 71.9], c_acc: [62.5| 84.4]}  G{v_l: 0.671, v_acc: 62.5, c_acc: 65.6}\n","STEP:173, D{v_l: 1.056, v_acc: [65.6| 56.2| 60.9], c_acc: [78.1| 84.4]}  G{v_l: 0.957, v_acc: 53.1, c_acc: 65.6}\n","STEP:174, D{v_l: 0.969, v_acc: [46.9| 68.8| 57.8], c_acc: [56.2| 87.5]}  G{v_l: 0.913, v_acc: 46.9, c_acc: 68.8}\n","STEP:175, D{v_l: 0.708, v_acc: [50.0| 68.8| 59.4], c_acc: [71.9| 93.8]}  G{v_l: 0.857, v_acc: 53.1, c_acc: 67.2}\n","STEP:176, D{v_l: 0.800, v_acc: [62.5| 62.5| 62.5], c_acc: [71.9| 87.5]}  G{v_l: 1.059, v_acc: 37.5, c_acc: 71.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.1721 - valid_loss: 0.6832 - class_loss: 1.1010 - valid_acc: 0.5647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.5403 - valid_loss: 0.7091 - class_loss: 0.4433 - valid_acc: 0.5529 - class_acc: 0.7529\n","average v_acc: 55.882, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:177, D{v_l: 0.872, v_acc: [59.8| 46.9| 53.4], c_acc: [73.5| 93.8]}  G{v_l: 0.787, v_acc: 51.6, c_acc: 68.8}\n","STEP:178, D{v_l: 0.858, v_acc: [34.4| 71.9| 53.1], c_acc: [62.5| 100.0]}  G{v_l: 0.909, v_acc: 54.7, c_acc: 64.1}\n","STEP:179, D{v_l: 0.663, v_acc: [50.0| 75.0| 62.5], c_acc: [65.6| 84.4]}  G{v_l: 0.798, v_acc: 59.4, c_acc: 78.1}\n","STEP:180, D{v_l: 0.765, v_acc: [65.6| 71.9| 68.8], c_acc: [59.4| 90.6]}  G{v_l: 0.857, v_acc: 45.3, c_acc: 73.4}\n","STEP:181, D{v_l: 0.879, v_acc: [50.0| 65.6| 57.8], c_acc: [56.2| 93.8]}  G{v_l: 0.699, v_acc: 53.1, c_acc: 82.8}\n","STEP:182, D{v_l: 1.020, v_acc: [37.5| 68.8| 53.1], c_acc: [71.9| 90.6]}  G{v_l: 0.710, v_acc: 62.5, c_acc: 68.8}\n","STEP:183, D{v_l: 0.630, v_acc: [46.9| 81.2| 64.1], c_acc: [59.4| 93.8]}  G{v_l: 0.913, v_acc: 54.7, c_acc: 70.3}\n","STEP:184, D{v_l: 0.913, v_acc: [46.9| 50.0| 48.4], c_acc: [56.2| 90.6]}  G{v_l: 1.111, v_acc: 37.5, c_acc: 75.0}\n","STEP:185, D{v_l: 0.749, v_acc: [50.0| 71.9| 60.9], c_acc: [71.9| 87.5]}  G{v_l: 0.962, v_acc: 50.0, c_acc: 68.8}\n","STEP:186, D{v_l: 0.720, v_acc: [59.4| 59.4| 59.4], c_acc: [62.5| 87.5]}  G{v_l: 0.967, v_acc: 45.3, c_acc: 68.8}\n","STEP:187, D{v_l: 0.905, v_acc: [40.6| 59.4| 50.0], c_acc: [59.4| 93.8]}  G{v_l: 0.759, v_acc: 59.4, c_acc: 67.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.4146 - valid_loss: 0.8000 - class_loss: 1.2267 - valid_acc: 0.0353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.4844 - valid_loss: 0.6984 - class_loss: 0.3981 - valid_acc: 0.4941 - class_acc: 0.8471\n","average v_acc: 26.471, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:188, D{v_l: 0.756, v_acc: [50.4| 68.8| 59.6], c_acc: [81.2| 93.8]}  G{v_l: 0.708, v_acc: 64.1, c_acc: 65.6}\n","STEP:189, D{v_l: 0.751, v_acc: [56.2| 62.5| 59.4], c_acc: [65.6| 93.8]}  G{v_l: 0.898, v_acc: 40.6, c_acc: 79.7}\n","STEP:190, D{v_l: 1.060, v_acc: [46.9| 68.8| 57.8], c_acc: [71.9| 87.5]}  G{v_l: 0.950, v_acc: 53.1, c_acc: 67.2}\n","STEP:191, D{v_l: 0.880, v_acc: [50.0| 53.1| 51.6], c_acc: [65.6| 100.0]}  G{v_l: 0.950, v_acc: 43.8, c_acc: 70.3}\n","STEP:192, D{v_l: 0.843, v_acc: [59.4| 62.5| 60.9], c_acc: [68.8| 90.6]}  G{v_l: 1.110, v_acc: 37.5, c_acc: 78.1}\n","STEP:193, D{v_l: 0.769, v_acc: [43.8| 78.1| 60.9], c_acc: [59.4| 90.6]}  G{v_l: 0.945, v_acc: 53.1, c_acc: 76.6}\n","STEP:194, D{v_l: 0.652, v_acc: [65.6| 68.8| 67.2], c_acc: [78.1| 100.0]}  G{v_l: 0.980, v_acc: 51.6, c_acc: 81.2}\n","STEP:195, D{v_l: 0.942, v_acc: [50.0| 78.1| 64.1], c_acc: [68.8| 93.8]}  G{v_l: 1.119, v_acc: 35.9, c_acc: 81.2}\n","STEP:196, D{v_l: 0.667, v_acc: [53.1| 75.0| 64.1], c_acc: [62.5| 90.6]}  G{v_l: 1.006, v_acc: 39.1, c_acc: 60.9}\n","STEP:197, D{v_l: 0.950, v_acc: [43.8| 65.6| 54.7], c_acc: [53.1| 100.0]}  G{v_l: 1.137, v_acc: 35.9, c_acc: 75.0}\n","STEP:198, D{v_l: 0.791, v_acc: [43.8| 65.6| 54.7], c_acc: [75.0| 84.4]}  G{v_l: 1.005, v_acc: 43.8, c_acc: 73.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.5519 - valid_loss: 0.8439 - class_loss: 1.3201 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.3981 - valid_loss: 0.6376 - class_loss: 0.3726 - valid_acc: 0.8000 - class_acc: 0.7765\n","average v_acc: 40.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:199, D{v_l: 0.719, v_acc: [71.8| 75.0| 73.4], c_acc: [75.2| 93.8]}  G{v_l: 0.986, v_acc: 45.3, c_acc: 75.0}\n","STEP:200, D{v_l: 0.588, v_acc: [62.5| 78.1| 70.3], c_acc: [59.4| 96.9]}  G{v_l: 0.841, v_acc: 54.7, c_acc: 76.6}\n","STEP:201, D{v_l: 0.804, v_acc: [56.2| 62.5| 59.4], c_acc: [56.2| 96.9]}  G{v_l: 0.895, v_acc: 53.1, c_acc: 67.2}\n","STEP:202, D{v_l: 0.969, v_acc: [53.1| 65.6| 59.4], c_acc: [65.6| 90.6]}  G{v_l: 1.035, v_acc: 40.6, c_acc: 75.0}\n","STEP:203, D{v_l: 0.832, v_acc: [53.1| 71.9| 62.5], c_acc: [53.1| 93.8]}  G{v_l: 1.132, v_acc: 39.1, c_acc: 73.4}\n","STEP:204, D{v_l: 0.785, v_acc: [59.4| 65.6| 62.5], c_acc: [53.1| 96.9]}  G{v_l: 0.941, v_acc: 50.0, c_acc: 76.6}\n","STEP:205, D{v_l: 0.737, v_acc: [43.8| 71.9| 57.8], c_acc: [53.1| 96.9]}  G{v_l: 1.137, v_acc: 32.8, c_acc: 73.4}\n","STEP:206, D{v_l: 0.825, v_acc: [50.0| 78.1| 64.1], c_acc: [68.8| 90.6]}  G{v_l: 0.767, v_acc: 53.1, c_acc: 76.6}\n","STEP:207, D{v_l: 0.828, v_acc: [34.4| 65.6| 50.0], c_acc: [59.4| 93.8]}  G{v_l: 1.011, v_acc: 54.7, c_acc: 82.8}\n","STEP:208, D{v_l: 0.844, v_acc: [50.0| 68.8| 59.4], c_acc: [53.1| 87.5]}  G{v_l: 0.924, v_acc: 56.2, c_acc: 71.9}\n","STEP:209, D{v_l: 0.638, v_acc: [53.1| 71.9| 62.5], c_acc: [65.6| 93.8]}  G{v_l: 1.038, v_acc: 37.5, c_acc: 78.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.4676 - valid_loss: 0.8116 - class_loss: 1.2680 - valid_acc: 0.0118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 1.4201 - valid_loss: 0.6464 - class_loss: 0.3857 - valid_acc: 0.6941 - class_acc: 0.7412\n","average v_acc: 35.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:210, D{v_l: 0.537, v_acc: [65.0| 75.0| 70.0], c_acc: [76.1| 93.8]}  G{v_l: 1.178, v_acc: 23.4, c_acc: 70.3}\n","STEP:211, D{v_l: 0.786, v_acc: [53.1| 68.8| 60.9], c_acc: [68.8| 90.6]}  G{v_l: 1.058, v_acc: 45.3, c_acc: 75.0}\n","STEP:212, D{v_l: 0.838, v_acc: [43.8| 68.8| 56.2], c_acc: [71.9| 93.8]}  G{v_l: 1.014, v_acc: 54.7, c_acc: 81.2}\n","STEP:213, D{v_l: 0.821, v_acc: [37.5| 81.2| 59.4], c_acc: [62.5| 96.9]}  G{v_l: 1.125, v_acc: 39.1, c_acc: 79.7}\n","STEP:214, D{v_l: 0.735, v_acc: [53.1| 78.1| 65.6], c_acc: [75.0| 87.5]}  G{v_l: 0.883, v_acc: 50.0, c_acc: 81.2}\n","STEP:215, D{v_l: 0.737, v_acc: [40.6| 78.1| 59.4], c_acc: [62.5| 100.0]}  G{v_l: 1.042, v_acc: 46.9, c_acc: 78.1}\n","STEP:216, D{v_l: 0.674, v_acc: [71.9| 59.4| 65.6], c_acc: [62.5| 93.8]}  G{v_l: 1.007, v_acc: 46.9, c_acc: 82.8}\n","STEP:217, D{v_l: 0.751, v_acc: [40.6| 75.0| 57.8], c_acc: [84.4| 96.9]}  G{v_l: 0.985, v_acc: 40.6, c_acc: 81.2}\n","STEP:218, D{v_l: 0.771, v_acc: [50.0| 75.0| 62.5], c_acc: [71.9| 90.6]}  G{v_l: 1.133, v_acc: 48.4, c_acc: 73.4}\n","STEP:219, D{v_l: 0.562, v_acc: [59.4| 81.2| 70.3], c_acc: [71.9| 90.6]}  G{v_l: 0.950, v_acc: 50.0, c_acc: 87.5}\n","STEP:220, D{v_l: 0.788, v_acc: [50.0| 68.8| 59.4], c_acc: [78.1| 96.9]}  G{v_l: 1.021, v_acc: 50.0, c_acc: 70.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.3683 - valid_loss: 0.7159 - class_loss: 1.2645 - valid_acc: 0.3647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.3233 - valid_loss: 0.6955 - class_loss: 0.2398 - valid_acc: 0.3294 - class_acc: 0.9647\n","average v_acc: 34.706, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 20\n","====================================================================================================\n","STEP:221, D{v_l: 0.551, v_acc: [43.6| 81.2| 62.4], c_acc: [85.5| 96.9]}  G{v_l: 1.067, v_acc: 56.2, c_acc: 76.6}\n","STEP:222, D{v_l: 0.657, v_acc: [46.9| 62.5| 54.7], c_acc: [71.9| 100.0]}  G{v_l: 1.031, v_acc: 43.8, c_acc: 82.8}\n","STEP:223, D{v_l: 0.658, v_acc: [46.9| 71.9| 59.4], c_acc: [71.9| 93.8]}  G{v_l: 1.075, v_acc: 43.8, c_acc: 78.1}\n","STEP:224, D{v_l: 0.893, v_acc: [40.6| 65.6| 53.1], c_acc: [75.0| 100.0]}  G{v_l: 0.834, v_acc: 57.8, c_acc: 85.9}\n","STEP:225, D{v_l: 0.778, v_acc: [75.0| 56.2| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 0.821, v_acc: 64.1, c_acc: 82.8}\n","STEP:226, D{v_l: 0.674, v_acc: [59.4| 78.1| 68.8], c_acc: [78.1| 100.0]}  G{v_l: 1.138, v_acc: 45.3, c_acc: 78.1}\n","STEP:227, D{v_l: 0.748, v_acc: [65.6| 81.2| 73.4], c_acc: [68.8| 87.5]}  G{v_l: 0.805, v_acc: 57.8, c_acc: 81.2}\n","STEP:228, D{v_l: 0.858, v_acc: [53.1| 71.9| 62.5], c_acc: [65.6| 93.8]}  G{v_l: 1.132, v_acc: 46.9, c_acc: 75.0}\n","STEP:229, D{v_l: 0.802, v_acc: [59.4| 59.4| 59.4], c_acc: [75.0| 93.8]}  G{v_l: 0.951, v_acc: 50.0, c_acc: 82.8}\n","STEP:230, D{v_l: 0.660, v_acc: [56.2| 81.2| 68.8], c_acc: [75.0| 90.6]}  G{v_l: 1.145, v_acc: 42.2, c_acc: 79.7}\n","STEP:231, D{v_l: 0.692, v_acc: [43.8| 96.9| 70.3], c_acc: [53.1| 96.9]}  G{v_l: 0.818, v_acc: 56.2, c_acc: 71.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.2471 - valid_loss: 0.6820 - class_loss: 1.1772 - valid_acc: 0.6118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.3583 - valid_loss: 0.7035 - class_loss: 0.2670 - valid_acc: 0.4118 - class_acc: 0.8471\n","average v_acc: 51.176, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:232, D{v_l: 0.736, v_acc: [43.6| 68.8| 56.2], c_acc: [82.1| 93.8]}  G{v_l: 0.966, v_acc: 51.6, c_acc: 76.6}\n","STEP:233, D{v_l: 0.879, v_acc: [59.4| 71.9| 65.6], c_acc: [59.4| 87.5]}  G{v_l: 1.084, v_acc: 43.8, c_acc: 78.1}\n","STEP:234, D{v_l: 0.788, v_acc: [56.2| 71.9| 64.1], c_acc: [68.8| 96.9]}  G{v_l: 0.878, v_acc: 48.4, c_acc: 79.7}\n","STEP:235, D{v_l: 0.849, v_acc: [65.6| 56.2| 60.9], c_acc: [78.1| 100.0]}  G{v_l: 0.949, v_acc: 50.0, c_acc: 78.1}\n","STEP:236, D{v_l: 0.709, v_acc: [56.2| 78.1| 67.2], c_acc: [75.0| 100.0]}  G{v_l: 0.919, v_acc: 51.6, c_acc: 73.4}\n","STEP:237, D{v_l: 0.887, v_acc: [53.1| 68.8| 60.9], c_acc: [62.5| 90.6]}  G{v_l: 0.906, v_acc: 51.6, c_acc: 84.4}\n","STEP:238, D{v_l: 0.749, v_acc: [43.8| 68.8| 56.2], c_acc: [68.8| 100.0]}  G{v_l: 1.143, v_acc: 53.1, c_acc: 81.2}\n","STEP:239, D{v_l: 0.845, v_acc: [50.0| 68.8| 59.4], c_acc: [65.6| 93.8]}  G{v_l: 0.749, v_acc: 59.4, c_acc: 87.5}\n","STEP:240, D{v_l: 0.758, v_acc: [43.8| 68.8| 56.2], c_acc: [59.4| 90.6]}  G{v_l: 0.963, v_acc: 50.0, c_acc: 81.2}\n","STEP:241, D{v_l: 0.762, v_acc: [62.5| 62.5| 62.5], c_acc: [84.4| 87.5]}  G{v_l: 0.739, v_acc: 62.5, c_acc: 84.4}\n","STEP:242, D{v_l: 0.835, v_acc: [59.4| 71.9| 65.6], c_acc: [71.9| 93.8]}  G{v_l: 0.921, v_acc: 50.0, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.4713 - valid_loss: 0.7425 - class_loss: 1.3409 - valid_acc: 0.3882 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.3266 - valid_loss: 0.6957 - class_loss: 0.2430 - valid_acc: 0.4000 - class_acc: 0.9529\n","average v_acc: 39.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:243, D{v_l: 0.886, v_acc: [42.7| 62.5| 52.6], c_acc: [88.0| 96.9]}  G{v_l: 1.090, v_acc: 43.8, c_acc: 84.4}\n","STEP:244, D{v_l: 0.603, v_acc: [62.5| 75.0| 68.8], c_acc: [62.5| 93.8]}  G{v_l: 0.996, v_acc: 48.4, c_acc: 85.9}\n","STEP:245, D{v_l: 0.528, v_acc: [68.8| 87.5| 78.1], c_acc: [65.6| 96.9]}  G{v_l: 1.120, v_acc: 48.4, c_acc: 84.4}\n","STEP:246, D{v_l: 0.920, v_acc: [43.8| 59.4| 51.6], c_acc: [75.0| 96.9]}  G{v_l: 0.975, v_acc: 50.0, c_acc: 84.4}\n","STEP:247, D{v_l: 0.531, v_acc: [65.6| 81.2| 73.4], c_acc: [75.0| 87.5]}  G{v_l: 1.130, v_acc: 40.6, c_acc: 82.8}\n","STEP:248, D{v_l: 0.825, v_acc: [43.8| 68.8| 56.2], c_acc: [65.6| 96.9]}  G{v_l: 0.919, v_acc: 56.2, c_acc: 87.5}\n","STEP:249, D{v_l: 0.849, v_acc: [59.4| 59.4| 59.4], c_acc: [65.6| 96.9]}  G{v_l: 1.098, v_acc: 46.9, c_acc: 81.2}\n","STEP:250, D{v_l: 0.825, v_acc: [56.2| 62.5| 59.4], c_acc: [68.8| 100.0]}  G{v_l: 0.900, v_acc: 51.6, c_acc: 92.2}\n","STEP:251, D{v_l: 0.805, v_acc: [81.2| 68.8| 75.0], c_acc: [65.6| 87.5]}  G{v_l: 0.962, v_acc: 43.8, c_acc: 79.7}\n","STEP:252, D{v_l: 0.805, v_acc: [56.2| 71.9| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 0.897, v_acc: 46.9, c_acc: 82.8}\n","STEP:253, D{v_l: 0.688, v_acc: [71.9| 75.0| 73.4], c_acc: [78.1| 96.9]}  G{v_l: 1.029, v_acc: 48.4, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.5333 - valid_loss: 0.7218 - class_loss: 1.4236 - valid_acc: 0.5059 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.2506 - valid_loss: 0.6551 - class_loss: 0.2076 - valid_acc: 0.4000 - class_acc: 0.9059\n","average v_acc: 45.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:254, D{v_l: 0.685, v_acc: [41.0| 71.9| 56.5], c_acc: [83.8| 100.0]}  G{v_l: 0.880, v_acc: 48.4, c_acc: 84.4}\n","STEP:255, D{v_l: 1.002, v_acc: [53.1| 71.9| 62.5], c_acc: [78.1| 96.9]}  G{v_l: 1.013, v_acc: 48.4, c_acc: 85.9}\n","STEP:256, D{v_l: 0.813, v_acc: [46.9| 71.9| 59.4], c_acc: [71.9| 96.9]}  G{v_l: 1.062, v_acc: 51.6, c_acc: 92.2}\n","STEP:257, D{v_l: 0.710, v_acc: [40.6| 87.5| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 0.921, v_acc: 50.0, c_acc: 82.8}\n","STEP:258, D{v_l: 1.020, v_acc: [43.8| 62.5| 53.1], c_acc: [75.0| 100.0]}  G{v_l: 0.885, v_acc: 56.2, c_acc: 84.4}\n","STEP:259, D{v_l: 0.709, v_acc: [53.1| 84.4| 68.8], c_acc: [68.8| 100.0]}  G{v_l: 0.767, v_acc: 57.8, c_acc: 82.8}\n","STEP:260, D{v_l: 0.757, v_acc: [56.2| 75.0| 65.6], c_acc: [56.2| 96.9]}  G{v_l: 1.011, v_acc: 48.4, c_acc: 87.5}\n","STEP:261, D{v_l: 0.494, v_acc: [62.5| 75.0| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 1.091, v_acc: 43.8, c_acc: 87.5}\n","STEP:262, D{v_l: 0.717, v_acc: [46.9| 75.0| 60.9], c_acc: [84.4| 96.9]}  G{v_l: 1.004, v_acc: 46.9, c_acc: 85.9}\n","STEP:263, D{v_l: 0.659, v_acc: [68.8| 71.9| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 0.878, v_acc: 50.0, c_acc: 89.1}\n","STEP:264, D{v_l: 0.584, v_acc: [68.8| 81.2| 75.0], c_acc: [75.0| 96.9]}  G{v_l: 1.010, v_acc: 60.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.2380 - valid_loss: 0.6514 - class_loss: 1.1987 - valid_acc: 0.7647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.2115 - valid_loss: 0.6481 - class_loss: 0.1756 - valid_acc: 0.5529 - class_acc: 0.9294\n","average v_acc: 65.882, three class acc: 52.941, two class acc: 54.118\n","====================================================================================================\n","STEP:265, D{v_l: 0.601, v_acc: [55.6| 78.1| 66.8], c_acc: [87.2| 96.9]}  G{v_l: 0.789, v_acc: 59.4, c_acc: 84.4}\n","STEP:266, D{v_l: 0.849, v_acc: [53.1| 75.0| 64.1], c_acc: [68.8| 96.9]}  G{v_l: 0.935, v_acc: 53.1, c_acc: 82.8}\n","STEP:267, D{v_l: 0.943, v_acc: [59.4| 56.2| 57.8], c_acc: [75.0| 90.6]}  G{v_l: 1.149, v_acc: 48.4, c_acc: 82.8}\n","STEP:268, D{v_l: 0.708, v_acc: [59.4| 81.2| 70.3], c_acc: [71.9| 100.0]}  G{v_l: 1.172, v_acc: 46.9, c_acc: 92.2}\n","STEP:269, D{v_l: 0.656, v_acc: [56.2| 71.9| 64.1], c_acc: [81.2| 96.9]}  G{v_l: 0.920, v_acc: 53.1, c_acc: 89.1}\n","STEP:270, D{v_l: 0.830, v_acc: [50.0| 59.4| 54.7], c_acc: [78.1| 96.9]}  G{v_l: 0.926, v_acc: 51.6, c_acc: 87.5}\n","STEP:271, D{v_l: 0.768, v_acc: [46.9| 65.6| 56.2], c_acc: [71.9| 100.0]}  G{v_l: 0.902, v_acc: 57.8, c_acc: 85.9}\n","STEP:272, D{v_l: 0.785, v_acc: [59.4| 90.6| 75.0], c_acc: [65.6| 100.0]}  G{v_l: 1.029, v_acc: 48.4, c_acc: 89.1}\n","STEP:273, D{v_l: 0.604, v_acc: [65.6| 84.4| 75.0], c_acc: [81.2| 90.6]}  G{v_l: 0.957, v_acc: 57.8, c_acc: 90.6}\n","STEP:274, D{v_l: 0.605, v_acc: [78.1| 71.9| 75.0], c_acc: [75.0| 90.6]}  G{v_l: 0.826, v_acc: 62.5, c_acc: 92.2}\n","STEP:275, D{v_l: 0.634, v_acc: [65.6| 65.6| 65.6], c_acc: [59.4| 93.8]}  G{v_l: 1.133, v_acc: 43.8, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.1449 - valid_loss: 0.6393 - class_loss: 1.1178 - valid_acc: 0.7765 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.2204 - valid_loss: 0.7144 - class_loss: 0.1181 - valid_acc: 0.3529 - class_acc: 0.9882\n","average v_acc: 56.471, three class acc: 52.941, two class acc: 55.294\n","====================================================================================================\n","STEP:276, D{v_l: 0.573, v_acc: [42.7| 78.1| 60.4], c_acc: [93.2| 96.9]}  G{v_l: 1.048, v_acc: 54.7, c_acc: 87.5}\n","STEP:277, D{v_l: 0.628, v_acc: [56.2| 81.2| 68.8], c_acc: [65.6| 96.9]}  G{v_l: 0.980, v_acc: 43.8, c_acc: 92.2}\n","STEP:278, D{v_l: 0.787, v_acc: [56.2| 71.9| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 0.729, v_acc: 56.2, c_acc: 92.2}\n","STEP:279, D{v_l: 0.884, v_acc: [65.6| 68.8| 67.2], c_acc: [71.9| 90.6]}  G{v_l: 0.806, v_acc: 56.2, c_acc: 90.6}\n","STEP:280, D{v_l: 0.707, v_acc: [56.2| 68.8| 62.5], c_acc: [65.6| 96.9]}  G{v_l: 0.951, v_acc: 46.9, c_acc: 92.2}\n","STEP:281, D{v_l: 0.722, v_acc: [43.8| 84.4| 64.1], c_acc: [68.8| 90.6]}  G{v_l: 0.960, v_acc: 57.8, c_acc: 90.6}\n","STEP:282, D{v_l: 0.605, v_acc: [65.6| 78.1| 71.9], c_acc: [68.8| 96.9]}  G{v_l: 0.935, v_acc: 50.0, c_acc: 95.3}\n","STEP:283, D{v_l: 0.665, v_acc: [62.5| 62.5| 62.5], c_acc: [68.8| 100.0]}  G{v_l: 0.807, v_acc: 60.9, c_acc: 95.3}\n","STEP:284, D{v_l: 0.568, v_acc: [65.6| 65.6| 65.6], c_acc: [71.9| 100.0]}  G{v_l: 0.926, v_acc: 54.7, c_acc: 89.1}\n","STEP:285, D{v_l: 0.548, v_acc: [65.6| 81.2| 73.4], c_acc: [81.2| 93.8]}  G{v_l: 1.055, v_acc: 53.1, c_acc: 92.2}\n","STEP:286, D{v_l: 0.511, v_acc: [68.8| 90.6| 79.7], c_acc: [71.9| 90.6]}  G{v_l: 0.974, v_acc: 50.0, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.3944 - valid_loss: 0.7845 - class_loss: 1.2221 - valid_acc: 0.3412 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.2080 - valid_loss: 0.7554 - class_loss: 0.0648 - valid_acc: 0.3294 - class_acc: 1.0000\n","average v_acc: 33.529, three class acc: 52.941, two class acc: 56.471\n","====================================================================================================\n","STEP:287, D{v_l: 0.865, v_acc: [40.2| 68.8| 54.5], c_acc: [92.3| 100.0]}  G{v_l: 0.731, v_acc: 67.2, c_acc: 98.4}\n","STEP:288, D{v_l: 0.680, v_acc: [53.1| 84.4| 68.8], c_acc: [68.8| 100.0]}  G{v_l: 1.196, v_acc: 46.9, c_acc: 96.9}\n","STEP:289, D{v_l: 0.668, v_acc: [53.1| 75.0| 64.1], c_acc: [78.1| 96.9]}  G{v_l: 0.631, v_acc: 71.9, c_acc: 87.5}\n","STEP:290, D{v_l: 0.677, v_acc: [62.5| 84.4| 73.4], c_acc: [81.2| 96.9]}  G{v_l: 1.164, v_acc: 51.6, c_acc: 98.4}\n","STEP:291, D{v_l: 0.639, v_acc: [62.5| 84.4| 73.4], c_acc: [71.9| 90.6]}  G{v_l: 1.328, v_acc: 37.5, c_acc: 96.9}\n","STEP:292, D{v_l: 0.762, v_acc: [50.0| 75.0| 62.5], c_acc: [53.1| 96.9]}  G{v_l: 1.084, v_acc: 48.4, c_acc: 95.3}\n","STEP:293, D{v_l: 0.678, v_acc: [71.9| 81.2| 76.6], c_acc: [78.1| 96.9]}  G{v_l: 1.256, v_acc: 45.3, c_acc: 95.3}\n","STEP:294, D{v_l: 0.607, v_acc: [71.9| 62.5| 67.2], c_acc: [84.4| 100.0]}  G{v_l: 0.952, v_acc: 50.0, c_acc: 89.1}\n","STEP:295, D{v_l: 0.721, v_acc: [62.5| 78.1| 70.3], c_acc: [81.2| 96.9]}  G{v_l: 1.089, v_acc: 46.9, c_acc: 95.3}\n","STEP:296, D{v_l: 0.684, v_acc: [68.8| 71.9| 70.3], c_acc: [65.6| 96.9]}  G{v_l: 1.094, v_acc: 56.2, c_acc: 95.3}\n","STEP:297, D{v_l: 0.595, v_acc: [68.8| 78.1| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 1.055, v_acc: 53.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 2.2184 - valid_loss: 0.7249 - class_loss: 1.1058 - valid_acc: 0.4824 - class_acc: 0.5647\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0870 - valid_loss: 0.6433 - class_loss: 0.0559 - valid_acc: 0.5176 - class_acc: 1.0000\n","average v_acc: 50.000, three class acc: 56.471, two class acc: 61.176\n","====================================================================================================\n","STEP:298, D{v_l: 0.606, v_acc: [57.3| 71.9| 64.6], c_acc: [91.5| 96.9]}  G{v_l: 1.030, v_acc: 40.6, c_acc: 90.6}\n","STEP:299, D{v_l: 0.731, v_acc: [75.0| 68.8| 71.9], c_acc: [81.2| 96.9]}  G{v_l: 0.960, v_acc: 59.4, c_acc: 92.2}\n","STEP:300, D{v_l: 0.680, v_acc: [71.9| 75.0| 73.4], c_acc: [81.2| 100.0]}  G{v_l: 0.907, v_acc: 53.1, c_acc: 93.8}\n","STEP:301, D{v_l: 0.704, v_acc: [62.5| 75.0| 68.8], c_acc: [87.5| 100.0]}  G{v_l: 1.091, v_acc: 48.4, c_acc: 93.8}\n","STEP:302, D{v_l: 0.663, v_acc: [62.5| 75.0| 68.8], c_acc: [75.0| 100.0]}  G{v_l: 0.987, v_acc: 54.7, c_acc: 100.0}\n","STEP:303, D{v_l: 0.584, v_acc: [65.6| 68.8| 67.2], c_acc: [75.0| 93.8]}  G{v_l: 0.898, v_acc: 54.7, c_acc: 92.2}\n","STEP:304, D{v_l: 0.710, v_acc: [65.6| 68.8| 67.2], c_acc: [75.0| 93.8]}  G{v_l: 0.903, v_acc: 51.6, c_acc: 95.3}\n","STEP:305, D{v_l: 0.549, v_acc: [65.6| 78.1| 71.9], c_acc: [84.4| 93.8]}  G{v_l: 0.903, v_acc: 50.0, c_acc: 95.3}\n","STEP:306, D{v_l: 0.654, v_acc: [71.9| 65.6| 68.8], c_acc: [75.0| 100.0]}  G{v_l: 0.986, v_acc: 45.3, c_acc: 95.3}\n","STEP:307, D{v_l: 0.603, v_acc: [65.6| 75.0| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 1.040, v_acc: 43.8, c_acc: 96.9}\n","STEP:308, D{v_l: 0.876, v_acc: [50.0| 68.8| 59.4], c_acc: [90.6| 93.8]}  G{v_l: 1.018, v_acc: 50.0, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.2659 - valid_loss: 0.7294 - class_loss: 1.1487 - valid_acc: 0.4235 - class_acc: 0.5529\n","3/3 [==============================] - 0s 44ms/step - loss: 1.1683 - valid_loss: 0.7042 - class_loss: 0.0763 - valid_acc: 0.5176 - class_acc: 1.0000\n","average v_acc: 47.059, three class acc: 55.294, two class acc: 62.353\n","====================================================================================================\n","STEP:309, D{v_l: 0.586, v_acc: [53.0| 81.2| 67.1], c_acc: [90.6| 100.0]}  G{v_l: 0.920, v_acc: 59.4, c_acc: 96.9}\n","STEP:310, D{v_l: 0.576, v_acc: [62.5| 78.1| 70.3], c_acc: [78.1| 96.9]}  G{v_l: 0.869, v_acc: 54.7, c_acc: 93.8}\n","STEP:311, D{v_l: 0.546, v_acc: [65.6| 87.5| 76.6], c_acc: [68.8| 96.9]}  G{v_l: 0.817, v_acc: 57.8, c_acc: 89.1}\n","STEP:312, D{v_l: 0.537, v_acc: [78.1| 71.9| 75.0], c_acc: [71.9| 100.0]}  G{v_l: 1.364, v_acc: 42.2, c_acc: 95.3}\n","STEP:313, D{v_l: 0.563, v_acc: [56.2| 75.0| 65.6], c_acc: [90.6| 100.0]}  G{v_l: 0.948, v_acc: 53.1, c_acc: 93.8}\n","STEP:314, D{v_l: 0.576, v_acc: [53.1| 78.1| 65.6], c_acc: [81.2| 96.9]}  G{v_l: 1.075, v_acc: 50.0, c_acc: 95.3}\n","STEP:315, D{v_l: 0.774, v_acc: [59.4| 56.2| 57.8], c_acc: [84.4| 100.0]}  G{v_l: 0.965, v_acc: 51.6, c_acc: 93.8}\n","STEP:316, D{v_l: 0.597, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 90.6]}  G{v_l: 1.165, v_acc: 43.8, c_acc: 98.4}\n","STEP:317, D{v_l: 1.020, v_acc: [53.1| 53.1| 53.1], c_acc: [59.4| 93.8]}  G{v_l: 1.042, v_acc: 50.0, c_acc: 93.8}\n","STEP:318, D{v_l: 0.543, v_acc: [68.8| 84.4| 76.6], c_acc: [68.8| 93.8]}  G{v_l: 1.190, v_acc: 51.6, c_acc: 90.6}\n","STEP:319, D{v_l: 0.563, v_acc: [50.0| 81.2| 65.6], c_acc: [62.5| 93.8]}  G{v_l: 1.020, v_acc: 46.9, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.2786 - valid_loss: 0.7509 - class_loss: 1.1399 - valid_acc: 0.3412 - class_acc: 0.5529\n","3/3 [==============================] - 0s 43ms/step - loss: 1.1877 - valid_loss: 0.7538 - class_loss: 0.0461 - valid_acc: 0.3647 - class_acc: 1.0000\n","average v_acc: 35.294, three class acc: 55.294, two class acc: 64.706\n","====================================================================================================\n","STEP:320, D{v_l: 0.650, v_acc: [42.7| 68.8| 55.7], c_acc: [90.6| 100.0]}  G{v_l: 1.196, v_acc: 42.2, c_acc: 90.6}\n","STEP:321, D{v_l: 0.477, v_acc: [62.5| 84.4| 73.4], c_acc: [81.2| 96.9]}  G{v_l: 1.064, v_acc: 43.8, c_acc: 95.3}\n","STEP:322, D{v_l: 0.650, v_acc: [62.5| 68.8| 65.6], c_acc: [87.5| 100.0]}  G{v_l: 0.791, v_acc: 62.5, c_acc: 89.1}\n","STEP:323, D{v_l: 0.717, v_acc: [62.5| 78.1| 70.3], c_acc: [75.0| 100.0]}  G{v_l: 1.073, v_acc: 43.8, c_acc: 96.9}\n","STEP:324, D{v_l: 0.715, v_acc: [65.6| 68.8| 67.2], c_acc: [68.8| 100.0]}  G{v_l: 1.028, v_acc: 54.7, c_acc: 95.3}\n","STEP:325, D{v_l: 0.761, v_acc: [62.5| 65.6| 64.1], c_acc: [84.4| 96.9]}  G{v_l: 0.977, v_acc: 50.0, c_acc: 98.4}\n","STEP:326, D{v_l: 0.879, v_acc: [56.2| 62.5| 59.4], c_acc: [84.4| 93.8]}  G{v_l: 0.969, v_acc: 57.8, c_acc: 95.3}\n","STEP:327, D{v_l: 0.681, v_acc: [59.4| 56.2| 57.8], c_acc: [65.6| 100.0]}  G{v_l: 1.032, v_acc: 42.2, c_acc: 92.2}\n","STEP:328, D{v_l: 0.565, v_acc: [53.1| 81.2| 67.2], c_acc: [78.1| 96.9]}  G{v_l: 0.966, v_acc: 62.5, c_acc: 95.3}\n","STEP:329, D{v_l: 0.763, v_acc: [59.4| 84.4| 71.9], c_acc: [62.5| 93.8]}  G{v_l: 1.108, v_acc: 46.9, c_acc: 85.9}\n","STEP:330, D{v_l: 0.794, v_acc: [59.4| 65.6| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 1.131, v_acc: 46.9, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.2718 - valid_loss: 0.7106 - class_loss: 1.1734 - valid_acc: 0.5412 - class_acc: 0.5765\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1313 - valid_loss: 0.6805 - class_loss: 0.0631 - valid_acc: 0.4941 - class_acc: 1.0000\n","average v_acc: 51.765, three class acc: 57.647, two class acc: 62.353\n","====================================================================================================\n","Epoch: 30\n","====================================================================================================\n","STEP:331, D{v_l: 0.607, v_acc: [56.4| 75.0| 65.7], c_acc: [96.6| 96.9]}  G{v_l: 1.064, v_acc: 51.6, c_acc: 92.2}\n","STEP:332, D{v_l: 0.690, v_acc: [59.4| 71.9| 65.6], c_acc: [75.0| 100.0]}  G{v_l: 1.405, v_acc: 40.6, c_acc: 92.2}\n","STEP:333, D{v_l: 0.521, v_acc: [75.0| 78.1| 76.6], c_acc: [65.6| 96.9]}  G{v_l: 1.189, v_acc: 56.2, c_acc: 95.3}\n","STEP:334, D{v_l: 0.592, v_acc: [53.1| 75.0| 64.1], c_acc: [78.1| 100.0]}  G{v_l: 1.075, v_acc: 45.3, c_acc: 96.9}\n","STEP:335, D{v_l: 0.646, v_acc: [65.6| 75.0| 70.3], c_acc: [78.1| 100.0]}  G{v_l: 1.026, v_acc: 48.4, c_acc: 96.9}\n","STEP:336, D{v_l: 0.586, v_acc: [62.5| 71.9| 67.2], c_acc: [68.8| 90.6]}  G{v_l: 0.783, v_acc: 56.2, c_acc: 93.8}\n","STEP:337, D{v_l: 0.896, v_acc: [59.4| 62.5| 60.9], c_acc: [71.9| 90.6]}  G{v_l: 0.983, v_acc: 59.4, c_acc: 89.1}\n","STEP:338, D{v_l: 0.582, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 1.161, v_acc: 40.6, c_acc: 95.3}\n","STEP:339, D{v_l: 0.532, v_acc: [59.4| 84.4| 71.9], c_acc: [75.0| 96.9]}  G{v_l: 1.067, v_acc: 53.1, c_acc: 92.2}\n","STEP:340, D{v_l: 0.669, v_acc: [71.9| 68.8| 70.3], c_acc: [84.4| 100.0]}  G{v_l: 0.754, v_acc: 65.6, c_acc: 87.5}\n","STEP:341, D{v_l: 0.519, v_acc: [68.8| 84.4| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 1.147, v_acc: 37.5, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.5633 - valid_loss: 0.8517 - class_loss: 1.3239 - valid_acc: 0.3882 - class_acc: 0.5412\n","3/3 [==============================] - 0s 48ms/step - loss: 1.2933 - valid_loss: 0.7782 - class_loss: 0.1274 - valid_acc: 0.3882 - class_acc: 0.9882\n","average v_acc: 38.824, three class acc: 54.118, two class acc: 58.824\n","====================================================================================================\n","STEP:342, D{v_l: 0.574, v_acc: [46.2| 81.2| 63.7], c_acc: [91.5| 96.9]}  G{v_l: 1.094, v_acc: 54.7, c_acc: 93.8}\n","STEP:343, D{v_l: 0.689, v_acc: [43.8| 84.4| 64.1], c_acc: [71.9| 93.8]}  G{v_l: 1.272, v_acc: 39.1, c_acc: 95.3}\n","STEP:344, D{v_l: 0.552, v_acc: [59.4| 93.8| 76.6], c_acc: [87.5| 100.0]}  G{v_l: 0.975, v_acc: 45.3, c_acc: 95.3}\n","STEP:345, D{v_l: 0.707, v_acc: [56.2| 78.1| 67.2], c_acc: [68.8| 90.6]}  G{v_l: 1.009, v_acc: 56.2, c_acc: 85.9}\n","STEP:346, D{v_l: 0.658, v_acc: [50.0| 71.9| 60.9], c_acc: [71.9| 100.0]}  G{v_l: 1.061, v_acc: 59.4, c_acc: 81.2}\n","STEP:347, D{v_l: 0.644, v_acc: [56.2| 84.4| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 1.194, v_acc: 50.0, c_acc: 85.9}\n","STEP:348, D{v_l: 0.779, v_acc: [53.1| 65.6| 59.4], c_acc: [75.0| 93.8]}  G{v_l: 1.070, v_acc: 42.2, c_acc: 95.3}\n","STEP:349, D{v_l: 0.620, v_acc: [68.8| 84.4| 76.6], c_acc: [68.8| 96.9]}  G{v_l: 0.994, v_acc: 43.8, c_acc: 93.8}\n","STEP:350, D{v_l: 0.696, v_acc: [65.6| 68.8| 67.2], c_acc: [65.6| 96.9]}  G{v_l: 1.048, v_acc: 50.0, c_acc: 92.2}\n","STEP:351, D{v_l: 0.642, v_acc: [62.5| 68.8| 65.6], c_acc: [87.5| 100.0]}  G{v_l: 1.247, v_acc: 48.4, c_acc: 89.1}\n","STEP:352, D{v_l: 0.725, v_acc: [53.1| 78.1| 65.6], c_acc: [68.8| 100.0]}  G{v_l: 1.156, v_acc: 51.6, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.0383 - valid_loss: 0.9855 - class_loss: 1.6651 - valid_acc: 0.1765 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.2338 - valid_loss: 0.7877 - class_loss: 0.0584 - valid_acc: 0.3412 - class_acc: 1.0000\n","average v_acc: 25.882, three class acc: 52.941, two class acc: 54.118\n","====================================================================================================\n","STEP:353, D{v_l: 0.701, v_acc: [45.3| 65.6| 55.5], c_acc: [90.6| 96.9]}  G{v_l: 0.754, v_acc: 64.1, c_acc: 93.8}\n","STEP:354, D{v_l: 0.793, v_acc: [56.2| 59.4| 57.8], c_acc: [78.1| 100.0]}  G{v_l: 0.836, v_acc: 56.2, c_acc: 92.2}\n","STEP:355, D{v_l: 0.592, v_acc: [65.6| 81.2| 73.4], c_acc: [71.9| 93.8]}  G{v_l: 0.773, v_acc: 60.9, c_acc: 93.8}\n","STEP:356, D{v_l: 0.598, v_acc: [62.5| 71.9| 67.2], c_acc: [75.0| 96.9]}  G{v_l: 0.920, v_acc: 59.4, c_acc: 92.2}\n","STEP:357, D{v_l: 0.849, v_acc: [53.1| 65.6| 59.4], c_acc: [87.5| 90.6]}  G{v_l: 0.905, v_acc: 54.7, c_acc: 96.9}\n","STEP:358, D{v_l: 0.606, v_acc: [62.5| 62.5| 62.5], c_acc: [71.9| 90.6]}  G{v_l: 1.138, v_acc: 45.3, c_acc: 93.8}\n","STEP:359, D{v_l: 0.680, v_acc: [59.4| 62.5| 60.9], c_acc: [78.1| 93.8]}  G{v_l: 1.152, v_acc: 40.6, c_acc: 85.9}\n","STEP:360, D{v_l: 0.896, v_acc: [46.9| 78.1| 62.5], c_acc: [84.4| 93.8]}  G{v_l: 0.962, v_acc: 53.1, c_acc: 87.5}\n","STEP:361, D{v_l: 0.636, v_acc: [53.1| 68.8| 60.9], c_acc: [84.4| 100.0]}  G{v_l: 0.779, v_acc: 59.4, c_acc: 90.6}\n","STEP:362, D{v_l: 0.727, v_acc: [59.4| 75.0| 67.2], c_acc: [81.2| 100.0]}  G{v_l: 0.956, v_acc: 53.1, c_acc: 95.3}\n","STEP:363, D{v_l: 0.704, v_acc: [71.9| 71.9| 71.9], c_acc: [78.1| 96.9]}  G{v_l: 0.989, v_acc: 51.6, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 52ms/step - loss: 2.3841 - valid_loss: 0.7495 - class_loss: 1.2469 - valid_acc: 0.4706 - class_acc: 0.4588\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1876 - valid_loss: 0.7512 - class_loss: 0.0487 - valid_acc: 0.4118 - class_acc: 1.0000\n","average v_acc: 44.118, three class acc: 45.882, two class acc: 57.647\n","====================================================================================================\n","STEP:364, D{v_l: 0.556, v_acc: [50.4| 84.4| 67.4], c_acc: [92.3| 100.0]}  G{v_l: 1.290, v_acc: 40.6, c_acc: 92.2}\n","STEP:365, D{v_l: 0.834, v_acc: [59.4| 62.5| 60.9], c_acc: [78.1| 96.9]}  G{v_l: 0.862, v_acc: 60.9, c_acc: 90.6}\n","STEP:366, D{v_l: 0.722, v_acc: [75.0| 65.6| 70.3], c_acc: [75.0| 93.8]}  G{v_l: 0.916, v_acc: 48.4, c_acc: 93.8}\n","STEP:367, D{v_l: 1.077, v_acc: [59.4| 68.8| 64.1], c_acc: [84.4| 93.8]}  G{v_l: 0.905, v_acc: 57.8, c_acc: 93.8}\n","STEP:368, D{v_l: 0.647, v_acc: [56.2| 81.2| 68.8], c_acc: [78.1| 100.0]}  G{v_l: 0.975, v_acc: 54.7, c_acc: 89.1}\n","STEP:369, D{v_l: 0.664, v_acc: [59.4| 81.2| 70.3], c_acc: [68.8| 100.0]}  G{v_l: 1.155, v_acc: 43.8, c_acc: 95.3}\n","STEP:370, D{v_l: 0.687, v_acc: [68.8| 65.6| 67.2], c_acc: [62.5| 96.9]}  G{v_l: 0.951, v_acc: 48.4, c_acc: 92.2}\n","STEP:371, D{v_l: 0.624, v_acc: [78.1| 71.9| 75.0], c_acc: [81.2| 93.8]}  G{v_l: 1.162, v_acc: 51.6, c_acc: 87.5}\n","STEP:372, D{v_l: 0.500, v_acc: [65.6| 84.4| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 0.914, v_acc: 45.3, c_acc: 92.2}\n","STEP:373, D{v_l: 0.727, v_acc: [59.4| 81.2| 70.3], c_acc: [84.4| 96.9]}  G{v_l: 0.951, v_acc: 56.2, c_acc: 92.2}\n","STEP:374, D{v_l: 0.561, v_acc: [68.8| 81.2| 75.0], c_acc: [84.4| 93.8]}  G{v_l: 1.167, v_acc: 46.9, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.6856 - valid_loss: 0.7966 - class_loss: 1.5014 - valid_acc: 0.3412 - class_acc: 0.4471\n","3/3 [==============================] - 0s 46ms/step - loss: 1.1788 - valid_loss: 0.7488 - class_loss: 0.0423 - valid_acc: 0.4471 - class_acc: 1.0000\n","average v_acc: 39.412, three class acc: 44.706, two class acc: 61.176\n","====================================================================================================\n","STEP:375, D{v_l: 0.667, v_acc: [55.6| 71.9| 63.7], c_acc: [94.9| 93.8]}  G{v_l: 1.078, v_acc: 54.7, c_acc: 92.2}\n","STEP:376, D{v_l: 0.507, v_acc: [71.9| 90.6| 81.2], c_acc: [75.0| 90.6]}  G{v_l: 0.863, v_acc: 64.1, c_acc: 98.4}\n","STEP:377, D{v_l: 0.634, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 96.9]}  G{v_l: 0.823, v_acc: 57.8, c_acc: 92.2}\n","STEP:378, D{v_l: 0.708, v_acc: [59.4| 68.8| 64.1], c_acc: [87.5| 93.8]}  G{v_l: 1.060, v_acc: 45.3, c_acc: 84.4}\n","STEP:379, D{v_l: 0.714, v_acc: [71.9| 71.9| 71.9], c_acc: [93.8| 93.8]}  G{v_l: 0.967, v_acc: 54.7, c_acc: 92.2}\n","STEP:380, D{v_l: 0.558, v_acc: [65.6| 81.2| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 0.962, v_acc: 59.4, c_acc: 89.1}\n","STEP:381, D{v_l: 0.721, v_acc: [50.0| 75.0| 62.5], c_acc: [75.0| 90.6]}  G{v_l: 1.152, v_acc: 48.4, c_acc: 85.9}\n","STEP:382, D{v_l: 0.508, v_acc: [68.8| 78.1| 73.4], c_acc: [81.2| 96.9]}  G{v_l: 0.815, v_acc: 59.4, c_acc: 93.8}\n","STEP:383, D{v_l: 0.638, v_acc: [75.0| 75.0| 75.0], c_acc: [75.0| 96.9]}  G{v_l: 1.120, v_acc: 42.2, c_acc: 87.5}\n","STEP:384, D{v_l: 0.626, v_acc: [65.6| 71.9| 68.8], c_acc: [68.8| 100.0]}  G{v_l: 1.071, v_acc: 53.1, c_acc: 90.6}\n","STEP:385, D{v_l: 0.527, v_acc: [65.6| 81.2| 73.4], c_acc: [78.1| 96.9]}  G{v_l: 1.007, v_acc: 50.0, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.7818 - valid_loss: 0.8829 - class_loss: 1.5112 - valid_acc: 0.2000 - class_acc: 0.4941\n","3/3 [==============================] - 0s 43ms/step - loss: 1.2883 - valid_loss: 0.8192 - class_loss: 0.0814 - valid_acc: 0.3647 - class_acc: 0.9882\n","average v_acc: 28.235, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","STEP:386, D{v_l: 0.905, v_acc: [44.4| 65.6| 55.0], c_acc: [94.0| 90.6]}  G{v_l: 0.918, v_acc: 59.4, c_acc: 85.9}\n","STEP:387, D{v_l: 0.674, v_acc: [43.8| 84.4| 64.1], c_acc: [81.2| 96.9]}  G{v_l: 0.961, v_acc: 53.1, c_acc: 87.5}\n","STEP:388, D{v_l: 0.521, v_acc: [65.6| 87.5| 76.6], c_acc: [59.4| 96.9]}  G{v_l: 1.014, v_acc: 50.0, c_acc: 75.0}\n","STEP:389, D{v_l: 0.629, v_acc: [65.6| 62.5| 64.1], c_acc: [87.5| 100.0]}  G{v_l: 1.165, v_acc: 51.6, c_acc: 76.6}\n","STEP:390, D{v_l: 0.625, v_acc: [68.8| 81.2| 75.0], c_acc: [71.9| 100.0]}  G{v_l: 1.257, v_acc: 57.8, c_acc: 81.2}\n","STEP:391, D{v_l: 0.621, v_acc: [53.1| 78.1| 65.6], c_acc: [75.0| 100.0]}  G{v_l: 0.949, v_acc: 56.2, c_acc: 95.3}\n","STEP:392, D{v_l: 0.524, v_acc: [71.9| 81.2| 76.6], c_acc: [68.8| 96.9]}  G{v_l: 1.141, v_acc: 48.4, c_acc: 92.2}\n","STEP:393, D{v_l: 1.013, v_acc: [59.4| 62.5| 60.9], c_acc: [81.2| 96.9]}  G{v_l: 0.762, v_acc: 59.4, c_acc: 95.3}\n","STEP:394, D{v_l: 0.586, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 1.271, v_acc: 51.6, c_acc: 87.5}\n","STEP:395, D{v_l: 0.854, v_acc: [56.2| 68.8| 62.5], c_acc: [78.1| 93.8]}  G{v_l: 1.531, v_acc: 51.6, c_acc: 93.8}\n","STEP:396, D{v_l: 0.743, v_acc: [59.4| 75.0| 67.2], c_acc: [81.2| 96.9]}  G{v_l: 1.107, v_acc: 50.0, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.8978 - valid_loss: 0.8730 - class_loss: 1.6371 - valid_acc: 0.1647 - class_acc: 0.5412\n","3/3 [==============================] - 0s 46ms/step - loss: 1.2165 - valid_loss: 0.7738 - class_loss: 0.0551 - valid_acc: 0.3647 - class_acc: 1.0000\n","average v_acc: 26.471, three class acc: 54.118, two class acc: 60.000\n","====================================================================================================\n","STEP:397, D{v_l: 0.617, v_acc: [48.7| 78.1| 63.4], c_acc: [98.3| 96.9]}  G{v_l: 1.242, v_acc: 51.6, c_acc: 96.9}\n","STEP:398, D{v_l: 0.604, v_acc: [68.8| 81.2| 75.0], c_acc: [71.9| 96.9]}  G{v_l: 0.985, v_acc: 59.4, c_acc: 95.3}\n","STEP:399, D{v_l: 0.577, v_acc: [68.8| 71.9| 70.3], c_acc: [71.9| 90.6]}  G{v_l: 0.741, v_acc: 60.9, c_acc: 90.6}\n","STEP:400, D{v_l: 0.562, v_acc: [78.1| 65.6| 71.9], c_acc: [87.5| 93.8]}  G{v_l: 1.058, v_acc: 51.6, c_acc: 90.6}\n","STEP:401, D{v_l: 0.865, v_acc: [78.1| 50.0| 64.1], c_acc: [68.8| 96.9]}  G{v_l: 1.150, v_acc: 39.1, c_acc: 96.9}\n","STEP:402, D{v_l: 0.581, v_acc: [68.8| 65.6| 67.2], c_acc: [87.5| 96.9]}  G{v_l: 1.192, v_acc: 46.9, c_acc: 96.9}\n","STEP:403, D{v_l: 0.524, v_acc: [78.1| 78.1| 78.1], c_acc: [78.1| 100.0]}  G{v_l: 1.102, v_acc: 50.0, c_acc: 98.4}\n","STEP:404, D{v_l: 0.559, v_acc: [71.9| 75.0| 73.4], c_acc: [78.1| 96.9]}  G{v_l: 1.103, v_acc: 46.9, c_acc: 92.2}\n","STEP:405, D{v_l: 0.880, v_acc: [50.0| 78.1| 64.1], c_acc: [78.1| 96.9]}  G{v_l: 1.361, v_acc: 45.3, c_acc: 92.2}\n","STEP:406, D{v_l: 0.698, v_acc: [59.4| 68.8| 64.1], c_acc: [78.1| 100.0]}  G{v_l: 1.156, v_acc: 42.2, c_acc: 95.3}\n","STEP:407, D{v_l: 0.565, v_acc: [65.6| 78.1| 71.9], c_acc: [68.8| 84.4]}  G{v_l: 1.193, v_acc: 43.8, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7411 - valid_loss: 0.7456 - class_loss: 1.6079 - valid_acc: 0.3882 - class_acc: 0.3765\n","3/3 [==============================] - 0s 46ms/step - loss: 1.1168 - valid_loss: 0.6639 - class_loss: 0.0652 - valid_acc: 0.5529 - class_acc: 0.9882\n","average v_acc: 47.059, three class acc: 37.647, two class acc: 55.294\n","====================================================================================================\n","STEP:408, D{v_l: 0.500, v_acc: [57.3| 90.6| 73.9], c_acc: [94.0| 96.9]}  G{v_l: 1.105, v_acc: 54.7, c_acc: 85.9}\n","STEP:409, D{v_l: 0.649, v_acc: [71.9| 59.4| 65.6], c_acc: [71.9| 71.9]}  G{v_l: 1.008, v_acc: 46.9, c_acc: 96.9}\n","STEP:410, D{v_l: 0.559, v_acc: [56.2| 75.0| 65.6], c_acc: [81.2| 96.9]}  G{v_l: 1.237, v_acc: 53.1, c_acc: 92.2}\n","STEP:411, D{v_l: 0.725, v_acc: [62.5| 65.6| 64.1], c_acc: [75.0| 93.8]}  G{v_l: 1.030, v_acc: 53.1, c_acc: 92.2}\n","STEP:412, D{v_l: 0.764, v_acc: [68.8| 53.1| 60.9], c_acc: [84.4| 93.8]}  G{v_l: 0.899, v_acc: 56.2, c_acc: 87.5}\n","STEP:413, D{v_l: 0.631, v_acc: [62.5| 75.0| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 1.028, v_acc: 56.2, c_acc: 92.2}\n","STEP:414, D{v_l: 0.654, v_acc: [50.0| 71.9| 60.9], c_acc: [84.4| 96.9]}  G{v_l: 1.271, v_acc: 51.6, c_acc: 84.4}\n","STEP:415, D{v_l: 0.741, v_acc: [53.1| 68.8| 60.9], c_acc: [78.1| 96.9]}  G{v_l: 1.094, v_acc: 46.9, c_acc: 93.8}\n","STEP:416, D{v_l: 0.694, v_acc: [68.8| 53.1| 60.9], c_acc: [71.9| 78.1]}  G{v_l: 1.291, v_acc: 54.7, c_acc: 89.1}\n","STEP:417, D{v_l: 0.585, v_acc: [68.8| 81.2| 75.0], c_acc: [68.8| 93.8]}  G{v_l: 1.531, v_acc: 40.6, c_acc: 81.2}\n","STEP:418, D{v_l: 0.617, v_acc: [68.8| 78.1| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 1.293, v_acc: 46.9, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.6605 - valid_loss: 0.7729 - class_loss: 1.5001 - valid_acc: 0.3294 - class_acc: 0.4471\n","3/3 [==============================] - 0s 49ms/step - loss: 1.4304 - valid_loss: 0.8409 - class_loss: 0.2020 - valid_acc: 0.3765 - class_acc: 0.9412\n","average v_acc: 35.294, three class acc: 44.706, two class acc: 61.176\n","====================================================================================================\n","STEP:419, D{v_l: 0.869, v_acc: [44.4| 65.6| 55.0], c_acc: [91.5| 100.0]}  G{v_l: 1.279, v_acc: 59.4, c_acc: 84.4}\n","STEP:420, D{v_l: 0.838, v_acc: [53.1| 56.2| 54.7], c_acc: [87.5| 90.6]}  G{v_l: 1.191, v_acc: 53.1, c_acc: 93.8}\n","STEP:421, D{v_l: 0.704, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 1.320, v_acc: 53.1, c_acc: 96.9}\n","STEP:422, D{v_l: 0.634, v_acc: [71.9| 78.1| 75.0], c_acc: [81.2| 100.0]}  G{v_l: 1.067, v_acc: 51.6, c_acc: 96.9}\n","STEP:423, D{v_l: 0.525, v_acc: [62.5| 84.4| 73.4], c_acc: [93.8| 96.9]}  G{v_l: 1.264, v_acc: 42.2, c_acc: 96.9}\n","STEP:424, D{v_l: 0.852, v_acc: [56.2| 68.8| 62.5], c_acc: [84.4| 100.0]}  G{v_l: 1.135, v_acc: 45.3, c_acc: 95.3}\n","STEP:425, D{v_l: 0.549, v_acc: [71.9| 75.0| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 1.170, v_acc: 37.5, c_acc: 93.8}\n","STEP:426, D{v_l: 0.651, v_acc: [62.5| 78.1| 70.3], c_acc: [87.5| 100.0]}  G{v_l: 1.080, v_acc: 43.8, c_acc: 95.3}\n","STEP:427, D{v_l: 0.638, v_acc: [68.8| 75.0| 71.9], c_acc: [84.4| 93.8]}  G{v_l: 0.962, v_acc: 56.2, c_acc: 95.3}\n","STEP:428, D{v_l: 0.440, v_acc: [78.1| 71.9| 75.0], c_acc: [84.4| 87.5]}  G{v_l: 1.190, v_acc: 48.4, c_acc: 93.8}\n","STEP:429, D{v_l: 0.582, v_acc: [71.9| 81.2| 76.6], c_acc: [81.2| 81.2]}  G{v_l: 1.240, v_acc: 39.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.6392 - valid_loss: 0.6083 - class_loss: 1.6434 - valid_acc: 0.7765 - class_acc: 0.2941\n","3/3 [==============================] - 0s 48ms/step - loss: 1.2144 - valid_loss: 0.6069 - class_loss: 0.2200 - valid_acc: 0.6706 - class_acc: 0.9412\n","average v_acc: 72.353, three class acc: 29.412, two class acc: 56.471\n","====================================================================================================\n","STEP:430, D{v_l: 0.680, v_acc: [64.1| 71.9| 68.0], c_acc: [94.0| 96.9]}  G{v_l: 1.171, v_acc: 45.3, c_acc: 93.8}\n","STEP:431, D{v_l: 0.582, v_acc: [78.1| 68.8| 73.4], c_acc: [93.8| 93.8]}  G{v_l: 0.996, v_acc: 43.8, c_acc: 90.6}\n","STEP:432, D{v_l: 0.713, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 0.919, v_acc: 56.2, c_acc: 95.3}\n","STEP:433, D{v_l: 0.677, v_acc: [65.6| 84.4| 75.0], c_acc: [84.4| 100.0]}  G{v_l: 0.899, v_acc: 45.3, c_acc: 90.6}\n","STEP:434, D{v_l: 0.547, v_acc: [71.9| 87.5| 79.7], c_acc: [65.6| 90.6]}  G{v_l: 1.158, v_acc: 46.9, c_acc: 95.3}\n","STEP:435, D{v_l: 0.594, v_acc: [56.2| 68.8| 62.5], c_acc: [87.5| 93.8]}  G{v_l: 1.280, v_acc: 45.3, c_acc: 89.1}\n","STEP:436, D{v_l: 0.419, v_acc: [78.1| 78.1| 78.1], c_acc: [78.1| 84.4]}  G{v_l: 1.250, v_acc: 39.1, c_acc: 89.1}\n","STEP:437, D{v_l: 0.608, v_acc: [75.0| 62.5| 68.8], c_acc: [81.2| 96.9]}  G{v_l: 1.021, v_acc: 51.6, c_acc: 82.8}\n","STEP:438, D{v_l: 0.602, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 87.5]}  G{v_l: 0.738, v_acc: 57.8, c_acc: 89.1}\n","STEP:439, D{v_l: 0.633, v_acc: [65.6| 71.9| 68.8], c_acc: [84.4| 93.8]}  G{v_l: 0.972, v_acc: 46.9, c_acc: 90.6}\n","STEP:440, D{v_l: 0.623, v_acc: [65.6| 65.6| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 1.118, v_acc: 48.4, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.4877 - valid_loss: 0.7594 - class_loss: 1.3408 - valid_acc: 0.4706 - class_acc: 0.4824\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0946 - valid_loss: 0.6693 - class_loss: 0.0378 - valid_acc: 0.5412 - class_acc: 1.0000\n","average v_acc: 50.588, three class acc: 48.235, two class acc: 58.824\n","====================================================================================================\n","Epoch: 40\n","====================================================================================================\n","STEP:441, D{v_l: 0.527, v_acc: [58.1| 81.2| 69.7], c_acc: [94.9| 100.0]}  G{v_l: 1.542, v_acc: 35.9, c_acc: 98.4}\n","STEP:442, D{v_l: 0.547, v_acc: [56.2| 75.0| 65.6], c_acc: [78.1| 100.0]}  G{v_l: 1.432, v_acc: 43.8, c_acc: 95.3}\n","STEP:443, D{v_l: 0.678, v_acc: [46.9| 75.0| 60.9], c_acc: [78.1| 96.9]}  G{v_l: 1.035, v_acc: 50.0, c_acc: 100.0}\n","STEP:444, D{v_l: 0.599, v_acc: [62.5| 78.1| 70.3], c_acc: [84.4| 81.2]}  G{v_l: 0.942, v_acc: 53.1, c_acc: 93.8}\n","STEP:445, D{v_l: 0.853, v_acc: [59.4| 62.5| 60.9], c_acc: [84.4| 87.5]}  G{v_l: 1.121, v_acc: 50.0, c_acc: 96.9}\n","STEP:446, D{v_l: 0.550, v_acc: [62.5| 71.9| 67.2], c_acc: [65.6| 96.9]}  G{v_l: 0.872, v_acc: 56.2, c_acc: 98.4}\n","STEP:447, D{v_l: 0.670, v_acc: [53.1| 75.0| 64.1], c_acc: [84.4| 93.8]}  G{v_l: 1.209, v_acc: 53.1, c_acc: 96.9}\n","STEP:448, D{v_l: 0.795, v_acc: [56.2| 65.6| 60.9], c_acc: [84.4| 93.8]}  G{v_l: 1.073, v_acc: 50.0, c_acc: 96.9}\n","STEP:449, D{v_l: 0.588, v_acc: [68.8| 81.2| 75.0], c_acc: [87.5| 100.0]}  G{v_l: 0.991, v_acc: 60.9, c_acc: 100.0}\n","STEP:450, D{v_l: 0.633, v_acc: [78.1| 68.8| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.341, v_acc: 48.4, c_acc: 92.2}\n","STEP:451, D{v_l: 0.529, v_acc: [71.9| 81.2| 76.6], c_acc: [81.2| 96.9]}  G{v_l: 0.858, v_acc: 53.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.8575 - valid_loss: 0.8764 - class_loss: 1.5937 - valid_acc: 0.3294 - class_acc: 0.5529\n","3/3 [==============================] - 0s 45ms/step - loss: 1.1866 - valid_loss: 0.6958 - class_loss: 0.1032 - valid_acc: 0.5059 - class_acc: 0.9529\n","average v_acc: 41.765, three class acc: 55.294, two class acc: 62.353\n","====================================================================================================\n","STEP:452, D{v_l: 0.548, v_acc: [59.0| 81.2| 70.1], c_acc: [93.2| 96.9]}  G{v_l: 1.153, v_acc: 56.2, c_acc: 96.9}\n","STEP:453, D{v_l: 0.468, v_acc: [71.9| 81.2| 76.6], c_acc: [84.4| 100.0]}  G{v_l: 1.147, v_acc: 45.3, c_acc: 95.3}\n","STEP:454, D{v_l: 0.603, v_acc: [62.5| 81.2| 71.9], c_acc: [78.1| 100.0]}  G{v_l: 1.342, v_acc: 46.9, c_acc: 98.4}\n","STEP:455, D{v_l: 0.590, v_acc: [59.4| 65.6| 62.5], c_acc: [84.4| 90.6]}  G{v_l: 0.958, v_acc: 51.6, c_acc: 95.3}\n","STEP:456, D{v_l: 0.508, v_acc: [78.1| 81.2| 79.7], c_acc: [71.9| 96.9]}  G{v_l: 0.841, v_acc: 59.4, c_acc: 89.1}\n","STEP:457, D{v_l: 0.649, v_acc: [65.6| 84.4| 75.0], c_acc: [87.5| 93.8]}  G{v_l: 1.135, v_acc: 53.1, c_acc: 90.6}\n","STEP:458, D{v_l: 0.718, v_acc: [59.4| 68.8| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 0.908, v_acc: 56.2, c_acc: 93.8}\n","STEP:459, D{v_l: 0.477, v_acc: [68.8| 90.6| 79.7], c_acc: [84.4| 96.9]}  G{v_l: 1.298, v_acc: 51.6, c_acc: 82.8}\n","STEP:460, D{v_l: 0.534, v_acc: [68.8| 78.1| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 1.273, v_acc: 45.3, c_acc: 92.2}\n","STEP:461, D{v_l: 0.534, v_acc: [59.4| 84.4| 71.9], c_acc: [84.4| 96.9]}  G{v_l: 1.221, v_acc: 46.9, c_acc: 92.2}\n","STEP:462, D{v_l: 0.602, v_acc: [78.1| 68.8| 73.4], c_acc: [90.6| 93.8]}  G{v_l: 0.876, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.7677 - valid_loss: 1.0122 - class_loss: 2.3680 - valid_acc: 0.2706 - class_acc: 0.5529\n","3/3 [==============================] - 0s 48ms/step - loss: 1.2116 - valid_loss: 0.7140 - class_loss: 0.1102 - valid_acc: 0.4353 - class_acc: 0.9647\n","average v_acc: 35.294, three class acc: 55.294, two class acc: 57.647\n","====================================================================================================\n","STEP:463, D{v_l: 0.782, v_acc: [47.9| 78.1| 63.0], c_acc: [94.9| 90.6]}  G{v_l: 1.074, v_acc: 48.4, c_acc: 98.4}\n","STEP:464, D{v_l: 0.600, v_acc: [75.0| 65.6| 70.3], c_acc: [84.4| 96.9]}  G{v_l: 1.069, v_acc: 46.9, c_acc: 85.9}\n","STEP:465, D{v_l: 0.552, v_acc: [68.8| 87.5| 78.1], c_acc: [81.2| 96.9]}  G{v_l: 0.973, v_acc: 57.8, c_acc: 96.9}\n","STEP:466, D{v_l: 0.673, v_acc: [65.6| 68.8| 67.2], c_acc: [75.0| 90.6]}  G{v_l: 1.103, v_acc: 51.6, c_acc: 95.3}\n","STEP:467, D{v_l: 0.576, v_acc: [59.4| 78.1| 68.8], c_acc: [78.1| 93.8]}  G{v_l: 1.122, v_acc: 50.0, c_acc: 93.8}\n","STEP:468, D{v_l: 0.671, v_acc: [71.9| 71.9| 71.9], c_acc: [84.4| 93.8]}  G{v_l: 1.485, v_acc: 51.6, c_acc: 54.7}\n","STEP:469, D{v_l: 0.643, v_acc: [78.1| 62.5| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 1.872, v_acc: 42.2, c_acc: 68.8}\n","STEP:470, D{v_l: 0.505, v_acc: [62.5| 68.8| 65.6], c_acc: [87.5| 84.4]}  G{v_l: 1.286, v_acc: 50.0, c_acc: 98.4}\n","STEP:471, D{v_l: 0.693, v_acc: [56.2| 75.0| 65.6], c_acc: [84.4| 93.8]}  G{v_l: 1.380, v_acc: 39.1, c_acc: 90.6}\n","STEP:472, D{v_l: 0.552, v_acc: [62.5| 81.2| 71.9], c_acc: [87.5| 96.9]}  G{v_l: 1.415, v_acc: 42.2, c_acc: 85.9}\n","STEP:473, D{v_l: 0.555, v_acc: [59.4| 78.1| 68.8], c_acc: [90.6| 96.9]}  G{v_l: 1.270, v_acc: 46.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.0787 - valid_loss: 0.8216 - class_loss: 1.8696 - valid_acc: 0.3647 - class_acc: 0.5412\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0996 - valid_loss: 0.6447 - class_loss: 0.0674 - valid_acc: 0.6000 - class_acc: 0.9647\n","average v_acc: 48.235, three class acc: 54.118, two class acc: 58.824\n","====================================================================================================\n","STEP:474, D{v_l: 0.629, v_acc: [63.2| 71.9| 67.6], c_acc: [93.2| 87.5]}  G{v_l: 1.030, v_acc: 50.0, c_acc: 92.2}\n","STEP:475, D{v_l: 0.598, v_acc: [59.4| 75.0| 67.2], c_acc: [75.0| 93.8]}  G{v_l: 1.223, v_acc: 45.3, c_acc: 93.8}\n","STEP:476, D{v_l: 0.545, v_acc: [68.8| 84.4| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 1.270, v_acc: 45.3, c_acc: 98.4}\n","STEP:477, D{v_l: 0.744, v_acc: [68.8| 65.6| 67.2], c_acc: [81.2| 96.9]}  G{v_l: 1.202, v_acc: 48.4, c_acc: 95.3}\n","STEP:478, D{v_l: 0.720, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 93.8]}  G{v_l: 1.222, v_acc: 51.6, c_acc: 93.8}\n","STEP:479, D{v_l: 0.672, v_acc: [65.6| 84.4| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 1.331, v_acc: 45.3, c_acc: 93.8}\n","STEP:480, D{v_l: 0.806, v_acc: [56.2| 68.8| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 0.947, v_acc: 57.8, c_acc: 93.8}\n","STEP:481, D{v_l: 0.485, v_acc: [75.0| 84.4| 79.7], c_acc: [78.1| 96.9]}  G{v_l: 1.025, v_acc: 46.9, c_acc: 92.2}\n","STEP:482, D{v_l: 0.550, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 100.0]}  G{v_l: 1.080, v_acc: 56.2, c_acc: 95.3}\n","STEP:483, D{v_l: 0.535, v_acc: [75.0| 68.8| 71.9], c_acc: [90.6| 90.6]}  G{v_l: 1.030, v_acc: 51.6, c_acc: 92.2}\n","STEP:484, D{v_l: 0.509, v_acc: [68.8| 96.9| 82.8], c_acc: [81.2| 93.8]}  G{v_l: 1.161, v_acc: 53.1, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.5063 - valid_loss: 0.6604 - class_loss: 1.4585 - valid_acc: 0.6706 - class_acc: 0.4706\n","3/3 [==============================] - 0s 46ms/step - loss: 1.1809 - valid_loss: 0.7655 - class_loss: 0.0280 - valid_acc: 0.3647 - class_acc: 1.0000\n","average v_acc: 51.765, three class acc: 47.059, two class acc: 56.471\n","====================================================================================================\n","STEP:485, D{v_l: 0.610, v_acc: [42.7| 71.9| 57.3], c_acc: [99.1| 100.0]}  G{v_l: 1.202, v_acc: 53.1, c_acc: 98.4}\n","STEP:486, D{v_l: 0.637, v_acc: [56.2| 68.8| 62.5], c_acc: [93.8| 93.8]}  G{v_l: 1.323, v_acc: 48.4, c_acc: 98.4}\n","STEP:487, D{v_l: 0.565, v_acc: [68.8| 78.1| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 1.259, v_acc: 62.5, c_acc: 98.4}\n","STEP:488, D{v_l: 0.657, v_acc: [65.6| 78.1| 71.9], c_acc: [84.4| 100.0]}  G{v_l: 0.924, v_acc: 51.6, c_acc: 95.3}\n","STEP:489, D{v_l: 0.558, v_acc: [87.5| 71.9| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 0.981, v_acc: 48.4, c_acc: 95.3}\n","STEP:490, D{v_l: 0.677, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 90.6]}  G{v_l: 1.252, v_acc: 48.4, c_acc: 89.1}\n","STEP:491, D{v_l: 0.550, v_acc: [75.0| 68.8| 71.9], c_acc: [84.4| 96.9]}  G{v_l: 0.982, v_acc: 51.6, c_acc: 92.2}\n","STEP:492, D{v_l: 0.559, v_acc: [65.6| 78.1| 71.9], c_acc: [81.2| 87.5]}  G{v_l: 1.199, v_acc: 45.3, c_acc: 95.3}\n","STEP:493, D{v_l: 0.522, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 1.155, v_acc: 57.8, c_acc: 95.3}\n","STEP:494, D{v_l: 0.665, v_acc: [62.5| 78.1| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 0.717, v_acc: 65.6, c_acc: 96.9}\n","STEP:495, D{v_l: 0.769, v_acc: [68.8| 56.2| 62.5], c_acc: [71.9| 100.0]}  G{v_l: 0.923, v_acc: 48.4, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 2.5395 - valid_loss: 0.6463 - class_loss: 1.5058 - valid_acc: 0.6235 - class_acc: 0.3882\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1698 - valid_loss: 0.7588 - class_loss: 0.0236 - valid_acc: 0.3882 - class_acc: 0.9882\n","average v_acc: 50.588, three class acc: 38.824, two class acc: 62.353\n","====================================================================================================\n","STEP:496, D{v_l: 0.650, v_acc: [41.9| 71.9| 56.9], c_acc: [94.9| 96.9]}  G{v_l: 0.921, v_acc: 50.0, c_acc: 92.2}\n","STEP:497, D{v_l: 0.639, v_acc: [65.6| 84.4| 75.0], c_acc: [78.1| 100.0]}  G{v_l: 0.981, v_acc: 53.1, c_acc: 87.5}\n","STEP:498, D{v_l: 0.671, v_acc: [84.4| 81.2| 82.8], c_acc: [84.4| 96.9]}  G{v_l: 1.108, v_acc: 42.2, c_acc: 93.8}\n","STEP:499, D{v_l: 0.570, v_acc: [78.1| 84.4| 81.2], c_acc: [84.4| 100.0]}  G{v_l: 1.164, v_acc: 51.6, c_acc: 95.3}\n","STEP:500, D{v_l: 0.580, v_acc: [53.1| 65.6| 59.4], c_acc: [81.2| 96.9]}  G{v_l: 1.115, v_acc: 46.9, c_acc: 92.2}\n","STEP:501, D{v_l: 0.488, v_acc: [62.5| 81.2| 71.9], c_acc: [93.8| 90.6]}  G{v_l: 0.954, v_acc: 56.2, c_acc: 92.2}\n","STEP:502, D{v_l: 0.457, v_acc: [75.0| 71.9| 73.4], c_acc: [90.6| 93.8]}  G{v_l: 1.046, v_acc: 50.0, c_acc: 98.4}\n","STEP:503, D{v_l: 0.644, v_acc: [56.2| 78.1| 67.2], c_acc: [84.4| 100.0]}  G{v_l: 0.928, v_acc: 54.7, c_acc: 95.3}\n","STEP:504, D{v_l: 0.756, v_acc: [53.1| 71.9| 62.5], c_acc: [65.6| 81.2]}  G{v_l: 0.956, v_acc: 59.4, c_acc: 92.2}\n","STEP:505, D{v_l: 0.479, v_acc: [78.1| 78.1| 78.1], c_acc: [81.2| 96.9]}  G{v_l: 1.161, v_acc: 46.9, c_acc: 93.8}\n","STEP:506, D{v_l: 0.572, v_acc: [71.9| 71.9| 71.9], c_acc: [87.5| 90.6]}  G{v_l: 0.912, v_acc: 53.1, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.4051 - valid_loss: 0.5980 - class_loss: 1.4197 - valid_acc: 0.7176 - class_acc: 0.4118\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1033 - valid_loss: 0.7065 - class_loss: 0.0095 - valid_acc: 0.4353 - class_acc: 1.0000\n","average v_acc: 57.647, three class acc: 41.176, two class acc: 61.176\n","====================================================================================================\n","STEP:507, D{v_l: 0.641, v_acc: [51.3| 75.0| 63.1], c_acc: [95.7| 96.9]}  G{v_l: 1.042, v_acc: 51.6, c_acc: 96.9}\n","STEP:508, D{v_l: 0.372, v_acc: [78.1| 90.6| 84.4], c_acc: [84.4| 96.9]}  G{v_l: 0.854, v_acc: 53.1, c_acc: 98.4}\n","STEP:509, D{v_l: 0.468, v_acc: [68.8| 81.2| 75.0], c_acc: [81.2| 93.8]}  G{v_l: 0.912, v_acc: 53.1, c_acc: 96.9}\n","STEP:510, D{v_l: 0.489, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 1.251, v_acc: 56.2, c_acc: 93.8}\n","STEP:511, D{v_l: 0.486, v_acc: [59.4| 78.1| 68.8], c_acc: [81.2| 96.9]}  G{v_l: 1.072, v_acc: 54.7, c_acc: 95.3}\n","STEP:512, D{v_l: 0.563, v_acc: [59.4| 81.2| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 1.194, v_acc: 48.4, c_acc: 98.4}\n","STEP:513, D{v_l: 0.592, v_acc: [75.0| 65.6| 70.3], c_acc: [84.4| 90.6]}  G{v_l: 0.989, v_acc: 56.2, c_acc: 96.9}\n","STEP:514, D{v_l: 0.545, v_acc: [68.8| 68.8| 68.8], c_acc: [84.4| 96.9]}  G{v_l: 1.041, v_acc: 43.8, c_acc: 81.2}\n","STEP:515, D{v_l: 0.607, v_acc: [62.5| 65.6| 64.1], c_acc: [81.2| 93.8]}  G{v_l: 1.503, v_acc: 37.5, c_acc: 92.2}\n","STEP:516, D{v_l: 0.802, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 1.066, v_acc: 46.9, c_acc: 93.8}\n","STEP:517, D{v_l: 0.673, v_acc: [75.0| 71.9| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 1.187, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.2911 - valid_loss: 0.5371 - class_loss: 1.3667 - valid_acc: 0.8353 - class_acc: 0.4353\n","3/3 [==============================] - 0s 51ms/step - loss: 1.1631 - valid_loss: 0.6796 - class_loss: 0.0962 - valid_acc: 0.4588 - class_acc: 0.9647\n","average v_acc: 64.706, three class acc: 43.529, two class acc: 61.176\n","====================================================================================================\n","STEP:518, D{v_l: 0.778, v_acc: [53.0| 62.5| 57.7], c_acc: [94.9| 90.6]}  G{v_l: 1.018, v_acc: 46.9, c_acc: 98.4}\n","STEP:519, D{v_l: 0.622, v_acc: [53.1| 78.1| 65.6], c_acc: [90.6| 96.9]}  G{v_l: 1.130, v_acc: 46.9, c_acc: 95.3}\n","STEP:520, D{v_l: 0.671, v_acc: [59.4| 59.4| 59.4], c_acc: [81.2| 90.6]}  G{v_l: 1.046, v_acc: 50.0, c_acc: 100.0}\n","STEP:521, D{v_l: 0.497, v_acc: [65.6| 84.4| 75.0], c_acc: [96.9| 93.8]}  G{v_l: 1.484, v_acc: 31.2, c_acc: 95.3}\n","STEP:522, D{v_l: 0.652, v_acc: [53.1| 78.1| 65.6], c_acc: [81.2| 90.6]}  G{v_l: 1.338, v_acc: 34.4, c_acc: 100.0}\n","STEP:523, D{v_l: 0.545, v_acc: [75.0| 81.2| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 1.087, v_acc: 51.6, c_acc: 95.3}\n","STEP:524, D{v_l: 0.527, v_acc: [68.8| 71.9| 70.3], c_acc: [90.6| 93.8]}  G{v_l: 1.284, v_acc: 39.1, c_acc: 100.0}\n","STEP:525, D{v_l: 0.529, v_acc: [75.0| 75.0| 75.0], c_acc: [84.4| 87.5]}  G{v_l: 0.975, v_acc: 50.0, c_acc: 92.2}\n","STEP:526, D{v_l: 0.599, v_acc: [81.2| 75.0| 78.1], c_acc: [84.4| 96.9]}  G{v_l: 1.000, v_acc: 48.4, c_acc: 89.1}\n","STEP:527, D{v_l: 0.565, v_acc: [65.6| 75.0| 70.3], c_acc: [87.5| 93.8]}  G{v_l: 1.336, v_acc: 42.2, c_acc: 95.3}\n","STEP:528, D{v_l: 0.574, v_acc: [68.8| 75.0| 71.9], c_acc: [90.6| 93.8]}  G{v_l: 0.944, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.5697 - valid_loss: 0.5757 - class_loss: 1.6067 - valid_acc: 0.7529 - class_acc: 0.4824\n","3/3 [==============================] - 0s 51ms/step - loss: 1.0598 - valid_loss: 0.6359 - class_loss: 0.0365 - valid_acc: 0.5412 - class_acc: 1.0000\n","average v_acc: 64.706, three class acc: 48.235, two class acc: 60.000\n","====================================================================================================\n","STEP:529, D{v_l: 0.540, v_acc: [59.8| 78.1| 69.0], c_acc: [96.6| 96.9]}  G{v_l: 1.000, v_acc: 54.7, c_acc: 96.9}\n","STEP:530, D{v_l: 0.440, v_acc: [81.2| 93.8| 87.5], c_acc: [87.5| 96.9]}  G{v_l: 1.105, v_acc: 46.9, c_acc: 89.1}\n","STEP:531, D{v_l: 0.422, v_acc: [71.9| 87.5| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.033, v_acc: 46.9, c_acc: 92.2}\n","STEP:532, D{v_l: 0.404, v_acc: [75.0| 75.0| 75.0], c_acc: [84.4| 93.8]}  G{v_l: 1.055, v_acc: 48.4, c_acc: 95.3}\n","STEP:533, D{v_l: 0.682, v_acc: [65.6| 81.2| 73.4], c_acc: [84.4| 90.6]}  G{v_l: 1.152, v_acc: 50.0, c_acc: 93.8}\n","STEP:534, D{v_l: 0.881, v_acc: [71.9| 62.5| 67.2], c_acc: [93.8| 100.0]}  G{v_l: 1.378, v_acc: 43.8, c_acc: 90.6}\n","STEP:535, D{v_l: 0.723, v_acc: [65.6| 68.8| 67.2], c_acc: [93.8| 100.0]}  G{v_l: 1.112, v_acc: 45.3, c_acc: 96.9}\n","STEP:536, D{v_l: 0.416, v_acc: [65.6| 87.5| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 0.791, v_acc: 62.5, c_acc: 87.5}\n","STEP:537, D{v_l: 0.592, v_acc: [59.4| 81.2| 70.3], c_acc: [84.4| 100.0]}  G{v_l: 1.291, v_acc: 46.9, c_acc: 95.3}\n","STEP:538, D{v_l: 0.684, v_acc: [62.5| 53.1| 57.8], c_acc: [87.5| 93.8]}  G{v_l: 1.113, v_acc: 51.6, c_acc: 92.2}\n","STEP:539, D{v_l: 0.681, v_acc: [68.8| 78.1| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.200, v_acc: 43.8, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.4946 - valid_loss: 0.5600 - class_loss: 1.5474 - valid_acc: 0.7882 - class_acc: 0.4118\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1268 - valid_loss: 0.6718 - class_loss: 0.0678 - valid_acc: 0.4471 - class_acc: 0.9765\n","average v_acc: 61.765, three class acc: 41.176, two class acc: 58.824\n","====================================================================================================\n","STEP:540, D{v_l: 0.611, v_acc: [53.0| 75.0| 64.0], c_acc: [96.6| 90.6]}  G{v_l: 0.778, v_acc: 56.2, c_acc: 92.2}\n","STEP:541, D{v_l: 0.482, v_acc: [68.8| 78.1| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 1.137, v_acc: 45.3, c_acc: 95.3}\n","STEP:542, D{v_l: 0.538, v_acc: [71.9| 71.9| 71.9], c_acc: [81.2| 100.0]}  G{v_l: 1.020, v_acc: 51.6, c_acc: 96.9}\n","STEP:543, D{v_l: 0.720, v_acc: [53.1| 75.0| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 0.849, v_acc: 60.9, c_acc: 98.4}\n","STEP:544, D{v_l: 0.600, v_acc: [68.8| 71.9| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 1.165, v_acc: 46.9, c_acc: 95.3}\n","STEP:545, D{v_l: 0.721, v_acc: [62.5| 71.9| 67.2], c_acc: [87.5| 90.6]}  G{v_l: 0.804, v_acc: 65.6, c_acc: 96.9}\n","STEP:546, D{v_l: 0.611, v_acc: [59.4| 81.2| 70.3], c_acc: [78.1| 96.9]}  G{v_l: 0.953, v_acc: 50.0, c_acc: 96.9}\n","STEP:547, D{v_l: 0.638, v_acc: [68.8| 68.8| 68.8], c_acc: [87.5| 93.8]}  G{v_l: 0.952, v_acc: 51.6, c_acc: 93.8}\n","STEP:548, D{v_l: 0.617, v_acc: [65.6| 75.0| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.368, v_acc: 40.6, c_acc: 98.4}\n","STEP:549, D{v_l: 0.579, v_acc: [68.8| 78.1| 73.4], c_acc: [93.8| 90.6]}  G{v_l: 1.164, v_acc: 46.9, c_acc: 92.2}\n","STEP:550, D{v_l: 0.582, v_acc: [84.4| 56.2| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.139, v_acc: 54.7, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7179 - valid_loss: 0.5997 - class_loss: 1.7309 - valid_acc: 0.7294 - class_acc: 0.4353\n","3/3 [==============================] - 0s 49ms/step - loss: 1.3095 - valid_loss: 0.7959 - class_loss: 0.1264 - valid_acc: 0.2588 - class_acc: 0.9647\n","average v_acc: 49.412, three class acc: 43.529, two class acc: 56.471\n","====================================================================================================\n","Epoch: 50\n","====================================================================================================\n","STEP:551, D{v_l: 0.540, v_acc: [36.8| 81.2| 59.0], c_acc: [94.0| 90.6]}  G{v_l: 1.084, v_acc: 50.0, c_acc: 93.8}\n","STEP:552, D{v_l: 0.557, v_acc: [75.0| 78.1| 76.6], c_acc: [81.2| 96.9]}  G{v_l: 1.275, v_acc: 50.0, c_acc: 98.4}\n","STEP:553, D{v_l: 0.397, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.052, v_acc: 51.6, c_acc: 96.9}\n","STEP:554, D{v_l: 0.662, v_acc: [62.5| 78.1| 70.3], c_acc: [84.4| 87.5]}  G{v_l: 1.020, v_acc: 59.4, c_acc: 87.5}\n","STEP:555, D{v_l: 0.653, v_acc: [71.9| 71.9| 71.9], c_acc: [90.6| 100.0]}  G{v_l: 1.030, v_acc: 50.0, c_acc: 87.5}\n","STEP:556, D{v_l: 0.720, v_acc: [62.5| 62.5| 62.5], c_acc: [90.6| 90.6]}  G{v_l: 1.079, v_acc: 40.6, c_acc: 93.8}\n","STEP:557, D{v_l: 0.458, v_acc: [81.2| 87.5| 84.4], c_acc: [81.2| 96.9]}  G{v_l: 0.976, v_acc: 54.7, c_acc: 90.6}\n","STEP:558, D{v_l: 0.739, v_acc: [56.2| 68.8| 62.5], c_acc: [96.9| 100.0]}  G{v_l: 0.816, v_acc: 50.0, c_acc: 95.3}\n","STEP:559, D{v_l: 0.518, v_acc: [71.9| 90.6| 81.2], c_acc: [78.1| 93.8]}  G{v_l: 1.060, v_acc: 50.0, c_acc: 90.6}\n","STEP:560, D{v_l: 0.506, v_acc: [62.5| 78.1| 70.3], c_acc: [75.0| 100.0]}  G{v_l: 1.097, v_acc: 40.6, c_acc: 92.2}\n","STEP:561, D{v_l: 0.814, v_acc: [59.4| 62.5| 60.9], c_acc: [96.9| 93.8]}  G{v_l: 1.254, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.5673 - valid_loss: 0.5526 - class_loss: 1.6275 - valid_acc: 0.8353 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1242 - valid_loss: 0.6743 - class_loss: 0.0628 - valid_acc: 0.5176 - class_acc: 1.0000\n","average v_acc: 67.647, three class acc: 49.412, two class acc: 58.824\n","====================================================================================================\n","STEP:562, D{v_l: 0.643, v_acc: [59.0| 71.9| 65.4], c_acc: [96.6| 100.0]}  G{v_l: 0.922, v_acc: 53.1, c_acc: 98.4}\n","STEP:563, D{v_l: 0.494, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 93.8]}  G{v_l: 1.135, v_acc: 50.0, c_acc: 98.4}\n","STEP:564, D{v_l: 0.420, v_acc: [65.6| 87.5| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.539, v_acc: 35.9, c_acc: 93.8}\n","STEP:565, D{v_l: 0.585, v_acc: [81.2| 65.6| 73.4], c_acc: [96.9| 93.8]}  G{v_l: 1.035, v_acc: 43.8, c_acc: 93.8}\n","STEP:566, D{v_l: 0.666, v_acc: [75.0| 65.6| 70.3], c_acc: [81.2| 93.8]}  G{v_l: 1.070, v_acc: 46.9, c_acc: 98.4}\n","STEP:567, D{v_l: 0.458, v_acc: [87.5| 71.9| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 0.845, v_acc: 57.8, c_acc: 98.4}\n","STEP:568, D{v_l: 0.462, v_acc: [75.0| 84.4| 79.7], c_acc: [78.1| 96.9]}  G{v_l: 0.875, v_acc: 46.9, c_acc: 96.9}\n","STEP:569, D{v_l: 0.566, v_acc: [65.6| 87.5| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 1.113, v_acc: 50.0, c_acc: 96.9}\n","STEP:570, D{v_l: 0.415, v_acc: [90.6| 84.4| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 0.986, v_acc: 46.9, c_acc: 98.4}\n","STEP:571, D{v_l: 0.620, v_acc: [68.8| 75.0| 71.9], c_acc: [93.8| 93.8]}  G{v_l: 0.902, v_acc: 56.2, c_acc: 93.8}\n","STEP:572, D{v_l: 0.399, v_acc: [78.1| 87.5| 82.8], c_acc: [78.1| 93.8]}  G{v_l: 0.927, v_acc: 53.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.6049 - valid_loss: 0.5501 - class_loss: 1.6677 - valid_acc: 0.8000 - class_acc: 0.4471\n","3/3 [==============================] - 0s 45ms/step - loss: 1.3244 - valid_loss: 0.7382 - class_loss: 0.1990 - valid_acc: 0.4353 - class_acc: 0.9294\n","average v_acc: 61.765, three class acc: 44.706, two class acc: 58.824\n","====================================================================================================\n","STEP:573, D{v_l: 0.616, v_acc: [47.9| 78.1| 63.0], c_acc: [93.2| 96.9]}  G{v_l: 1.034, v_acc: 51.6, c_acc: 92.2}\n","STEP:574, D{v_l: 0.623, v_acc: [75.0| 68.8| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 0.785, v_acc: 57.8, c_acc: 95.3}\n","STEP:575, D{v_l: 0.471, v_acc: [81.2| 81.2| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 0.846, v_acc: 53.1, c_acc: 93.8}\n","STEP:576, D{v_l: 0.557, v_acc: [71.9| 68.8| 70.3], c_acc: [87.5| 84.4]}  G{v_l: 0.982, v_acc: 48.4, c_acc: 96.9}\n","STEP:577, D{v_l: 0.716, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 100.0]}  G{v_l: 0.967, v_acc: 53.1, c_acc: 96.9}\n","STEP:578, D{v_l: 0.615, v_acc: [68.8| 78.1| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 0.954, v_acc: 43.8, c_acc: 98.4}\n","STEP:579, D{v_l: 0.863, v_acc: [56.2| 75.0| 65.6], c_acc: [78.1| 90.6]}  G{v_l: 0.690, v_acc: 70.3, c_acc: 100.0}\n","STEP:580, D{v_l: 0.421, v_acc: [71.9| 84.4| 78.1], c_acc: [93.8| 93.8]}  G{v_l: 1.102, v_acc: 48.4, c_acc: 89.1}\n","STEP:581, D{v_l: 0.561, v_acc: [68.8| 81.2| 75.0], c_acc: [84.4| 100.0]}  G{v_l: 0.834, v_acc: 56.2, c_acc: 96.9}\n","STEP:582, D{v_l: 0.494, v_acc: [96.9| 78.1| 87.5], c_acc: [81.2| 96.9]}  G{v_l: 0.813, v_acc: 67.2, c_acc: 95.3}\n","STEP:583, D{v_l: 0.500, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 90.6]}  G{v_l: 1.250, v_acc: 48.4, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.4033 - valid_loss: 0.6867 - class_loss: 2.3294 - valid_acc: 0.5647 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.2675 - valid_loss: 0.7434 - class_loss: 0.1370 - valid_acc: 0.4235 - class_acc: 0.9647\n","average v_acc: 49.412, three class acc: 51.765, two class acc: 55.294\n","====================================================================================================\n","STEP:584, D{v_l: 0.657, v_acc: [51.3| 75.0| 63.1], c_acc: [94.9| 93.8]}  G{v_l: 0.944, v_acc: 46.9, c_acc: 96.9}\n","STEP:585, D{v_l: 0.468, v_acc: [84.4| 75.0| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.019, v_acc: 53.1, c_acc: 100.0}\n","STEP:586, D{v_l: 0.570, v_acc: [65.6| 78.1| 71.9], c_acc: [90.6| 93.8]}  G{v_l: 0.966, v_acc: 60.9, c_acc: 93.8}\n","STEP:587, D{v_l: 0.495, v_acc: [75.0| 71.9| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 0.927, v_acc: 54.7, c_acc: 92.2}\n","STEP:588, D{v_l: 0.543, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 0.897, v_acc: 62.5, c_acc: 93.8}\n","STEP:589, D{v_l: 0.451, v_acc: [75.0| 84.4| 79.7], c_acc: [84.4| 96.9]}  G{v_l: 0.751, v_acc: 67.2, c_acc: 90.6}\n","STEP:590, D{v_l: 0.518, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 0.981, v_acc: 59.4, c_acc: 92.2}\n","STEP:591, D{v_l: 0.525, v_acc: [87.5| 78.1| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.336, v_acc: 45.3, c_acc: 73.4}\n","STEP:592, D{v_l: 0.588, v_acc: [68.8| 75.0| 71.9], c_acc: [75.0| 93.8]}  G{v_l: 0.946, v_acc: 56.2, c_acc: 93.8}\n","STEP:593, D{v_l: 0.662, v_acc: [71.9| 71.9| 71.9], c_acc: [75.0| 93.8]}  G{v_l: 0.849, v_acc: 54.7, c_acc: 84.4}\n","STEP:594, D{v_l: 0.470, v_acc: [75.0| 65.6| 70.3], c_acc: [81.2| 96.9]}  G{v_l: 0.911, v_acc: 64.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.5035 - valid_loss: 0.5467 - class_loss: 1.5697 - valid_acc: 0.7647 - class_acc: 0.4471\n","3/3 [==============================] - 0s 48ms/step - loss: 1.4196 - valid_loss: 0.9333 - class_loss: 0.0992 - valid_acc: 0.2706 - class_acc: 0.9529\n","average v_acc: 51.765, three class acc: 44.706, two class acc: 61.176\n","====================================================================================================\n","STEP:595, D{v_l: 0.752, v_acc: [37.6| 62.5| 50.1], c_acc: [90.6| 96.9]}  G{v_l: 0.864, v_acc: 65.6, c_acc: 92.2}\n","STEP:596, D{v_l: 0.511, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 90.6]}  G{v_l: 1.389, v_acc: 51.6, c_acc: 93.8}\n","STEP:597, D{v_l: 0.398, v_acc: [78.1| 84.4| 81.2], c_acc: [84.4| 93.8]}  G{v_l: 1.164, v_acc: 40.6, c_acc: 90.6}\n","STEP:598, D{v_l: 0.446, v_acc: [84.4| 78.1| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.348, v_acc: 39.1, c_acc: 100.0}\n","STEP:599, D{v_l: 0.458, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 0.991, v_acc: 53.1, c_acc: 93.8}\n","STEP:600, D{v_l: 0.410, v_acc: [71.9| 87.5| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 1.103, v_acc: 51.6, c_acc: 87.5}\n","STEP:601, D{v_l: 0.433, v_acc: [87.5| 84.4| 85.9], c_acc: [90.6| 90.6]}  G{v_l: 0.793, v_acc: 56.2, c_acc: 93.8}\n","STEP:602, D{v_l: 0.566, v_acc: [59.4| 75.0| 67.2], c_acc: [90.6| 93.8]}  G{v_l: 1.139, v_acc: 35.9, c_acc: 90.6}\n","STEP:603, D{v_l: 0.432, v_acc: [84.4| 68.8| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 1.086, v_acc: 50.0, c_acc: 93.8}\n","STEP:604, D{v_l: 0.425, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.239, v_acc: 54.7, c_acc: 100.0}\n","STEP:605, D{v_l: 0.500, v_acc: [75.0| 84.4| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 1.241, v_acc: 43.8, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.6679 - valid_loss: 0.5947 - class_loss: 1.6862 - valid_acc: 0.7176 - class_acc: 0.4941\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0531 - valid_loss: 0.6447 - class_loss: 0.0214 - valid_acc: 0.5176 - class_acc: 1.0000\n","average v_acc: 61.765, three class acc: 49.412, two class acc: 60.000\n","====================================================================================================\n","STEP:606, D{v_l: 0.485, v_acc: [59.8| 84.4| 72.1], c_acc: [96.6| 100.0]}  G{v_l: 1.158, v_acc: 46.9, c_acc: 96.9}\n","STEP:607, D{v_l: 0.574, v_acc: [78.1| 78.1| 78.1], c_acc: [75.0| 96.9]}  G{v_l: 1.099, v_acc: 43.8, c_acc: 90.6}\n","STEP:608, D{v_l: 0.406, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.314, v_acc: 39.1, c_acc: 96.9}\n","STEP:609, D{v_l: 0.371, v_acc: [84.4| 71.9| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 0.906, v_acc: 53.1, c_acc: 95.3}\n","STEP:610, D{v_l: 0.434, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.832, v_acc: 59.4, c_acc: 92.2}\n","STEP:611, D{v_l: 0.500, v_acc: [75.0| 71.9| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 0.975, v_acc: 56.2, c_acc: 96.9}\n","STEP:612, D{v_l: 0.455, v_acc: [75.0| 81.2| 78.1], c_acc: [96.9| 93.8]}  G{v_l: 1.316, v_acc: 43.8, c_acc: 93.8}\n","STEP:613, D{v_l: 0.527, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.851, v_acc: 54.7, c_acc: 93.8}\n","STEP:614, D{v_l: 0.458, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.009, v_acc: 45.3, c_acc: 98.4}\n","STEP:615, D{v_l: 0.569, v_acc: [65.6| 65.6| 65.6], c_acc: [90.6| 100.0]}  G{v_l: 0.972, v_acc: 56.2, c_acc: 98.4}\n","STEP:616, D{v_l: 0.643, v_acc: [84.4| 62.5| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 0.876, v_acc: 59.4, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.9084 - valid_loss: 0.6453 - class_loss: 1.8760 - valid_acc: 0.6000 - class_acc: 0.4824\n","3/3 [==============================] - 0s 48ms/step - loss: 1.2810 - valid_loss: 0.8170 - class_loss: 0.0769 - valid_acc: 0.3529 - class_acc: 0.9765\n","average v_acc: 47.647, three class acc: 48.235, two class acc: 63.529\n","====================================================================================================\n","STEP:617, D{v_l: 0.691, v_acc: [48.7| 81.2| 65.0], c_acc: [95.7| 93.8]}  G{v_l: 1.092, v_acc: 56.2, c_acc: 93.8}\n","STEP:618, D{v_l: 0.526, v_acc: [68.8| 87.5| 78.1], c_acc: [84.4| 96.9]}  G{v_l: 1.091, v_acc: 46.9, c_acc: 93.8}\n","STEP:619, D{v_l: 0.620, v_acc: [68.8| 68.8| 68.8], c_acc: [90.6| 100.0]}  G{v_l: 1.006, v_acc: 60.9, c_acc: 92.2}\n","STEP:620, D{v_l: 0.516, v_acc: [71.9| 75.0| 73.4], c_acc: [81.2| 96.9]}  G{v_l: 1.038, v_acc: 53.1, c_acc: 96.9}\n","STEP:621, D{v_l: 0.530, v_acc: [75.0| 81.2| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 0.874, v_acc: 57.8, c_acc: 96.9}\n","STEP:622, D{v_l: 0.405, v_acc: [75.0| 93.8| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 1.127, v_acc: 57.8, c_acc: 95.3}\n","STEP:623, D{v_l: 0.406, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 1.107, v_acc: 46.9, c_acc: 96.9}\n","STEP:624, D{v_l: 0.382, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 0.996, v_acc: 56.2, c_acc: 87.5}\n","STEP:625, D{v_l: 0.471, v_acc: [78.1| 84.4| 81.2], c_acc: [81.2| 96.9]}  G{v_l: 0.940, v_acc: 50.0, c_acc: 95.3}\n","STEP:626, D{v_l: 0.480, v_acc: [68.8| 87.5| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 0.941, v_acc: 54.7, c_acc: 95.3}\n","STEP:627, D{v_l: 0.412, v_acc: [81.2| 84.4| 82.8], c_acc: [78.1| 100.0]}  G{v_l: 0.880, v_acc: 54.7, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9731 - valid_loss: 0.6316 - class_loss: 1.9546 - valid_acc: 0.6235 - class_acc: 0.4588\n","3/3 [==============================] - 0s 50ms/step - loss: 1.3691 - valid_loss: 0.8617 - class_loss: 0.1204 - valid_acc: 0.3412 - class_acc: 0.9294\n","average v_acc: 48.235, three class acc: 45.882, two class acc: 58.824\n","====================================================================================================\n","STEP:628, D{v_l: 0.655, v_acc: [46.2| 71.9| 59.0], c_acc: [91.5| 100.0]}  G{v_l: 0.758, v_acc: 68.8, c_acc: 95.3}\n","STEP:629, D{v_l: 0.508, v_acc: [71.9| 81.2| 76.6], c_acc: [75.0| 93.8]}  G{v_l: 0.790, v_acc: 57.8, c_acc: 82.8}\n","STEP:630, D{v_l: 0.594, v_acc: [78.1| 71.9| 75.0], c_acc: [81.2| 93.8]}  G{v_l: 0.988, v_acc: 51.6, c_acc: 92.2}\n","STEP:631, D{v_l: 0.561, v_acc: [68.8| 84.4| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.936, v_acc: 56.2, c_acc: 89.1}\n","STEP:632, D{v_l: 0.396, v_acc: [81.2| 87.5| 84.4], c_acc: [84.4| 96.9]}  G{v_l: 0.854, v_acc: 59.4, c_acc: 92.2}\n","STEP:633, D{v_l: 0.441, v_acc: [78.1| 78.1| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 0.977, v_acc: 56.2, c_acc: 90.6}\n","STEP:634, D{v_l: 0.529, v_acc: [68.8| 71.9| 70.3], c_acc: [84.4| 90.6]}  G{v_l: 0.868, v_acc: 57.8, c_acc: 95.3}\n","STEP:635, D{v_l: 0.395, v_acc: [81.2| 78.1| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 0.753, v_acc: 59.4, c_acc: 93.8}\n","STEP:636, D{v_l: 0.540, v_acc: [65.6| 81.2| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 0.796, v_acc: 67.2, c_acc: 93.8}\n","STEP:637, D{v_l: 0.684, v_acc: [75.0| 75.0| 75.0], c_acc: [96.9| 96.9]}  G{v_l: 0.827, v_acc: 56.2, c_acc: 92.2}\n","STEP:638, D{v_l: 0.494, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 90.6]}  G{v_l: 1.165, v_acc: 50.0, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.5899 - valid_loss: 0.9286 - class_loss: 2.2744 - valid_acc: 0.4118 - class_acc: 0.4941\n","3/3 [==============================] - 0s 45ms/step - loss: 1.5579 - valid_loss: 1.0814 - class_loss: 0.0896 - valid_acc: 0.2824 - class_acc: 0.9647\n","average v_acc: 34.706, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","STEP:639, D{v_l: 0.755, v_acc: [38.5| 75.0| 56.7], c_acc: [95.7| 96.9]}  G{v_l: 0.837, v_acc: 57.8, c_acc: 89.1}\n","STEP:640, D{v_l: 0.639, v_acc: [56.2| 75.0| 65.6], c_acc: [96.9| 90.6]}  G{v_l: 0.876, v_acc: 59.4, c_acc: 93.8}\n","STEP:641, D{v_l: 0.357, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 0.815, v_acc: 54.7, c_acc: 87.5}\n","STEP:642, D{v_l: 0.429, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.810, v_acc: 67.2, c_acc: 96.9}\n","STEP:643, D{v_l: 0.457, v_acc: [84.4| 81.2| 82.8], c_acc: [84.4| 93.8]}  G{v_l: 0.789, v_acc: 60.9, c_acc: 90.6}\n","STEP:644, D{v_l: 0.603, v_acc: [75.0| 68.8| 71.9], c_acc: [90.6| 100.0]}  G{v_l: 0.797, v_acc: 57.8, c_acc: 90.6}\n","STEP:645, D{v_l: 0.621, v_acc: [75.0| 78.1| 76.6], c_acc: [96.9| 87.5]}  G{v_l: 0.870, v_acc: 53.1, c_acc: 98.4}\n","STEP:646, D{v_l: 0.495, v_acc: [65.6| 81.2| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 0.976, v_acc: 57.8, c_acc: 96.9}\n","STEP:647, D{v_l: 0.542, v_acc: [81.2| 68.8| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.341, v_acc: 45.3, c_acc: 96.9}\n","STEP:648, D{v_l: 0.715, v_acc: [65.6| 75.0| 70.3], c_acc: [93.8| 87.5]}  G{v_l: 1.038, v_acc: 57.8, c_acc: 98.4}\n","STEP:649, D{v_l: 0.555, v_acc: [81.2| 68.8| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.177, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.6031 - valid_loss: 0.8737 - class_loss: 2.3425 - valid_acc: 0.3765 - class_acc: 0.4941\n","3/3 [==============================] - 0s 51ms/step - loss: 1.2773 - valid_loss: 0.8374 - class_loss: 0.0530 - valid_acc: 0.4000 - class_acc: 1.0000\n","average v_acc: 38.824, three class acc: 49.412, two class acc: 57.647\n","====================================================================================================\n","STEP:650, D{v_l: 0.615, v_acc: [47.0| 84.4| 65.7], c_acc: [98.3| 93.8]}  G{v_l: 1.204, v_acc: 51.6, c_acc: 96.9}\n","STEP:651, D{v_l: 0.554, v_acc: [81.2| 75.0| 78.1], c_acc: [81.2| 100.0]}  G{v_l: 1.104, v_acc: 50.0, c_acc: 95.3}\n","STEP:652, D{v_l: 0.396, v_acc: [75.0| 84.4| 79.7], c_acc: [84.4| 93.8]}  G{v_l: 0.931, v_acc: 48.4, c_acc: 87.5}\n","STEP:653, D{v_l: 0.549, v_acc: [78.1| 68.8| 73.4], c_acc: [96.9| 100.0]}  G{v_l: 0.742, v_acc: 62.5, c_acc: 96.9}\n","STEP:654, D{v_l: 0.547, v_acc: [68.8| 81.2| 75.0], c_acc: [87.5| 96.9]}  G{v_l: 0.961, v_acc: 50.0, c_acc: 93.8}\n","STEP:655, D{v_l: 0.484, v_acc: [81.2| 71.9| 76.6], c_acc: [100.0| 90.6]}  G{v_l: 0.828, v_acc: 59.4, c_acc: 95.3}\n","STEP:656, D{v_l: 0.333, v_acc: [87.5| 84.4| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.175, v_acc: 46.9, c_acc: 95.3}\n","STEP:657, D{v_l: 0.393, v_acc: [84.4| 71.9| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 1.060, v_acc: 53.1, c_acc: 89.1}\n","STEP:658, D{v_l: 0.567, v_acc: [62.5| 78.1| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 1.293, v_acc: 40.6, c_acc: 92.2}\n","STEP:659, D{v_l: 0.445, v_acc: [78.1| 78.1| 78.1], c_acc: [81.2| 93.8]}  G{v_l: 1.028, v_acc: 54.7, c_acc: 90.6}\n","STEP:660, D{v_l: 0.543, v_acc: [65.6| 71.9| 68.8], c_acc: [84.4| 90.6]}  G{v_l: 0.978, v_acc: 64.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9583 - valid_loss: 0.6719 - class_loss: 1.8995 - valid_acc: 0.6118 - class_acc: 0.4588\n","3/3 [==============================] - 0s 46ms/step - loss: 1.2411 - valid_loss: 0.6827 - class_loss: 0.1715 - valid_acc: 0.4235 - class_acc: 0.9412\n","average v_acc: 51.765, three class acc: 45.882, two class acc: 61.176\n","====================================================================================================\n","Epoch: 60\n","====================================================================================================\n","STEP:661, D{v_l: 0.537, v_acc: [51.3| 75.0| 63.1], c_acc: [94.9| 96.9]}  G{v_l: 1.207, v_acc: 50.0, c_acc: 85.9}\n","STEP:662, D{v_l: 0.646, v_acc: [71.9| 65.6| 68.8], c_acc: [96.9| 96.9]}  G{v_l: 1.419, v_acc: 46.9, c_acc: 89.1}\n","STEP:663, D{v_l: 0.581, v_acc: [78.1| 71.9| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 1.479, v_acc: 53.1, c_acc: 96.9}\n","STEP:664, D{v_l: 0.435, v_acc: [81.2| 84.4| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 0.922, v_acc: 62.5, c_acc: 95.3}\n","STEP:665, D{v_l: 0.387, v_acc: [68.8| 90.6| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 0.904, v_acc: 43.8, c_acc: 98.4}\n","STEP:666, D{v_l: 0.407, v_acc: [75.0| 75.0| 75.0], c_acc: [78.1| 100.0]}  G{v_l: 1.278, v_acc: 46.9, c_acc: 96.9}\n","STEP:667, D{v_l: 0.757, v_acc: [56.2| 81.2| 68.8], c_acc: [93.8| 93.8]}  G{v_l: 1.230, v_acc: 50.0, c_acc: 95.3}\n","STEP:668, D{v_l: 0.425, v_acc: [65.6| 75.0| 70.3], c_acc: [90.6| 100.0]}  G{v_l: 1.155, v_acc: 53.1, c_acc: 93.8}\n","STEP:669, D{v_l: 0.438, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.030, v_acc: 46.9, c_acc: 95.3}\n","STEP:670, D{v_l: 0.333, v_acc: [90.6| 87.5| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 1.189, v_acc: 46.9, c_acc: 95.3}\n","STEP:671, D{v_l: 0.498, v_acc: [65.6| 87.5| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 1.054, v_acc: 50.0, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.9832 - valid_loss: 0.3782 - class_loss: 2.2182 - valid_acc: 0.8941 - class_acc: 0.2353\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1885 - valid_loss: 0.7592 - class_loss: 0.0425 - valid_acc: 0.4235 - class_acc: 0.9882\n","average v_acc: 65.882, three class acc: 23.529, two class acc: 50.588\n","====================================================================================================\n","STEP:672, D{v_l: 0.578, v_acc: [53.0| 75.0| 64.0], c_acc: [94.0| 93.8]}  G{v_l: 0.902, v_acc: 50.0, c_acc: 96.9}\n","STEP:673, D{v_l: 0.530, v_acc: [71.9| 75.0| 73.4], c_acc: [90.6| 100.0]}  G{v_l: 1.112, v_acc: 48.4, c_acc: 92.2}\n","STEP:674, D{v_l: 0.383, v_acc: [84.4| 78.1| 81.2], c_acc: [84.4| 100.0]}  G{v_l: 0.953, v_acc: 54.7, c_acc: 96.9}\n","STEP:675, D{v_l: 0.376, v_acc: [78.1| 90.6| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 0.885, v_acc: 54.7, c_acc: 95.3}\n","STEP:676, D{v_l: 0.409, v_acc: [84.4| 78.1| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.095, v_acc: 46.9, c_acc: 98.4}\n","STEP:677, D{v_l: 0.457, v_acc: [78.1| 87.5| 82.8], c_acc: [84.4| 100.0]}  G{v_l: 1.030, v_acc: 46.9, c_acc: 96.9}\n","STEP:678, D{v_l: 0.609, v_acc: [71.9| 84.4| 78.1], c_acc: [87.5| 100.0]}  G{v_l: 1.035, v_acc: 54.7, c_acc: 100.0}\n","STEP:679, D{v_l: 0.483, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 100.0]}  G{v_l: 0.973, v_acc: 56.2, c_acc: 98.4}\n","STEP:680, D{v_l: 0.434, v_acc: [84.4| 81.2| 82.8], c_acc: [81.2| 96.9]}  G{v_l: 0.936, v_acc: 56.2, c_acc: 96.9}\n","STEP:681, D{v_l: 0.422, v_acc: [68.8| 90.6| 79.7], c_acc: [93.8| 93.8]}  G{v_l: 1.158, v_acc: 43.8, c_acc: 95.3}\n","STEP:682, D{v_l: 0.548, v_acc: [65.6| 84.4| 75.0], c_acc: [90.6| 100.0]}  G{v_l: 1.257, v_acc: 45.3, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.4599 - valid_loss: 0.5206 - class_loss: 1.5524 - valid_acc: 0.7529 - class_acc: 0.4118\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1618 - valid_loss: 0.6765 - class_loss: 0.0985 - valid_acc: 0.4706 - class_acc: 0.9647\n","average v_acc: 61.176, three class acc: 41.176, two class acc: 61.176\n","====================================================================================================\n","STEP:683, D{v_l: 0.516, v_acc: [56.4| 75.0| 65.7], c_acc: [94.0| 93.8]}  G{v_l: 1.086, v_acc: 48.4, c_acc: 96.9}\n","STEP:684, D{v_l: 0.553, v_acc: [75.0| 78.1| 76.6], c_acc: [84.4| 100.0]}  G{v_l: 1.042, v_acc: 50.0, c_acc: 90.6}\n","STEP:685, D{v_l: 0.455, v_acc: [78.1| 87.5| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 0.970, v_acc: 54.7, c_acc: 93.8}\n","STEP:686, D{v_l: 0.434, v_acc: [65.6| 93.8| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 1.037, v_acc: 45.3, c_acc: 96.9}\n","STEP:687, D{v_l: 0.590, v_acc: [75.0| 78.1| 76.6], c_acc: [96.9| 93.8]}  G{v_l: 0.867, v_acc: 59.4, c_acc: 95.3}\n","STEP:688, D{v_l: 0.462, v_acc: [75.0| 71.9| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 1.119, v_acc: 48.4, c_acc: 96.9}\n","STEP:689, D{v_l: 0.537, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 90.6]}  G{v_l: 0.884, v_acc: 50.0, c_acc: 95.3}\n","STEP:690, D{v_l: 0.448, v_acc: [75.0| 81.2| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.080, v_acc: 43.8, c_acc: 93.8}\n","STEP:691, D{v_l: 0.423, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 1.112, v_acc: 45.3, c_acc: 90.6}\n","STEP:692, D{v_l: 0.434, v_acc: [78.1| 84.4| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.178, v_acc: 50.0, c_acc: 93.8}\n","STEP:693, D{v_l: 0.332, v_acc: [84.4| 87.5| 85.9], c_acc: [100.0| 96.9]}  G{v_l: 1.361, v_acc: 42.2, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7211 - valid_loss: 0.5930 - class_loss: 1.7414 - valid_acc: 0.6706 - class_acc: 0.4588\n","3/3 [==============================] - 0s 49ms/step - loss: 1.2138 - valid_loss: 0.6169 - class_loss: 0.2101 - valid_acc: 0.6588 - class_acc: 0.9059\n","average v_acc: 66.471, three class acc: 45.882, two class acc: 62.353\n","====================================================================================================\n","STEP:694, D{v_l: 0.678, v_acc: [66.7| 75.0| 70.8], c_acc: [91.5| 100.0]}  G{v_l: 1.195, v_acc: 48.4, c_acc: 79.7}\n","STEP:695, D{v_l: 0.370, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.086, v_acc: 46.9, c_acc: 93.8}\n","STEP:696, D{v_l: 0.541, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.429, v_acc: 46.9, c_acc: 98.4}\n","STEP:697, D{v_l: 0.403, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 1.303, v_acc: 39.1, c_acc: 95.3}\n","STEP:698, D{v_l: 0.358, v_acc: [75.0| 81.2| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.039, v_acc: 48.4, c_acc: 89.1}\n","STEP:699, D{v_l: 0.379, v_acc: [81.2| 93.8| 87.5], c_acc: [93.8| 100.0]}  G{v_l: 1.072, v_acc: 40.6, c_acc: 96.9}\n","STEP:700, D{v_l: 0.538, v_acc: [75.0| 78.1| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 0.875, v_acc: 54.7, c_acc: 96.9}\n","STEP:701, D{v_l: 0.267, v_acc: [90.6| 93.8| 92.2], c_acc: [84.4| 100.0]}  G{v_l: 1.403, v_acc: 39.1, c_acc: 96.9}\n","STEP:702, D{v_l: 0.511, v_acc: [87.5| 71.9| 79.7], c_acc: [84.4| 100.0]}  G{v_l: 1.099, v_acc: 48.4, c_acc: 90.6}\n","STEP:703, D{v_l: 0.266, v_acc: [100.0| 87.5| 93.8], c_acc: [96.9| 100.0]}  G{v_l: 0.991, v_acc: 56.2, c_acc: 95.3}\n","STEP:704, D{v_l: 0.454, v_acc: [75.0| 75.0| 75.0], c_acc: [100.0| 90.6]}  G{v_l: 1.324, v_acc: 42.2, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.4430 - valid_loss: 0.5030 - class_loss: 1.5533 - valid_acc: 0.7765 - class_acc: 0.4235\n","3/3 [==============================] - 0s 45ms/step - loss: 1.1056 - valid_loss: 0.6874 - class_loss: 0.0315 - valid_acc: 0.5059 - class_acc: 1.0000\n","average v_acc: 64.118, three class acc: 42.353, two class acc: 57.647\n","====================================================================================================\n","STEP:705, D{v_l: 0.541, v_acc: [57.3| 87.5| 72.4], c_acc: [96.6| 93.8]}  G{v_l: 0.919, v_acc: 64.1, c_acc: 90.6}\n","STEP:706, D{v_l: 0.322, v_acc: [71.9| 93.8| 82.8], c_acc: [81.2| 100.0]}  G{v_l: 1.128, v_acc: 39.1, c_acc: 100.0}\n","STEP:707, D{v_l: 0.329, v_acc: [81.2| 93.8| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 1.469, v_acc: 35.9, c_acc: 95.3}\n","STEP:708, D{v_l: 0.510, v_acc: [71.9| 93.8| 82.8], c_acc: [84.4| 93.8]}  G{v_l: 0.961, v_acc: 53.1, c_acc: 95.3}\n","STEP:709, D{v_l: 0.508, v_acc: [65.6| 87.5| 76.6], c_acc: [81.2| 96.9]}  G{v_l: 0.794, v_acc: 60.9, c_acc: 96.9}\n","STEP:710, D{v_l: 0.303, v_acc: [93.8| 81.2| 87.5], c_acc: [87.5| 90.6]}  G{v_l: 1.025, v_acc: 53.1, c_acc: 95.3}\n","STEP:711, D{v_l: 0.386, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 87.5]}  G{v_l: 0.882, v_acc: 65.6, c_acc: 93.8}\n","STEP:712, D{v_l: 0.362, v_acc: [90.6| 78.1| 84.4], c_acc: [90.6| 87.5]}  G{v_l: 0.852, v_acc: 51.6, c_acc: 90.6}\n","STEP:713, D{v_l: 0.395, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 0.947, v_acc: 51.6, c_acc: 95.3}\n","STEP:714, D{v_l: 0.400, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 90.6]}  G{v_l: 1.042, v_acc: 53.1, c_acc: 92.2}\n","STEP:715, D{v_l: 0.412, v_acc: [71.9| 84.4| 78.1], c_acc: [96.9| 100.0]}  G{v_l: 0.875, v_acc: 57.8, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.9526 - valid_loss: 0.6034 - class_loss: 1.9624 - valid_acc: 0.6118 - class_acc: 0.3765\n","3/3 [==============================] - 0s 47ms/step - loss: 1.2287 - valid_loss: 0.7333 - class_loss: 0.1087 - valid_acc: 0.4824 - class_acc: 0.9647\n","average v_acc: 54.706, three class acc: 37.647, two class acc: 61.176\n","====================================================================================================\n","STEP:716, D{v_l: 0.537, v_acc: [57.3| 81.2| 69.3], c_acc: [94.9| 93.8]}  G{v_l: 0.807, v_acc: 53.1, c_acc: 95.3}\n","STEP:717, D{v_l: 0.499, v_acc: [78.1| 68.8| 73.4], c_acc: [84.4| 90.6]}  G{v_l: 1.134, v_acc: 45.3, c_acc: 98.4}\n","STEP:718, D{v_l: 0.545, v_acc: [68.8| 81.2| 75.0], c_acc: [87.5| 93.8]}  G{v_l: 1.155, v_acc: 45.3, c_acc: 96.9}\n","STEP:719, D{v_l: 0.579, v_acc: [71.9| 71.9| 71.9], c_acc: [96.9| 93.8]}  G{v_l: 1.182, v_acc: 40.6, c_acc: 98.4}\n","STEP:720, D{v_l: 0.381, v_acc: [81.2| 84.4| 82.8], c_acc: [87.5| 96.9]}  G{v_l: 0.808, v_acc: 54.7, c_acc: 92.2}\n","STEP:721, D{v_l: 0.576, v_acc: [81.2| 81.2| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 0.871, v_acc: 57.8, c_acc: 96.9}\n","STEP:722, D{v_l: 0.288, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 1.225, v_acc: 53.1, c_acc: 98.4}\n","STEP:723, D{v_l: 0.513, v_acc: [71.9| 71.9| 71.9], c_acc: [96.9| 84.4]}  G{v_l: 0.990, v_acc: 51.6, c_acc: 84.4}\n","STEP:724, D{v_l: 0.485, v_acc: [87.5| 71.9| 79.7], c_acc: [100.0| 90.6]}  G{v_l: 0.889, v_acc: 54.7, c_acc: 87.5}\n","STEP:725, D{v_l: 0.385, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 0.984, v_acc: 56.2, c_acc: 84.4}\n","STEP:726, D{v_l: 0.477, v_acc: [71.9| 81.2| 76.6], c_acc: [81.2| 93.8]}  G{v_l: 1.082, v_acc: 51.6, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.7006 - valid_loss: 0.4534 - class_loss: 1.8605 - valid_acc: 0.8588 - class_acc: 0.2824\n","3/3 [==============================] - 0s 46ms/step - loss: 1.3182 - valid_loss: 0.7659 - class_loss: 0.1656 - valid_acc: 0.4588 - class_acc: 0.9412\n","average v_acc: 65.882, three class acc: 28.235, two class acc: 54.118\n","====================================================================================================\n","STEP:727, D{v_l: 0.529, v_acc: [53.8| 78.1| 66.0], c_acc: [93.2| 96.9]}  G{v_l: 1.315, v_acc: 43.8, c_acc: 96.9}\n","STEP:728, D{v_l: 0.494, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 93.8]}  G{v_l: 1.140, v_acc: 48.4, c_acc: 95.3}\n","STEP:729, D{v_l: 0.463, v_acc: [68.8| 90.6| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.018, v_acc: 64.1, c_acc: 93.8}\n","STEP:730, D{v_l: 0.453, v_acc: [75.0| 71.9| 73.4], c_acc: [100.0| 90.6]}  G{v_l: 1.292, v_acc: 45.3, c_acc: 89.1}\n","STEP:731, D{v_l: 0.665, v_acc: [71.9| 81.2| 76.6], c_acc: [87.5| 90.6]}  G{v_l: 1.224, v_acc: 43.8, c_acc: 93.8}\n","STEP:732, D{v_l: 0.507, v_acc: [96.9| 65.6| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 0.982, v_acc: 54.7, c_acc: 100.0}\n","STEP:733, D{v_l: 0.573, v_acc: [71.9| 90.6| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 1.026, v_acc: 42.2, c_acc: 98.4}\n","STEP:734, D{v_l: 0.414, v_acc: [78.1| 84.4| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 1.067, v_acc: 50.0, c_acc: 92.2}\n","STEP:735, D{v_l: 0.410, v_acc: [78.1| 81.2| 79.7], c_acc: [84.4| 96.9]}  G{v_l: 1.149, v_acc: 62.5, c_acc: 98.4}\n","STEP:736, D{v_l: 0.396, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 0.983, v_acc: 53.1, c_acc: 96.9}\n","STEP:737, D{v_l: 0.235, v_acc: [90.6| 90.6| 90.6], c_acc: [90.6| 100.0]}  G{v_l: 0.992, v_acc: 50.0, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.8432 - valid_loss: 0.5364 - class_loss: 1.9202 - valid_acc: 0.7059 - class_acc: 0.3294\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1683 - valid_loss: 0.7296 - class_loss: 0.0521 - valid_acc: 0.4824 - class_acc: 0.9765\n","average v_acc: 59.412, three class acc: 32.941, two class acc: 56.471\n","====================================================================================================\n","STEP:738, D{v_l: 0.503, v_acc: [56.4| 84.4| 70.4], c_acc: [94.0| 93.8]}  G{v_l: 1.018, v_acc: 48.4, c_acc: 98.4}\n","STEP:739, D{v_l: 0.427, v_acc: [75.0| 81.2| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.117, v_acc: 45.3, c_acc: 96.9}\n","STEP:740, D{v_l: 0.415, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.054, v_acc: 57.8, c_acc: 100.0}\n","STEP:741, D{v_l: 0.239, v_acc: [90.6| 90.6| 90.6], c_acc: [90.6| 96.9]}  G{v_l: 0.942, v_acc: 48.4, c_acc: 92.2}\n","STEP:742, D{v_l: 0.518, v_acc: [71.9| 71.9| 71.9], c_acc: [87.5| 96.9]}  G{v_l: 1.191, v_acc: 53.1, c_acc: 95.3}\n","STEP:743, D{v_l: 0.682, v_acc: [78.1| 65.6| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 0.886, v_acc: 53.1, c_acc: 90.6}\n","STEP:744, D{v_l: 0.358, v_acc: [78.1| 93.8| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.172, v_acc: 51.6, c_acc: 98.4}\n","STEP:745, D{v_l: 0.308, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 1.030, v_acc: 64.1, c_acc: 96.9}\n","STEP:746, D{v_l: 0.387, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.899, v_acc: 54.7, c_acc: 93.8}\n","STEP:747, D{v_l: 0.382, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.886, v_acc: 60.9, c_acc: 89.1}\n","STEP:748, D{v_l: 0.574, v_acc: [75.0| 71.9| 73.4], c_acc: [93.8| 96.9]}  G{v_l: 0.875, v_acc: 54.7, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.8947 - valid_loss: 0.6672 - class_loss: 1.8410 - valid_acc: 0.5765 - class_acc: 0.5176\n","3/3 [==============================] - 0s 46ms/step - loss: 1.5255 - valid_loss: 0.9652 - class_loss: 0.1738 - valid_acc: 0.3294 - class_acc: 0.9059\n","average v_acc: 45.294, three class acc: 51.765, two class acc: 61.176\n","====================================================================================================\n","STEP:749, D{v_l: 0.644, v_acc: [47.0| 78.1| 62.6], c_acc: [92.3| 93.8]}  G{v_l: 0.816, v_acc: 54.7, c_acc: 96.9}\n","STEP:750, D{v_l: 0.578, v_acc: [62.5| 81.2| 71.9], c_acc: [87.5| 93.8]}  G{v_l: 0.938, v_acc: 64.1, c_acc: 90.6}\n","STEP:751, D{v_l: 0.370, v_acc: [71.9| 84.4| 78.1], c_acc: [96.9| 90.6]}  G{v_l: 0.786, v_acc: 62.5, c_acc: 95.3}\n","STEP:752, D{v_l: 0.362, v_acc: [84.4| 81.2| 82.8], c_acc: [100.0| 93.8]}  G{v_l: 0.896, v_acc: 59.4, c_acc: 84.4}\n","STEP:753, D{v_l: 0.425, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 90.6]}  G{v_l: 0.710, v_acc: 67.2, c_acc: 92.2}\n","STEP:754, D{v_l: 0.512, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.014, v_acc: 64.1, c_acc: 90.6}\n","STEP:755, D{v_l: 0.490, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.635, v_acc: 75.0, c_acc: 95.3}\n","STEP:756, D{v_l: 0.298, v_acc: [84.4| 90.6| 87.5], c_acc: [87.5| 96.9]}  G{v_l: 1.000, v_acc: 57.8, c_acc: 98.4}\n","STEP:757, D{v_l: 0.409, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 93.8]}  G{v_l: 0.692, v_acc: 65.6, c_acc: 89.1}\n","STEP:758, D{v_l: 0.441, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.893, v_acc: 57.8, c_acc: 85.9}\n","STEP:759, D{v_l: 0.413, v_acc: [75.0| 81.2| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 0.703, v_acc: 60.9, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.9449 - valid_loss: 0.7246 - class_loss: 1.8339 - valid_acc: 0.5412 - class_acc: 0.4471\n","3/3 [==============================] - 0s 47ms/step - loss: 1.7610 - valid_loss: 1.0293 - class_loss: 0.3453 - valid_acc: 0.2706 - class_acc: 0.9059\n","average v_acc: 40.588, three class acc: 44.706, two class acc: 57.647\n","====================================================================================================\n","STEP:760, D{v_l: 0.650, v_acc: [41.0| 78.1| 59.6], c_acc: [91.5| 96.9]}  G{v_l: 1.048, v_acc: 48.4, c_acc: 85.9}\n","STEP:761, D{v_l: 0.543, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 90.6]}  G{v_l: 0.687, v_acc: 64.1, c_acc: 89.1}\n","STEP:762, D{v_l: 0.677, v_acc: [78.1| 68.8| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 1.074, v_acc: 45.3, c_acc: 87.5}\n","STEP:763, D{v_l: 0.458, v_acc: [75.0| 78.1| 76.6], c_acc: [100.0| 96.9]}  G{v_l: 0.981, v_acc: 59.4, c_acc: 100.0}\n","STEP:764, D{v_l: 0.449, v_acc: [78.1| 90.6| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.264, v_acc: 53.1, c_acc: 89.1}\n","STEP:765, D{v_l: 0.388, v_acc: [75.0| 84.4| 79.7], c_acc: [93.8| 93.8]}  G{v_l: 1.145, v_acc: 53.1, c_acc: 92.2}\n","STEP:766, D{v_l: 0.533, v_acc: [65.6| 84.4| 75.0], c_acc: [90.6| 90.6]}  G{v_l: 0.925, v_acc: 54.7, c_acc: 98.4}\n","STEP:767, D{v_l: 0.449, v_acc: [93.8| 71.9| 82.8], c_acc: [93.8| 87.5]}  G{v_l: 1.138, v_acc: 51.6, c_acc: 96.9}\n","STEP:768, D{v_l: 0.312, v_acc: [78.1| 96.9| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.902, v_acc: 46.9, c_acc: 98.4}\n","STEP:769, D{v_l: 0.437, v_acc: [78.1| 87.5| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 1.273, v_acc: 39.1, c_acc: 93.8}\n","STEP:770, D{v_l: 0.454, v_acc: [81.2| 71.9| 76.6], c_acc: [96.9| 93.8]}  G{v_l: 1.015, v_acc: 50.0, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.0577 - valid_loss: 0.7072 - class_loss: 1.9641 - valid_acc: 0.5294 - class_acc: 0.4706\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1142 - valid_loss: 0.6881 - class_loss: 0.0396 - valid_acc: 0.5176 - class_acc: 0.9882\n","average v_acc: 52.353, three class acc: 47.059, two class acc: 58.824\n","====================================================================================================\n","Epoch: 70\n","====================================================================================================\n","STEP:771, D{v_l: 0.419, v_acc: [61.5| 84.4| 73.0], c_acc: [97.4| 96.9]}  G{v_l: 0.956, v_acc: 51.6, c_acc: 92.2}\n","STEP:772, D{v_l: 0.407, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 93.8]}  G{v_l: 1.038, v_acc: 51.6, c_acc: 96.9}\n","STEP:773, D{v_l: 0.323, v_acc: [71.9| 90.6| 81.2], c_acc: [84.4| 96.9]}  G{v_l: 0.802, v_acc: 57.8, c_acc: 90.6}\n","STEP:774, D{v_l: 0.375, v_acc: [87.5| 93.8| 90.6], c_acc: [84.4| 96.9]}  G{v_l: 1.110, v_acc: 45.3, c_acc: 89.1}\n","STEP:775, D{v_l: 0.404, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.430, v_acc: 37.5, c_acc: 90.6}\n","STEP:776, D{v_l: 0.342, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.826, v_acc: 54.7, c_acc: 93.8}\n","STEP:777, D{v_l: 0.597, v_acc: [71.9| 78.1| 75.0], c_acc: [100.0| 100.0]}  G{v_l: 1.114, v_acc: 48.4, c_acc: 90.6}\n","STEP:778, D{v_l: 0.346, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.958, v_acc: 53.1, c_acc: 93.8}\n","STEP:779, D{v_l: 0.366, v_acc: [78.1| 87.5| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 0.907, v_acc: 67.2, c_acc: 92.2}\n","STEP:780, D{v_l: 0.366, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 93.8]}  G{v_l: 1.022, v_acc: 53.1, c_acc: 100.0}\n","STEP:781, D{v_l: 0.303, v_acc: [90.6| 78.1| 84.4], c_acc: [90.6| 93.8]}  G{v_l: 0.924, v_acc: 46.9, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.8092 - valid_loss: 0.6204 - class_loss: 1.8024 - valid_acc: 0.6588 - class_acc: 0.4471\n","3/3 [==============================] - 0s 45ms/step - loss: 1.2587 - valid_loss: 0.8248 - class_loss: 0.0476 - valid_acc: 0.4353 - class_acc: 0.9882\n","average v_acc: 54.706, three class acc: 44.706, two class acc: 62.353\n","====================================================================================================\n","STEP:782, D{v_l: 0.488, v_acc: [55.6| 87.5| 71.5], c_acc: [99.1| 96.9]}  G{v_l: 1.174, v_acc: 43.8, c_acc: 95.3}\n","STEP:783, D{v_l: 0.437, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 93.8]}  G{v_l: 0.933, v_acc: 54.7, c_acc: 95.3}\n","STEP:784, D{v_l: 0.418, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 0.834, v_acc: 57.8, c_acc: 96.9}\n","STEP:785, D{v_l: 0.308, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 0.674, v_acc: 68.8, c_acc: 90.6}\n","STEP:786, D{v_l: 0.426, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 90.6]}  G{v_l: 0.897, v_acc: 56.2, c_acc: 92.2}\n","STEP:787, D{v_l: 0.378, v_acc: [84.4| 78.1| 81.2], c_acc: [96.9| 90.6]}  G{v_l: 0.833, v_acc: 54.7, c_acc: 87.5}\n","STEP:788, D{v_l: 0.413, v_acc: [81.2| 81.2| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.041, v_acc: 57.8, c_acc: 98.4}\n","STEP:789, D{v_l: 0.388, v_acc: [87.5| 93.8| 90.6], c_acc: [90.6| 87.5]}  G{v_l: 0.881, v_acc: 56.2, c_acc: 96.9}\n","STEP:790, D{v_l: 0.388, v_acc: [87.5| 90.6| 89.1], c_acc: [87.5| 87.5]}  G{v_l: 0.833, v_acc: 57.8, c_acc: 89.1}\n","STEP:791, D{v_l: 0.440, v_acc: [81.2| 81.2| 81.2], c_acc: [81.2| 100.0]}  G{v_l: 0.529, v_acc: 70.3, c_acc: 84.4}\n","STEP:792, D{v_l: 0.383, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 93.8]}  G{v_l: 0.831, v_acc: 67.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 4.3899 - valid_loss: 1.2853 - class_loss: 2.7183 - valid_acc: 0.2471 - class_acc: 0.5412\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8199 - valid_loss: 1.1986 - class_loss: 0.2350 - valid_acc: 0.2706 - class_acc: 0.9059\n","average v_acc: 25.882, three class acc: 54.118, two class acc: 62.353\n","====================================================================================================\n","STEP:793, D{v_l: 0.596, v_acc: [43.6| 84.4| 64.0], c_acc: [90.6| 93.8]}  G{v_l: 0.849, v_acc: 62.5, c_acc: 84.4}\n","STEP:794, D{v_l: 0.317, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 90.6]}  G{v_l: 1.065, v_acc: 50.0, c_acc: 95.3}\n","STEP:795, D{v_l: 0.446, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 87.5]}  G{v_l: 0.816, v_acc: 59.4, c_acc: 90.6}\n","STEP:796, D{v_l: 0.329, v_acc: [93.8| 84.4| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.826, v_acc: 56.2, c_acc: 96.9}\n","STEP:797, D{v_l: 0.502, v_acc: [81.2| 65.6| 73.4], c_acc: [96.9| 81.2]}  G{v_l: 0.881, v_acc: 53.1, c_acc: 92.2}\n","STEP:798, D{v_l: 0.600, v_acc: [65.6| 68.8| 67.2], c_acc: [78.1| 96.9]}  G{v_l: 0.745, v_acc: 57.8, c_acc: 96.9}\n","STEP:799, D{v_l: 0.317, v_acc: [84.4| 87.5| 85.9], c_acc: [81.2| 90.6]}  G{v_l: 0.966, v_acc: 51.6, c_acc: 98.4}\n","STEP:800, D{v_l: 0.358, v_acc: [93.8| 87.5| 90.6], c_acc: [90.6| 93.8]}  G{v_l: 0.912, v_acc: 60.9, c_acc: 93.8}\n","STEP:801, D{v_l: 0.342, v_acc: [87.5| 84.4| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 0.967, v_acc: 56.2, c_acc: 98.4}\n","STEP:802, D{v_l: 0.387, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.788, v_acc: 62.5, c_acc: 98.4}\n","STEP:803, D{v_l: 0.495, v_acc: [75.0| 84.4| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 1.007, v_acc: 53.1, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.7783 - valid_loss: 0.8921 - class_loss: 2.4999 - valid_acc: 0.3765 - class_acc: 0.5529\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8030 - valid_loss: 1.0878 - class_loss: 0.3289 - valid_acc: 0.2588 - class_acc: 0.8824\n","average v_acc: 31.765, three class acc: 55.294, two class acc: 61.176\n","====================================================================================================\n","STEP:804, D{v_l: 0.861, v_acc: [41.9| 75.0| 58.4], c_acc: [89.7| 87.5]}  G{v_l: 0.635, v_acc: 67.2, c_acc: 93.8}\n","STEP:805, D{v_l: 0.427, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 1.002, v_acc: 54.7, c_acc: 84.4}\n","STEP:806, D{v_l: 0.476, v_acc: [78.1| 90.6| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 0.915, v_acc: 46.9, c_acc: 95.3}\n","STEP:807, D{v_l: 0.466, v_acc: [87.5| 65.6| 76.6], c_acc: [90.6| 87.5]}  G{v_l: 1.326, v_acc: 35.9, c_acc: 98.4}\n","STEP:808, D{v_l: 0.273, v_acc: [93.8| 81.2| 87.5], c_acc: [87.5| 96.9]}  G{v_l: 1.029, v_acc: 48.4, c_acc: 92.2}\n","STEP:809, D{v_l: 0.441, v_acc: [78.1| 93.8| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 1.100, v_acc: 51.6, c_acc: 93.8}\n","STEP:810, D{v_l: 0.407, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 1.147, v_acc: 43.8, c_acc: 93.8}\n","STEP:811, D{v_l: 0.413, v_acc: [90.6| 71.9| 81.2], c_acc: [96.9| 90.6]}  G{v_l: 1.165, v_acc: 53.1, c_acc: 98.4}\n","STEP:812, D{v_l: 0.410, v_acc: [84.4| 71.9| 78.1], c_acc: [100.0| 96.9]}  G{v_l: 0.838, v_acc: 57.8, c_acc: 98.4}\n","STEP:813, D{v_l: 0.483, v_acc: [81.2| 75.0| 78.1], c_acc: [96.9| 100.0]}  G{v_l: 1.138, v_acc: 45.3, c_acc: 96.9}\n","STEP:814, D{v_l: 0.382, v_acc: [84.4| 84.4| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 0.702, v_acc: 59.4, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.8029 - valid_loss: 1.0441 - class_loss: 2.3726 - valid_acc: 0.3529 - class_acc: 0.5412\n","3/3 [==============================] - 0s 46ms/step - loss: 1.1786 - valid_loss: 0.7227 - class_loss: 0.0697 - valid_acc: 0.4588 - class_acc: 0.9765\n","average v_acc: 40.588, three class acc: 54.118, two class acc: 61.176\n","====================================================================================================\n","STEP:815, D{v_l: 0.493, v_acc: [55.6| 90.6| 73.1], c_acc: [96.6| 100.0]}  G{v_l: 1.181, v_acc: 48.4, c_acc: 96.9}\n","STEP:816, D{v_l: 0.331, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 1.002, v_acc: 54.7, c_acc: 95.3}\n","STEP:817, D{v_l: 0.455, v_acc: [75.0| 78.1| 76.6], c_acc: [100.0| 100.0]}  G{v_l: 0.945, v_acc: 50.0, c_acc: 96.9}\n","STEP:818, D{v_l: 0.285, v_acc: [90.6| 90.6| 90.6], c_acc: [93.8| 100.0]}  G{v_l: 1.030, v_acc: 51.6, c_acc: 93.8}\n","STEP:819, D{v_l: 0.263, v_acc: [93.8| 90.6| 92.2], c_acc: [90.6| 96.9]}  G{v_l: 1.017, v_acc: 51.6, c_acc: 93.8}\n","STEP:820, D{v_l: 0.385, v_acc: [90.6| 87.5| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 1.025, v_acc: 50.0, c_acc: 95.3}\n","STEP:821, D{v_l: 0.558, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 1.092, v_acc: 46.9, c_acc: 92.2}\n","STEP:822, D{v_l: 0.352, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 1.144, v_acc: 34.4, c_acc: 90.6}\n","STEP:823, D{v_l: 0.607, v_acc: [78.1| 78.1| 78.1], c_acc: [100.0| 100.0]}  G{v_l: 1.140, v_acc: 50.0, c_acc: 90.6}\n","STEP:824, D{v_l: 0.578, v_acc: [78.1| 68.8| 73.4], c_acc: [93.8| 93.8]}  G{v_l: 1.387, v_acc: 46.9, c_acc: 95.3}\n","STEP:825, D{v_l: 0.543, v_acc: [81.2| 62.5| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 1.145, v_acc: 46.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.1099 - valid_loss: 0.7314 - class_loss: 1.9924 - valid_acc: 0.5412 - class_acc: 0.4588\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1211 - valid_loss: 0.7067 - class_loss: 0.0282 - valid_acc: 0.4706 - class_acc: 0.9882\n","average v_acc: 50.588, three class acc: 45.882, two class acc: 58.824\n","====================================================================================================\n","STEP:826, D{v_l: 0.384, v_acc: [57.3| 90.6| 73.9], c_acc: [97.4| 96.9]}  G{v_l: 1.110, v_acc: 50.0, c_acc: 98.4}\n","STEP:827, D{v_l: 0.290, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 1.113, v_acc: 51.6, c_acc: 95.3}\n","STEP:828, D{v_l: 0.338, v_acc: [84.4| 90.6| 87.5], c_acc: [100.0| 96.9]}  G{v_l: 1.000, v_acc: 46.9, c_acc: 95.3}\n","STEP:829, D{v_l: 0.374, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.992, v_acc: 50.0, c_acc: 100.0}\n","STEP:830, D{v_l: 0.286, v_acc: [93.8| 87.5| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 1.294, v_acc: 39.1, c_acc: 96.9}\n","STEP:831, D{v_l: 0.320, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 1.574, v_acc: 32.8, c_acc: 98.4}\n","STEP:832, D{v_l: 0.356, v_acc: [90.6| 78.1| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 0.943, v_acc: 54.7, c_acc: 92.2}\n","STEP:833, D{v_l: 0.294, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 1.023, v_acc: 42.2, c_acc: 92.2}\n","STEP:834, D{v_l: 0.375, v_acc: [68.8| 96.9| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.210, v_acc: 40.6, c_acc: 95.3}\n","STEP:835, D{v_l: 0.345, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.294, v_acc: 42.2, c_acc: 95.3}\n","STEP:836, D{v_l: 0.428, v_acc: [75.0| 84.4| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 0.886, v_acc: 54.7, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 2.5359 - valid_loss: 0.4958 - class_loss: 1.6540 - valid_acc: 0.7647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0836 - valid_loss: 0.6719 - class_loss: 0.0256 - valid_acc: 0.6118 - class_acc: 0.9882\n","average v_acc: 68.824, three class acc: 52.941, two class acc: 67.059\n","====================================================================================================\n",">Saved: AC_Brain/mode3/weights/d_model_0836.h5\n","STEP:837, D{v_l: 0.624, v_acc: [68.4| 75.0| 71.7], c_acc: [98.3| 100.0]}  G{v_l: 0.933, v_acc: 50.0, c_acc: 92.2}\n","STEP:838, D{v_l: 0.477, v_acc: [87.5| 81.2| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 0.904, v_acc: 53.1, c_acc: 96.9}\n","STEP:839, D{v_l: 0.389, v_acc: [87.5| 71.9| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.928, v_acc: 48.4, c_acc: 98.4}\n","STEP:840, D{v_l: 0.455, v_acc: [75.0| 90.6| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 0.886, v_acc: 59.4, c_acc: 96.9}\n","STEP:841, D{v_l: 0.281, v_acc: [93.8| 87.5| 90.6], c_acc: [84.4| 100.0]}  G{v_l: 0.959, v_acc: 59.4, c_acc: 98.4}\n","STEP:842, D{v_l: 0.611, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 0.724, v_acc: 57.8, c_acc: 93.8}\n","STEP:843, D{v_l: 0.184, v_acc: [90.6| 93.8| 92.2], c_acc: [93.8| 96.9]}  G{v_l: 0.799, v_acc: 57.8, c_acc: 92.2}\n","STEP:844, D{v_l: 0.300, v_acc: [87.5| 84.4| 85.9], c_acc: [84.4| 96.9]}  G{v_l: 1.043, v_acc: 48.4, c_acc: 93.8}\n","STEP:845, D{v_l: 0.247, v_acc: [93.8| 87.5| 90.6], c_acc: [100.0| 96.9]}  G{v_l: 0.808, v_acc: 60.9, c_acc: 93.8}\n","STEP:846, D{v_l: 0.315, v_acc: [81.2| 93.8| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 1.056, v_acc: 53.1, c_acc: 96.9}\n","STEP:847, D{v_l: 0.376, v_acc: [84.4| 75.0| 79.7], c_acc: [90.6| 87.5]}  G{v_l: 1.098, v_acc: 53.1, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.8848 - valid_loss: 0.5786 - class_loss: 1.9201 - valid_acc: 0.6235 - class_acc: 0.4706\n","3/3 [==============================] - 0s 47ms/step - loss: 1.3103 - valid_loss: 0.8849 - class_loss: 0.0393 - valid_acc: 0.4000 - class_acc: 0.9882\n","average v_acc: 51.176, three class acc: 47.059, two class acc: 65.882\n","====================================================================================================\n","STEP:848, D{v_l: 0.533, v_acc: [53.0| 87.5| 70.2], c_acc: [98.3| 96.9]}  G{v_l: 1.297, v_acc: 46.9, c_acc: 96.9}\n","STEP:849, D{v_l: 0.293, v_acc: [87.5| 84.4| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 0.857, v_acc: 62.5, c_acc: 92.2}\n","STEP:850, D{v_l: 0.318, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 93.8]}  G{v_l: 0.877, v_acc: 53.1, c_acc: 100.0}\n","STEP:851, D{v_l: 0.475, v_acc: [71.9| 81.2| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.916, v_acc: 56.2, c_acc: 98.4}\n","STEP:852, D{v_l: 0.445, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 100.0]}  G{v_l: 0.904, v_acc: 48.4, c_acc: 98.4}\n","STEP:853, D{v_l: 0.417, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.020, v_acc: 53.1, c_acc: 100.0}\n","STEP:854, D{v_l: 0.500, v_acc: [87.5| 71.9| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.997, v_acc: 56.2, c_acc: 93.8}\n","STEP:855, D{v_l: 0.396, v_acc: [93.8| 75.0| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.993, v_acc: 53.1, c_acc: 96.9}\n","STEP:856, D{v_l: 0.303, v_acc: [78.1| 90.6| 84.4], c_acc: [87.5| 93.8]}  G{v_l: 0.796, v_acc: 64.1, c_acc: 96.9}\n","STEP:857, D{v_l: 0.566, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 90.6]}  G{v_l: 0.864, v_acc: 56.2, c_acc: 89.1}\n","STEP:858, D{v_l: 0.303, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 90.6]}  G{v_l: 0.881, v_acc: 64.1, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.0273 - valid_loss: 0.6566 - class_loss: 1.9847 - valid_acc: 0.6824 - class_acc: 0.4706\n","3/3 [==============================] - 0s 47ms/step - loss: 1.7658 - valid_loss: 1.0926 - class_loss: 0.2872 - valid_acc: 0.2353 - class_acc: 0.8941\n","average v_acc: 45.882, three class acc: 47.059, two class acc: 62.353\n","====================================================================================================\n","STEP:859, D{v_l: 0.552, v_acc: [43.6| 81.2| 62.4], c_acc: [92.3| 90.6]}  G{v_l: 0.859, v_acc: 68.8, c_acc: 90.6}\n","STEP:860, D{v_l: 0.414, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.813, v_acc: 64.1, c_acc: 89.1}\n","STEP:861, D{v_l: 0.424, v_acc: [87.5| 78.1| 82.8], c_acc: [100.0| 100.0]}  G{v_l: 0.832, v_acc: 54.7, c_acc: 90.6}\n","STEP:862, D{v_l: 0.342, v_acc: [78.1| 90.6| 84.4], c_acc: [84.4| 100.0]}  G{v_l: 0.830, v_acc: 59.4, c_acc: 90.6}\n","STEP:863, D{v_l: 0.291, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 0.731, v_acc: 59.4, c_acc: 96.9}\n","STEP:864, D{v_l: 0.358, v_acc: [87.5| 90.6| 89.1], c_acc: [84.4| 96.9]}  G{v_l: 1.138, v_acc: 46.9, c_acc: 84.4}\n","STEP:865, D{v_l: 0.262, v_acc: [96.9| 87.5| 92.2], c_acc: [96.9| 87.5]}  G{v_l: 0.838, v_acc: 54.7, c_acc: 87.5}\n","STEP:866, D{v_l: 0.367, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.060, v_acc: 53.1, c_acc: 95.3}\n","STEP:867, D{v_l: 0.275, v_acc: [90.6| 87.5| 89.1], c_acc: [87.5| 100.0]}  G{v_l: 0.908, v_acc: 60.9, c_acc: 96.9}\n","STEP:868, D{v_l: 0.421, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.157, v_acc: 54.7, c_acc: 96.9}\n","STEP:869, D{v_l: 0.311, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.849, v_acc: 59.4, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 5.5141 - valid_loss: 1.0062 - class_loss: 4.1220 - valid_acc: 0.4588 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.4611 - valid_loss: 0.9380 - class_loss: 0.1372 - valid_acc: 0.4118 - class_acc: 0.9412\n","average v_acc: 43.529, three class acc: 52.941, two class acc: 57.647\n","====================================================================================================\n","STEP:870, D{v_l: 0.524, v_acc: [53.8| 93.8| 73.8], c_acc: [94.0| 96.9]}  G{v_l: 1.091, v_acc: 53.1, c_acc: 90.6}\n","STEP:871, D{v_l: 0.455, v_acc: [75.0| 90.6| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 0.844, v_acc: 60.9, c_acc: 87.5}\n","STEP:872, D{v_l: 0.425, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.943, v_acc: 62.5, c_acc: 90.6}\n","STEP:873, D{v_l: 0.326, v_acc: [100.0| 81.2| 90.6], c_acc: [93.8| 100.0]}  G{v_l: 1.083, v_acc: 56.2, c_acc: 92.2}\n","STEP:874, D{v_l: 0.391, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 87.5]}  G{v_l: 0.902, v_acc: 56.2, c_acc: 84.4}\n","STEP:875, D{v_l: 0.407, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.751, v_acc: 64.1, c_acc: 79.7}\n","STEP:876, D{v_l: 0.362, v_acc: [87.5| 93.8| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 0.784, v_acc: 65.6, c_acc: 98.4}\n","STEP:877, D{v_l: 0.421, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.085, v_acc: 68.8, c_acc: 96.9}\n","STEP:878, D{v_l: 0.342, v_acc: [81.2| 90.6| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.821, v_acc: 56.2, c_acc: 96.9}\n","STEP:879, D{v_l: 0.389, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 0.880, v_acc: 54.7, c_acc: 95.3}\n","STEP:880, D{v_l: 0.445, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 0.948, v_acc: 56.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 52ms/step - loss: 2.8776 - valid_loss: 0.2733 - class_loss: 2.2185 - valid_acc: 0.9176 - class_acc: 0.4235\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8383 - valid_loss: 1.3496 - class_loss: 0.1029 - valid_acc: 0.2941 - class_acc: 0.9529\n","average v_acc: 60.588, three class acc: 42.353, two class acc: 61.176\n","====================================================================================================\n","Epoch: 80\n","====================================================================================================\n","STEP:881, D{v_l: 0.656, v_acc: [42.7| 93.8| 68.2], c_acc: [96.6| 96.9]}  G{v_l: 0.873, v_acc: 57.8, c_acc: 90.6}\n","STEP:882, D{v_l: 0.206, v_acc: [96.9| 87.5| 92.2], c_acc: [93.8| 96.9]}  G{v_l: 0.616, v_acc: 73.4, c_acc: 93.8}\n","STEP:883, D{v_l: 0.318, v_acc: [81.2| 90.6| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 0.776, v_acc: 67.2, c_acc: 96.9}\n","STEP:884, D{v_l: 0.278, v_acc: [90.6| 87.5| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 1.073, v_acc: 57.8, c_acc: 98.4}\n","STEP:885, D{v_l: 0.354, v_acc: [81.2| 84.4| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 0.990, v_acc: 57.8, c_acc: 96.9}\n","STEP:886, D{v_l: 0.382, v_acc: [75.0| 87.5| 81.2], c_acc: [100.0| 100.0]}  G{v_l: 0.794, v_acc: 54.7, c_acc: 95.3}\n","STEP:887, D{v_l: 0.403, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 1.150, v_acc: 54.7, c_acc: 95.3}\n","STEP:888, D{v_l: 0.398, v_acc: [93.8| 84.4| 89.1], c_acc: [87.5| 100.0]}  G{v_l: 0.849, v_acc: 57.8, c_acc: 98.4}\n","STEP:889, D{v_l: 0.413, v_acc: [84.4| 87.5| 85.9], c_acc: [84.4| 96.9]}  G{v_l: 0.893, v_acc: 57.8, c_acc: 93.8}\n","STEP:890, D{v_l: 0.211, v_acc: [87.5| 96.9| 92.2], c_acc: [100.0| 96.9]}  G{v_l: 0.854, v_acc: 59.4, c_acc: 95.3}\n","STEP:891, D{v_l: 0.217, v_acc: [93.8| 93.8| 93.8], c_acc: [84.4| 93.8]}  G{v_l: 0.980, v_acc: 60.9, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.2576 - valid_loss: 0.3956 - class_loss: 2.4761 - valid_acc: 0.8235 - class_acc: 0.4706\n","3/3 [==============================] - 0s 45ms/step - loss: 1.5206 - valid_loss: 1.1176 - class_loss: 0.0171 - valid_acc: 0.3647 - class_acc: 1.0000\n","average v_acc: 59.412, three class acc: 47.059, two class acc: 61.176\n","====================================================================================================\n","STEP:892, D{v_l: 0.704, v_acc: [51.3| 81.2| 66.3], c_acc: [98.3| 100.0]}  G{v_l: 1.228, v_acc: 57.8, c_acc: 100.0}\n","STEP:893, D{v_l: 0.316, v_acc: [96.9| 81.2| 89.1], c_acc: [90.6| 90.6]}  G{v_l: 1.185, v_acc: 54.7, c_acc: 96.9}\n","STEP:894, D{v_l: 0.356, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 84.4]}  G{v_l: 0.939, v_acc: 54.7, c_acc: 96.9}\n","STEP:895, D{v_l: 0.367, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 100.0]}  G{v_l: 0.940, v_acc: 57.8, c_acc: 95.3}\n","STEP:896, D{v_l: 0.297, v_acc: [100.0| 90.6| 95.3], c_acc: [93.8| 93.8]}  G{v_l: 0.907, v_acc: 54.7, c_acc: 95.3}\n","STEP:897, D{v_l: 0.312, v_acc: [87.5| 84.4| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.156, v_acc: 43.8, c_acc: 98.4}\n","STEP:898, D{v_l: 0.247, v_acc: [84.4| 96.9| 90.6], c_acc: [100.0| 96.9]}  G{v_l: 1.289, v_acc: 51.6, c_acc: 100.0}\n","STEP:899, D{v_l: 0.455, v_acc: [84.4| 75.0| 79.7], c_acc: [87.5| 93.8]}  G{v_l: 0.814, v_acc: 65.6, c_acc: 96.9}\n","STEP:900, D{v_l: 0.295, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 1.154, v_acc: 53.1, c_acc: 95.3}\n","STEP:901, D{v_l: 0.257, v_acc: [84.4| 93.8| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.991, v_acc: 56.2, c_acc: 93.8}\n","STEP:902, D{v_l: 0.394, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 0.852, v_acc: 57.8, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.0475 - valid_loss: 0.4666 - class_loss: 2.1951 - valid_acc: 0.7765 - class_acc: 0.4941\n","3/3 [==============================] - 0s 54ms/step - loss: 1.7056 - valid_loss: 1.2258 - class_loss: 0.0940 - valid_acc: 0.3059 - class_acc: 0.9647\n","average v_acc: 54.118, three class acc: 49.412, two class acc: 61.176\n","====================================================================================================\n","STEP:903, D{v_l: 0.861, v_acc: [47.9| 84.4| 66.1], c_acc: [97.4| 100.0]}  G{v_l: 0.744, v_acc: 60.9, c_acc: 92.2}\n","STEP:904, D{v_l: 0.413, v_acc: [93.8| 81.2| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 0.888, v_acc: 60.9, c_acc: 100.0}\n","STEP:905, D{v_l: 0.392, v_acc: [78.1| 78.1| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 1.002, v_acc: 53.1, c_acc: 93.8}\n","STEP:906, D{v_l: 0.300, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 0.961, v_acc: 59.4, c_acc: 93.8}\n","STEP:907, D{v_l: 0.567, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 0.889, v_acc: 57.8, c_acc: 96.9}\n","STEP:908, D{v_l: 0.312, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.806, v_acc: 65.6, c_acc: 96.9}\n","STEP:909, D{v_l: 0.324, v_acc: [84.4| 84.4| 84.4], c_acc: [78.1| 96.9]}  G{v_l: 0.797, v_acc: 60.9, c_acc: 95.3}\n","STEP:910, D{v_l: 0.262, v_acc: [93.8| 93.8| 93.8], c_acc: [84.4| 96.9]}  G{v_l: 0.895, v_acc: 59.4, c_acc: 93.8}\n","STEP:911, D{v_l: 0.395, v_acc: [81.2| 93.8| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.682, v_acc: 73.4, c_acc: 95.3}\n","STEP:912, D{v_l: 0.639, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 96.9]}  G{v_l: 0.652, v_acc: 65.6, c_acc: 98.4}\n","STEP:913, D{v_l: 0.445, v_acc: [78.1| 75.0| 76.6], c_acc: [96.9| 100.0]}  G{v_l: 1.173, v_acc: 42.2, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.4887 - valid_loss: 0.6119 - class_loss: 2.4911 - valid_acc: 0.6118 - class_acc: 0.5765\n","3/3 [==============================] - 0s 48ms/step - loss: 1.5331 - valid_loss: 1.1127 - class_loss: 0.0347 - valid_acc: 0.3059 - class_acc: 0.9882\n","average v_acc: 45.882, three class acc: 57.647, two class acc: 63.529\n","====================================================================================================\n","STEP:914, D{v_l: 0.604, v_acc: [45.3| 87.5| 66.4], c_acc: [99.1| 100.0]}  G{v_l: 0.872, v_acc: 59.4, c_acc: 100.0}\n","STEP:915, D{v_l: 0.301, v_acc: [93.8| 81.2| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 0.831, v_acc: 50.0, c_acc: 98.4}\n","STEP:916, D{v_l: 0.302, v_acc: [84.4| 90.6| 87.5], c_acc: [100.0| 96.9]}  G{v_l: 0.902, v_acc: 54.7, c_acc: 92.2}\n","STEP:917, D{v_l: 0.318, v_acc: [90.6| 90.6| 90.6], c_acc: [90.6| 96.9]}  G{v_l: 0.899, v_acc: 53.1, c_acc: 93.8}\n","STEP:918, D{v_l: 0.313, v_acc: [71.9| 96.9| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 0.678, v_acc: 62.5, c_acc: 96.9}\n","STEP:919, D{v_l: 0.224, v_acc: [90.6| 93.8| 92.2], c_acc: [90.6| 96.9]}  G{v_l: 0.738, v_acc: 65.6, c_acc: 95.3}\n","STEP:920, D{v_l: 0.277, v_acc: [87.5| 87.5| 87.5], c_acc: [100.0| 100.0]}  G{v_l: 0.832, v_acc: 59.4, c_acc: 93.8}\n","STEP:921, D{v_l: 0.378, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 0.902, v_acc: 53.1, c_acc: 98.4}\n","STEP:922, D{v_l: 0.304, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 0.826, v_acc: 59.4, c_acc: 100.0}\n","STEP:923, D{v_l: 0.279, v_acc: [100.0| 84.4| 92.2], c_acc: [96.9| 100.0]}  G{v_l: 0.848, v_acc: 54.7, c_acc: 96.9}\n","STEP:924, D{v_l: 0.499, v_acc: [84.4| 81.2| 82.8], c_acc: [84.4| 100.0]}  G{v_l: 1.191, v_acc: 35.9, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.8189 - valid_loss: 0.5782 - class_loss: 1.8550 - valid_acc: 0.6706 - class_acc: 0.4471\n","3/3 [==============================] - 0s 45ms/step - loss: 1.4286 - valid_loss: 0.9488 - class_loss: 0.0941 - valid_acc: 0.3529 - class_acc: 0.9765\n","average v_acc: 51.176, three class acc: 44.706, two class acc: 58.824\n","====================================================================================================\n","STEP:925, D{v_l: 0.466, v_acc: [50.4| 96.9| 73.7], c_acc: [98.3| 100.0]}  G{v_l: 0.769, v_acc: 60.9, c_acc: 89.1}\n","STEP:926, D{v_l: 0.328, v_acc: [90.6| 81.2| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.878, v_acc: 46.9, c_acc: 95.3}\n","STEP:927, D{v_l: 0.380, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 93.8]}  G{v_l: 0.706, v_acc: 71.9, c_acc: 98.4}\n","STEP:928, D{v_l: 0.394, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 0.856, v_acc: 67.2, c_acc: 95.3}\n","STEP:929, D{v_l: 0.448, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.792, v_acc: 60.9, c_acc: 93.8}\n","STEP:930, D{v_l: 0.450, v_acc: [93.8| 90.6| 92.2], c_acc: [96.9| 96.9]}  G{v_l: 0.568, v_acc: 71.9, c_acc: 96.9}\n","STEP:931, D{v_l: 0.207, v_acc: [90.6| 96.9| 93.8], c_acc: [96.9| 100.0]}  G{v_l: 0.891, v_acc: 60.9, c_acc: 92.2}\n","STEP:932, D{v_l: 0.237, v_acc: [87.5| 90.6| 89.1], c_acc: [87.5| 93.8]}  G{v_l: 0.856, v_acc: 59.4, c_acc: 100.0}\n","STEP:933, D{v_l: 0.284, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 0.641, v_acc: 70.3, c_acc: 96.9}\n","STEP:934, D{v_l: 0.323, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 1.027, v_acc: 57.8, c_acc: 98.4}\n","STEP:935, D{v_l: 0.291, v_acc: [81.2| 90.6| 85.9], c_acc: [90.6| 100.0]}  G{v_l: 0.834, v_acc: 70.3, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.8298 - valid_loss: 1.0940 - class_loss: 3.3502 - valid_acc: 0.3294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.6273 - valid_loss: 1.1064 - class_loss: 0.1353 - valid_acc: 0.2588 - class_acc: 0.9412\n","average v_acc: 29.412, three class acc: 52.941, two class acc: 60.000\n","====================================================================================================\n","STEP:936, D{v_l: 0.558, v_acc: [42.7| 87.5| 65.1], c_acc: [94.9| 93.8]}  G{v_l: 0.798, v_acc: 59.4, c_acc: 89.1}\n","STEP:937, D{v_l: 0.336, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.623, v_acc: 64.1, c_acc: 95.3}\n","STEP:938, D{v_l: 0.206, v_acc: [93.8| 87.5| 90.6], c_acc: [100.0| 96.9]}  G{v_l: 0.657, v_acc: 68.8, c_acc: 85.9}\n","STEP:939, D{v_l: 0.227, v_acc: [93.8| 87.5| 90.6], c_acc: [87.5| 100.0]}  G{v_l: 0.553, v_acc: 71.9, c_acc: 90.6}\n","STEP:940, D{v_l: 0.285, v_acc: [90.6| 87.5| 89.1], c_acc: [90.6| 93.8]}  G{v_l: 0.684, v_acc: 60.9, c_acc: 95.3}\n","STEP:941, D{v_l: 0.355, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.965, v_acc: 59.4, c_acc: 93.8}\n","STEP:942, D{v_l: 0.400, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 0.824, v_acc: 64.1, c_acc: 98.4}\n","STEP:943, D{v_l: 0.221, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 96.9]}  G{v_l: 0.993, v_acc: 46.9, c_acc: 98.4}\n","STEP:944, D{v_l: 0.349, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 0.763, v_acc: 60.9, c_acc: 95.3}\n","STEP:945, D{v_l: 0.267, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.904, v_acc: 60.9, c_acc: 96.9}\n","STEP:946, D{v_l: 0.269, v_acc: [81.2| 87.5| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.903, v_acc: 64.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.1259 - valid_loss: 0.5791 - class_loss: 2.1613 - valid_acc: 0.6000 - class_acc: 0.5059\n","3/3 [==============================] - 0s 51ms/step - loss: 1.5081 - valid_loss: 1.1038 - class_loss: 0.0188 - valid_acc: 0.2706 - class_acc: 0.9882\n","average v_acc: 43.529, three class acc: 50.588, two class acc: 58.824\n","====================================================================================================\n","STEP:947, D{v_l: 0.647, v_acc: [42.7| 81.2| 62.0], c_acc: [95.7| 100.0]}  G{v_l: 0.867, v_acc: 62.5, c_acc: 93.8}\n","STEP:948, D{v_l: 0.389, v_acc: [84.4| 87.5| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 0.746, v_acc: 67.2, c_acc: 92.2}\n","STEP:949, D{v_l: 0.257, v_acc: [93.8| 87.5| 90.6], c_acc: [90.6| 100.0]}  G{v_l: 0.650, v_acc: 64.1, c_acc: 92.2}\n","STEP:950, D{v_l: 0.268, v_acc: [93.8| 87.5| 90.6], c_acc: [90.6| 96.9]}  G{v_l: 0.895, v_acc: 56.2, c_acc: 96.9}\n","STEP:951, D{v_l: 0.365, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.705, v_acc: 67.2, c_acc: 95.3}\n","STEP:952, D{v_l: 0.328, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.699, v_acc: 65.6, c_acc: 100.0}\n","STEP:953, D{v_l: 0.153, v_acc: [93.8| 96.9| 95.3], c_acc: [96.9| 100.0]}  G{v_l: 0.776, v_acc: 62.5, c_acc: 96.9}\n","STEP:954, D{v_l: 0.214, v_acc: [93.8| 90.6| 92.2], c_acc: [93.8| 100.0]}  G{v_l: 0.650, v_acc: 65.6, c_acc: 96.9}\n","STEP:955, D{v_l: 0.373, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.138, v_acc: 46.9, c_acc: 100.0}\n","STEP:956, D{v_l: 0.219, v_acc: [93.8| 90.6| 92.2], c_acc: [96.9| 96.9]}  G{v_l: 0.766, v_acc: 59.4, c_acc: 93.8}\n","STEP:957, D{v_l: 0.305, v_acc: [81.2| 93.8| 87.5], c_acc: [100.0| 100.0]}  G{v_l: 1.055, v_acc: 46.9, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.9370 - valid_loss: 0.5864 - class_loss: 1.9651 - valid_acc: 0.7059 - class_acc: 0.4588\n","3/3 [==============================] - 0s 47ms/step - loss: 1.8384 - valid_loss: 1.4078 - class_loss: 0.0452 - valid_acc: 0.1176 - class_acc: 0.9765\n","average v_acc: 41.176, three class acc: 45.882, two class acc: 61.176\n","====================================================================================================\n","STEP:958, D{v_l: 0.708, v_acc: [30.8| 84.4| 57.6], c_acc: [97.4| 96.9]}  G{v_l: 0.882, v_acc: 64.1, c_acc: 98.4}\n","STEP:959, D{v_l: 0.252, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 1.280, v_acc: 51.6, c_acc: 93.8}\n","STEP:960, D{v_l: 0.377, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 0.905, v_acc: 56.2, c_acc: 85.9}\n","STEP:961, D{v_l: 0.257, v_acc: [90.6| 90.6| 90.6], c_acc: [90.6| 93.8]}  G{v_l: 0.769, v_acc: 57.8, c_acc: 96.9}\n","STEP:962, D{v_l: 0.283, v_acc: [78.1| 87.5| 82.8], c_acc: [84.4| 100.0]}  G{v_l: 0.913, v_acc: 46.9, c_acc: 93.8}\n","STEP:963, D{v_l: 0.244, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 100.0]}  G{v_l: 0.946, v_acc: 57.8, c_acc: 98.4}\n","STEP:964, D{v_l: 0.430, v_acc: [87.5| 84.4| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 0.664, v_acc: 56.2, c_acc: 93.8}\n","STEP:965, D{v_l: 0.291, v_acc: [90.6| 75.0| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 0.918, v_acc: 60.9, c_acc: 93.8}\n","STEP:966, D{v_l: 0.342, v_acc: [90.6| 93.8| 92.2], c_acc: [100.0| 96.9]}  G{v_l: 0.837, v_acc: 59.4, c_acc: 96.9}\n","STEP:967, D{v_l: 0.445, v_acc: [93.8| 81.2| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.901, v_acc: 60.9, c_acc: 98.4}\n","STEP:968, D{v_l: 0.232, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 0.717, v_acc: 73.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 3.0774 - valid_loss: 0.5785 - class_loss: 2.1135 - valid_acc: 0.6824 - class_acc: 0.3294\n","3/3 [==============================] - 0s 51ms/step - loss: 1.4191 - valid_loss: 1.0068 - class_loss: 0.0269 - valid_acc: 0.3176 - class_acc: 1.0000\n","average v_acc: 50.000, three class acc: 32.941, two class acc: 51.765\n","====================================================================================================\n","STEP:969, D{v_l: 0.502, v_acc: [49.6| 96.9| 73.2], c_acc: [98.3| 100.0]}  G{v_l: 0.824, v_acc: 62.5, c_acc: 93.8}\n","STEP:970, D{v_l: 0.381, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 0.902, v_acc: 59.4, c_acc: 98.4}\n","STEP:971, D{v_l: 0.218, v_acc: [90.6| 90.6| 90.6], c_acc: [100.0| 100.0]}  G{v_l: 1.091, v_acc: 46.9, c_acc: 100.0}\n","STEP:972, D{v_l: 0.255, v_acc: [84.4| 93.8| 89.1], c_acc: [84.4| 100.0]}  G{v_l: 1.615, v_acc: 53.1, c_acc: 98.4}\n","STEP:973, D{v_l: 0.207, v_acc: [90.6| 90.6| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 1.180, v_acc: 54.7, c_acc: 95.3}\n","STEP:974, D{v_l: 0.302, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 0.876, v_acc: 54.7, c_acc: 93.8}\n","STEP:975, D{v_l: 0.266, v_acc: [93.8| 78.1| 85.9], c_acc: [100.0| 93.8]}  G{v_l: 0.718, v_acc: 64.1, c_acc: 90.6}\n","STEP:976, D{v_l: 0.241, v_acc: [78.1| 96.9| 87.5], c_acc: [100.0| 96.9]}  G{v_l: 0.882, v_acc: 64.1, c_acc: 78.1}\n","STEP:977, D{v_l: 0.138, v_acc: [87.5| 96.9| 92.2], c_acc: [93.8| 96.9]}  G{v_l: 0.834, v_acc: 62.5, c_acc: 92.2}\n","STEP:978, D{v_l: 0.400, v_acc: [87.5| 84.4| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 1.115, v_acc: 60.9, c_acc: 89.1}\n","STEP:979, D{v_l: 0.239, v_acc: [93.8| 84.4| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 1.066, v_acc: 48.4, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.5997 - valid_loss: 0.5626 - class_loss: 2.6518 - valid_acc: 0.7529 - class_acc: 0.4353\n","3/3 [==============================] - 0s 47ms/step - loss: 1.6909 - valid_loss: 1.2123 - class_loss: 0.0933 - valid_acc: 0.2941 - class_acc: 0.9765\n","average v_acc: 52.353, three class acc: 43.529, two class acc: 62.353\n","====================================================================================================\n","STEP:980, D{v_l: 0.579, v_acc: [47.9| 93.8| 70.8], c_acc: [96.6| 96.9]}  G{v_l: 0.908, v_acc: 64.1, c_acc: 100.0}\n","STEP:981, D{v_l: 0.286, v_acc: [84.4| 93.8| 89.1], c_acc: [90.6| 96.9]}  G{v_l: 0.794, v_acc: 65.6, c_acc: 95.3}\n","STEP:982, D{v_l: 0.226, v_acc: [84.4| 93.8| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 0.780, v_acc: 64.1, c_acc: 92.2}\n","STEP:983, D{v_l: 0.322, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 0.816, v_acc: 62.5, c_acc: 85.9}\n","STEP:984, D{v_l: 0.196, v_acc: [90.6| 93.8| 92.2], c_acc: [81.2| 100.0]}  G{v_l: 0.826, v_acc: 57.8, c_acc: 89.1}\n","STEP:985, D{v_l: 0.286, v_acc: [93.8| 84.4| 89.1], c_acc: [100.0| 96.9]}  G{v_l: 1.109, v_acc: 50.0, c_acc: 98.4}\n","STEP:986, D{v_l: 0.663, v_acc: [84.4| 78.1| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 1.320, v_acc: 50.0, c_acc: 96.9}\n","STEP:987, D{v_l: 0.289, v_acc: [90.6| 93.8| 92.2], c_acc: [96.9| 100.0]}  G{v_l: 1.102, v_acc: 54.7, c_acc: 100.0}\n","STEP:988, D{v_l: 0.296, v_acc: [87.5| 84.4| 85.9], c_acc: [87.5| 96.9]}  G{v_l: 0.925, v_acc: 51.6, c_acc: 98.4}\n","STEP:989, D{v_l: 0.230, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 0.877, v_acc: 57.8, c_acc: 98.4}\n","STEP:990, D{v_l: 0.285, v_acc: [93.8| 84.4| 89.1], c_acc: [90.6| 93.8]}  G{v_l: 0.764, v_acc: 60.9, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 55ms/step - loss: 3.5156 - valid_loss: 0.6434 - class_loss: 2.4869 - valid_acc: 0.7412 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.5597 - valid_loss: 1.1211 - class_loss: 0.0533 - valid_acc: 0.2824 - class_acc: 0.9765\n","average v_acc: 51.176, three class acc: 49.412, two class acc: 58.824\n","====================================================================================================\n","Epoch: 90\n","====================================================================================================\n","STEP:991, D{v_l: 0.567, v_acc: [44.4| 84.4| 64.4], c_acc: [96.6| 93.8]}  G{v_l: 1.052, v_acc: 57.8, c_acc: 96.9}\n","STEP:992, D{v_l: 0.191, v_acc: [87.5| 96.9| 92.2], c_acc: [90.6| 96.9]}  G{v_l: 0.962, v_acc: 57.8, c_acc: 90.6}\n","STEP:993, D{v_l: 0.282, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 0.666, v_acc: 75.0, c_acc: 92.2}\n","STEP:994, D{v_l: 0.199, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 0.991, v_acc: 60.9, c_acc: 95.3}\n","STEP:995, D{v_l: 0.516, v_acc: [90.6| 81.2| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.900, v_acc: 59.4, c_acc: 93.8}\n","STEP:996, D{v_l: 0.330, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.817, v_acc: 59.4, c_acc: 95.3}\n","STEP:997, D{v_l: 0.300, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.850, v_acc: 60.9, c_acc: 92.2}\n","STEP:998, D{v_l: 0.327, v_acc: [93.8| 84.4| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 0.738, v_acc: 70.3, c_acc: 90.6}\n","STEP:999, D{v_l: 0.205, v_acc: [93.8| 93.8| 93.8], c_acc: [100.0| 100.0]}  G{v_l: 0.741, v_acc: 60.9, c_acc: 90.6}\n","STEP:1000, D{v_l: 0.384, v_acc: [90.6| 78.1| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 0.724, v_acc: 67.2, c_acc: 90.6}\n","STEP:1001, D{v_l: 0.378, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 0.814, v_acc: 54.7, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.9531 - valid_loss: 0.4007 - class_loss: 2.1673 - valid_acc: 0.8824 - class_acc: 0.4588\n","3/3 [==============================] - 0s 46ms/step - loss: 2.3244 - valid_loss: 1.7159 - class_loss: 0.2233 - valid_acc: 0.1529 - class_acc: 0.8706\n","average v_acc: 51.765, three class acc: 45.882, two class acc: 58.824\n","====================================================================================================\n","STEP:1002, D{v_l: 0.756, v_acc: [35.0| 96.9| 66.0], c_acc: [90.6| 93.8]}  G{v_l: 0.613, v_acc: 65.6, c_acc: 93.8}\n","STEP:1003, D{v_l: 0.510, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 90.6]}  G{v_l: 0.592, v_acc: 68.8, c_acc: 90.6}\n","STEP:1004, D{v_l: 0.213, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 96.9]}  G{v_l: 0.701, v_acc: 70.3, c_acc: 90.6}\n","STEP:1005, D{v_l: 0.240, v_acc: [93.8| 90.6| 92.2], c_acc: [87.5| 96.9]}  G{v_l: 0.730, v_acc: 62.5, c_acc: 92.2}\n","STEP:1006, D{v_l: 0.280, v_acc: [90.6| 81.2| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 0.653, v_acc: 68.8, c_acc: 95.3}\n","STEP:1007, D{v_l: 0.359, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 0.717, v_acc: 75.0, c_acc: 95.3}\n","STEP:1008, D{v_l: 0.181, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.952, v_acc: 56.2, c_acc: 92.2}\n","STEP:1009, D{v_l: 0.307, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.761, v_acc: 59.4, c_acc: 93.8}\n","STEP:1010, D{v_l: 0.298, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 0.875, v_acc: 59.4, c_acc: 95.3}\n","STEP:1011, D{v_l: 0.270, v_acc: [93.8| 87.5| 90.6], c_acc: [100.0| 93.8]}  G{v_l: 0.677, v_acc: 62.5, c_acc: 93.8}\n","STEP:1012, D{v_l: 0.153, v_acc: [93.8| 100.0| 96.9], c_acc: [96.9| 100.0]}  G{v_l: 0.867, v_acc: 68.8, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.0798 - valid_loss: 0.6722 - class_loss: 2.0226 - valid_acc: 0.6588 - class_acc: 0.4118\n","3/3 [==============================] - 0s 52ms/step - loss: 1.8249 - valid_loss: 1.3925 - class_loss: 0.0473 - valid_acc: 0.2706 - class_acc: 0.9882\n","average v_acc: 46.471, three class acc: 41.176, two class acc: 58.824\n","====================================================================================================\n","STEP:1013, D{v_l: 0.662, v_acc: [42.7| 87.5| 65.1], c_acc: [99.1| 100.0]}  G{v_l: 0.977, v_acc: 57.8, c_acc: 96.9}\n","STEP:1014, D{v_l: 0.313, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 0.832, v_acc: 59.4, c_acc: 95.3}\n","STEP:1015, D{v_l: 0.185, v_acc: [90.6| 90.6| 90.6], c_acc: [93.8| 96.9]}  G{v_l: 0.755, v_acc: 68.8, c_acc: 98.4}\n","STEP:1016, D{v_l: 0.244, v_acc: [90.6| 87.5| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 1.061, v_acc: 54.7, c_acc: 96.9}\n","STEP:1017, D{v_l: 0.276, v_acc: [93.8| 87.5| 90.6], c_acc: [100.0| 93.8]}  G{v_l: 0.806, v_acc: 59.4, c_acc: 96.9}\n","STEP:1018, D{v_l: 0.224, v_acc: [81.2| 96.9| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.976, v_acc: 54.7, c_acc: 98.4}\n","STEP:1019, D{v_l: 0.255, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 0.916, v_acc: 51.6, c_acc: 98.4}\n","STEP:1020, D{v_l: 0.166, v_acc: [93.8| 96.9| 95.3], c_acc: [96.9| 93.8]}  G{v_l: 0.888, v_acc: 57.8, c_acc: 100.0}\n","STEP:1021, D{v_l: 0.249, v_acc: [87.5| 100.0| 93.8], c_acc: [96.9| 100.0]}  G{v_l: 0.850, v_acc: 59.4, c_acc: 96.9}\n","STEP:1022, D{v_l: 0.374, v_acc: [93.8| 84.4| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 0.615, v_acc: 70.3, c_acc: 98.4}\n","STEP:1023, D{v_l: 0.160, v_acc: [93.8| 93.8| 93.8], c_acc: [96.9| 100.0]}  G{v_l: 0.812, v_acc: 67.2, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.0237 - valid_loss: 0.8350 - class_loss: 2.8037 - valid_acc: 0.5294 - class_acc: 0.4941\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8959 - valid_loss: 1.4570 - class_loss: 0.0539 - valid_acc: 0.2471 - class_acc: 0.9765\n","average v_acc: 38.824, three class acc: 49.412, two class acc: 60.000\n","====================================================================================================\n","STEP:1024, D{v_l: 0.737, v_acc: [38.5| 87.5| 63.0], c_acc: [98.3| 96.9]}  G{v_l: 0.853, v_acc: 64.1, c_acc: 100.0}\n","STEP:1025, D{v_l: 0.263, v_acc: [87.5| 87.5| 87.5], c_acc: [100.0| 84.4]}  G{v_l: 1.013, v_acc: 54.7, c_acc: 98.4}\n","STEP:1026, D{v_l: 0.239, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 0.883, v_acc: 62.5, c_acc: 100.0}\n","STEP:1027, D{v_l: 0.321, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 90.6]}  G{v_l: 0.574, v_acc: 68.8, c_acc: 92.2}\n","STEP:1028, D{v_l: 0.253, v_acc: [87.5| 93.8| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 0.887, v_acc: 57.8, c_acc: 96.9}\n","STEP:1029, D{v_l: 0.241, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.646, v_acc: 70.3, c_acc: 98.4}\n","STEP:1030, D{v_l: 0.306, v_acc: [90.6| 90.6| 90.6], c_acc: [93.8| 100.0]}  G{v_l: 0.538, v_acc: 75.0, c_acc: 100.0}\n","STEP:1031, D{v_l: 0.345, v_acc: [90.6| 84.4| 87.5], c_acc: [100.0| 96.9]}  G{v_l: 0.586, v_acc: 67.2, c_acc: 98.4}\n","STEP:1032, D{v_l: 0.272, v_acc: [96.9| 87.5| 92.2], c_acc: [93.8| 100.0]}  G{v_l: 0.837, v_acc: 64.1, c_acc: 100.0}\n","STEP:1033, D{v_l: 0.358, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 0.610, v_acc: 73.4, c_acc: 93.8}\n","STEP:1034, D{v_l: 0.577, v_acc: [90.6| 75.0| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.790, v_acc: 68.8, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.5533 - valid_loss: 0.6975 - class_loss: 2.4708 - valid_acc: 0.5765 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 2.0769 - valid_loss: 1.6446 - class_loss: 0.0474 - valid_acc: 0.2000 - class_acc: 0.9765\n","average v_acc: 38.824, three class acc: 51.765, two class acc: 62.353\n","====================================================================================================\n","STEP:1035, D{v_l: 0.750, v_acc: [38.5| 93.8| 66.1], c_acc: [96.6| 96.9]}  G{v_l: 0.690, v_acc: 68.8, c_acc: 93.8}\n","STEP:1036, D{v_l: 0.372, v_acc: [84.4| 93.8| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 0.759, v_acc: 67.2, c_acc: 100.0}\n","STEP:1037, D{v_l: 0.310, v_acc: [78.1| 93.8| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 0.814, v_acc: 68.8, c_acc: 98.4}\n","STEP:1038, D{v_l: 0.698, v_acc: [87.5| 62.5| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.127, v_acc: 57.8, c_acc: 98.4}\n","STEP:1039, D{v_l: 0.286, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 100.0]}  G{v_l: 0.731, v_acc: 60.9, c_acc: 98.4}\n","STEP:1040, D{v_l: 0.420, v_acc: [71.9| 93.8| 82.8], c_acc: [100.0| 100.0]}  G{v_l: 0.825, v_acc: 57.8, c_acc: 93.8}\n","STEP:1041, D{v_l: 0.254, v_acc: [81.2| 93.8| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.595, v_acc: 71.9, c_acc: 93.8}\n","STEP:1042, D{v_l: 0.325, v_acc: [87.5| 75.0| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.774, v_acc: 59.4, c_acc: 93.8}\n","STEP:1043, D{v_l: 0.421, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 100.0]}  G{v_l: 0.682, v_acc: 76.6, c_acc: 96.9}\n","STEP:1044, D{v_l: 0.271, v_acc: [90.6| 90.6| 90.6], c_acc: [100.0| 100.0]}  G{v_l: 0.763, v_acc: 64.1, c_acc: 95.3}\n","STEP:1045, D{v_l: 0.231, v_acc: [96.9| 87.5| 92.2], c_acc: [96.9| 100.0]}  G{v_l: 0.775, v_acc: 64.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.5769 - valid_loss: 0.6418 - class_loss: 2.5503 - valid_acc: 0.6471 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8889 - valid_loss: 1.4257 - class_loss: 0.0784 - valid_acc: 0.2588 - class_acc: 0.9882\n","average v_acc: 45.294, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:1046, D{v_l: 0.653, v_acc: [43.6| 84.4| 64.0], c_acc: [99.1| 100.0]}  G{v_l: 0.559, v_acc: 67.2, c_acc: 90.6}\n","STEP:1047, D{v_l: 0.364, v_acc: [75.0| 90.6| 82.8], c_acc: [93.8| 93.8]}  G{v_l: 1.007, v_acc: 54.7, c_acc: 95.3}\n","STEP:1048, D{v_l: 0.278, v_acc: [87.5| 87.5| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 0.837, v_acc: 62.5, c_acc: 93.8}\n","STEP:1049, D{v_l: 0.300, v_acc: [100.0| 84.4| 92.2], c_acc: [90.6| 100.0]}  G{v_l: 0.740, v_acc: 64.1, c_acc: 98.4}\n","STEP:1050, D{v_l: 0.223, v_acc: [90.6| 93.8| 92.2], c_acc: [96.9| 100.0]}  G{v_l: 1.030, v_acc: 56.2, c_acc: 100.0}\n","STEP:1051, D{v_l: 0.334, v_acc: [87.5| 90.6| 89.1], c_acc: [90.6| 96.9]}  G{v_l: 0.737, v_acc: 60.9, c_acc: 100.0}\n","STEP:1052, D{v_l: 0.220, v_acc: [84.4| 90.6| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 0.607, v_acc: 71.9, c_acc: 90.6}\n","STEP:1053, D{v_l: 0.354, v_acc: [87.5| 84.4| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 0.763, v_acc: 67.2, c_acc: 95.3}\n","STEP:1054, D{v_l: 0.267, v_acc: [96.9| 78.1| 87.5], c_acc: [100.0| 93.8]}  G{v_l: 0.826, v_acc: 67.2, c_acc: 92.2}\n","STEP:1055, D{v_l: 0.399, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.932, v_acc: 57.8, c_acc: 96.9}\n","STEP:1056, D{v_l: 0.395, v_acc: [90.6| 78.1| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.966, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 3.1348 - valid_loss: 0.6379 - class_loss: 2.1121 - valid_acc: 0.6824 - class_acc: 0.4941\n","3/3 [==============================] - 0s 45ms/step - loss: 1.9652 - valid_loss: 1.4446 - class_loss: 0.1358 - valid_acc: 0.2000 - class_acc: 0.9529\n","average v_acc: 44.118, three class acc: 49.412, two class acc: 60.000\n","====================================================================================================\n","STEP:1057, D{v_l: 0.749, v_acc: [39.3| 90.6| 65.0], c_acc: [93.2| 93.8]}  G{v_l: 0.891, v_acc: 57.8, c_acc: 93.8}\n","STEP:1058, D{v_l: 0.413, v_acc: [93.8| 78.1| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 1.254, v_acc: 48.4, c_acc: 95.3}\n","STEP:1059, D{v_l: 0.156, v_acc: [93.8| 96.9| 95.3], c_acc: [93.8| 100.0]}  G{v_l: 0.624, v_acc: 67.2, c_acc: 93.8}\n","STEP:1060, D{v_l: 0.189, v_acc: [96.9| 93.8| 95.3], c_acc: [93.8| 100.0]}  G{v_l: 0.887, v_acc: 53.1, c_acc: 98.4}\n","STEP:1061, D{v_l: 0.241, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 0.771, v_acc: 56.2, c_acc: 92.2}\n","STEP:1062, D{v_l: 0.364, v_acc: [81.2| 93.8| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.778, v_acc: 65.6, c_acc: 90.6}\n","STEP:1063, D{v_l: 0.375, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 0.676, v_acc: 70.3, c_acc: 92.2}\n","STEP:1064, D{v_l: 0.173, v_acc: [100.0| 93.8| 96.9], c_acc: [96.9| 100.0]}  G{v_l: 0.872, v_acc: 59.4, c_acc: 96.9}\n","STEP:1065, D{v_l: 0.190, v_acc: [90.6| 93.8| 92.2], c_acc: [100.0| 96.9]}  G{v_l: 0.740, v_acc: 62.5, c_acc: 98.4}\n","STEP:1066, D{v_l: 0.122, v_acc: [100.0| 93.8| 96.9], c_acc: [96.9| 100.0]}  G{v_l: 0.611, v_acc: 70.3, c_acc: 96.9}\n","STEP:1067, D{v_l: 0.302, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.621, v_acc: 79.7, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.2369 - valid_loss: 0.6194 - class_loss: 2.2328 - valid_acc: 0.6471 - class_acc: 0.4706\n","3/3 [==============================] - 0s 48ms/step - loss: 1.9055 - valid_loss: 1.4405 - class_loss: 0.0804 - valid_acc: 0.2353 - class_acc: 0.9647\n","average v_acc: 44.118, three class acc: 47.059, two class acc: 58.824\n","====================================================================================================\n","STEP:1068, D{v_l: 0.697, v_acc: [42.7| 81.2| 62.0], c_acc: [97.4| 96.9]}  G{v_l: 0.663, v_acc: 62.5, c_acc: 98.4}\n","STEP:1069, D{v_l: 0.433, v_acc: [75.0| 90.6| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 0.914, v_acc: 60.9, c_acc: 98.4}\n","STEP:1070, D{v_l: 0.267, v_acc: [93.8| 90.6| 92.2], c_acc: [100.0| 96.9]}  G{v_l: 0.955, v_acc: 59.4, c_acc: 95.3}\n","STEP:1071, D{v_l: 0.218, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 96.9]}  G{v_l: 1.030, v_acc: 56.2, c_acc: 98.4}\n","STEP:1072, D{v_l: 0.308, v_acc: [96.9| 87.5| 92.2], c_acc: [96.9| 96.9]}  G{v_l: 0.708, v_acc: 68.8, c_acc: 93.8}\n","STEP:1073, D{v_l: 0.219, v_acc: [84.4| 93.8| 89.1], c_acc: [100.0| 93.8]}  G{v_l: 0.942, v_acc: 53.1, c_acc: 95.3}\n","STEP:1074, D{v_l: 0.382, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 0.775, v_acc: 60.9, c_acc: 98.4}\n","STEP:1075, D{v_l: 0.401, v_acc: [78.1| 87.5| 82.8], c_acc: [93.8| 93.8]}  G{v_l: 0.769, v_acc: 65.6, c_acc: 98.4}\n","STEP:1076, D{v_l: 0.438, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 0.854, v_acc: 65.6, c_acc: 96.9}\n","STEP:1077, D{v_l: 0.199, v_acc: [96.9| 93.8| 95.3], c_acc: [96.9| 93.8]}  G{v_l: 0.983, v_acc: 53.1, c_acc: 100.0}\n","STEP:1078, D{v_l: 0.213, v_acc: [84.4| 96.9| 90.6], c_acc: [100.0| 100.0]}  G{v_l: 1.181, v_acc: 53.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.0107 - valid_loss: 0.5569 - class_loss: 2.0692 - valid_acc: 0.7176 - class_acc: 0.4941\n","3/3 [==============================] - 0s 52ms/step - loss: 1.8057 - valid_loss: 1.1671 - class_loss: 0.2540 - valid_acc: 0.2588 - class_acc: 0.9059\n","average v_acc: 48.824, three class acc: 49.412, two class acc: 61.176\n","====================================================================================================\n","STEP:1079, D{v_l: 0.638, v_acc: [41.9| 84.4| 63.1], c_acc: [92.3| 87.5]}  G{v_l: 0.626, v_acc: 62.5, c_acc: 93.8}\n","STEP:1080, D{v_l: 0.240, v_acc: [93.8| 87.5| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 0.956, v_acc: 54.7, c_acc: 98.4}\n","STEP:1081, D{v_l: 0.239, v_acc: [100.0| 84.4| 92.2], c_acc: [96.9| 93.8]}  G{v_l: 0.841, v_acc: 65.6, c_acc: 96.9}\n","STEP:1082, D{v_l: 0.275, v_acc: [90.6| 87.5| 89.1], c_acc: [90.6| 93.8]}  G{v_l: 0.924, v_acc: 56.2, c_acc: 93.8}\n","STEP:1083, D{v_l: 0.255, v_acc: [90.6| 84.4| 87.5], c_acc: [100.0| 100.0]}  G{v_l: 1.030, v_acc: 60.9, c_acc: 95.3}\n","STEP:1084, D{v_l: 0.271, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 0.773, v_acc: 65.6, c_acc: 79.7}\n","STEP:1085, D{v_l: 0.273, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 0.901, v_acc: 56.2, c_acc: 96.9}\n","STEP:1086, D{v_l: 0.330, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.742, v_acc: 64.1, c_acc: 93.8}\n","STEP:1087, D{v_l: 0.237, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 100.0]}  G{v_l: 0.688, v_acc: 67.2, c_acc: 95.3}\n","STEP:1088, D{v_l: 0.258, v_acc: [96.9| 84.4| 90.6], c_acc: [100.0| 90.6]}  G{v_l: 0.896, v_acc: 56.2, c_acc: 100.0}\n","STEP:1089, D{v_l: 0.429, v_acc: [93.8| 75.0| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.719, v_acc: 68.8, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.8163 - valid_loss: 0.4778 - class_loss: 1.9540 - valid_acc: 0.8000 - class_acc: 0.4353\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0173 - valid_loss: 1.4944 - class_loss: 0.1384 - valid_acc: 0.1412 - class_acc: 0.9412\n","average v_acc: 47.059, three class acc: 43.529, two class acc: 52.941\n","====================================================================================================\n","STEP:1090, D{v_l: 0.711, v_acc: [35.0| 87.5| 61.3], c_acc: [94.0| 100.0]}  G{v_l: 1.000, v_acc: 60.9, c_acc: 96.9}\n","STEP:1091, D{v_l: 0.262, v_acc: [84.4| 87.5| 85.9], c_acc: [87.5| 96.9]}  G{v_l: 0.720, v_acc: 67.2, c_acc: 96.9}\n","STEP:1092, D{v_l: 0.218, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 0.690, v_acc: 67.2, c_acc: 100.0}\n","STEP:1093, D{v_l: 0.260, v_acc: [75.0| 93.8| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.198, v_acc: 42.2, c_acc: 100.0}\n","STEP:1094, D{v_l: 0.256, v_acc: [87.5| 90.6| 89.1], c_acc: [90.6| 93.8]}  G{v_l: 0.910, v_acc: 56.2, c_acc: 98.4}\n","STEP:1095, D{v_l: 0.205, v_acc: [90.6| 96.9| 93.8], c_acc: [90.6| 96.9]}  G{v_l: 0.934, v_acc: 53.1, c_acc: 93.8}\n","STEP:1096, D{v_l: 0.363, v_acc: [90.6| 78.1| 84.4], c_acc: [90.6| 93.8]}  G{v_l: 0.757, v_acc: 64.1, c_acc: 96.9}\n","STEP:1097, D{v_l: 0.241, v_acc: [81.2| 96.9| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 0.921, v_acc: 64.1, c_acc: 100.0}\n","STEP:1098, D{v_l: 0.344, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 0.865, v_acc: 59.4, c_acc: 96.9}\n","STEP:1099, D{v_l: 0.280, v_acc: [84.4| 93.8| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 0.725, v_acc: 68.8, c_acc: 100.0}\n","STEP:1100, D{v_l: 0.322, v_acc: [90.6| 78.1| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 0.698, v_acc: 70.3, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.0014 - valid_loss: 0.4690 - class_loss: 2.1480 - valid_acc: 0.7882 - class_acc: 0.3647\n","3/3 [==============================] - 0s 48ms/step - loss: 1.7639 - valid_loss: 1.3199 - class_loss: 0.0595 - valid_acc: 0.2588 - class_acc: 0.9765\n","average v_acc: 52.353, three class acc: 36.471, two class acc: 58.824\n","====================================================================================================\n","Epoch: 100\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZuSOHFh7PwIK"},"source":["# Test\n"]},{"cell_type":"code","metadata":{"id":"0MjkQsg3Pxuy"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(latent_dim, test_dataset, pathway):\n","  # load model\n","  path = 'ACGAN/mode3'\n","\n","  d_model, _, _ = all_model(LATENT_DIM)\n","  d_model.load_weights(path + pathway)\n","\n","  X_test, labels_test = test_dataset\n","  num_test = X_test.shape[0]\n","  y_test = ones((num_test, 1))\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = d_model.evaluate(X_test, [y_test, labels_test], verbose=1)\n","  v_acc = 100 * test_metrics[3]\n","  three_c_acc = 100 * test_metrics[4]\n","\n","  # two class accuracy\n","  _, temp_pred = d_model.predict(X_test)\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names))\n","\n","  # calculate AUC\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4eKDxvXQYkH"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples()\n","\n","test(LATENT_DIM, test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Po9vtKuWxv1"},"source":[""],"execution_count":null,"outputs":[]}]}