{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_Brain_mode0.ipynb","provenance":[],"collapsed_sections":["GI_kANkKEnmQ","Qtzgq8Anm_Qc","5fwsQasMgjkG","UyIRcJy2hxMX"],"authorship_tag":"ABX9TyP9zXpy8/+uzXnoU3cuDJiC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621339560382,"user_tz":-480,"elapsed":21588,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"3cec685f-0917-40fe-9ab5-17e4f763bce6"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['BrainNet',\n"," 'ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621339582090,"user_tz":-480,"elapsed":1309,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"a479d500-98ea-4020-f3f1-4489772f7469"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621339582967,"user_tz":-480,"elapsed":2182,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"0778203b-f264-42d6-b198-1a8026d66c42"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.52261498 1.        ]\n"," [1.         0.45191942 1.        ]\n"," [2.         0.34840998 1.        ]\n"," [0.         0.50665146 1.        ]\n"," [2.         0.4245534  0.        ]\n"," [1.         0.33257317 1.        ]\n"," [0.         0.40174838 0.        ]\n"," [1.         0.49714937 1.        ]\n"," [2.         0.65868491 1.        ]\n"," [0.         0.56404409 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621339582967,"user_tz":-480,"elapsed":2177,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"c5c529d0-0a67-444b-8f6a-2d4640914069"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[1.         0.         0.         0.52261498 1.        ]\n"," [0.         1.         0.         0.45191942 1.        ]\n"," [0.         0.         1.         0.34840998 1.        ]\n"," [1.         0.         0.         0.50665146 1.        ]\n"," [0.         0.         1.         0.4245534  0.        ]\n"," [0.         1.         0.         0.33257317 1.        ]\n"," [1.         0.         0.         0.40174838 0.        ]\n"," [0.         1.         0.         0.49714937 1.        ]\n"," [0.         0.         1.         0.65868491 1.        ]\n"," [1.         0.         0.         0.56404409 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, combine_val, combine_test = train_test_split(X_remain, combine_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  # seperate label, age, gender\n","  y_train = combine_train[:, 0]\n","  y_test = combine_test[:, 0]\n","  y_val = combine_val[:, 0]\n","  as_train = combine_train[:, 1:] \n","  as_test = combine_test[:, 1:]  \n","  as_val = combine_val[:, 1:]\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}, as shape: {as_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}, as shape: {as_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}, as shape: {as_test.shape}\")\n","\n","  output = [X_train, y_train, as_train],[X_val, y_val, as_val],[X_test, y_test, as_test]\n","  print(f\"Code_train shape: {as_train.shape}\")\n","\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621339583368,"user_tz":-480,"elapsed":1801,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"147b727f-1c65-482a-ca1b-02635f547305"},"source":["DROPOUT = 0.5\n","MOMENTUM = 0.9\n","LR = 0.001 \n","DECAY = 0.0005\n","ALPHA = 0.33\n","FE_CHANNEL = 64\n","CODE_CHANNEL = 16\n","MERGE_CHANNEL = 32\n","BATCH_SIZE = 32\n","\n","'''\n","The number of E2E layers\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\n'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"Qtzgq8Anm_Qc"},"source":["#Build Model"]},{"cell_type":"code","metadata":{"id":"GQnmpA-znDOP"},"source":["class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5fwsQasMgjkG"},"source":["#Model"]},{"cell_type":"code","metadata":{"id":"B7G8B4M4oO6x"},"source":["def define_E2E(in_shape=(190,190,1), n_classes=3):\n","  # Setting l2_norm regularizer\n","  reg = regularizers.l2(DECAY)\n","  # kernel initialization\n","  kernel_init = initializers.he_uniform()\n","  in_image = Input(shape=in_shape)\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 16, (2, 190), kernel_regularizer=reg)(in_image) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(fe) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(64, (1, 190), kernel_regularizer=reg, name='row')(fe)   \n","  temp2 = Conv2D(64, (190, 1), kernel_regularizer=reg, name='column')(fe) \n","  temp2 = Reshape((190, 1, 64))(temp2)\n","  fe = Add()([temp1, temp2])                    \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(128, (190, 1), kernel_regularizer=reg)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(DROPOUT)(fe)\n","\n","  # code input\n","  code_shape = (2,)  \n","  in_code = Input(shape=code_shape, name='in_code')\n","\n","  code = Dense(CODE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(in_code)\n","  code = LeakyReLU(alpha=ALPHA)(code)\n","  code = Dropout(DROPOUT)(code)\n","\n","  # concatenate image and code\n","  merge = Concatenate()([fe, code])\n","\n","  # # concatenate image and code\n","  # merge = Concatenate()([fe, in_code])\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(merge)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(DROPOUT)(merge)\n","\n","  out = Dense(n_classes, activation='softmax', name='out')(merge)\n","    \n","  # define model\n","  model = Model([in_image, in_code], out)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuQssoINq2Jd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621339589383,"user_tz":-480,"elapsed":6381,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"d5a584b6-7df3-494b-bf98-63732ccfa14b"},"source":["BrainNetCNN = define_E2E()\n","BrainNetCNN.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 16) 6080        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 16) 0           e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 32) 194560      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 32) 0           e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 64)   0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 64)   0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 64)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 128)    1556608     leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 128)    0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 128)          0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","in_code (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 64)           8256        flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 16)           48          in_code[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 64)           0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 64)           0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 80)           0           dropout[0][0]                    \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 32)           2592        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32)           0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","out (Dense)                     (None, 3)            99          dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 2,546,611\n","Trainable params: 2,546,611\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UyIRcJy2hxMX"},"source":["# Load"]},{"cell_type":"code","metadata":{"id":"inVRFCBByAYA","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"error","timestamp":1621340414262,"user_tz":-480,"elapsed":1094,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"e5d2eff1-b5d4-4a4c-a002-5ee6881c2eba"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)\n","X_train, y_train, code_train = train_data\n","X_val, y_val, code_val = val_data\n","X_test, y_test, code_test = test_data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order, subok=True)\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-d48f2055cde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-e40ecde90890>\u001b[0m in \u001b[0;36mload_real_samples\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# expand to 3d, e.g. add channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mX_remain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_remain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (758,190,190,1) into shape (758)"]}]},{"cell_type":"markdown","metadata":{"id":"XVnoUekra-5Z"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"9m8iJp4eq3Cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621343022201,"user_tz":-480,"elapsed":126781,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"e694e6e7-911f-4af1-971f-e0531a2a6046"},"source":["path = \"./BrainNet/mode0/epoch_100.h5\"\n","batch_size = 32\n","\n","opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","checkpoint = ModelCheckpoint(path, monitor='val_acc', verbose=0, save_best_only=True)\n","earlystopping = EarlyStopping(patience=10)\n","callbacks_list = [checkpoint,earlystopping]\n","\n","# define model\n","model_1 = define_E2E()\n","model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","\n","# train\n","history = model_1.fit([X_train, code_train], y_train,\n","              epochs=100,\n","              batch_size=batch_size,\n","              validation_data=([X_val, code_val], y_val),\n","              callbacks=callbacks_list,\n","              shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","24/24 [==============================] - 7s 188ms/step - loss: 1.2559 - acc: 0.4911 - val_loss: 1.2321 - val_acc: 0.5294\n","Epoch 2/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.2391 - acc: 0.5675 - val_loss: 1.2151 - val_acc: 0.5294\n","Epoch 3/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1622 - acc: 0.6205 - val_loss: 1.2045 - val_acc: 0.5294\n","Epoch 4/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.1653 - acc: 0.6160 - val_loss: 1.1872 - val_acc: 0.5294\n","Epoch 5/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1252 - acc: 0.6268 - val_loss: 1.1759 - val_acc: 0.5294\n","Epoch 6/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1680 - acc: 0.5930 - val_loss: 1.1700 - val_acc: 0.5294\n","Epoch 7/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.1790 - acc: 0.5725 - val_loss: 1.1650 - val_acc: 0.5294\n","Epoch 8/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.1294 - acc: 0.6063 - val_loss: 1.1601 - val_acc: 0.5294\n","Epoch 9/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1201 - acc: 0.6157 - val_loss: 1.1538 - val_acc: 0.5294\n","Epoch 10/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.1180 - acc: 0.6016 - val_loss: 1.1463 - val_acc: 0.5294\n","Epoch 11/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.0660 - acc: 0.6357 - val_loss: 1.1392 - val_acc: 0.5294\n","Epoch 12/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.1018 - acc: 0.6023 - val_loss: 1.1268 - val_acc: 0.5294\n","Epoch 13/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1314 - acc: 0.5951 - val_loss: 1.1192 - val_acc: 0.5294\n","Epoch 14/100\n","24/24 [==============================] - 4s 168ms/step - loss: 1.1009 - acc: 0.5920 - val_loss: 1.1161 - val_acc: 0.5294\n","Epoch 15/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.0484 - acc: 0.6363 - val_loss: 1.1078 - val_acc: 0.5294\n","Epoch 16/100\n","24/24 [==============================] - 4s 166ms/step - loss: 1.0331 - acc: 0.6397 - val_loss: 1.0985 - val_acc: 0.5294\n","Epoch 17/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.0222 - acc: 0.6473 - val_loss: 1.0892 - val_acc: 0.5765\n","Epoch 18/100\n","24/24 [==============================] - 4s 167ms/step - loss: 1.0072 - acc: 0.6647 - val_loss: 1.0857 - val_acc: 0.5765\n","Epoch 19/100\n","24/24 [==============================] - 4s 168ms/step - loss: 0.9323 - acc: 0.6576 - val_loss: 1.0898 - val_acc: 0.5647\n","Epoch 20/100\n","24/24 [==============================] - 4s 166ms/step - loss: 0.9179 - acc: 0.6856 - val_loss: 1.0752 - val_acc: 0.5882\n","Epoch 21/100\n","24/24 [==============================] - 4s 166ms/step - loss: 0.8637 - acc: 0.6988 - val_loss: 1.1398 - val_acc: 0.6000\n","Epoch 22/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.8602 - acc: 0.7006 - val_loss: 1.2011 - val_acc: 0.6000\n","Epoch 23/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.9231 - acc: 0.6627 - val_loss: 1.1946 - val_acc: 0.6000\n","Epoch 24/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.8441 - acc: 0.6907 - val_loss: 1.1672 - val_acc: 0.5882\n","Epoch 25/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.8361 - acc: 0.7214 - val_loss: 1.3212 - val_acc: 0.6118\n","Epoch 26/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.8430 - acc: 0.7190 - val_loss: 1.2811 - val_acc: 0.5647\n","Epoch 27/100\n","24/24 [==============================] - 4s 166ms/step - loss: 0.8264 - acc: 0.7031 - val_loss: 1.4829 - val_acc: 0.5765\n","Epoch 28/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.7180 - acc: 0.7535 - val_loss: 2.3669 - val_acc: 0.5647\n","Epoch 29/100\n","24/24 [==============================] - 4s 167ms/step - loss: 0.7604 - acc: 0.7400 - val_loss: 1.6961 - val_acc: 0.5529\n","Epoch 30/100\n","24/24 [==============================] - 4s 168ms/step - loss: 0.6557 - acc: 0.7928 - val_loss: 1.6106 - val_acc: 0.5529\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_h9U3vpfae2d","executionInfo":{"status":"ok","timestamp":1621343026934,"user_tz":-480,"elapsed":130703,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"42abbe64-0996-4e00-db33-5d8b8b214eb6"},"source":["test(test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 49ms/step - loss: 1.3004 - acc: 0.5797\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f77a931f5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","test: 60.465\n","three class acc: 60.465, two class acc: 65.116\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6301    0.9388    0.7541        49\n","     class 1     0.4615    0.2308    0.3077        26\n","     class 2     0.0000    0.0000    0.0000        11\n","\n","    accuracy                         0.6047        86\n","   macro avg     0.3639    0.3898    0.3539        86\n","weighted avg     0.4986    0.6047    0.5227        86\n","\n","AUC:  0.7217242860100003\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6301    0.9388    0.7541        49\n","     class 1     0.7692    0.2703    0.4000        37\n","\n","    accuracy                         0.6512        86\n","   macro avg     0.6997    0.6045    0.5770        86\n","weighted avg     0.6900    0.6512    0.6018        86\n","\n","specificity: 0.9387755102040817\n","AUC:  0.750137892995036\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"X70XqBemjGDD"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"xPBbaCfhe6XB"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(test_dataset):\n","  # load model\n","  path = \"./BrainNet/mode0/epoch_100.h5\"\n","  model_1 = define_E2E()\n","  opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","  model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","  model_1.load_weights(path)\n","\n","  X_test, labels_test, code_test = test_dataset\n","  num_test = X_test.shape[0]\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = model_1.evaluate([X_test, code_test], labels_test, verbose=1)\n","  three_c_acc = 100 * test_metrics[1]\n","\n","  # two class accuracy\n","  temp_pred = model_1.predict([X_test, code_test])\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('three class acc: %.3f, two class acc: %.3f' % (three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names, digits=4))\n","\n","  # calculate AUC\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names, digits=4))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DhuhxEeiX9X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621340312392,"user_tz":-480,"elapsed":2700,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"f29d1668-3198-4fdd-eae0-29df25182ea7"},"source":["test(test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 49ms/step - loss: 1.0821 - acc: 0.5544\n","test: 56.977\n","three class acc: 56.977, two class acc: 56.977\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.5714    0.9796    0.7218        49\n","     class 1     0.5000    0.0385    0.0714        26\n","     class 2     0.0000    0.0000    0.0000        11\n","\n","    accuracy                         0.5698        86\n","   macro avg     0.3571    0.3394    0.2644        86\n","weighted avg     0.4767    0.5698    0.4329        86\n","\n","AUC:  0.7355500484071912\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.5714    0.9796    0.7218        49\n","     class 1     0.5000    0.0270    0.0513        37\n","\n","    accuracy                         0.5698        86\n","   macro avg     0.5357    0.5033    0.3865        86\n","weighted avg     0.5407    0.5698    0.4333        86\n","\n","specificity: 0.9795918367346939\n","AUC:  0.7446221731936018\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}