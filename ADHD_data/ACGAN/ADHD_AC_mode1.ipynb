{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_AC_mode1.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","GI_kANkKEnmQ","_lIT_ZxfE1mZ","xaIOGJ22LzA6","cLWWWfE6L20n","fK7NGsGKL5Ts"],"authorship_tag":"ABX9TyP8fIclwING0+u6DHxtxVJu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621396240870,"user_tz":-480,"elapsed":18604,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"f2544037-2dca-408e-f5c1-5e54c67e1d23"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'BrainNet',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621396269102,"user_tz":-480,"elapsed":675,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"cd86364d-8925-47d7-b98e-123362945323"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621396269457,"user_tz":-480,"elapsed":1026,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"1ad43f57-e1b6-4582-8aa2-f22aad387666"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[2.         0.43076143 1.        ]\n"," [2.         0.3736222  1.        ]\n"," [1.         0.67578867 1.        ]\n"," [0.         0.3945268  0.        ]\n"," [0.         0.30064614 0.        ]\n"," [2.         0.60167237 1.        ]\n"," [1.         0.45686051 0.        ]\n"," [0.         0.65108324 0.        ]\n"," [0.         0.42721399 1.        ]\n"," [0.         0.32155074 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621396269458,"user_tz":-480,"elapsed":1021,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"a85dac11-3f16-4ac3-cd4d-c2cbde053bec"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[0.         0.         1.         0.43076143 1.        ]\n"," [0.         0.         1.         0.3736222  1.        ]\n"," [0.         1.         0.         0.67578867 1.        ]\n"," [1.         0.         0.         0.3945268  0.        ]\n"," [1.         0.         0.         0.30064614 0.        ]\n"," [0.         0.         1.         0.60167237 1.        ]\n"," [0.         1.         0.         0.45686051 0.        ]\n"," [1.         0.         0.         0.65108324 0.        ]\n"," [1.         0.         0.         0.42721399 1.        ]\n"," [1.         0.         0.         0.32155074 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621396271689,"user_tz":-480,"elapsed":652,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"c96e038b-27fb-447f-f7c1-b2b74fc4305d"},"source":["# Discriminator\n","DECAY = 0.0005\n","ALPHA = 0.33\n","LR_D = 0.0001\n","BETA_D = 0.5\n","FE_CHANNEL = 128\n","CODE_CHANNEL = 16\n","MERGE_CHANNEL = 64\n","\n","# Generator\n","D = 10\n","STD = 0.02\n","\n","# GAN\n","LR_G = 0.0001\n","BETA_G = 0.5\n","\n","# Loss weights\n","LOSS_WEIGHTS = [1.0, 1.0]\n","\n","# Train function\n","LATENT_DIM = 50\n","BATCH_SIZE = 64\n","\n","'''\n","The number of E2E layers\n","Channel size of E2E layers\n","Dropout\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\nChannel size of E2E layers\\nDropout\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"_lIT_ZxfE1mZ"},"source":["#Model function"]},{"cell_type":"code","metadata":{"id":"kYW-Fke9E5tT"},"source":["# define E2E layer\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.utils import conv_utils\n","\n","class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaIOGJ22LzA6"},"source":["# define D"]},{"cell_type":"code","metadata":{"id":"ySQCRi_RFACM"},"source":["# define the standalone discriminator model\n","def define_discriminator(image_shape=(190,190,1), n_classes=3):\n","  # weight regularization\n","  reg = regularizers.l2(DECAY)\n","  # weight initialization\n","  kernel_init = initializers.he_uniform()\n","  # image input\n","  in_image = Input(shape=image_shape, name='in_image')\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(in_image)  \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 64, (2, 190), kernel_regularizer=reg)(fe)     \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(128, (1, 190), kernel_regularizer=reg, name='row')(fe)  \n","  temp2 = Conv2D(128, (190, 1), kernel_regularizer=reg, name='column')(fe)\n","  temp2 = Reshape((190, 1, 128))(temp2)\n","  fe = Add()([temp1, temp2])\n","  fe = BatchNormalization()(fe)                          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(256, (190, 1), kernel_regularizer=reg)(fe) \n","  fe = BatchNormalization()(fe)          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # code input\n","  code_shape = (1,)\n","  in_code = Input(shape=code_shape, name='in_code')\n","\n","  code = Dense(CODE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(in_code)\n","  code = LeakyReLU(alpha=ALPHA)(code)\n","  code = Dropout(0.5)(code)\n","\n","  # concatenate image and code\n","  merge = Concatenate()([fe, code])\n","\n","  # # concatenate image and code\n","  # merge = Concatenate()([fe, in_code])\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(merge)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(0.5)(merge)\n","\n","  # real/fake output\n","  out1 = Dense(1, activation='sigmoid', name='valid')(merge)\n","  # class label output\n","  out2 = Dense(n_classes, activation='softmax', name='class')(merge)\n","  # define model\n","  model = Model([in_image, in_code], [out1, out2], name=\"Discriminator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLWWWfE6L20n"},"source":["# define G"]},{"cell_type":"code","metadata":{"id":"feTOreTCFQEr"},"source":["# define the standalone generator model\n","def define_generator(latent_dim=50, n_classes=3, d=D):\n","  #Initailize Weights\n","  init = RandomNormal(stddev=STD)\n","    \n","  #Take in noise as input\n","  in_z = keras.Input(shape=(latent_dim,))\n","  print(f\"Shape of Noise Vector: {in_z.shape}\")\n","  \n","  #Create a dense layer\n","  dense = keras.layers.Dense(190*d, activation=\"relu\", kernel_initializer = init)\n","  \n","  X = dense(in_z)\n","  X = keras.layers.Reshape((190,d))(X)\n","  print(f\"Shape of X: {X.shape}\")\n","\n","  A = keras.layers.Dot(axes=(2, 2))([X,X])\n","  A = keras.backend.expand_dims(A, axis = -1)\n","  \n","  A = Activation('tanh')(A)\n","  print(f\"Shape of A: {A.shape}\")\n","  \n","  # define model\n","  model = Model(in_z, A, name=\"Generator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK7NGsGKL5Ts"},"source":["#define GAN"]},{"cell_type":"code","metadata":{"id":"bzf_8DlyHJGD"},"source":["def all_model(latent_dim=LATENT_DIM):\n","  # define D & G\n","  d_model = define_discriminator()\n","  g_model = define_generator(latent_dim)\n","\n","  # compile D\n","  opt = optimizers.Adam(lr=LR_D, beta_1=BETA_D)\n","  d_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  # define GAN\n","  d_model.trainable = False\n"," \n","  in_noise = keras.Input(shape=(latent_dim,))\n","  img = g_model(in_noise)\n","\n","  in_code = keras.Input(shape=(1,))\n","  valid, label = d_model([img, in_code])\n","  gan_model = Model([in_noise, in_code], [valid, label], name=\"GAN\")\n","\n","  opt = optimizers.Adam(lr=LR_G, beta_1=BETA_G)\n","  gan_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  return d_model, g_model, gan_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8CEB6VkKsQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621396296846,"user_tz":-480,"elapsed":6784,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"c9fcafc2-24d7-4d3d-ac01-d4a2e8267620"},"source":["d_model, g_model, gan_model = all_model(LATENT_DIM)\n","d_model.summary()\n","g_model.summary()\n","gan_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","in_image (InputLayer)           [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 32) 12160       in_image[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 190, 190, 32) 128         e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 64) 778240      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 190, 190, 64) 256         e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 190, 190, 64) 0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 128)  0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 128)  0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 190, 1, 128)  512         add[0][0]                        \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 190, 1, 128)  0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 256)    6226176     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 1, 1, 256)    1024        conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 256)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1, 1, 256)    0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 256)          0           dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","in_code (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          32896       flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 16)           32          in_code[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 144)          0           dropout_3[0][0]                  \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           9280        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 64)           0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","valid (Dense)                   (None, 1)            65          dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 3)            195         dropout_5[0][0]                  \n","==================================================================================================\n","Total params: 10,174,180\n","Trainable params: 0\n","Non-trainable params: 10,174,180\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1900)         96900       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 190, 10)      0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 190, 190)     0           reshape_1[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","tf.expand_dims (TFOpLambda)     (None, 190, 190, 1)  0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 190, 190, 1)  0           tf.expand_dims[0][0]             \n","==================================================================================================\n","Total params: 96,900\n","Trainable params: 96,900\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","Generator (Functional)          (None, 190, 190, 1)  96900       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Discriminator (Functional)      [(None, 1), (None, 3 10174180    Generator[0][0]                  \n","                                                                 input_3[0][0]                    \n","==================================================================================================\n","Total params: 10,271,080\n","Trainable params: 96,900\n","Non-trainable params: 10,174,180\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zm7qDbXsMJcD"},"source":["#Auxiliary function"]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, combine_val, combine_test = train_test_split(X_remain, combine_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  # seperate label, age, gender\n","  y_train = combine_train[:, 0]\n","  y_test = combine_test[:, 0]\n","  y_val = combine_val[:, 0]\n","  as_train = combine_train[:, 1:] \n","  as_test = combine_test[:, 1:]  \n","  as_val = combine_val[:, 1:]\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}, as shape: {as_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}, as shape: {as_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}, as shape: {as_test.shape}\")\n","\n","  output = [X_train, y_train, as_train[:, 0]],[X_val, y_val, as_val[:, 0]],[X_test, y_test, as_test[:, 0]]\n","  print(f\"Code_train shape: {as_train[:, 0].shape}\")\n","\n","  return output\n","\n","# select real samples\n","def generate_real_samples(dataset, n_samples):\n","  # split into images and labels\n","  images, labels, codes = dataset\n","  # choose random instances\n","  ix = np.random.randint(0, images.shape[0], n_samples)\n","  # select images and labels and codes\n","  y = np.ones((n_samples, 1))\n","  X, label, code = images[ix], labels[ix], codes[ix]\n","  return [X, code], [y, label]\n","\n","def generate_random_ecodings(n_samples):\n","  enc_idx = np.arange(0, len(encoded_data))\n","  sample_idx = np.random.choice(enc_idx, size = n_samples)\n","  samples = []\n","  labels = []\n","\n","  for idx in sample_idx:\n","    samples.append(encoded_data[idx])\n","    label = encoded_data[idx][:3]\n","    if label[0]==1:\n","        labels.append(0)\n","    elif label[1]==1:\n","        labels.append(1)\n","    else:\n","        labels.append(2)\n","  \n","  samples = np.array(samples)\n","  label = samples[:, :3]\n","  age = samples[:, 3].reshape(-1,1)\n","  samples = np.concatenate([label, age], axis=1)\n","  codes = age\n","  return [samples, codes], labels\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, n_classes=3):\n","  #Generate noise, n_code dimension + label dimension \n","  n = 4      \n","  z_noise = np.random.normal(0, 1, size=[n_samples,latent_dim-n])   # Gaussian distribution\n","  #Generate encoding of 4 dimensions\n","  [z_encoding, codes], labels = generate_random_ecodings(n_samples)\n","  #Concatenate z_noise and z_encoding to create input of latent_dim\n","  z_input = np.concatenate((z_noise, z_encoding), axis = 1)\n","  labels = np.array(labels)\n","  return [z_input, codes], labels\n","\n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","  # generate points in latent space\n","  [z_input, codes], labels_input = generate_latent_points(latent_dim, n_samples)\n","  # predict outputs\n","  images = generator.predict(z_input)\n","  y = np.zeros((n_samples, 1))           \n","  return [images, codes], [y, labels_input]\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, d_model):\n","  path = 'ACGAN/mode1'\n","  filename1 = path + '/weights/d_model_%04d.h5' % (step+1)\n","  d_model.save_weights(filename1)\n","  print('>Saved: %s' % filename1)\n","\n","# create a line plot of loss for the gan and save to file\n","def plot_history(train_hist, validation_hist):\n","  path = 'ACGAN/mode1'\n","  # dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = train_hist\n","  # # plot train_data loss\n","  # pyplot.plot(dr_v_loss1, label='D-validity-real')\n","  # pyplot.plot(df_v_loss1, label='D-validity-fake')\n","  # pyplot.plot(g_v_loss1, label='G-validity')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_loss.pdf')\n","  # pyplot.close()\n"," \n","  # # plot train_datad accuracy\n","  # pyplot.plot(dr_v_acc1, label='validity-real')\n","  # pyplot.plot(df_v_acc1, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_valid_acc.pdf')\n","  # pyplot.close()\n","\n","  # pyplot.plot(dr_c_acc1, label='class-real')\n","  # pyplot.plot(df_c_acc1, label='class-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_class_acc.pdf')\n","  # pyplot.close()\n"," \n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = validation_hist\n","  # # plot validation_data loss\n","  # pyplot.plot(dr_v_loss2, label='validity-real')\n","  # pyplot.plot(df_v_loss2, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_validation_loss.pdf')\n","  # pyplot.close()\n","\n","  # plot validation_data accuracy\n","  pyplot.plot(dr_v_acc2, label='validity-real')\n","  pyplot.plot(df_v_acc2, label='validity-fake')\n","  pyplot.plot(dr_c_acc2, label='class-real')\n","  pyplot.legend()\n","  pyplot.savefig(path + '/val_acc.pdf')\n","  pyplot.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_aFGLeJHxs5"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"T9RhPPnOHxs6"},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, val_dataset, n_epochs=300, latent_dim=LATENT_DIM, n_batch=BATCH_SIZE):\n","  epoch=0\n","  # calculate the number of batches per training epoch\n","  bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","  # calculate the number of training iterations\n","  n_steps = bat_per_epo * n_epochs\n","  # calculate the real/fake batch_size\n","  half_batch = int(n_batch / 2)\n","  # prepare lists for train_data hist\n","  dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = list(), list(), list(), list(), list(), list(), list()\n","  # prepare lists for validation_data hist\n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = list(), list(), list(), list(), list()\n","\n","  # manually enumerate epochs\n","  for i in range(n_steps):\n","    #----------------------------------------\n","    # update discriminator model weights\n","    #----------------------------------------\n","\n","    # get randomly selected 'real' samples\n","    [X_real, code_real], [y_real, labels_real] = generate_real_samples(dataset, half_batch)\n","    dr_metrics = d_model.train_on_batch([X_real, code_real], [y_real, labels_real])\n","    # generate 'fake' \n","    [X_fake, code_fake], [y_fake, labels_fake] = generate_fake_samples(g_model, latent_dim, half_batch)\n","    df_metrics = d_model.train_on_batch([X_fake, code_fake], [y_fake, labels_fake])\n","\n","    # summarize the loss and accuracy\n","    d_metrics = 0.5 * np.add(dr_metrics, df_metrics)\n","\n","    #----------------------------------------\n","    # update the generator via the discriminator's error\n","    #----------------------------------------\n","\n","    # prepare points in latent space as input for the generator\n","    [z_input, codes_input], z_labels = generate_latent_points(latent_dim, n_batch)   \n","    y_gan = np.ones((n_batch, 1)) \n","    g_metrics = gan_model.train_on_batch([z_input, codes_input], [y_gan, z_labels])\n","\n","    # summarize loss on this batch\n","    print('STEP:%d, D{v_l: %.3f, v_acc: [%.1f| %.1f| %.1f], c_acc: [%.1f| %.1f]}  G{v_l: %.3f, v_acc: %.1f, c_acc: %.1f}'\n","        % (i+1, d_metrics[1], 100*dr_metrics[3], 100*df_metrics[3], 100*d_metrics[3], 100*dr_metrics[4], 100*df_metrics[4], \n","          g_metrics[1], 100*g_metrics[3], 100*g_metrics[4]))\n","    # metrics[0]: loss, metrics[1]: validity_loss, metrics[2]: classification_loss, metrics[3]: validity_accuracy, metrics[4]: classification_accuracy\n","\n","    # record history\n","    dr_v_loss1.append(dr_metrics[1])\n","    df_v_loss1.append(df_metrics[1])\n","    g_v_loss1.append(g_metrics[1])\n","    dr_v_acc1.append(dr_metrics[3])\n","    df_v_acc1.append(df_metrics[3])\n","    dr_c_acc1.append(dr_metrics[4])\n","    df_c_acc1.append(df_metrics[4])\n","\n","    #----------------------------------------\n","    # evaluation\n","    #----------------------------------------\n","    if (i+1) % (bat_per_epo) == 0:\n","      epoch+=1\n","      # generate real validation data\n","      X_r_val, labels_r_val, codes_r_val = val_dataset\n","      num_test = X_r_val.shape[0]\n","      # generate fake validation data\n","      y_r_val = ones((num_test, 1))\n","      [X_f_val, codes_f_val], [y_f_val, labels_f_val] = generate_fake_samples(g_model, latent_dim, num_test)\n","\n","      print(f\"\\nValidation Metrics of Discriminator:\")\n","      # evaluate both real and fake valid_dataset\n","      valid_metrics_r = d_model.evaluate([X_r_val, codes_r_val], [y_r_val, labels_r_val], verbose=1)\n","      valid_metrics_f = d_model.evaluate([X_f_val, codes_f_val], [y_f_val, labels_f_val], verbose=1)\n","\n","      v_acc = 50 * (valid_metrics_r[3] + valid_metrics_f[3])   \n","      three_c_acc = 100 * valid_metrics_r[4]\n","\n","      # two class accuracy\n","      _, labels_pred = d_model.predict([X_r_val, codes_r_val])\n","      labels_pred = np.argmax(labels_pred, axis=1)\n","      # print('val {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_r_val==0), np.sum(labels_r_val==1), np.sum(labels_r_val==2)))\n","      # print('pred {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_pred==0), np.sum(labels_pred==1), np.sum(labels_pred==2)))\n","      labels_2_val, labels_2_pred = labels_r_val.copy(), labels_pred.copy()\n","      # classify 2 as 1\n","      labels_2_val[labels_2_val==2] = 1\n","      labels_2_pred[labels_2_pred==2] = 1\n","      # calculate the accuracy \n","      correct = np.sum(labels_2_val==labels_2_pred)\n","      two_c_acc = correct / num_test * 100\n","\n","      print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","      print(\"=\"*100)\n","      # save good models\n","      # if (40 < v_acc < 60) and (three_c_acc > 63):\n","      if three_c_acc >60 or two_c_acc > 65:   # baseline 57 65\n","        summarize_performance(i, d_model)\n","\n","      # record history\n","      dr_v_loss2.append(valid_metrics_r[1])\n","      df_v_loss2.append(valid_metrics_f[1])\n","      dr_v_acc2.append(valid_metrics_r[3])\n","      df_v_acc2.append(valid_metrics_f[3])\n","      dr_c_acc2.append(valid_metrics_r[4])\n","\n","    # print epoch\n","    if (i+1) % (bat_per_epo * 10) == 0:\n","      print(f\"Epoch: {epoch}\")\n","      print(\"=\"*100)\n","      \n","      # plot history\n","      train_hist = [dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1]\n","      validation_hist = [dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      plot_history(train_hist, validation_hist)\n","      point = [dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      np.save('ACGAN/mode1/point_1', point)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHWEBxezHxs6","executionInfo":{"status":"ok","timestamp":1621396457291,"user_tz":-480,"elapsed":674,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"15e0fed6-17a2-49ed-971c-fe5ed47467e8"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,), as shape: (758, 2)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,), as shape: (85, 2)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,), as shape: (86, 2)\n","Code_train shape: (758,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5Eitw1JHxs7","executionInfo":{"status":"ok","timestamp":1621397663840,"user_tz":-480,"elapsed":1205876,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"c4243350-261a-4aa0-b1ce-2d8b4eb265ee"},"source":["epochs = 100\n","\n","# define model\n","discriminator, generator, gan_model = all_model(LATENT_DIM)\n","# train model\n","train(generator, discriminator, gan_model, train_data, val_data, n_epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","STEP:1, D{v_l: 1.553, v_acc: [68.8| 25.0| 46.9], c_acc: [40.6| 31.2]}  G{v_l: 0.765, v_acc: 46.9, c_acc: 31.2}\n","STEP:2, D{v_l: 0.880, v_acc: [59.4| 68.8| 64.1], c_acc: [9.4| 43.8]}  G{v_l: 0.737, v_acc: 53.1, c_acc: 31.2}\n","STEP:3, D{v_l: 1.181, v_acc: [62.5| 59.4| 60.9], c_acc: [31.2| 31.2]}  G{v_l: 0.686, v_acc: 59.4, c_acc: 31.2}\n","STEP:4, D{v_l: 1.566, v_acc: [46.9| 50.0| 48.4], c_acc: [43.8| 28.1]}  G{v_l: 0.725, v_acc: 54.7, c_acc: 37.5}\n","STEP:5, D{v_l: 1.181, v_acc: [43.8| 59.4| 51.6], c_acc: [21.9| 21.9]}  G{v_l: 0.660, v_acc: 56.2, c_acc: 46.9}\n","STEP:6, D{v_l: 1.437, v_acc: [46.9| 43.8| 45.3], c_acc: [40.6| 31.2]}  G{v_l: 0.682, v_acc: 56.2, c_acc: 40.6}\n","STEP:7, D{v_l: 1.185, v_acc: [65.6| 46.9| 56.2], c_acc: [25.0| 21.9]}  G{v_l: 0.634, v_acc: 65.6, c_acc: 43.8}\n","STEP:8, D{v_l: 1.273, v_acc: [53.1| 46.9| 50.0], c_acc: [40.6| 34.4]}  G{v_l: 0.655, v_acc: 54.7, c_acc: 40.6}\n","STEP:9, D{v_l: 1.169, v_acc: [62.5| 46.9| 54.7], c_acc: [21.9| 21.9]}  G{v_l: 0.694, v_acc: 54.7, c_acc: 40.6}\n","STEP:10, D{v_l: 1.297, v_acc: [50.0| 40.6| 45.3], c_acc: [25.0| 31.2]}  G{v_l: 0.705, v_acc: 51.6, c_acc: 40.6}\n","STEP:11, D{v_l: 1.193, v_acc: [53.1| 46.9| 50.0], c_acc: [34.4| 31.2]}  G{v_l: 0.662, v_acc: 57.8, c_acc: 34.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 278ms/step - loss: 2.0742 - valid_loss: 0.6310 - class_loss: 1.0393 - valid_acc: 1.0000 - class_acc: 0.5294\n","3/3 [==============================] - 1s 43ms/step - loss: 2.1617 - valid_loss: 0.7544 - class_loss: 1.0034 - valid_acc: 0.0000e+00 - class_acc: 0.5647\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:12, D{v_l: 1.490, v_acc: [15.4| 28.1| 21.8], c_acc: [48.7| 28.1]}  G{v_l: 0.642, v_acc: 65.6, c_acc: 42.2}\n","STEP:13, D{v_l: 1.012, v_acc: [59.4| 62.5| 60.9], c_acc: [31.2| 28.1]}  G{v_l: 0.648, v_acc: 73.4, c_acc: 45.3}\n","STEP:14, D{v_l: 1.361, v_acc: [46.9| 56.2| 51.6], c_acc: [56.2| 43.8]}  G{v_l: 0.616, v_acc: 62.5, c_acc: 50.0}\n","STEP:15, D{v_l: 1.194, v_acc: [40.6| 56.2| 48.4], c_acc: [46.9| 34.4]}  G{v_l: 0.683, v_acc: 53.1, c_acc: 42.2}\n","STEP:16, D{v_l: 1.349, v_acc: [50.0| 50.0| 50.0], c_acc: [34.4| 34.4]}  G{v_l: 0.625, v_acc: 64.1, c_acc: 43.8}\n","STEP:17, D{v_l: 1.510, v_acc: [59.4| 37.5| 48.4], c_acc: [34.4| 46.9]}  G{v_l: 0.671, v_acc: 59.4, c_acc: 42.2}\n","STEP:18, D{v_l: 1.058, v_acc: [68.8| 56.2| 62.5], c_acc: [31.2| 37.5]}  G{v_l: 0.708, v_acc: 53.1, c_acc: 34.4}\n","STEP:19, D{v_l: 1.516, v_acc: [21.9| 56.2| 39.1], c_acc: [31.2| 37.5]}  G{v_l: 0.643, v_acc: 57.8, c_acc: 48.4}\n","STEP:20, D{v_l: 1.293, v_acc: [56.2| 43.8| 50.0], c_acc: [43.8| 43.8]}  G{v_l: 0.664, v_acc: 60.9, c_acc: 42.2}\n","STEP:21, D{v_l: 1.175, v_acc: [71.9| 50.0| 60.9], c_acc: [18.8| 46.9]}  G{v_l: 0.694, v_acc: 54.7, c_acc: 57.8}\n","STEP:22, D{v_l: 1.087, v_acc: [53.1| 62.5| 57.8], c_acc: [40.6| 40.6]}  G{v_l: 0.767, v_acc: 42.2, c_acc: 46.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.0787 - valid_loss: 0.6688 - class_loss: 1.0053 - valid_acc: 0.9882 - class_acc: 0.5294\n","3/3 [==============================] - 0s 41ms/step - loss: 2.1103 - valid_loss: 0.7229 - class_loss: 0.9828 - valid_acc: 0.0000e+00 - class_acc: 0.5529\n","average v_acc: 49.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:23, D{v_l: 1.046, v_acc: [15.4| 62.5| 38.9], c_acc: [54.7| 46.9]}  G{v_l: 0.736, v_acc: 51.6, c_acc: 43.8}\n","STEP:24, D{v_l: 1.106, v_acc: [68.8| 50.0| 59.4], c_acc: [37.5| 34.4]}  G{v_l: 0.674, v_acc: 57.8, c_acc: 48.4}\n","STEP:25, D{v_l: 1.380, v_acc: [53.1| 40.6| 46.9], c_acc: [43.8| 25.0]}  G{v_l: 0.629, v_acc: 70.3, c_acc: 48.4}\n","STEP:26, D{v_l: 1.206, v_acc: [50.0| 50.0| 50.0], c_acc: [53.1| 28.1]}  G{v_l: 0.755, v_acc: 50.0, c_acc: 43.8}\n","STEP:27, D{v_l: 1.069, v_acc: [62.5| 65.6| 64.1], c_acc: [40.6| 37.5]}  G{v_l: 0.623, v_acc: 65.6, c_acc: 64.1}\n","STEP:28, D{v_l: 1.246, v_acc: [53.1| 40.6| 46.9], c_acc: [40.6| 31.2]}  G{v_l: 0.654, v_acc: 62.5, c_acc: 37.5}\n","STEP:29, D{v_l: 1.209, v_acc: [56.2| 56.2| 56.2], c_acc: [28.1| 34.4]}  G{v_l: 0.712, v_acc: 60.9, c_acc: 56.2}\n","STEP:30, D{v_l: 1.466, v_acc: [43.8| 56.2| 50.0], c_acc: [43.8| 53.1]}  G{v_l: 0.728, v_acc: 59.4, c_acc: 48.4}\n","STEP:31, D{v_l: 1.448, v_acc: [40.6| 56.2| 48.4], c_acc: [34.4| 53.1]}  G{v_l: 0.720, v_acc: 59.4, c_acc: 50.0}\n","STEP:32, D{v_l: 0.965, v_acc: [50.0| 71.9| 60.9], c_acc: [40.6| 34.4]}  G{v_l: 0.875, v_acc: 42.2, c_acc: 54.7}\n","STEP:33, D{v_l: 1.356, v_acc: [46.9| 43.8| 45.3], c_acc: [43.8| 53.1]}  G{v_l: 0.757, v_acc: 48.4, c_acc: 64.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.1558 - valid_loss: 0.7070 - class_loss: 1.0438 - valid_acc: 0.1059 - class_acc: 0.5294\n","3/3 [==============================] - 0s 41ms/step - loss: 2.0617 - valid_loss: 0.7230 - class_loss: 0.9338 - valid_acc: 0.0000e+00 - class_acc: 0.6235\n","average v_acc: 5.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:34, D{v_l: 0.970, v_acc: [16.2| 50.0| 33.1], c_acc: [57.3| 46.9]}  G{v_l: 0.678, v_acc: 60.9, c_acc: 46.9}\n","STEP:35, D{v_l: 0.969, v_acc: [56.2| 62.5| 59.4], c_acc: [46.9| 43.8]}  G{v_l: 0.788, v_acc: 53.1, c_acc: 54.7}\n","STEP:36, D{v_l: 1.128, v_acc: [59.4| 59.4| 59.4], c_acc: [21.9| 40.6]}  G{v_l: 0.768, v_acc: 51.6, c_acc: 53.1}\n","STEP:37, D{v_l: 1.270, v_acc: [53.1| 53.1| 53.1], c_acc: [25.0| 62.5]}  G{v_l: 0.701, v_acc: 53.1, c_acc: 56.2}\n","STEP:38, D{v_l: 1.064, v_acc: [56.2| 56.2| 56.2], c_acc: [18.8| 40.6]}  G{v_l: 0.775, v_acc: 54.7, c_acc: 51.6}\n","STEP:39, D{v_l: 1.247, v_acc: [40.6| 65.6| 53.1], c_acc: [37.5| 40.6]}  G{v_l: 0.840, v_acc: 45.3, c_acc: 48.4}\n","STEP:40, D{v_l: 1.419, v_acc: [43.8| 50.0| 46.9], c_acc: [46.9| 46.9]}  G{v_l: 0.836, v_acc: 48.4, c_acc: 56.2}\n","STEP:41, D{v_l: 1.193, v_acc: [46.9| 50.0| 48.4], c_acc: [50.0| 40.6]}  G{v_l: 0.741, v_acc: 54.7, c_acc: 43.8}\n","STEP:42, D{v_l: 1.332, v_acc: [50.0| 31.2| 40.6], c_acc: [53.1| 46.9]}  G{v_l: 0.763, v_acc: 48.4, c_acc: 40.6}\n","STEP:43, D{v_l: 1.148, v_acc: [50.0| 53.1| 51.6], c_acc: [46.9| 37.5]}  G{v_l: 0.895, v_acc: 43.8, c_acc: 54.7}\n","STEP:44, D{v_l: 1.232, v_acc: [50.0| 50.0| 50.0], c_acc: [43.8| 46.9]}  G{v_l: 0.902, v_acc: 37.5, c_acc: 50.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.2220 - valid_loss: 0.7667 - class_loss: 1.0498 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 1.9316 - valid_loss: 0.6963 - class_loss: 0.8299 - valid_acc: 0.4353 - class_acc: 0.6824\n","average v_acc: 21.765, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:45, D{v_l: 0.977, v_acc: [43.6| 53.1| 48.4], c_acc: [60.7| 68.8]}  G{v_l: 0.831, v_acc: 56.2, c_acc: 54.7}\n","STEP:46, D{v_l: 1.168, v_acc: [53.1| 56.2| 54.7], c_acc: [43.8| 50.0]}  G{v_l: 0.789, v_acc: 51.6, c_acc: 51.6}\n","STEP:47, D{v_l: 1.405, v_acc: [59.4| 40.6| 50.0], c_acc: [40.6| 50.0]}  G{v_l: 0.799, v_acc: 50.0, c_acc: 54.7}\n","STEP:48, D{v_l: 1.208, v_acc: [50.0| 40.6| 45.3], c_acc: [53.1| 65.6]}  G{v_l: 0.906, v_acc: 46.9, c_acc: 48.4}\n","STEP:49, D{v_l: 1.358, v_acc: [50.0| 50.0| 50.0], c_acc: [46.9| 65.6]}  G{v_l: 0.947, v_acc: 43.8, c_acc: 56.2}\n","STEP:50, D{v_l: 1.130, v_acc: [46.9| 68.8| 57.8], c_acc: [43.8| 53.1]}  G{v_l: 0.819, v_acc: 53.1, c_acc: 60.9}\n","STEP:51, D{v_l: 1.491, v_acc: [46.9| 43.8| 45.3], c_acc: [31.2| 40.6]}  G{v_l: 0.888, v_acc: 35.9, c_acc: 57.8}\n","STEP:52, D{v_l: 1.188, v_acc: [43.8| 43.8| 43.8], c_acc: [40.6| 68.8]}  G{v_l: 0.886, v_acc: 46.9, c_acc: 64.1}\n","STEP:53, D{v_l: 1.173, v_acc: [46.9| 50.0| 48.4], c_acc: [62.5| 56.2]}  G{v_l: 0.909, v_acc: 50.0, c_acc: 57.8}\n","STEP:54, D{v_l: 1.230, v_acc: [37.5| 50.0| 43.8], c_acc: [59.4| 62.5]}  G{v_l: 0.787, v_acc: 53.1, c_acc: 51.6}\n","STEP:55, D{v_l: 1.127, v_acc: [43.8| 56.2| 50.0], c_acc: [53.1| 62.5]}  G{v_l: 0.882, v_acc: 45.3, c_acc: 48.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 41ms/step - loss: 2.3829 - valid_loss: 0.8272 - class_loss: 1.1500 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0124 - valid_loss: 0.6193 - class_loss: 0.9874 - valid_acc: 1.0000 - class_acc: 0.6353\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:56, D{v_l: 0.719, v_acc: [89.7| 71.9| 80.8], c_acc: [60.7| 56.2]}  G{v_l: 0.817, v_acc: 46.9, c_acc: 60.9}\n","STEP:57, D{v_l: 1.506, v_acc: [40.6| 43.8| 42.2], c_acc: [40.6| 53.1]}  G{v_l: 0.925, v_acc: 40.6, c_acc: 64.1}\n","STEP:58, D{v_l: 1.030, v_acc: [40.6| 68.8| 54.7], c_acc: [56.2| 68.8]}  G{v_l: 1.159, v_acc: 39.1, c_acc: 43.8}\n","STEP:59, D{v_l: 1.415, v_acc: [34.4| 53.1| 43.8], c_acc: [31.2| 62.5]}  G{v_l: 0.921, v_acc: 42.2, c_acc: 54.7}\n","STEP:60, D{v_l: 1.276, v_acc: [50.0| 43.8| 46.9], c_acc: [50.0| 56.2]}  G{v_l: 1.215, v_acc: 29.7, c_acc: 54.7}\n","STEP:61, D{v_l: 0.960, v_acc: [40.6| 59.4| 50.0], c_acc: [40.6| 50.0]}  G{v_l: 0.974, v_acc: 45.3, c_acc: 42.2}\n","STEP:62, D{v_l: 1.129, v_acc: [43.8| 62.5| 53.1], c_acc: [59.4| 68.8]}  G{v_l: 0.925, v_acc: 42.2, c_acc: 45.3}\n","STEP:63, D{v_l: 1.289, v_acc: [37.5| 34.4| 35.9], c_acc: [43.8| 59.4]}  G{v_l: 1.061, v_acc: 40.6, c_acc: 59.4}\n","STEP:64, D{v_l: 1.116, v_acc: [53.1| 50.0| 51.6], c_acc: [65.6| 71.9]}  G{v_l: 1.051, v_acc: 39.1, c_acc: 48.4}\n","STEP:65, D{v_l: 1.061, v_acc: [43.8| 46.9| 45.3], c_acc: [40.6| 53.1]}  G{v_l: 1.026, v_acc: 46.9, c_acc: 67.2}\n","STEP:66, D{v_l: 1.514, v_acc: [46.9| 50.0| 48.4], c_acc: [43.8| 71.9]}  G{v_l: 1.147, v_acc: 35.9, c_acc: 56.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.5842 - valid_loss: 0.8822 - class_loss: 1.2960 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.9703 - valid_loss: 0.5734 - class_loss: 0.9909 - valid_acc: 1.0000 - class_acc: 0.6235\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:67, D{v_l: 0.884, v_acc: [86.3| 62.5| 74.4], c_acc: [59.8| 56.2]}  G{v_l: 0.899, v_acc: 46.9, c_acc: 59.4}\n","STEP:68, D{v_l: 1.326, v_acc: [34.4| 56.2| 45.3], c_acc: [53.1| 62.5]}  G{v_l: 1.261, v_acc: 31.2, c_acc: 50.0}\n","STEP:69, D{v_l: 1.161, v_acc: [50.0| 43.8| 46.9], c_acc: [50.0| 37.5]}  G{v_l: 0.871, v_acc: 48.4, c_acc: 56.2}\n","STEP:70, D{v_l: 1.143, v_acc: [50.0| 46.9| 48.4], c_acc: [37.5| 71.9]}  G{v_l: 0.914, v_acc: 46.9, c_acc: 62.5}\n","STEP:71, D{v_l: 1.046, v_acc: [59.4| 62.5| 60.9], c_acc: [40.6| 62.5]}  G{v_l: 0.958, v_acc: 48.4, c_acc: 39.1}\n","STEP:72, D{v_l: 1.026, v_acc: [59.4| 56.2| 57.8], c_acc: [43.8| 71.9]}  G{v_l: 0.866, v_acc: 50.0, c_acc: 53.1}\n","STEP:73, D{v_l: 1.351, v_acc: [50.0| 40.6| 45.3], c_acc: [43.8| 65.6]}  G{v_l: 0.807, v_acc: 54.7, c_acc: 59.4}\n","STEP:74, D{v_l: 1.184, v_acc: [56.2| 50.0| 53.1], c_acc: [43.8| 59.4]}  G{v_l: 0.871, v_acc: 48.4, c_acc: 40.6}\n","STEP:75, D{v_l: 1.678, v_acc: [37.5| 43.8| 40.6], c_acc: [50.0| 71.9]}  G{v_l: 0.918, v_acc: 53.1, c_acc: 56.2}\n","STEP:76, D{v_l: 1.170, v_acc: [53.1| 40.6| 46.9], c_acc: [50.0| 46.9]}  G{v_l: 0.893, v_acc: 50.0, c_acc: 68.8}\n","STEP:77, D{v_l: 1.215, v_acc: [53.1| 37.5| 45.3], c_acc: [53.1| 53.1]}  G{v_l: 1.047, v_acc: 45.3, c_acc: 56.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.3934 - valid_loss: 0.7557 - class_loss: 1.2315 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.8882 - valid_loss: 0.6293 - class_loss: 0.8528 - valid_acc: 1.0000 - class_acc: 0.6588\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:78, D{v_l: 0.863, v_acc: [85.5| 62.5| 74.0], c_acc: [64.1| 81.2]}  G{v_l: 0.940, v_acc: 39.1, c_acc: 62.5}\n","STEP:79, D{v_l: 1.040, v_acc: [50.0| 46.9| 48.4], c_acc: [43.8| 56.2]}  G{v_l: 0.731, v_acc: 56.2, c_acc: 53.1}\n","STEP:80, D{v_l: 1.289, v_acc: [50.0| 43.8| 46.9], c_acc: [56.2| 62.5]}  G{v_l: 0.958, v_acc: 51.6, c_acc: 62.5}\n","STEP:81, D{v_l: 1.405, v_acc: [28.1| 62.5| 45.3], c_acc: [53.1| 65.6]}  G{v_l: 0.930, v_acc: 43.8, c_acc: 62.5}\n","STEP:82, D{v_l: 1.174, v_acc: [50.0| 37.5| 43.8], c_acc: [59.4| 78.1]}  G{v_l: 0.863, v_acc: 53.1, c_acc: 45.3}\n","STEP:83, D{v_l: 1.149, v_acc: [50.0| 40.6| 45.3], c_acc: [53.1| 68.8]}  G{v_l: 1.048, v_acc: 54.7, c_acc: 53.1}\n","STEP:84, D{v_l: 1.018, v_acc: [46.9| 59.4| 53.1], c_acc: [62.5| 65.6]}  G{v_l: 0.816, v_acc: 57.8, c_acc: 56.2}\n","STEP:85, D{v_l: 0.835, v_acc: [71.9| 62.5| 67.2], c_acc: [46.9| 75.0]}  G{v_l: 0.919, v_acc: 50.0, c_acc: 53.1}\n","STEP:86, D{v_l: 1.031, v_acc: [43.8| 65.6| 54.7], c_acc: [56.2| 68.8]}  G{v_l: 0.924, v_acc: 45.3, c_acc: 57.8}\n","STEP:87, D{v_l: 1.267, v_acc: [50.0| 53.1| 51.6], c_acc: [65.6| 75.0]}  G{v_l: 0.845, v_acc: 50.0, c_acc: 56.2}\n","STEP:88, D{v_l: 1.535, v_acc: [43.8| 62.5| 53.1], c_acc: [56.2| 65.6]}  G{v_l: 0.947, v_acc: 50.0, c_acc: 65.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 41ms/step - loss: 2.4913 - valid_loss: 0.8430 - class_loss: 1.2420 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 42ms/step - loss: 1.9182 - valid_loss: 0.6098 - class_loss: 0.9021 - valid_acc: 0.9882 - class_acc: 0.5882\n","average v_acc: 49.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:89, D{v_l: 0.805, v_acc: [83.8| 68.8| 76.3], c_acc: [54.7| 84.4]}  G{v_l: 1.059, v_acc: 40.6, c_acc: 46.9}\n","STEP:90, D{v_l: 1.233, v_acc: [50.0| 43.8| 46.9], c_acc: [68.8| 50.0]}  G{v_l: 0.898, v_acc: 46.9, c_acc: 43.8}\n","STEP:91, D{v_l: 1.186, v_acc: [37.5| 56.2| 46.9], c_acc: [56.2| 81.2]}  G{v_l: 1.054, v_acc: 45.3, c_acc: 53.1}\n","STEP:92, D{v_l: 1.262, v_acc: [43.8| 50.0| 46.9], c_acc: [56.2| 84.4]}  G{v_l: 1.049, v_acc: 40.6, c_acc: 53.1}\n","STEP:93, D{v_l: 1.506, v_acc: [37.5| 37.5| 37.5], c_acc: [78.1| 81.2]}  G{v_l: 0.848, v_acc: 50.0, c_acc: 48.4}\n","STEP:94, D{v_l: 0.792, v_acc: [56.2| 53.1| 54.7], c_acc: [56.2| 71.9]}  G{v_l: 1.007, v_acc: 42.2, c_acc: 53.1}\n","STEP:95, D{v_l: 1.109, v_acc: [59.4| 53.1| 56.2], c_acc: [50.0| 68.8]}  G{v_l: 0.959, v_acc: 53.1, c_acc: 43.8}\n","STEP:96, D{v_l: 1.359, v_acc: [46.9| 37.5| 42.2], c_acc: [56.2| 78.1]}  G{v_l: 0.965, v_acc: 46.9, c_acc: 64.1}\n","STEP:97, D{v_l: 1.143, v_acc: [53.1| 46.9| 50.0], c_acc: [46.9| 81.2]}  G{v_l: 0.968, v_acc: 40.6, c_acc: 50.0}\n","STEP:98, D{v_l: 0.877, v_acc: [53.1| 75.0| 64.1], c_acc: [43.8| 78.1]}  G{v_l: 1.001, v_acc: 45.3, c_acc: 57.8}\n","STEP:99, D{v_l: 1.081, v_acc: [40.6| 43.8| 42.2], c_acc: [53.1| 75.0]}  G{v_l: 0.864, v_acc: 57.8, c_acc: 65.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.6912 - valid_loss: 0.9060 - class_loss: 1.3788 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.9023 - valid_loss: 0.6250 - class_loss: 0.8708 - valid_acc: 0.9765 - class_acc: 0.6471\n","average v_acc: 48.824, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:100, D{v_l: 0.749, v_acc: [82.9| 65.6| 74.3], c_acc: [61.5| 84.4]}  G{v_l: 0.871, v_acc: 48.4, c_acc: 51.6}\n","STEP:101, D{v_l: 1.193, v_acc: [56.2| 40.6| 48.4], c_acc: [37.5| 65.6]}  G{v_l: 1.085, v_acc: 39.1, c_acc: 73.4}\n","STEP:102, D{v_l: 1.151, v_acc: [34.4| 56.2| 45.3], c_acc: [59.4| 81.2]}  G{v_l: 0.955, v_acc: 46.9, c_acc: 60.9}\n","STEP:103, D{v_l: 1.420, v_acc: [40.6| 46.9| 43.8], c_acc: [46.9| 87.5]}  G{v_l: 0.838, v_acc: 51.6, c_acc: 53.1}\n","STEP:104, D{v_l: 1.176, v_acc: [50.0| 34.4| 42.2], c_acc: [40.6| 68.8]}  G{v_l: 1.014, v_acc: 42.2, c_acc: 57.8}\n","STEP:105, D{v_l: 0.863, v_acc: [59.4| 59.4| 59.4], c_acc: [46.9| 65.6]}  G{v_l: 0.953, v_acc: 42.2, c_acc: 60.9}\n","STEP:106, D{v_l: 0.876, v_acc: [59.4| 59.4| 59.4], c_acc: [62.5| 75.0]}  G{v_l: 0.953, v_acc: 45.3, c_acc: 56.2}\n","STEP:107, D{v_l: 0.838, v_acc: [62.5| 59.4| 60.9], c_acc: [53.1| 78.1]}  G{v_l: 0.906, v_acc: 48.4, c_acc: 51.6}\n","STEP:108, D{v_l: 0.860, v_acc: [62.5| 50.0| 56.2], c_acc: [59.4| 81.2]}  G{v_l: 0.820, v_acc: 45.3, c_acc: 57.8}\n","STEP:109, D{v_l: 1.034, v_acc: [65.6| 50.0| 57.8], c_acc: [46.9| 84.4]}  G{v_l: 1.007, v_acc: 45.3, c_acc: 51.6}\n","STEP:110, D{v_l: 0.893, v_acc: [53.1| 62.5| 57.8], c_acc: [56.2| 65.6]}  G{v_l: 0.933, v_acc: 48.4, c_acc: 46.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.6601 - valid_loss: 0.8858 - class_loss: 1.3678 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.5351 - valid_loss: 0.5903 - class_loss: 0.5382 - valid_acc: 0.9882 - class_acc: 0.7765\n","average v_acc: 49.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 10\n","====================================================================================================\n","STEP:111, D{v_l: 0.859, v_acc: [87.2| 50.0| 68.6], c_acc: [71.8| 71.9]}  G{v_l: 0.925, v_acc: 43.8, c_acc: 57.8}\n","STEP:112, D{v_l: 1.085, v_acc: [62.5| 46.9| 54.7], c_acc: [53.1| 78.1]}  G{v_l: 1.127, v_acc: 39.1, c_acc: 65.6}\n","STEP:113, D{v_l: 1.022, v_acc: [50.0| 53.1| 51.6], c_acc: [43.8| 81.2]}  G{v_l: 0.966, v_acc: 39.1, c_acc: 59.4}\n","STEP:114, D{v_l: 0.954, v_acc: [43.8| 59.4| 51.6], c_acc: [59.4| 90.6]}  G{v_l: 1.075, v_acc: 42.2, c_acc: 71.9}\n","STEP:115, D{v_l: 1.372, v_acc: [43.8| 50.0| 46.9], c_acc: [65.6| 90.6]}  G{v_l: 1.047, v_acc: 46.9, c_acc: 68.8}\n","STEP:116, D{v_l: 1.059, v_acc: [37.5| 62.5| 50.0], c_acc: [46.9| 81.2]}  G{v_l: 1.239, v_acc: 32.8, c_acc: 59.4}\n","STEP:117, D{v_l: 0.877, v_acc: [56.2| 68.8| 62.5], c_acc: [62.5| 75.0]}  G{v_l: 0.977, v_acc: 40.6, c_acc: 64.1}\n","STEP:118, D{v_l: 1.186, v_acc: [56.2| 68.8| 62.5], c_acc: [43.8| 87.5]}  G{v_l: 1.129, v_acc: 37.5, c_acc: 48.4}\n","STEP:119, D{v_l: 1.159, v_acc: [53.1| 59.4| 56.2], c_acc: [56.2| 87.5]}  G{v_l: 1.100, v_acc: 42.2, c_acc: 60.9}\n","STEP:120, D{v_l: 0.993, v_acc: [43.8| 65.6| 54.7], c_acc: [37.5| 78.1]}  G{v_l: 1.040, v_acc: 42.2, c_acc: 48.4}\n","STEP:121, D{v_l: 0.999, v_acc: [50.0| 53.1| 51.6], c_acc: [43.8| 84.4]}  G{v_l: 0.961, v_acc: 46.9, c_acc: 64.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 41ms/step - loss: 2.9919 - valid_loss: 1.0059 - class_loss: 1.5794 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.7225 - valid_loss: 0.5716 - class_loss: 0.7444 - valid_acc: 0.9765 - class_acc: 0.6000\n","average v_acc: 48.824, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:122, D{v_l: 0.753, v_acc: [87.2| 71.9| 79.5], c_acc: [58.1| 84.4]}  G{v_l: 1.030, v_acc: 42.2, c_acc: 54.7}\n","STEP:123, D{v_l: 1.112, v_acc: [28.1| 59.4| 43.8], c_acc: [46.9| 84.4]}  G{v_l: 1.022, v_acc: 35.9, c_acc: 50.0}\n","STEP:124, D{v_l: 1.141, v_acc: [37.5| 53.1| 45.3], c_acc: [59.4| 87.5]}  G{v_l: 1.291, v_acc: 35.9, c_acc: 56.2}\n","STEP:125, D{v_l: 0.959, v_acc: [43.8| 50.0| 46.9], c_acc: [46.9| 96.9]}  G{v_l: 0.975, v_acc: 48.4, c_acc: 67.2}\n","STEP:126, D{v_l: 1.379, v_acc: [46.9| 56.2| 51.6], c_acc: [59.4| 75.0]}  G{v_l: 1.107, v_acc: 37.5, c_acc: 50.0}\n","STEP:127, D{v_l: 0.873, v_acc: [40.6| 62.5| 51.6], c_acc: [65.6| 93.8]}  G{v_l: 0.948, v_acc: 46.9, c_acc: 67.2}\n","STEP:128, D{v_l: 0.950, v_acc: [43.8| 56.2| 50.0], c_acc: [53.1| 81.2]}  G{v_l: 1.012, v_acc: 42.2, c_acc: 62.5}\n","STEP:129, D{v_l: 0.950, v_acc: [50.0| 56.2| 53.1], c_acc: [53.1| 87.5]}  G{v_l: 0.781, v_acc: 53.1, c_acc: 64.1}\n","STEP:130, D{v_l: 1.017, v_acc: [50.0| 53.1| 51.6], c_acc: [62.5| 84.4]}  G{v_l: 1.026, v_acc: 46.9, c_acc: 60.9}\n","STEP:131, D{v_l: 1.064, v_acc: [40.6| 53.1| 46.9], c_acc: [56.2| 87.5]}  G{v_l: 1.073, v_acc: 37.5, c_acc: 59.4}\n","STEP:132, D{v_l: 1.090, v_acc: [50.0| 50.0| 50.0], c_acc: [46.9| 96.9]}  G{v_l: 0.975, v_acc: 42.2, c_acc: 73.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.0213 - valid_loss: 0.9561 - class_loss: 1.6585 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.6330 - valid_loss: 0.6023 - class_loss: 0.6240 - valid_acc: 0.9647 - class_acc: 0.6588\n","average v_acc: 48.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:133, D{v_l: 0.739, v_acc: [85.5| 75.0| 80.2], c_acc: [60.7| 90.6]}  G{v_l: 0.937, v_acc: 46.9, c_acc: 68.8}\n","STEP:134, D{v_l: 1.096, v_acc: [50.0| 53.1| 51.6], c_acc: [59.4| 84.4]}  G{v_l: 1.004, v_acc: 40.6, c_acc: 75.0}\n","STEP:135, D{v_l: 1.055, v_acc: [34.4| 46.9| 40.6], c_acc: [53.1| 81.2]}  G{v_l: 1.051, v_acc: 32.8, c_acc: 65.6}\n","STEP:136, D{v_l: 1.033, v_acc: [50.0| 46.9| 48.4], c_acc: [62.5| 84.4]}  G{v_l: 0.896, v_acc: 45.3, c_acc: 75.0}\n","STEP:137, D{v_l: 1.021, v_acc: [56.2| 50.0| 53.1], c_acc: [46.9| 87.5]}  G{v_l: 1.055, v_acc: 35.9, c_acc: 71.9}\n","STEP:138, D{v_l: 1.156, v_acc: [43.8| 50.0| 46.9], c_acc: [59.4| 78.1]}  G{v_l: 0.789, v_acc: 51.6, c_acc: 65.6}\n","STEP:139, D{v_l: 0.771, v_acc: [56.2| 68.8| 62.5], c_acc: [68.8| 81.2]}  G{v_l: 0.946, v_acc: 48.4, c_acc: 65.6}\n","STEP:140, D{v_l: 0.929, v_acc: [53.1| 59.4| 56.2], c_acc: [56.2| 93.8]}  G{v_l: 0.686, v_acc: 71.9, c_acc: 67.2}\n","STEP:141, D{v_l: 0.918, v_acc: [59.4| 62.5| 60.9], c_acc: [56.2| 90.6]}  G{v_l: 0.878, v_acc: 43.8, c_acc: 64.1}\n","STEP:142, D{v_l: 0.958, v_acc: [40.6| 53.1| 46.9], c_acc: [59.4| 87.5]}  G{v_l: 1.070, v_acc: 43.8, c_acc: 60.9}\n","STEP:143, D{v_l: 0.974, v_acc: [56.2| 40.6| 48.4], c_acc: [78.1| 84.4]}  G{v_l: 0.956, v_acc: 46.9, c_acc: 71.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9834 - valid_loss: 0.7987 - class_loss: 1.7780 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.6395 - valid_loss: 0.6369 - class_loss: 0.5959 - valid_acc: 0.6471 - class_acc: 0.6588\n","average v_acc: 32.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:144, D{v_l: 0.909, v_acc: [60.7| 59.4| 60.0], c_acc: [68.4| 87.5]}  G{v_l: 0.881, v_acc: 43.8, c_acc: 81.2}\n","STEP:145, D{v_l: 0.919, v_acc: [50.0| 65.6| 57.8], c_acc: [59.4| 100.0]}  G{v_l: 0.751, v_acc: 56.2, c_acc: 59.4}\n","STEP:146, D{v_l: 1.168, v_acc: [46.9| 50.0| 48.4], c_acc: [56.2| 93.8]}  G{v_l: 0.965, v_acc: 45.3, c_acc: 70.3}\n","STEP:147, D{v_l: 0.897, v_acc: [43.8| 71.9| 57.8], c_acc: [56.2| 96.9]}  G{v_l: 0.861, v_acc: 53.1, c_acc: 64.1}\n","STEP:148, D{v_l: 0.984, v_acc: [50.0| 65.6| 57.8], c_acc: [65.6| 87.5]}  G{v_l: 0.967, v_acc: 48.4, c_acc: 67.2}\n","STEP:149, D{v_l: 0.822, v_acc: [59.4| 68.8| 64.1], c_acc: [62.5| 87.5]}  G{v_l: 0.902, v_acc: 48.4, c_acc: 62.5}\n","STEP:150, D{v_l: 0.916, v_acc: [56.2| 59.4| 57.8], c_acc: [43.8| 90.6]}  G{v_l: 0.830, v_acc: 51.6, c_acc: 64.1}\n","STEP:151, D{v_l: 1.036, v_acc: [43.8| 56.2| 50.0], c_acc: [71.9| 93.8]}  G{v_l: 0.883, v_acc: 50.0, c_acc: 78.1}\n","STEP:152, D{v_l: 0.815, v_acc: [59.4| 59.4| 59.4], c_acc: [53.1| 81.2]}  G{v_l: 0.934, v_acc: 50.0, c_acc: 62.5}\n","STEP:153, D{v_l: 1.087, v_acc: [56.2| 59.4| 57.8], c_acc: [62.5| 90.6]}  G{v_l: 0.884, v_acc: 53.1, c_acc: 62.5}\n","STEP:154, D{v_l: 0.945, v_acc: [40.6| 68.8| 54.7], c_acc: [62.5| 87.5]}  G{v_l: 1.001, v_acc: 46.9, c_acc: 68.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.1873 - valid_loss: 0.8282 - class_loss: 1.9524 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.7092 - valid_loss: 0.6797 - class_loss: 0.6228 - valid_acc: 0.5529 - class_acc: 0.6235\n","average v_acc: 27.647, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:155, D{v_l: 0.598, v_acc: [53.8| 75.0| 64.4], c_acc: [64.1| 81.2]}  G{v_l: 0.856, v_acc: 53.1, c_acc: 67.2}\n","STEP:156, D{v_l: 1.028, v_acc: [50.0| 62.5| 56.2], c_acc: [62.5| 93.8]}  G{v_l: 0.991, v_acc: 42.2, c_acc: 51.6}\n","STEP:157, D{v_l: 0.933, v_acc: [50.0| 65.6| 57.8], c_acc: [62.5| 87.5]}  G{v_l: 1.053, v_acc: 53.1, c_acc: 62.5}\n","STEP:158, D{v_l: 0.883, v_acc: [46.9| 53.1| 50.0], c_acc: [65.6| 90.6]}  G{v_l: 0.802, v_acc: 68.8, c_acc: 57.8}\n","STEP:159, D{v_l: 0.847, v_acc: [62.5| 56.2| 59.4], c_acc: [59.4| 84.4]}  G{v_l: 0.911, v_acc: 43.8, c_acc: 67.2}\n","STEP:160, D{v_l: 0.944, v_acc: [43.8| 50.0| 46.9], c_acc: [59.4| 93.8]}  G{v_l: 0.838, v_acc: 57.8, c_acc: 73.4}\n","STEP:161, D{v_l: 0.660, v_acc: [65.6| 71.9| 68.8], c_acc: [56.2| 90.6]}  G{v_l: 0.986, v_acc: 56.2, c_acc: 79.7}\n","STEP:162, D{v_l: 0.697, v_acc: [56.2| 75.0| 65.6], c_acc: [59.4| 96.9]}  G{v_l: 0.901, v_acc: 43.8, c_acc: 68.8}\n","STEP:163, D{v_l: 1.033, v_acc: [40.6| 43.8| 42.2], c_acc: [50.0| 87.5]}  G{v_l: 0.807, v_acc: 48.4, c_acc: 70.3}\n","STEP:164, D{v_l: 1.002, v_acc: [40.6| 59.4| 50.0], c_acc: [59.4| 93.8]}  G{v_l: 0.885, v_acc: 43.8, c_acc: 64.1}\n","STEP:165, D{v_l: 0.636, v_acc: [59.4| 75.0| 67.2], c_acc: [46.9| 87.5]}  G{v_l: 0.935, v_acc: 51.6, c_acc: 68.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 3.1008 - valid_loss: 0.8679 - class_loss: 1.8262 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 42ms/step - loss: 1.5446 - valid_loss: 0.6747 - class_loss: 0.4632 - valid_acc: 0.6824 - class_acc: 0.7176\n","average v_acc: 34.118, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:166, D{v_l: 0.851, v_acc: [64.1| 56.2| 60.2], c_acc: [65.8| 93.8]}  G{v_l: 1.027, v_acc: 43.8, c_acc: 82.8}\n","STEP:167, D{v_l: 1.024, v_acc: [40.6| 65.6| 53.1], c_acc: [68.8| 100.0]}  G{v_l: 1.045, v_acc: 40.6, c_acc: 73.4}\n","STEP:168, D{v_l: 0.895, v_acc: [59.4| 65.6| 62.5], c_acc: [62.5| 81.2]}  G{v_l: 0.953, v_acc: 46.9, c_acc: 64.1}\n","STEP:169, D{v_l: 1.036, v_acc: [40.6| 43.8| 42.2], c_acc: [68.8| 84.4]}  G{v_l: 0.909, v_acc: 43.8, c_acc: 71.9}\n","STEP:170, D{v_l: 1.279, v_acc: [40.6| 53.1| 46.9], c_acc: [50.0| 75.0]}  G{v_l: 0.688, v_acc: 64.1, c_acc: 73.4}\n","STEP:171, D{v_l: 0.776, v_acc: [62.5| 65.6| 64.1], c_acc: [50.0| 84.4]}  G{v_l: 0.984, v_acc: 46.9, c_acc: 70.3}\n","STEP:172, D{v_l: 0.970, v_acc: [56.2| 53.1| 54.7], c_acc: [65.6| 96.9]}  G{v_l: 0.888, v_acc: 54.7, c_acc: 78.1}\n","STEP:173, D{v_l: 1.042, v_acc: [59.4| 59.4| 59.4], c_acc: [62.5| 90.6]}  G{v_l: 0.924, v_acc: 45.3, c_acc: 78.1}\n","STEP:174, D{v_l: 0.862, v_acc: [50.0| 75.0| 62.5], c_acc: [53.1| 90.6]}  G{v_l: 0.942, v_acc: 42.2, c_acc: 84.4}\n","STEP:175, D{v_l: 0.771, v_acc: [56.2| 81.2| 68.8], c_acc: [71.9| 100.0]}  G{v_l: 0.774, v_acc: 56.2, c_acc: 73.4}\n","STEP:176, D{v_l: 0.799, v_acc: [59.4| 65.6| 62.5], c_acc: [59.4| 90.6]}  G{v_l: 0.924, v_acc: 34.4, c_acc: 67.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.1360 - valid_loss: 0.9060 - class_loss: 1.8233 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.3939 - valid_loss: 0.6469 - class_loss: 0.3402 - valid_acc: 0.8000 - class_acc: 0.8706\n","average v_acc: 40.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:177, D{v_l: 0.841, v_acc: [72.6| 56.2| 64.4], c_acc: [82.1| 93.8]}  G{v_l: 0.886, v_acc: 45.3, c_acc: 75.0}\n","STEP:178, D{v_l: 0.896, v_acc: [68.8| 71.9| 70.3], c_acc: [68.8| 96.9]}  G{v_l: 1.029, v_acc: 43.8, c_acc: 84.4}\n","STEP:179, D{v_l: 0.965, v_acc: [31.2| 71.9| 51.6], c_acc: [71.9| 90.6]}  G{v_l: 0.938, v_acc: 46.9, c_acc: 65.6}\n","STEP:180, D{v_l: 1.159, v_acc: [34.4| 68.8| 51.6], c_acc: [62.5| 93.8]}  G{v_l: 0.913, v_acc: 40.6, c_acc: 75.0}\n","STEP:181, D{v_l: 0.827, v_acc: [75.0| 56.2| 65.6], c_acc: [40.6| 93.8]}  G{v_l: 0.796, v_acc: 59.4, c_acc: 84.4}\n","STEP:182, D{v_l: 0.861, v_acc: [56.2| 68.8| 62.5], c_acc: [59.4| 93.8]}  G{v_l: 0.963, v_acc: 50.0, c_acc: 75.0}\n","STEP:183, D{v_l: 0.899, v_acc: [34.4| 59.4| 46.9], c_acc: [71.9| 84.4]}  G{v_l: 0.968, v_acc: 45.3, c_acc: 78.1}\n","STEP:184, D{v_l: 0.814, v_acc: [46.9| 71.9| 59.4], c_acc: [71.9| 93.8]}  G{v_l: 0.938, v_acc: 45.3, c_acc: 82.8}\n","STEP:185, D{v_l: 1.011, v_acc: [53.1| 59.4| 56.2], c_acc: [78.1| 93.8]}  G{v_l: 0.905, v_acc: 50.0, c_acc: 78.1}\n","STEP:186, D{v_l: 0.919, v_acc: [46.9| 56.2| 51.6], c_acc: [65.6| 90.6]}  G{v_l: 0.924, v_acc: 50.0, c_acc: 79.7}\n","STEP:187, D{v_l: 0.800, v_acc: [50.0| 68.8| 59.4], c_acc: [68.8| 93.8]}  G{v_l: 0.926, v_acc: 48.4, c_acc: 75.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.3596 - valid_loss: 0.9001 - class_loss: 2.0528 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.3660 - valid_loss: 0.6175 - class_loss: 0.3418 - valid_acc: 0.7647 - class_acc: 0.8824\n","average v_acc: 38.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:188, D{v_l: 0.751, v_acc: [71.8| 53.1| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 0.943, v_acc: 50.0, c_acc: 84.4}\n","STEP:189, D{v_l: 1.000, v_acc: [50.0| 59.4| 54.7], c_acc: [56.2| 93.8]}  G{v_l: 1.006, v_acc: 46.9, c_acc: 73.4}\n","STEP:190, D{v_l: 0.845, v_acc: [40.6| 65.6| 53.1], c_acc: [71.9| 93.8]}  G{v_l: 1.118, v_acc: 37.5, c_acc: 70.3}\n","STEP:191, D{v_l: 1.166, v_acc: [46.9| 56.2| 51.6], c_acc: [56.2| 93.8]}  G{v_l: 0.984, v_acc: 46.9, c_acc: 68.8}\n","STEP:192, D{v_l: 0.823, v_acc: [46.9| 56.2| 51.6], c_acc: [59.4| 87.5]}  G{v_l: 1.001, v_acc: 48.4, c_acc: 81.2}\n","STEP:193, D{v_l: 0.944, v_acc: [46.9| 62.5| 54.7], c_acc: [81.2| 87.5]}  G{v_l: 0.980, v_acc: 42.2, c_acc: 79.7}\n","STEP:194, D{v_l: 0.703, v_acc: [65.6| 56.2| 60.9], c_acc: [46.9| 90.6]}  G{v_l: 1.077, v_acc: 42.2, c_acc: 82.8}\n","STEP:195, D{v_l: 0.740, v_acc: [53.1| 68.8| 60.9], c_acc: [62.5| 90.6]}  G{v_l: 1.099, v_acc: 40.6, c_acc: 73.4}\n","STEP:196, D{v_l: 0.690, v_acc: [56.2| 71.9| 64.1], c_acc: [56.2| 93.8]}  G{v_l: 0.827, v_acc: 51.6, c_acc: 70.3}\n","STEP:197, D{v_l: 0.775, v_acc: [46.9| 56.2| 51.6], c_acc: [62.5| 90.6]}  G{v_l: 1.014, v_acc: 50.0, c_acc: 79.7}\n","STEP:198, D{v_l: 0.640, v_acc: [56.2| 68.8| 62.5], c_acc: [62.5| 96.9]}  G{v_l: 0.911, v_acc: 48.4, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.4181 - valid_loss: 0.9388 - class_loss: 2.0727 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 1.2638 - valid_loss: 0.5972 - class_loss: 0.2599 - valid_acc: 0.8824 - class_acc: 0.9412\n","average v_acc: 44.118, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:199, D{v_l: 0.714, v_acc: [75.2| 68.8| 72.0], c_acc: [88.0| 87.5]}  G{v_l: 0.998, v_acc: 40.6, c_acc: 78.1}\n","STEP:200, D{v_l: 0.784, v_acc: [56.2| 81.2| 68.8], c_acc: [65.6| 87.5]}  G{v_l: 0.852, v_acc: 46.9, c_acc: 76.6}\n","STEP:201, D{v_l: 0.935, v_acc: [65.6| 59.4| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 0.863, v_acc: 50.0, c_acc: 87.5}\n","STEP:202, D{v_l: 0.995, v_acc: [28.1| 59.4| 43.8], c_acc: [59.4| 96.9]}  G{v_l: 1.094, v_acc: 42.2, c_acc: 81.2}\n","STEP:203, D{v_l: 1.041, v_acc: [56.2| 56.2| 56.2], c_acc: [71.9| 90.6]}  G{v_l: 0.931, v_acc: 40.6, c_acc: 84.4}\n","STEP:204, D{v_l: 0.570, v_acc: [56.2| 84.4| 70.3], c_acc: [71.9| 87.5]}  G{v_l: 0.849, v_acc: 48.4, c_acc: 78.1}\n","STEP:205, D{v_l: 0.685, v_acc: [43.8| 75.0| 59.4], c_acc: [62.5| 96.9]}  G{v_l: 0.852, v_acc: 53.1, c_acc: 85.9}\n","STEP:206, D{v_l: 0.735, v_acc: [71.9| 62.5| 67.2], c_acc: [71.9| 87.5]}  G{v_l: 0.958, v_acc: 50.0, c_acc: 78.1}\n","STEP:207, D{v_l: 0.949, v_acc: [59.4| 62.5| 60.9], c_acc: [59.4| 90.6]}  G{v_l: 1.095, v_acc: 40.6, c_acc: 84.4}\n","STEP:208, D{v_l: 1.007, v_acc: [46.9| 62.5| 54.7], c_acc: [87.5| 87.5]}  G{v_l: 0.924, v_acc: 42.2, c_acc: 81.2}\n","STEP:209, D{v_l: 0.834, v_acc: [62.5| 62.5| 62.5], c_acc: [65.6| 93.8]}  G{v_l: 0.781, v_acc: 53.1, c_acc: 68.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.5952 - valid_loss: 0.9538 - class_loss: 2.2346 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.1900 - valid_loss: 0.6029 - class_loss: 0.1803 - valid_acc: 0.8471 - class_acc: 1.0000\n","average v_acc: 42.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:210, D{v_l: 0.880, v_acc: [77.8| 46.9| 62.3], c_acc: [90.6| 96.9]}  G{v_l: 1.013, v_acc: 50.0, c_acc: 75.0}\n","STEP:211, D{v_l: 0.914, v_acc: [56.2| 56.2| 56.2], c_acc: [75.0| 96.9]}  G{v_l: 0.803, v_acc: 56.2, c_acc: 76.6}\n","STEP:212, D{v_l: 1.051, v_acc: [53.1| 53.1| 53.1], c_acc: [59.4| 93.8]}  G{v_l: 1.197, v_acc: 43.8, c_acc: 84.4}\n","STEP:213, D{v_l: 0.757, v_acc: [65.6| 62.5| 64.1], c_acc: [65.6| 93.8]}  G{v_l: 1.017, v_acc: 48.4, c_acc: 79.7}\n","STEP:214, D{v_l: 0.730, v_acc: [56.2| 68.8| 62.5], c_acc: [68.8| 96.9]}  G{v_l: 0.833, v_acc: 53.1, c_acc: 78.1}\n","STEP:215, D{v_l: 0.871, v_acc: [53.1| 68.8| 60.9], c_acc: [68.8| 93.8]}  G{v_l: 1.162, v_acc: 35.9, c_acc: 82.8}\n","STEP:216, D{v_l: 0.913, v_acc: [59.4| 71.9| 65.6], c_acc: [65.6| 87.5]}  G{v_l: 0.863, v_acc: 60.9, c_acc: 96.9}\n","STEP:217, D{v_l: 0.819, v_acc: [56.2| 65.6| 60.9], c_acc: [56.2| 93.8]}  G{v_l: 0.949, v_acc: 57.8, c_acc: 68.8}\n","STEP:218, D{v_l: 0.846, v_acc: [53.1| 65.6| 59.4], c_acc: [65.6| 96.9]}  G{v_l: 1.148, v_acc: 37.5, c_acc: 81.2}\n","STEP:219, D{v_l: 0.707, v_acc: [71.9| 65.6| 68.8], c_acc: [65.6| 96.9]}  G{v_l: 0.877, v_acc: 50.0, c_acc: 92.2}\n","STEP:220, D{v_l: 0.914, v_acc: [50.0| 62.5| 56.2], c_acc: [62.5| 90.6]}  G{v_l: 1.091, v_acc: 37.5, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.4322 - valid_loss: 0.9218 - class_loss: 2.1037 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0945 - valid_loss: 0.5837 - class_loss: 0.1041 - valid_acc: 0.9529 - class_acc: 1.0000\n","average v_acc: 47.647, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 20\n","====================================================================================================\n","STEP:221, D{v_l: 0.657, v_acc: [83.8| 71.9| 77.8], c_acc: [91.5| 90.6]}  G{v_l: 0.965, v_acc: 53.1, c_acc: 87.5}\n","STEP:222, D{v_l: 0.926, v_acc: [43.8| 59.4| 51.6], c_acc: [62.5| 96.9]}  G{v_l: 0.921, v_acc: 48.4, c_acc: 90.6}\n","STEP:223, D{v_l: 0.736, v_acc: [65.6| 68.8| 67.2], c_acc: [81.2| 96.9]}  G{v_l: 0.839, v_acc: 50.0, c_acc: 92.2}\n","STEP:224, D{v_l: 0.521, v_acc: [71.9| 71.9| 71.9], c_acc: [50.0| 93.8]}  G{v_l: 0.939, v_acc: 43.8, c_acc: 84.4}\n","STEP:225, D{v_l: 0.900, v_acc: [50.0| 71.9| 60.9], c_acc: [68.8| 93.8]}  G{v_l: 1.059, v_acc: 43.8, c_acc: 89.1}\n","STEP:226, D{v_l: 0.928, v_acc: [43.8| 75.0| 59.4], c_acc: [75.0| 90.6]}  G{v_l: 0.971, v_acc: 46.9, c_acc: 89.1}\n","STEP:227, D{v_l: 0.750, v_acc: [56.2| 65.6| 60.9], c_acc: [65.6| 84.4]}  G{v_l: 0.846, v_acc: 56.2, c_acc: 90.6}\n","STEP:228, D{v_l: 0.677, v_acc: [62.5| 71.9| 67.2], c_acc: [78.1| 96.9]}  G{v_l: 1.005, v_acc: 51.6, c_acc: 95.3}\n","STEP:229, D{v_l: 0.811, v_acc: [50.0| 75.0| 62.5], c_acc: [75.0| 93.8]}  G{v_l: 0.865, v_acc: 56.2, c_acc: 93.8}\n","STEP:230, D{v_l: 0.691, v_acc: [62.5| 71.9| 67.2], c_acc: [71.9| 96.9]}  G{v_l: 1.112, v_acc: 42.2, c_acc: 89.1}\n","STEP:231, D{v_l: 0.756, v_acc: [53.1| 71.9| 62.5], c_acc: [62.5| 87.5]}  G{v_l: 0.905, v_acc: 51.6, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.5458 - valid_loss: 0.8761 - class_loss: 2.2630 - valid_acc: 0.0118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1592 - valid_loss: 0.6510 - class_loss: 0.1015 - valid_acc: 0.4235 - class_acc: 1.0000\n","average v_acc: 21.765, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:232, D{v_l: 0.771, v_acc: [46.2| 71.9| 59.0], c_acc: [88.0| 93.8]}  G{v_l: 1.011, v_acc: 48.4, c_acc: 90.6}\n","STEP:233, D{v_l: 0.823, v_acc: [65.6| 59.4| 62.5], c_acc: [75.0| 93.8]}  G{v_l: 0.837, v_acc: 51.6, c_acc: 90.6}\n","STEP:234, D{v_l: 0.961, v_acc: [50.0| 53.1| 51.6], c_acc: [65.6| 100.0]}  G{v_l: 0.981, v_acc: 46.9, c_acc: 82.8}\n","STEP:235, D{v_l: 0.769, v_acc: [56.2| 56.2| 56.2], c_acc: [65.6| 84.4]}  G{v_l: 0.893, v_acc: 43.8, c_acc: 92.2}\n","STEP:236, D{v_l: 0.818, v_acc: [50.0| 68.8| 59.4], c_acc: [65.6| 100.0]}  G{v_l: 0.927, v_acc: 46.9, c_acc: 89.1}\n","STEP:237, D{v_l: 0.818, v_acc: [53.1| 71.9| 62.5], c_acc: [56.2| 90.6]}  G{v_l: 0.815, v_acc: 54.7, c_acc: 93.8}\n","STEP:238, D{v_l: 0.915, v_acc: [50.0| 56.2| 53.1], c_acc: [84.4| 96.9]}  G{v_l: 1.158, v_acc: 46.9, c_acc: 92.2}\n","STEP:239, D{v_l: 0.869, v_acc: [50.0| 75.0| 62.5], c_acc: [56.2| 90.6]}  G{v_l: 1.058, v_acc: 45.3, c_acc: 92.2}\n","STEP:240, D{v_l: 0.869, v_acc: [46.9| 71.9| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 0.845, v_acc: 50.0, c_acc: 82.8}\n","STEP:241, D{v_l: 0.668, v_acc: [62.5| 71.9| 67.2], c_acc: [62.5| 96.9]}  G{v_l: 0.902, v_acc: 46.9, c_acc: 82.8}\n","STEP:242, D{v_l: 0.653, v_acc: [56.2| 78.1| 67.2], c_acc: [65.6| 96.9]}  G{v_l: 0.763, v_acc: 57.8, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.8519 - valid_loss: 0.9306 - class_loss: 2.5146 - valid_acc: 0.0235 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1354 - valid_loss: 0.6381 - class_loss: 0.0906 - valid_acc: 0.5412 - class_acc: 1.0000\n","average v_acc: 28.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:243, D{v_l: 0.677, v_acc: [49.6| 71.9| 60.7], c_acc: [88.0| 96.9]}  G{v_l: 0.817, v_acc: 48.4, c_acc: 90.6}\n","STEP:244, D{v_l: 0.731, v_acc: [56.2| 65.6| 60.9], c_acc: [71.9| 100.0]}  G{v_l: 0.890, v_acc: 53.1, c_acc: 82.8}\n","STEP:245, D{v_l: 0.992, v_acc: [50.0| 53.1| 51.6], c_acc: [56.2| 96.9]}  G{v_l: 0.924, v_acc: 56.2, c_acc: 75.0}\n","STEP:246, D{v_l: 0.875, v_acc: [56.2| 59.4| 57.8], c_acc: [75.0| 87.5]}  G{v_l: 1.070, v_acc: 37.5, c_acc: 87.5}\n","STEP:247, D{v_l: 0.938, v_acc: [46.9| 62.5| 54.7], c_acc: [65.6| 93.8]}  G{v_l: 0.912, v_acc: 53.1, c_acc: 90.6}\n","STEP:248, D{v_l: 1.064, v_acc: [46.9| 68.8| 57.8], c_acc: [56.2| 100.0]}  G{v_l: 1.230, v_acc: 39.1, c_acc: 96.9}\n","STEP:249, D{v_l: 0.762, v_acc: [53.1| 71.9| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 0.922, v_acc: 45.3, c_acc: 89.1}\n","STEP:250, D{v_l: 0.846, v_acc: [53.1| 65.6| 59.4], c_acc: [65.6| 90.6]}  G{v_l: 1.040, v_acc: 51.6, c_acc: 79.7}\n","STEP:251, D{v_l: 0.784, v_acc: [50.0| 75.0| 62.5], c_acc: [75.0| 84.4]}  G{v_l: 0.863, v_acc: 50.0, c_acc: 87.5}\n","STEP:252, D{v_l: 0.873, v_acc: [59.4| 59.4| 59.4], c_acc: [75.0| 93.8]}  G{v_l: 0.905, v_acc: 57.8, c_acc: 93.8}\n","STEP:253, D{v_l: 0.816, v_acc: [56.2| 56.2| 56.2], c_acc: [84.4| 93.8]}  G{v_l: 1.054, v_acc: 42.2, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 4.4436 - valid_loss: 1.0930 - class_loss: 2.9439 - valid_acc: 0.0235 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0617 - valid_loss: 0.5715 - class_loss: 0.0835 - valid_acc: 0.6471 - class_acc: 1.0000\n","average v_acc: 33.529, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:254, D{v_l: 0.767, v_acc: [59.0| 56.2| 57.6], c_acc: [91.5| 93.8]}  G{v_l: 0.976, v_acc: 45.3, c_acc: 90.6}\n","STEP:255, D{v_l: 0.746, v_acc: [62.5| 59.4| 60.9], c_acc: [65.6| 96.9]}  G{v_l: 0.951, v_acc: 50.0, c_acc: 95.3}\n","STEP:256, D{v_l: 0.937, v_acc: [53.1| 62.5| 57.8], c_acc: [59.4| 90.6]}  G{v_l: 0.995, v_acc: 48.4, c_acc: 92.2}\n","STEP:257, D{v_l: 0.727, v_acc: [65.6| 59.4| 62.5], c_acc: [84.4| 93.8]}  G{v_l: 1.025, v_acc: 45.3, c_acc: 92.2}\n","STEP:258, D{v_l: 0.839, v_acc: [40.6| 65.6| 53.1], c_acc: [68.8| 93.8]}  G{v_l: 0.878, v_acc: 50.0, c_acc: 95.3}\n","STEP:259, D{v_l: 0.743, v_acc: [62.5| 62.5| 62.5], c_acc: [68.8| 90.6]}  G{v_l: 0.924, v_acc: 56.2, c_acc: 95.3}\n","STEP:260, D{v_l: 0.973, v_acc: [59.4| 62.5| 60.9], c_acc: [84.4| 81.2]}  G{v_l: 0.732, v_acc: 57.8, c_acc: 98.4}\n","STEP:261, D{v_l: 0.767, v_acc: [56.2| 65.6| 60.9], c_acc: [65.6| 96.9]}  G{v_l: 1.079, v_acc: 50.0, c_acc: 93.8}\n","STEP:262, D{v_l: 1.007, v_acc: [46.9| 59.4| 53.1], c_acc: [78.1| 90.6]}  G{v_l: 0.866, v_acc: 57.8, c_acc: 87.5}\n","STEP:263, D{v_l: 0.730, v_acc: [53.1| 75.0| 64.1], c_acc: [65.6| 96.9]}  G{v_l: 0.983, v_acc: 45.3, c_acc: 93.8}\n","STEP:264, D{v_l: 0.696, v_acc: [65.6| 65.6| 65.6], c_acc: [78.1| 87.5]}  G{v_l: 0.984, v_acc: 51.6, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.2343 - valid_loss: 1.1351 - class_loss: 2.6925 - valid_acc: 0.0353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.1128 - valid_loss: 0.6558 - class_loss: 0.0503 - valid_acc: 0.4118 - class_acc: 1.0000\n","average v_acc: 22.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:265, D{v_l: 0.875, v_acc: [45.3| 56.2| 50.8], c_acc: [94.9| 90.6]}  G{v_l: 1.097, v_acc: 48.4, c_acc: 89.1}\n","STEP:266, D{v_l: 0.684, v_acc: [53.1| 62.5| 57.8], c_acc: [78.1| 93.8]}  G{v_l: 1.126, v_acc: 51.6, c_acc: 90.6}\n","STEP:267, D{v_l: 0.674, v_acc: [71.9| 68.8| 70.3], c_acc: [81.2| 90.6]}  G{v_l: 0.931, v_acc: 53.1, c_acc: 96.9}\n","STEP:268, D{v_l: 0.780, v_acc: [50.0| 71.9| 60.9], c_acc: [75.0| 93.8]}  G{v_l: 1.272, v_acc: 40.6, c_acc: 87.5}\n","STEP:269, D{v_l: 0.649, v_acc: [81.2| 65.6| 73.4], c_acc: [68.8| 93.8]}  G{v_l: 0.854, v_acc: 50.0, c_acc: 89.1}\n","STEP:270, D{v_l: 0.800, v_acc: [56.2| 68.8| 62.5], c_acc: [71.9| 93.8]}  G{v_l: 1.078, v_acc: 43.8, c_acc: 92.2}\n","STEP:271, D{v_l: 0.868, v_acc: [50.0| 68.8| 59.4], c_acc: [75.0| 96.9]}  G{v_l: 1.056, v_acc: 43.8, c_acc: 92.2}\n","STEP:272, D{v_l: 0.737, v_acc: [62.5| 71.9| 67.2], c_acc: [65.6| 96.9]}  G{v_l: 1.086, v_acc: 39.1, c_acc: 93.8}\n","STEP:273, D{v_l: 0.758, v_acc: [53.1| 59.4| 56.2], c_acc: [75.0| 93.8]}  G{v_l: 1.061, v_acc: 46.9, c_acc: 96.9}\n","STEP:274, D{v_l: 0.885, v_acc: [43.8| 65.6| 54.7], c_acc: [68.8| 96.9]}  G{v_l: 1.190, v_acc: 40.6, c_acc: 89.1}\n","STEP:275, D{v_l: 0.794, v_acc: [65.6| 59.4| 62.5], c_acc: [65.6| 100.0]}  G{v_l: 1.147, v_acc: 39.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.1174 - valid_loss: 1.0863 - class_loss: 2.6244 - valid_acc: 0.0471 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 0.9401 - valid_loss: 0.5111 - class_loss: 0.0223 - valid_acc: 0.8824 - class_acc: 1.0000\n","average v_acc: 46.471, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:276, D{v_l: 0.656, v_acc: [80.3| 68.8| 74.5], c_acc: [92.3| 96.9]}  G{v_l: 1.026, v_acc: 40.6, c_acc: 92.2}\n","STEP:277, D{v_l: 1.019, v_acc: [53.1| 62.5| 57.8], c_acc: [71.9| 93.8]}  G{v_l: 1.195, v_acc: 45.3, c_acc: 93.8}\n","STEP:278, D{v_l: 0.618, v_acc: [53.1| 78.1| 65.6], c_acc: [71.9| 96.9]}  G{v_l: 1.196, v_acc: 45.3, c_acc: 92.2}\n","STEP:279, D{v_l: 0.697, v_acc: [59.4| 65.6| 62.5], c_acc: [65.6| 96.9]}  G{v_l: 1.100, v_acc: 53.1, c_acc: 89.1}\n","STEP:280, D{v_l: 0.791, v_acc: [65.6| 56.2| 60.9], c_acc: [71.9| 96.9]}  G{v_l: 0.952, v_acc: 46.9, c_acc: 95.3}\n","STEP:281, D{v_l: 0.865, v_acc: [46.9| 65.6| 56.2], c_acc: [68.8| 93.8]}  G{v_l: 1.188, v_acc: 39.1, c_acc: 100.0}\n","STEP:282, D{v_l: 0.992, v_acc: [46.9| 46.9| 46.9], c_acc: [75.0| 100.0]}  G{v_l: 1.137, v_acc: 43.8, c_acc: 93.8}\n","STEP:283, D{v_l: 0.621, v_acc: [56.2| 75.0| 65.6], c_acc: [75.0| 96.9]}  G{v_l: 0.941, v_acc: 51.6, c_acc: 90.6}\n","STEP:284, D{v_l: 0.840, v_acc: [62.5| 65.6| 64.1], c_acc: [75.0| 93.8]}  G{v_l: 0.960, v_acc: 51.6, c_acc: 90.6}\n","STEP:285, D{v_l: 0.604, v_acc: [59.4| 81.2| 70.3], c_acc: [62.5| 96.9]}  G{v_l: 1.167, v_acc: 50.0, c_acc: 84.4}\n","STEP:286, D{v_l: 0.817, v_acc: [65.6| 68.8| 67.2], c_acc: [71.9| 96.9]}  G{v_l: 1.083, v_acc: 48.4, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 4.0124 - valid_loss: 1.0140 - class_loss: 2.5917 - valid_acc: 0.0941 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9274 - valid_loss: 0.4967 - class_loss: 0.0240 - valid_acc: 0.8706 - class_acc: 1.0000\n","average v_acc: 48.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:287, D{v_l: 0.677, v_acc: [78.6| 75.0| 76.8], c_acc: [94.0| 90.6]}  G{v_l: 1.104, v_acc: 39.1, c_acc: 89.1}\n","STEP:288, D{v_l: 0.622, v_acc: [62.5| 75.0| 68.8], c_acc: [59.4| 96.9]}  G{v_l: 1.088, v_acc: 50.0, c_acc: 96.9}\n","STEP:289, D{v_l: 0.796, v_acc: [62.5| 62.5| 62.5], c_acc: [59.4| 93.8]}  G{v_l: 1.261, v_acc: 37.5, c_acc: 95.3}\n","STEP:290, D{v_l: 0.666, v_acc: [75.0| 56.2| 65.6], c_acc: [87.5| 96.9]}  G{v_l: 1.012, v_acc: 56.2, c_acc: 95.3}\n","STEP:291, D{v_l: 0.943, v_acc: [65.6| 65.6| 65.6], c_acc: [68.8| 93.8]}  G{v_l: 0.954, v_acc: 53.1, c_acc: 92.2}\n","STEP:292, D{v_l: 0.903, v_acc: [56.2| 65.6| 60.9], c_acc: [75.0| 100.0]}  G{v_l: 1.019, v_acc: 56.2, c_acc: 93.8}\n","STEP:293, D{v_l: 0.737, v_acc: [71.9| 53.1| 62.5], c_acc: [68.8| 90.6]}  G{v_l: 1.133, v_acc: 48.4, c_acc: 96.9}\n","STEP:294, D{v_l: 0.740, v_acc: [78.1| 75.0| 76.6], c_acc: [62.5| 100.0]}  G{v_l: 1.016, v_acc: 50.0, c_acc: 98.4}\n","STEP:295, D{v_l: 0.758, v_acc: [53.1| 50.0| 51.6], c_acc: [75.0| 93.8]}  G{v_l: 1.075, v_acc: 48.4, c_acc: 98.4}\n","STEP:296, D{v_l: 0.587, v_acc: [62.5| 68.8| 65.6], c_acc: [75.0| 87.5]}  G{v_l: 1.162, v_acc: 51.6, c_acc: 96.9}\n","STEP:297, D{v_l: 0.688, v_acc: [56.2| 68.8| 62.5], c_acc: [84.4| 96.9]}  G{v_l: 0.841, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 4.3322 - valid_loss: 1.0666 - class_loss: 2.8590 - valid_acc: 0.0706 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9790 - valid_loss: 0.5488 - class_loss: 0.0235 - valid_acc: 0.5529 - class_acc: 1.0000\n","average v_acc: 31.176, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:298, D{v_l: 0.842, v_acc: [54.7| 50.0| 52.4], c_acc: [94.0| 100.0]}  G{v_l: 1.189, v_acc: 48.4, c_acc: 89.1}\n","STEP:299, D{v_l: 0.722, v_acc: [62.5| 68.8| 65.6], c_acc: [68.8| 96.9]}  G{v_l: 1.199, v_acc: 50.0, c_acc: 96.9}\n","STEP:300, D{v_l: 0.721, v_acc: [75.0| 71.9| 73.4], c_acc: [62.5| 90.6]}  G{v_l: 0.998, v_acc: 59.4, c_acc: 89.1}\n","STEP:301, D{v_l: 0.818, v_acc: [62.5| 62.5| 62.5], c_acc: [87.5| 100.0]}  G{v_l: 0.998, v_acc: 50.0, c_acc: 95.3}\n","STEP:302, D{v_l: 1.049, v_acc: [50.0| 50.0| 50.0], c_acc: [68.8| 93.8]}  G{v_l: 0.866, v_acc: 53.1, c_acc: 96.9}\n","STEP:303, D{v_l: 0.534, v_acc: [78.1| 68.8| 73.4], c_acc: [71.9| 100.0]}  G{v_l: 0.940, v_acc: 50.0, c_acc: 95.3}\n","STEP:304, D{v_l: 0.922, v_acc: [43.8| 65.6| 54.7], c_acc: [62.5| 100.0]}  G{v_l: 1.088, v_acc: 50.0, c_acc: 93.8}\n","STEP:305, D{v_l: 0.708, v_acc: [59.4| 59.4| 59.4], c_acc: [81.2| 90.6]}  G{v_l: 0.951, v_acc: 57.8, c_acc: 96.9}\n","STEP:306, D{v_l: 0.620, v_acc: [65.6| 68.8| 67.2], c_acc: [75.0| 96.9]}  G{v_l: 1.094, v_acc: 40.6, c_acc: 98.4}\n","STEP:307, D{v_l: 0.821, v_acc: [53.1| 65.6| 59.4], c_acc: [81.2| 96.9]}  G{v_l: 1.042, v_acc: 54.7, c_acc: 89.1}\n","STEP:308, D{v_l: 0.563, v_acc: [56.2| 78.1| 67.2], c_acc: [59.4| 100.0]}  G{v_l: 1.235, v_acc: 40.6, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 3.8046 - valid_loss: 0.9874 - class_loss: 2.4106 - valid_acc: 0.0824 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9152 - valid_loss: 0.4852 - class_loss: 0.0234 - valid_acc: 0.8118 - class_acc: 1.0000\n","average v_acc: 44.706, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:309, D{v_l: 0.580, v_acc: [71.8| 78.1| 75.0], c_acc: [93.2| 96.9]}  G{v_l: 1.181, v_acc: 46.9, c_acc: 95.3}\n","STEP:310, D{v_l: 0.687, v_acc: [50.0| 84.4| 67.2], c_acc: [84.4| 100.0]}  G{v_l: 1.284, v_acc: 46.9, c_acc: 96.9}\n","STEP:311, D{v_l: 0.813, v_acc: [53.1| 65.6| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 1.081, v_acc: 54.7, c_acc: 96.9}\n","STEP:312, D{v_l: 0.683, v_acc: [65.6| 56.2| 60.9], c_acc: [59.4| 93.8]}  G{v_l: 1.133, v_acc: 48.4, c_acc: 93.8}\n","STEP:313, D{v_l: 0.674, v_acc: [56.2| 75.0| 65.6], c_acc: [71.9| 84.4]}  G{v_l: 0.999, v_acc: 53.1, c_acc: 92.2}\n","STEP:314, D{v_l: 0.808, v_acc: [53.1| 75.0| 64.1], c_acc: [81.2| 93.8]}  G{v_l: 1.206, v_acc: 43.8, c_acc: 98.4}\n","STEP:315, D{v_l: 0.767, v_acc: [59.4| 71.9| 65.6], c_acc: [87.5| 87.5]}  G{v_l: 1.277, v_acc: 43.8, c_acc: 95.3}\n","STEP:316, D{v_l: 0.972, v_acc: [56.2| 68.8| 62.5], c_acc: [65.6| 90.6]}  G{v_l: 1.188, v_acc: 40.6, c_acc: 96.9}\n","STEP:317, D{v_l: 0.799, v_acc: [53.1| 62.5| 57.8], c_acc: [78.1| 93.8]}  G{v_l: 0.842, v_acc: 51.6, c_acc: 96.9}\n","STEP:318, D{v_l: 0.820, v_acc: [56.2| 68.8| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 1.008, v_acc: 50.0, c_acc: 93.8}\n","STEP:319, D{v_l: 0.790, v_acc: [59.4| 59.4| 59.4], c_acc: [65.6| 100.0]}  G{v_l: 0.886, v_acc: 54.7, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.9014 - valid_loss: 0.9343 - class_loss: 2.5604 - valid_acc: 0.1176 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 0.9752 - valid_loss: 0.5470 - class_loss: 0.0217 - valid_acc: 0.6706 - class_acc: 1.0000\n","average v_acc: 39.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:320, D{v_l: 0.520, v_acc: [62.4| 81.2| 71.8], c_acc: [92.3| 96.9]}  G{v_l: 0.937, v_acc: 48.4, c_acc: 93.8}\n","STEP:321, D{v_l: 0.745, v_acc: [62.5| 59.4| 60.9], c_acc: [65.6| 96.9]}  G{v_l: 1.193, v_acc: 43.8, c_acc: 93.8}\n","STEP:322, D{v_l: 0.795, v_acc: [56.2| 65.6| 60.9], c_acc: [56.2| 96.9]}  G{v_l: 1.149, v_acc: 57.8, c_acc: 93.8}\n","STEP:323, D{v_l: 0.573, v_acc: [62.5| 71.9| 67.2], c_acc: [71.9| 96.9]}  G{v_l: 1.272, v_acc: 37.5, c_acc: 95.3}\n","STEP:324, D{v_l: 0.577, v_acc: [56.2| 81.2| 68.8], c_acc: [75.0| 96.9]}  G{v_l: 1.120, v_acc: 40.6, c_acc: 87.5}\n","STEP:325, D{v_l: 0.789, v_acc: [59.4| 75.0| 67.2], c_acc: [81.2| 100.0]}  G{v_l: 1.255, v_acc: 37.5, c_acc: 92.2}\n","STEP:326, D{v_l: 0.659, v_acc: [56.2| 68.8| 62.5], c_acc: [78.1| 90.6]}  G{v_l: 0.925, v_acc: 53.1, c_acc: 100.0}\n","STEP:327, D{v_l: 0.719, v_acc: [62.5| 81.2| 71.9], c_acc: [75.0| 100.0]}  G{v_l: 0.993, v_acc: 50.0, c_acc: 92.2}\n","STEP:328, D{v_l: 0.708, v_acc: [43.8| 84.4| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 1.028, v_acc: 48.4, c_acc: 96.9}\n","STEP:329, D{v_l: 0.737, v_acc: [56.2| 68.8| 62.5], c_acc: [81.2| 96.9]}  G{v_l: 1.044, v_acc: 50.0, c_acc: 96.9}\n","STEP:330, D{v_l: 0.918, v_acc: [62.5| 59.4| 60.9], c_acc: [65.6| 96.9]}  G{v_l: 0.944, v_acc: 54.7, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.4115 - valid_loss: 0.8310 - class_loss: 2.1739 - valid_acc: 0.2941 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 0.9345 - valid_loss: 0.5091 - class_loss: 0.0188 - valid_acc: 0.7882 - class_acc: 1.0000\n","average v_acc: 54.118, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 30\n","====================================================================================================\n","STEP:331, D{v_l: 0.517, v_acc: [73.5| 65.6| 69.6], c_acc: [90.6| 100.0]}  G{v_l: 0.995, v_acc: 50.0, c_acc: 90.6}\n","STEP:332, D{v_l: 0.800, v_acc: [65.6| 59.4| 62.5], c_acc: [75.0| 100.0]}  G{v_l: 1.155, v_acc: 50.0, c_acc: 96.9}\n","STEP:333, D{v_l: 0.725, v_acc: [53.1| 75.0| 64.1], c_acc: [75.0| 100.0]}  G{v_l: 0.796, v_acc: 56.2, c_acc: 93.8}\n","STEP:334, D{v_l: 0.775, v_acc: [46.9| 71.9| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 0.980, v_acc: 56.2, c_acc: 96.9}\n","STEP:335, D{v_l: 0.880, v_acc: [71.9| 56.2| 64.1], c_acc: [84.4| 100.0]}  G{v_l: 1.211, v_acc: 50.0, c_acc: 93.8}\n","STEP:336, D{v_l: 0.709, v_acc: [56.2| 71.9| 64.1], c_acc: [84.4| 96.9]}  G{v_l: 1.305, v_acc: 45.3, c_acc: 89.1}\n","STEP:337, D{v_l: 0.659, v_acc: [68.8| 59.4| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 1.073, v_acc: 43.8, c_acc: 95.3}\n","STEP:338, D{v_l: 0.866, v_acc: [37.5| 75.0| 56.2], c_acc: [78.1| 93.8]}  G{v_l: 0.952, v_acc: 50.0, c_acc: 90.6}\n","STEP:339, D{v_l: 0.655, v_acc: [62.5| 81.2| 71.9], c_acc: [75.0| 93.8]}  G{v_l: 1.352, v_acc: 42.2, c_acc: 90.6}\n","STEP:340, D{v_l: 0.871, v_acc: [40.6| 71.9| 56.2], c_acc: [75.0| 93.8]}  G{v_l: 1.171, v_acc: 45.3, c_acc: 93.8}\n","STEP:341, D{v_l: 0.680, v_acc: [65.6| 62.5| 64.1], c_acc: [71.9| 96.9]}  G{v_l: 1.115, v_acc: 54.7, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.1697 - valid_loss: 0.9808 - class_loss: 2.7824 - valid_acc: 0.1412 - class_acc: 0.5176\n","3/3 [==============================] - 0s 44ms/step - loss: 0.9585 - valid_loss: 0.5042 - class_loss: 0.0477 - valid_acc: 0.8118 - class_acc: 1.0000\n","average v_acc: 47.647, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:342, D{v_l: 0.641, v_acc: [78.6| 68.8| 73.7], c_acc: [92.3| 96.9]}  G{v_l: 1.047, v_acc: 53.1, c_acc: 96.9}\n","STEP:343, D{v_l: 0.514, v_acc: [68.8| 68.8| 68.8], c_acc: [71.9| 96.9]}  G{v_l: 1.116, v_acc: 39.1, c_acc: 95.3}\n","STEP:344, D{v_l: 0.738, v_acc: [53.1| 71.9| 62.5], c_acc: [87.5| 96.9]}  G{v_l: 1.228, v_acc: 39.1, c_acc: 96.9}\n","STEP:345, D{v_l: 0.584, v_acc: [62.5| 71.9| 67.2], c_acc: [65.6| 100.0]}  G{v_l: 1.141, v_acc: 45.3, c_acc: 95.3}\n","STEP:346, D{v_l: 0.903, v_acc: [62.5| 68.8| 65.6], c_acc: [78.1| 93.8]}  G{v_l: 1.257, v_acc: 45.3, c_acc: 93.8}\n","STEP:347, D{v_l: 0.921, v_acc: [68.8| 53.1| 60.9], c_acc: [59.4| 90.6]}  G{v_l: 1.327, v_acc: 45.3, c_acc: 98.4}\n","STEP:348, D{v_l: 1.033, v_acc: [53.1| 59.4| 56.2], c_acc: [81.2| 93.8]}  G{v_l: 1.104, v_acc: 53.1, c_acc: 93.8}\n","STEP:349, D{v_l: 0.950, v_acc: [37.5| 84.4| 60.9], c_acc: [71.9| 100.0]}  G{v_l: 1.085, v_acc: 51.6, c_acc: 100.0}\n","STEP:350, D{v_l: 0.645, v_acc: [68.8| 68.8| 68.8], c_acc: [84.4| 87.5]}  G{v_l: 1.170, v_acc: 48.4, c_acc: 98.4}\n","STEP:351, D{v_l: 0.728, v_acc: [62.5| 75.0| 68.8], c_acc: [90.6| 100.0]}  G{v_l: 1.078, v_acc: 48.4, c_acc: 92.2}\n","STEP:352, D{v_l: 0.853, v_acc: [43.8| 71.9| 57.8], c_acc: [71.9| 93.8]}  G{v_l: 1.204, v_acc: 54.7, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 5.0125 - valid_loss: 1.1673 - class_loss: 3.4387 - valid_acc: 0.0353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0985 - valid_loss: 0.6606 - class_loss: 0.0313 - valid_acc: 0.4118 - class_acc: 1.0000\n","average v_acc: 22.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:353, D{v_l: 0.697, v_acc: [49.6| 71.9| 60.7], c_acc: [94.0| 100.0]}  G{v_l: 1.377, v_acc: 37.5, c_acc: 92.2}\n","STEP:354, D{v_l: 0.803, v_acc: [46.9| 65.6| 56.2], c_acc: [84.4| 96.9]}  G{v_l: 1.030, v_acc: 39.1, c_acc: 95.3}\n","STEP:355, D{v_l: 0.889, v_acc: [62.5| 65.6| 64.1], c_acc: [68.8| 96.9]}  G{v_l: 1.193, v_acc: 46.9, c_acc: 93.8}\n","STEP:356, D{v_l: 0.573, v_acc: [56.2| 75.0| 65.6], c_acc: [75.0| 93.8]}  G{v_l: 0.770, v_acc: 62.5, c_acc: 87.5}\n","STEP:357, D{v_l: 0.831, v_acc: [56.2| 71.9| 64.1], c_acc: [84.4| 100.0]}  G{v_l: 1.075, v_acc: 50.0, c_acc: 95.3}\n","STEP:358, D{v_l: 0.846, v_acc: [71.9| 68.8| 70.3], c_acc: [78.1| 96.9]}  G{v_l: 1.416, v_acc: 34.4, c_acc: 95.3}\n","STEP:359, D{v_l: 0.788, v_acc: [43.8| 75.0| 59.4], c_acc: [81.2| 96.9]}  G{v_l: 1.007, v_acc: 46.9, c_acc: 89.1}\n","STEP:360, D{v_l: 0.659, v_acc: [59.4| 81.2| 70.3], c_acc: [65.6| 96.9]}  G{v_l: 1.170, v_acc: 43.8, c_acc: 93.8}\n","STEP:361, D{v_l: 0.607, v_acc: [65.6| 71.9| 68.8], c_acc: [68.8| 90.6]}  G{v_l: 1.093, v_acc: 34.4, c_acc: 89.1}\n","STEP:362, D{v_l: 0.665, v_acc: [59.4| 71.9| 65.6], c_acc: [71.9| 96.9]}  G{v_l: 1.035, v_acc: 50.0, c_acc: 98.4}\n","STEP:363, D{v_l: 0.922, v_acc: [50.0| 56.2| 53.1], c_acc: [71.9| 93.8]}  G{v_l: 0.994, v_acc: 53.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 5.7507 - valid_loss: 1.1831 - class_loss: 4.1611 - valid_acc: 0.0353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0167 - valid_loss: 0.5801 - class_loss: 0.0302 - valid_acc: 0.6353 - class_acc: 1.0000\n","average v_acc: 33.529, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:364, D{v_l: 0.497, v_acc: [65.0| 87.5| 76.2], c_acc: [94.0| 93.8]}  G{v_l: 1.134, v_acc: 45.3, c_acc: 92.2}\n","STEP:365, D{v_l: 0.852, v_acc: [50.0| 65.6| 57.8], c_acc: [90.6| 90.6]}  G{v_l: 1.048, v_acc: 51.6, c_acc: 98.4}\n","STEP:366, D{v_l: 0.662, v_acc: [50.0| 71.9| 60.9], c_acc: [84.4| 93.8]}  G{v_l: 1.239, v_acc: 42.2, c_acc: 90.6}\n","STEP:367, D{v_l: 0.638, v_acc: [53.1| 68.8| 60.9], c_acc: [65.6| 90.6]}  G{v_l: 0.964, v_acc: 53.1, c_acc: 95.3}\n","STEP:368, D{v_l: 0.695, v_acc: [59.4| 84.4| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.659, v_acc: 35.9, c_acc: 95.3}\n","STEP:369, D{v_l: 0.731, v_acc: [68.8| 56.2| 62.5], c_acc: [68.8| 93.8]}  G{v_l: 1.197, v_acc: 40.6, c_acc: 95.3}\n","STEP:370, D{v_l: 0.664, v_acc: [53.1| 75.0| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 1.038, v_acc: 50.0, c_acc: 92.2}\n","STEP:371, D{v_l: 0.771, v_acc: [65.6| 75.0| 70.3], c_acc: [71.9| 87.5]}  G{v_l: 1.073, v_acc: 48.4, c_acc: 89.1}\n","STEP:372, D{v_l: 0.724, v_acc: [71.9| 50.0| 60.9], c_acc: [81.2| 96.9]}  G{v_l: 1.262, v_acc: 51.6, c_acc: 87.5}\n","STEP:373, D{v_l: 0.694, v_acc: [71.9| 65.6| 68.8], c_acc: [93.8| 78.1]}  G{v_l: 1.108, v_acc: 37.5, c_acc: 95.3}\n","STEP:374, D{v_l: 0.725, v_acc: [68.8| 50.0| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 1.672, v_acc: 23.4, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.2396 - valid_loss: 0.8844 - class_loss: 2.9487 - valid_acc: 0.2824 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 0.8721 - valid_loss: 0.3778 - class_loss: 0.0878 - valid_acc: 0.9412 - class_acc: 0.9765\n","average v_acc: 61.176, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:375, D{v_l: 0.624, v_acc: [91.5| 59.4| 75.4], c_acc: [94.9| 96.9]}  G{v_l: 1.208, v_acc: 50.0, c_acc: 92.2}\n","STEP:376, D{v_l: 0.718, v_acc: [53.1| 65.6| 59.4], c_acc: [84.4| 87.5]}  G{v_l: 1.272, v_acc: 43.8, c_acc: 92.2}\n","STEP:377, D{v_l: 0.554, v_acc: [59.4| 84.4| 71.9], c_acc: [78.1| 93.8]}  G{v_l: 1.403, v_acc: 34.4, c_acc: 90.6}\n","STEP:378, D{v_l: 0.693, v_acc: [71.9| 71.9| 71.9], c_acc: [65.6| 96.9]}  G{v_l: 0.999, v_acc: 59.4, c_acc: 92.2}\n","STEP:379, D{v_l: 0.630, v_acc: [59.4| 84.4| 71.9], c_acc: [75.0| 87.5]}  G{v_l: 1.322, v_acc: 40.6, c_acc: 93.8}\n","STEP:380, D{v_l: 0.758, v_acc: [56.2| 78.1| 67.2], c_acc: [71.9| 96.9]}  G{v_l: 1.204, v_acc: 46.9, c_acc: 96.9}\n","STEP:381, D{v_l: 0.700, v_acc: [68.8| 65.6| 67.2], c_acc: [81.2| 84.4]}  G{v_l: 1.375, v_acc: 39.1, c_acc: 93.8}\n","STEP:382, D{v_l: 0.649, v_acc: [56.2| 68.8| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 1.124, v_acc: 45.3, c_acc: 85.9}\n","STEP:383, D{v_l: 0.919, v_acc: [46.9| 62.5| 54.7], c_acc: [78.1| 90.6]}  G{v_l: 1.321, v_acc: 39.1, c_acc: 95.3}\n","STEP:384, D{v_l: 0.800, v_acc: [62.5| 59.4| 60.9], c_acc: [75.0| 96.9]}  G{v_l: 1.069, v_acc: 53.1, c_acc: 85.9}\n","STEP:385, D{v_l: 0.676, v_acc: [65.6| 75.0| 70.3], c_acc: [75.0| 100.0]}  G{v_l: 1.284, v_acc: 42.2, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.9317 - valid_loss: 0.7394 - class_loss: 1.7858 - valid_acc: 0.5059 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9224 - valid_loss: 0.4905 - class_loss: 0.0255 - valid_acc: 0.8000 - class_acc: 0.9882\n","average v_acc: 65.294, three class acc: 52.941, two class acc: 58.824\n","====================================================================================================\n","STEP:386, D{v_l: 0.485, v_acc: [71.8| 81.2| 76.5], c_acc: [94.9| 96.9]}  G{v_l: 0.982, v_acc: 51.6, c_acc: 96.9}\n","STEP:387, D{v_l: 0.603, v_acc: [75.0| 68.8| 71.9], c_acc: [78.1| 93.8]}  G{v_l: 0.937, v_acc: 57.8, c_acc: 93.8}\n","STEP:388, D{v_l: 0.707, v_acc: [53.1| 65.6| 59.4], c_acc: [84.4| 96.9]}  G{v_l: 1.211, v_acc: 45.3, c_acc: 92.2}\n","STEP:389, D{v_l: 1.048, v_acc: [62.5| 56.2| 59.4], c_acc: [84.4| 93.8]}  G{v_l: 0.938, v_acc: 50.0, c_acc: 90.6}\n","STEP:390, D{v_l: 0.600, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 96.9]}  G{v_l: 0.971, v_acc: 53.1, c_acc: 98.4}\n","STEP:391, D{v_l: 0.527, v_acc: [65.6| 90.6| 78.1], c_acc: [81.2| 96.9]}  G{v_l: 1.384, v_acc: 45.3, c_acc: 93.8}\n","STEP:392, D{v_l: 0.686, v_acc: [62.5| 56.2| 59.4], c_acc: [81.2| 90.6]}  G{v_l: 0.959, v_acc: 51.6, c_acc: 89.1}\n","STEP:393, D{v_l: 0.633, v_acc: [68.8| 78.1| 73.4], c_acc: [78.1| 100.0]}  G{v_l: 1.111, v_acc: 48.4, c_acc: 100.0}\n","STEP:394, D{v_l: 0.776, v_acc: [75.0| 59.4| 67.2], c_acc: [78.1| 93.8]}  G{v_l: 1.250, v_acc: 37.5, c_acc: 90.6}\n","STEP:395, D{v_l: 0.863, v_acc: [62.5| 71.9| 67.2], c_acc: [87.5| 96.9]}  G{v_l: 1.218, v_acc: 42.2, c_acc: 95.3}\n","STEP:396, D{v_l: 0.894, v_acc: [50.0| 62.5| 56.2], c_acc: [84.4| 96.9]}  G{v_l: 1.270, v_acc: 42.2, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.1876 - valid_loss: 0.7153 - class_loss: 2.0659 - valid_acc: 0.5059 - class_acc: 0.5059\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0460 - valid_loss: 0.4641 - class_loss: 0.1756 - valid_acc: 0.9176 - class_acc: 0.9529\n","average v_acc: 71.176, three class acc: 50.588, two class acc: 56.471\n","====================================================================================================\n","STEP:397, D{v_l: 0.517, v_acc: [85.5| 75.0| 80.2], c_acc: [95.7| 96.9]}  G{v_l: 1.386, v_acc: 37.5, c_acc: 87.5}\n","STEP:398, D{v_l: 0.736, v_acc: [68.8| 68.8| 68.8], c_acc: [75.0| 93.8]}  G{v_l: 0.952, v_acc: 45.3, c_acc: 96.9}\n","STEP:399, D{v_l: 0.728, v_acc: [71.9| 68.8| 70.3], c_acc: [81.2| 96.9]}  G{v_l: 1.393, v_acc: 57.8, c_acc: 93.8}\n","STEP:400, D{v_l: 0.666, v_acc: [46.9| 75.0| 60.9], c_acc: [81.2| 93.8]}  G{v_l: 1.363, v_acc: 50.0, c_acc: 87.5}\n","STEP:401, D{v_l: 0.598, v_acc: [65.6| 65.6| 65.6], c_acc: [90.6| 96.9]}  G{v_l: 1.028, v_acc: 51.6, c_acc: 92.2}\n","STEP:402, D{v_l: 0.587, v_acc: [71.9| 68.8| 70.3], c_acc: [75.0| 84.4]}  G{v_l: 1.130, v_acc: 48.4, c_acc: 98.4}\n","STEP:403, D{v_l: 0.558, v_acc: [68.8| 78.1| 73.4], c_acc: [78.1| 93.8]}  G{v_l: 1.162, v_acc: 45.3, c_acc: 90.6}\n","STEP:404, D{v_l: 0.850, v_acc: [65.6| 53.1| 59.4], c_acc: [84.4| 100.0]}  G{v_l: 1.079, v_acc: 53.1, c_acc: 92.2}\n","STEP:405, D{v_l: 0.697, v_acc: [53.1| 75.0| 64.1], c_acc: [84.4| 100.0]}  G{v_l: 1.141, v_acc: 43.8, c_acc: 96.9}\n","STEP:406, D{v_l: 0.653, v_acc: [65.6| 71.9| 68.8], c_acc: [68.8| 93.8]}  G{v_l: 1.051, v_acc: 54.7, c_acc: 93.8}\n","STEP:407, D{v_l: 0.634, v_acc: [59.4| 71.9| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 1.259, v_acc: 39.1, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.5963 - valid_loss: 0.5589 - class_loss: 1.6310 - valid_acc: 0.8235 - class_acc: 0.4471\n","3/3 [==============================] - 0s 44ms/step - loss: 1.1679 - valid_loss: 0.5168 - class_loss: 0.2448 - valid_acc: 0.8353 - class_acc: 0.9412\n","average v_acc: 82.941, three class acc: 44.706, two class acc: 60.000\n","====================================================================================================\n","STEP:408, D{v_l: 0.704, v_acc: [71.8| 65.6| 68.7], c_acc: [89.7| 96.9]}  G{v_l: 1.206, v_acc: 39.1, c_acc: 95.3}\n","STEP:409, D{v_l: 0.748, v_acc: [62.5| 75.0| 68.8], c_acc: [78.1| 96.9]}  G{v_l: 1.266, v_acc: 39.1, c_acc: 92.2}\n","STEP:410, D{v_l: 0.609, v_acc: [68.8| 84.4| 76.6], c_acc: [71.9| 96.9]}  G{v_l: 1.377, v_acc: 45.3, c_acc: 89.1}\n","STEP:411, D{v_l: 0.724, v_acc: [53.1| 68.8| 60.9], c_acc: [87.5| 84.4]}  G{v_l: 1.077, v_acc: 56.2, c_acc: 92.2}\n","STEP:412, D{v_l: 0.662, v_acc: [68.8| 78.1| 73.4], c_acc: [71.9| 96.9]}  G{v_l: 0.942, v_acc: 53.1, c_acc: 75.0}\n","STEP:413, D{v_l: 0.693, v_acc: [75.0| 65.6| 70.3], c_acc: [81.2| 93.8]}  G{v_l: 1.286, v_acc: 51.6, c_acc: 85.9}\n","STEP:414, D{v_l: 0.762, v_acc: [65.6| 71.9| 68.8], c_acc: [75.0| 93.8]}  G{v_l: 1.417, v_acc: 42.2, c_acc: 89.1}\n","STEP:415, D{v_l: 0.761, v_acc: [56.2| 75.0| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.228, v_acc: 42.2, c_acc: 96.9}\n","STEP:416, D{v_l: 0.588, v_acc: [62.5| 75.0| 68.8], c_acc: [78.1| 96.9]}  G{v_l: 1.221, v_acc: 48.4, c_acc: 93.8}\n","STEP:417, D{v_l: 0.750, v_acc: [53.1| 59.4| 56.2], c_acc: [62.5| 93.8]}  G{v_l: 1.125, v_acc: 48.4, c_acc: 98.4}\n","STEP:418, D{v_l: 0.711, v_acc: [56.2| 68.8| 62.5], c_acc: [84.4| 96.9]}  G{v_l: 1.227, v_acc: 40.6, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.9758 - valid_loss: 0.6891 - class_loss: 1.8805 - valid_acc: 0.5882 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9075 - valid_loss: 0.4584 - class_loss: 0.0428 - valid_acc: 0.8588 - class_acc: 0.9765\n","average v_acc: 72.353, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:419, D{v_l: 0.596, v_acc: [78.6| 75.0| 76.8], c_acc: [92.3| 84.4]}  G{v_l: 0.879, v_acc: 57.8, c_acc: 95.3}\n","STEP:420, D{v_l: 0.847, v_acc: [68.8| 62.5| 65.6], c_acc: [84.4| 100.0]}  G{v_l: 1.247, v_acc: 45.3, c_acc: 92.2}\n","STEP:421, D{v_l: 0.593, v_acc: [65.6| 68.8| 67.2], c_acc: [78.1| 90.6]}  G{v_l: 1.149, v_acc: 42.2, c_acc: 93.8}\n","STEP:422, D{v_l: 0.804, v_acc: [62.5| 68.8| 65.6], c_acc: [71.9| 100.0]}  G{v_l: 0.947, v_acc: 57.8, c_acc: 98.4}\n","STEP:423, D{v_l: 0.833, v_acc: [53.1| 65.6| 59.4], c_acc: [71.9| 93.8]}  G{v_l: 1.123, v_acc: 53.1, c_acc: 100.0}\n","STEP:424, D{v_l: 0.474, v_acc: [78.1| 81.2| 79.7], c_acc: [71.9| 100.0]}  G{v_l: 1.148, v_acc: 43.8, c_acc: 96.9}\n","STEP:425, D{v_l: 0.777, v_acc: [50.0| 78.1| 64.1], c_acc: [93.8| 93.8]}  G{v_l: 0.881, v_acc: 54.7, c_acc: 93.8}\n","STEP:426, D{v_l: 0.900, v_acc: [56.2| 62.5| 59.4], c_acc: [78.1| 90.6]}  G{v_l: 0.845, v_acc: 54.7, c_acc: 89.1}\n","STEP:427, D{v_l: 0.789, v_acc: [68.8| 71.9| 70.3], c_acc: [81.2| 90.6]}  G{v_l: 1.240, v_acc: 34.4, c_acc: 82.8}\n","STEP:428, D{v_l: 0.619, v_acc: [43.8| 78.1| 60.9], c_acc: [84.4| 87.5]}  G{v_l: 1.103, v_acc: 37.5, c_acc: 85.9}\n","STEP:429, D{v_l: 0.660, v_acc: [65.6| 71.9| 68.8], c_acc: [75.0| 90.6]}  G{v_l: 1.028, v_acc: 39.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.1537 - valid_loss: 0.6686 - class_loss: 2.0788 - valid_acc: 0.6353 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9283 - valid_loss: 0.4989 - class_loss: 0.0231 - valid_acc: 0.8000 - class_acc: 0.9882\n","average v_acc: 71.765, three class acc: 49.412, two class acc: 54.118\n","====================================================================================================\n","STEP:430, D{v_l: 0.604, v_acc: [76.9| 62.5| 69.7], c_acc: [91.5| 90.6]}  G{v_l: 0.992, v_acc: 50.0, c_acc: 90.6}\n","STEP:431, D{v_l: 0.785, v_acc: [65.6| 68.8| 67.2], c_acc: [87.5| 96.9]}  G{v_l: 1.198, v_acc: 56.2, c_acc: 90.6}\n","STEP:432, D{v_l: 0.765, v_acc: [62.5| 59.4| 60.9], c_acc: [78.1| 90.6]}  G{v_l: 1.304, v_acc: 43.8, c_acc: 92.2}\n","STEP:433, D{v_l: 0.682, v_acc: [68.8| 78.1| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 1.228, v_acc: 46.9, c_acc: 96.9}\n","STEP:434, D{v_l: 0.617, v_acc: [50.0| 75.0| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 1.180, v_acc: 53.1, c_acc: 93.8}\n","STEP:435, D{v_l: 0.678, v_acc: [50.0| 81.2| 65.6], c_acc: [84.4| 96.9]}  G{v_l: 1.548, v_acc: 45.3, c_acc: 95.3}\n","STEP:436, D{v_l: 0.765, v_acc: [65.6| 59.4| 62.5], c_acc: [68.8| 96.9]}  G{v_l: 1.019, v_acc: 62.5, c_acc: 98.4}\n","STEP:437, D{v_l: 0.720, v_acc: [68.8| 71.9| 70.3], c_acc: [93.8| 93.8]}  G{v_l: 1.012, v_acc: 51.6, c_acc: 100.0}\n","STEP:438, D{v_l: 0.734, v_acc: [53.1| 75.0| 64.1], c_acc: [93.8| 93.8]}  G{v_l: 0.926, v_acc: 53.1, c_acc: 90.6}\n","STEP:439, D{v_l: 0.611, v_acc: [81.2| 75.0| 78.1], c_acc: [81.2| 93.8]}  G{v_l: 1.164, v_acc: 50.0, c_acc: 89.1}\n","STEP:440, D{v_l: 0.643, v_acc: [56.2| 62.5| 59.4], c_acc: [75.0| 96.9]}  G{v_l: 1.472, v_acc: 53.1, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.4857 - valid_loss: 0.6926 - class_loss: 2.3868 - valid_acc: 0.5412 - class_acc: 0.4941\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9772 - valid_loss: 0.5503 - class_loss: 0.0206 - valid_acc: 0.4941 - class_acc: 1.0000\n","average v_acc: 51.765, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","Epoch: 40\n","====================================================================================================\n","STEP:441, D{v_l: 0.602, v_acc: [53.8| 68.8| 61.3], c_acc: [94.9| 100.0]}  G{v_l: 1.481, v_acc: 54.7, c_acc: 95.3}\n","STEP:442, D{v_l: 0.785, v_acc: [62.5| 68.8| 65.6], c_acc: [81.2| 100.0]}  G{v_l: 1.358, v_acc: 35.9, c_acc: 92.2}\n","STEP:443, D{v_l: 0.565, v_acc: [65.6| 71.9| 68.8], c_acc: [87.5| 90.6]}  G{v_l: 1.266, v_acc: 53.1, c_acc: 93.8}\n","STEP:444, D{v_l: 0.580, v_acc: [65.6| 71.9| 68.8], c_acc: [90.6| 96.9]}  G{v_l: 1.129, v_acc: 53.1, c_acc: 95.3}\n","STEP:445, D{v_l: 0.645, v_acc: [59.4| 65.6| 62.5], c_acc: [84.4| 100.0]}  G{v_l: 1.009, v_acc: 54.7, c_acc: 98.4}\n","STEP:446, D{v_l: 0.525, v_acc: [75.0| 71.9| 73.4], c_acc: [84.4| 90.6]}  G{v_l: 1.015, v_acc: 54.7, c_acc: 100.0}\n","STEP:447, D{v_l: 0.600, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 90.6]}  G{v_l: 0.993, v_acc: 56.2, c_acc: 93.8}\n","STEP:448, D{v_l: 0.699, v_acc: [62.5| 78.1| 70.3], c_acc: [84.4| 100.0]}  G{v_l: 1.138, v_acc: 53.1, c_acc: 98.4}\n","STEP:449, D{v_l: 0.771, v_acc: [43.8| 84.4| 64.1], c_acc: [90.6| 93.8]}  G{v_l: 1.156, v_acc: 43.8, c_acc: 98.4}\n","STEP:450, D{v_l: 0.561, v_acc: [78.1| 65.6| 71.9], c_acc: [68.8| 96.9]}  G{v_l: 1.122, v_acc: 46.9, c_acc: 90.6}\n","STEP:451, D{v_l: 0.641, v_acc: [59.4| 65.6| 62.5], c_acc: [87.5| 96.9]}  G{v_l: 1.328, v_acc: 46.9, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.8259 - valid_loss: 0.7559 - class_loss: 2.6637 - valid_acc: 0.4235 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0244 - valid_loss: 0.5262 - class_loss: 0.0921 - valid_acc: 0.6353 - class_acc: 0.9765\n","average v_acc: 52.941, three class acc: 49.412, two class acc: 54.118\n","====================================================================================================\n","STEP:452, D{v_l: 0.718, v_acc: [67.5| 53.1| 60.3], c_acc: [93.2| 93.8]}  G{v_l: 1.107, v_acc: 54.7, c_acc: 95.3}\n","STEP:453, D{v_l: 0.842, v_acc: [75.0| 59.4| 67.2], c_acc: [84.4| 87.5]}  G{v_l: 1.121, v_acc: 48.4, c_acc: 90.6}\n","STEP:454, D{v_l: 0.760, v_acc: [68.8| 68.8| 68.8], c_acc: [78.1| 100.0]}  G{v_l: 0.914, v_acc: 53.1, c_acc: 90.6}\n","STEP:455, D{v_l: 0.579, v_acc: [62.5| 75.0| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 1.423, v_acc: 43.8, c_acc: 90.6}\n","STEP:456, D{v_l: 0.726, v_acc: [68.8| 62.5| 65.6], c_acc: [93.8| 96.9]}  G{v_l: 0.977, v_acc: 56.2, c_acc: 93.8}\n","STEP:457, D{v_l: 0.652, v_acc: [65.6| 62.5| 64.1], c_acc: [75.0| 93.8]}  G{v_l: 1.187, v_acc: 45.3, c_acc: 98.4}\n","STEP:458, D{v_l: 0.597, v_acc: [68.8| 75.0| 71.9], c_acc: [87.5| 96.9]}  G{v_l: 1.210, v_acc: 51.6, c_acc: 90.6}\n","STEP:459, D{v_l: 0.583, v_acc: [68.8| 75.0| 71.9], c_acc: [71.9| 96.9]}  G{v_l: 1.057, v_acc: 45.3, c_acc: 93.8}\n","STEP:460, D{v_l: 0.737, v_acc: [50.0| 81.2| 65.6], c_acc: [81.2| 100.0]}  G{v_l: 1.103, v_acc: 45.3, c_acc: 92.2}\n","STEP:461, D{v_l: 0.956, v_acc: [56.2| 65.6| 60.9], c_acc: [81.2| 96.9]}  G{v_l: 1.104, v_acc: 48.4, c_acc: 92.2}\n","STEP:462, D{v_l: 0.571, v_acc: [59.4| 81.2| 70.3], c_acc: [65.6| 100.0]}  G{v_l: 1.057, v_acc: 57.8, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 3.9560 - valid_loss: 0.6554 - class_loss: 2.8944 - valid_acc: 0.5412 - class_acc: 0.5059\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9650 - valid_loss: 0.5194 - class_loss: 0.0394 - valid_acc: 0.6824 - class_acc: 1.0000\n","average v_acc: 61.176, three class acc: 50.588, two class acc: 51.765\n","====================================================================================================\n","STEP:463, D{v_l: 0.483, v_acc: [69.2| 78.1| 73.7], c_acc: [95.7| 96.9]}  G{v_l: 1.100, v_acc: 40.6, c_acc: 96.9}\n","STEP:464, D{v_l: 0.538, v_acc: [84.4| 81.2| 82.8], c_acc: [84.4| 84.4]}  G{v_l: 1.402, v_acc: 31.2, c_acc: 89.1}\n","STEP:465, D{v_l: 0.552, v_acc: [62.5| 59.4| 60.9], c_acc: [81.2| 100.0]}  G{v_l: 0.872, v_acc: 50.0, c_acc: 96.9}\n","STEP:466, D{v_l: 0.748, v_acc: [59.4| 78.1| 68.8], c_acc: [87.5| 100.0]}  G{v_l: 1.257, v_acc: 43.8, c_acc: 95.3}\n","STEP:467, D{v_l: 0.636, v_acc: [62.5| 65.6| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 1.059, v_acc: 57.8, c_acc: 96.9}\n","STEP:468, D{v_l: 0.614, v_acc: [65.6| 65.6| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 1.047, v_acc: 53.1, c_acc: 90.6}\n","STEP:469, D{v_l: 0.759, v_acc: [62.5| 56.2| 59.4], c_acc: [78.1| 93.8]}  G{v_l: 1.473, v_acc: 32.8, c_acc: 93.8}\n","STEP:470, D{v_l: 0.635, v_acc: [62.5| 71.9| 67.2], c_acc: [84.4| 87.5]}  G{v_l: 1.304, v_acc: 42.2, c_acc: 98.4}\n","STEP:471, D{v_l: 0.730, v_acc: [68.8| 62.5| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 0.990, v_acc: 48.4, c_acc: 93.8}\n","STEP:472, D{v_l: 0.565, v_acc: [78.1| 71.9| 75.0], c_acc: [84.4| 90.6]}  G{v_l: 1.262, v_acc: 37.5, c_acc: 95.3}\n","STEP:473, D{v_l: 0.787, v_acc: [78.1| 68.8| 73.4], c_acc: [78.1| 100.0]}  G{v_l: 1.194, v_acc: 45.3, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.7212 - valid_loss: 0.6924 - class_loss: 2.6226 - valid_acc: 0.5059 - class_acc: 0.4941\n","3/3 [==============================] - 0s 49ms/step - loss: 0.8910 - valid_loss: 0.4742 - class_loss: 0.0107 - valid_acc: 0.7529 - class_acc: 1.0000\n","average v_acc: 62.941, three class acc: 49.412, two class acc: 52.941\n","====================================================================================================\n","STEP:474, D{v_l: 0.558, v_acc: [74.4| 75.0| 74.7], c_acc: [96.6| 100.0]}  G{v_l: 1.339, v_acc: 32.8, c_acc: 95.3}\n","STEP:475, D{v_l: 0.573, v_acc: [68.8| 59.4| 64.1], c_acc: [96.9| 90.6]}  G{v_l: 1.212, v_acc: 45.3, c_acc: 95.3}\n","STEP:476, D{v_l: 0.716, v_acc: [46.9| 65.6| 56.2], c_acc: [84.4| 100.0]}  G{v_l: 1.052, v_acc: 45.3, c_acc: 92.2}\n","STEP:477, D{v_l: 0.670, v_acc: [56.2| 75.0| 65.6], c_acc: [84.4| 100.0]}  G{v_l: 1.241, v_acc: 42.2, c_acc: 89.1}\n","STEP:478, D{v_l: 0.645, v_acc: [68.8| 78.1| 73.4], c_acc: [75.0| 90.6]}  G{v_l: 1.492, v_acc: 40.6, c_acc: 82.8}\n","STEP:479, D{v_l: 0.737, v_acc: [62.5| 68.8| 65.6], c_acc: [93.8| 93.8]}  G{v_l: 1.159, v_acc: 43.8, c_acc: 92.2}\n","STEP:480, D{v_l: 0.525, v_acc: [65.6| 78.1| 71.9], c_acc: [84.4| 100.0]}  G{v_l: 1.184, v_acc: 45.3, c_acc: 87.5}\n","STEP:481, D{v_l: 0.615, v_acc: [56.2| 71.9| 64.1], c_acc: [75.0| 87.5]}  G{v_l: 1.084, v_acc: 46.9, c_acc: 93.8}\n","STEP:482, D{v_l: 0.591, v_acc: [59.4| 84.4| 71.9], c_acc: [84.4| 96.9]}  G{v_l: 1.191, v_acc: 45.3, c_acc: 98.4}\n","STEP:483, D{v_l: 0.591, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 84.4]}  G{v_l: 1.063, v_acc: 39.1, c_acc: 92.2}\n","STEP:484, D{v_l: 0.727, v_acc: [59.4| 65.6| 62.5], c_acc: [78.1| 93.8]}  G{v_l: 1.063, v_acc: 43.8, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.7340 - valid_loss: 0.6371 - class_loss: 1.6908 - valid_acc: 0.6235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1900 - valid_loss: 0.5245 - class_loss: 0.2594 - valid_acc: 0.7529 - class_acc: 0.9294\n","average v_acc: 68.824, three class acc: 51.765, two class acc: 67.059\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0484.h5\n","STEP:485, D{v_l: 0.538, v_acc: [73.5| 81.2| 77.4], c_acc: [88.9| 84.4]}  G{v_l: 1.115, v_acc: 43.8, c_acc: 85.9}\n","STEP:486, D{v_l: 0.692, v_acc: [68.8| 59.4| 64.1], c_acc: [87.5| 93.8]}  G{v_l: 0.693, v_acc: 59.4, c_acc: 89.1}\n","STEP:487, D{v_l: 0.634, v_acc: [78.1| 78.1| 78.1], c_acc: [71.9| 100.0]}  G{v_l: 1.374, v_acc: 45.3, c_acc: 98.4}\n","STEP:488, D{v_l: 0.567, v_acc: [62.5| 78.1| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.340, v_acc: 54.7, c_acc: 96.9}\n","STEP:489, D{v_l: 0.678, v_acc: [65.6| 68.8| 67.2], c_acc: [84.4| 93.8]}  G{v_l: 1.265, v_acc: 57.8, c_acc: 90.6}\n","STEP:490, D{v_l: 0.634, v_acc: [71.9| 65.6| 68.8], c_acc: [81.2| 96.9]}  G{v_l: 0.962, v_acc: 53.1, c_acc: 95.3}\n","STEP:491, D{v_l: 0.703, v_acc: [81.2| 75.0| 78.1], c_acc: [75.0| 96.9]}  G{v_l: 1.079, v_acc: 43.8, c_acc: 96.9}\n","STEP:492, D{v_l: 0.422, v_acc: [75.0| 81.2| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 1.152, v_acc: 45.3, c_acc: 96.9}\n","STEP:493, D{v_l: 0.644, v_acc: [71.9| 81.2| 76.6], c_acc: [68.8| 96.9]}  G{v_l: 1.390, v_acc: 37.5, c_acc: 95.3}\n","STEP:494, D{v_l: 0.691, v_acc: [62.5| 59.4| 60.9], c_acc: [81.2| 87.5]}  G{v_l: 1.234, v_acc: 45.3, c_acc: 93.8}\n","STEP:495, D{v_l: 0.741, v_acc: [68.8| 56.2| 62.5], c_acc: [84.4| 93.8]}  G{v_l: 0.918, v_acc: 60.9, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.1677 - valid_loss: 0.7207 - class_loss: 2.0410 - valid_acc: 0.5412 - class_acc: 0.5176\n","3/3 [==============================] - 0s 44ms/step - loss: 1.2256 - valid_loss: 0.6210 - class_loss: 0.1985 - valid_acc: 0.5294 - class_acc: 0.9412\n","average v_acc: 53.529, three class acc: 51.765, two class acc: 62.353\n","====================================================================================================\n","STEP:496, D{v_l: 0.632, v_acc: [58.1| 65.6| 61.9], c_acc: [93.2| 96.9]}  G{v_l: 1.135, v_acc: 46.9, c_acc: 90.6}\n","STEP:497, D{v_l: 0.839, v_acc: [59.4| 71.9| 65.6], c_acc: [93.8| 96.9]}  G{v_l: 1.006, v_acc: 51.6, c_acc: 85.9}\n","STEP:498, D{v_l: 0.554, v_acc: [75.0| 71.9| 73.4], c_acc: [90.6| 90.6]}  G{v_l: 1.399, v_acc: 39.1, c_acc: 90.6}\n","STEP:499, D{v_l: 0.697, v_acc: [56.2| 75.0| 65.6], c_acc: [93.8| 96.9]}  G{v_l: 1.182, v_acc: 39.1, c_acc: 87.5}\n","STEP:500, D{v_l: 0.755, v_acc: [71.9| 62.5| 67.2], c_acc: [81.2| 100.0]}  G{v_l: 1.356, v_acc: 42.2, c_acc: 95.3}\n","STEP:501, D{v_l: 0.858, v_acc: [65.6| 68.8| 67.2], c_acc: [84.4| 100.0]}  G{v_l: 1.404, v_acc: 37.5, c_acc: 92.2}\n","STEP:502, D{v_l: 0.420, v_acc: [78.1| 71.9| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.152, v_acc: 48.4, c_acc: 95.3}\n","STEP:503, D{v_l: 0.690, v_acc: [65.6| 65.6| 65.6], c_acc: [71.9| 93.8]}  G{v_l: 1.354, v_acc: 40.6, c_acc: 92.2}\n","STEP:504, D{v_l: 0.785, v_acc: [56.2| 71.9| 64.1], c_acc: [90.6| 100.0]}  G{v_l: 1.425, v_acc: 48.4, c_acc: 96.9}\n","STEP:505, D{v_l: 0.618, v_acc: [62.5| 68.8| 65.6], c_acc: [87.5| 81.2]}  G{v_l: 1.129, v_acc: 54.7, c_acc: 93.8}\n","STEP:506, D{v_l: 0.769, v_acc: [59.4| 62.5| 60.9], c_acc: [84.4| 100.0]}  G{v_l: 1.145, v_acc: 54.7, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 5.4945 - valid_loss: 0.9109 - class_loss: 4.1775 - valid_acc: 0.2941 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1035 - valid_loss: 0.6080 - class_loss: 0.0894 - valid_acc: 0.4588 - class_acc: 0.9882\n","average v_acc: 37.647, three class acc: 51.765, two class acc: 52.941\n","====================================================================================================\n","STEP:507, D{v_l: 0.635, v_acc: [53.0| 65.6| 59.3], c_acc: [94.9| 100.0]}  G{v_l: 1.018, v_acc: 53.1, c_acc: 85.9}\n","STEP:508, D{v_l: 0.645, v_acc: [59.4| 78.1| 68.8], c_acc: [90.6| 100.0]}  G{v_l: 0.997, v_acc: 57.8, c_acc: 98.4}\n","STEP:509, D{v_l: 0.580, v_acc: [78.1| 71.9| 75.0], c_acc: [87.5| 93.8]}  G{v_l: 1.123, v_acc: 50.0, c_acc: 98.4}\n","STEP:510, D{v_l: 0.555, v_acc: [62.5| 84.4| 73.4], c_acc: [93.8| 100.0]}  G{v_l: 1.183, v_acc: 42.2, c_acc: 90.6}\n","STEP:511, D{v_l: 0.649, v_acc: [71.9| 62.5| 67.2], c_acc: [81.2| 100.0]}  G{v_l: 1.205, v_acc: 56.2, c_acc: 92.2}\n","STEP:512, D{v_l: 0.624, v_acc: [71.9| 75.0| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 1.100, v_acc: 48.4, c_acc: 93.8}\n","STEP:513, D{v_l: 0.658, v_acc: [62.5| 71.9| 67.2], c_acc: [78.1| 100.0]}  G{v_l: 0.976, v_acc: 50.0, c_acc: 96.9}\n","STEP:514, D{v_l: 0.766, v_acc: [50.0| 75.0| 62.5], c_acc: [87.5| 93.8]}  G{v_l: 1.101, v_acc: 45.3, c_acc: 95.3}\n","STEP:515, D{v_l: 0.742, v_acc: [65.6| 75.0| 70.3], c_acc: [93.8| 100.0]}  G{v_l: 1.051, v_acc: 59.4, c_acc: 95.3}\n","STEP:516, D{v_l: 0.882, v_acc: [53.1| 62.5| 57.8], c_acc: [93.8| 100.0]}  G{v_l: 0.976, v_acc: 46.9, c_acc: 98.4}\n","STEP:517, D{v_l: 0.671, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.991, v_acc: 50.0, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 5.2412 - valid_loss: 0.7898 - class_loss: 4.0454 - valid_acc: 0.3647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0046 - valid_loss: 0.5679 - class_loss: 0.0306 - valid_acc: 0.5294 - class_acc: 0.9882\n","average v_acc: 44.706, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:518, D{v_l: 0.660, v_acc: [54.7| 68.8| 61.7], c_acc: [95.7| 87.5]}  G{v_l: 1.278, v_acc: 54.7, c_acc: 96.9}\n","STEP:519, D{v_l: 0.602, v_acc: [56.2| 78.1| 67.2], c_acc: [93.8| 96.9]}  G{v_l: 0.984, v_acc: 56.2, c_acc: 90.6}\n","STEP:520, D{v_l: 0.758, v_acc: [78.1| 62.5| 70.3], c_acc: [78.1| 93.8]}  G{v_l: 0.967, v_acc: 54.7, c_acc: 93.8}\n","STEP:521, D{v_l: 0.758, v_acc: [71.9| 62.5| 67.2], c_acc: [93.8| 100.0]}  G{v_l: 1.075, v_acc: 59.4, c_acc: 92.2}\n","STEP:522, D{v_l: 0.570, v_acc: [68.8| 62.5| 65.6], c_acc: [96.9| 96.9]}  G{v_l: 0.898, v_acc: 51.6, c_acc: 85.9}\n","STEP:523, D{v_l: 0.516, v_acc: [68.8| 75.0| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.158, v_acc: 54.7, c_acc: 90.6}\n","STEP:524, D{v_l: 0.772, v_acc: [53.1| 65.6| 59.4], c_acc: [68.8| 93.8]}  G{v_l: 0.892, v_acc: 53.1, c_acc: 95.3}\n","STEP:525, D{v_l: 0.596, v_acc: [71.9| 71.9| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 1.255, v_acc: 46.9, c_acc: 98.4}\n","STEP:526, D{v_l: 0.973, v_acc: [65.6| 50.0| 57.8], c_acc: [78.1| 93.8]}  G{v_l: 1.096, v_acc: 50.0, c_acc: 100.0}\n","STEP:527, D{v_l: 0.659, v_acc: [62.5| 71.9| 67.2], c_acc: [90.6| 87.5]}  G{v_l: 1.206, v_acc: 46.9, c_acc: 96.9}\n","STEP:528, D{v_l: 0.605, v_acc: [84.4| 62.5| 73.4], c_acc: [96.9| 93.8]}  G{v_l: 1.136, v_acc: 45.3, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 52ms/step - loss: 4.4383 - valid_loss: 0.8153 - class_loss: 3.2171 - valid_acc: 0.3412 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0434 - valid_loss: 0.5031 - class_loss: 0.1344 - valid_acc: 0.7647 - class_acc: 0.9412\n","average v_acc: 55.294, three class acc: 51.765, two class acc: 52.941\n","====================================================================================================\n","STEP:529, D{v_l: 0.647, v_acc: [76.1| 65.6| 70.8], c_acc: [89.7| 90.6]}  G{v_l: 1.073, v_acc: 50.0, c_acc: 98.4}\n","STEP:530, D{v_l: 0.497, v_acc: [71.9| 78.1| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 1.064, v_acc: 53.1, c_acc: 85.9}\n","STEP:531, D{v_l: 0.532, v_acc: [71.9| 84.4| 78.1], c_acc: [78.1| 100.0]}  G{v_l: 1.335, v_acc: 56.2, c_acc: 89.1}\n","STEP:532, D{v_l: 0.518, v_acc: [68.8| 84.4| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.012, v_acc: 59.4, c_acc: 82.8}\n","STEP:533, D{v_l: 0.731, v_acc: [71.9| 53.1| 62.5], c_acc: [96.9| 93.8]}  G{v_l: 0.894, v_acc: 59.4, c_acc: 95.3}\n","STEP:534, D{v_l: 0.501, v_acc: [71.9| 78.1| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 1.215, v_acc: 43.8, c_acc: 96.9}\n","STEP:535, D{v_l: 0.697, v_acc: [62.5| 71.9| 67.2], c_acc: [90.6| 93.8]}  G{v_l: 0.985, v_acc: 56.2, c_acc: 90.6}\n","STEP:536, D{v_l: 0.792, v_acc: [50.0| 65.6| 57.8], c_acc: [96.9| 100.0]}  G{v_l: 1.141, v_acc: 50.0, c_acc: 85.9}\n","STEP:537, D{v_l: 0.849, v_acc: [46.9| 68.8| 57.8], c_acc: [78.1| 96.9]}  G{v_l: 0.934, v_acc: 53.1, c_acc: 82.8}\n","STEP:538, D{v_l: 0.641, v_acc: [65.6| 65.6| 65.6], c_acc: [87.5| 96.9]}  G{v_l: 1.067, v_acc: 51.6, c_acc: 90.6}\n","STEP:539, D{v_l: 0.491, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 100.0]}  G{v_l: 1.099, v_acc: 48.4, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 2.7217 - valid_loss: 0.6335 - class_loss: 1.6823 - valid_acc: 0.7059 - class_acc: 0.5059\n","3/3 [==============================] - 0s 51ms/step - loss: 1.1082 - valid_loss: 0.5594 - class_loss: 0.1428 - valid_acc: 0.7294 - class_acc: 0.9294\n","average v_acc: 71.765, three class acc: 50.588, two class acc: 63.529\n","====================================================================================================\n","STEP:540, D{v_l: 0.560, v_acc: [69.2| 75.0| 72.1], c_acc: [90.6| 100.0]}  G{v_l: 1.160, v_acc: 48.4, c_acc: 89.1}\n","STEP:541, D{v_l: 0.494, v_acc: [71.9| 75.0| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 0.889, v_acc: 59.4, c_acc: 93.8}\n","STEP:542, D{v_l: 0.487, v_acc: [75.0| 81.2| 78.1], c_acc: [84.4| 100.0]}  G{v_l: 1.094, v_acc: 43.8, c_acc: 96.9}\n","STEP:543, D{v_l: 0.770, v_acc: [65.6| 65.6| 65.6], c_acc: [84.4| 90.6]}  G{v_l: 1.099, v_acc: 50.0, c_acc: 98.4}\n","STEP:544, D{v_l: 0.724, v_acc: [53.1| 71.9| 62.5], c_acc: [81.2| 93.8]}  G{v_l: 1.136, v_acc: 51.6, c_acc: 98.4}\n","STEP:545, D{v_l: 0.453, v_acc: [84.4| 84.4| 84.4], c_acc: [81.2| 96.9]}  G{v_l: 1.181, v_acc: 50.0, c_acc: 100.0}\n","STEP:546, D{v_l: 0.559, v_acc: [65.6| 75.0| 70.3], c_acc: [84.4| 96.9]}  G{v_l: 0.846, v_acc: 56.2, c_acc: 95.3}\n","STEP:547, D{v_l: 0.689, v_acc: [56.2| 75.0| 65.6], c_acc: [84.4| 96.9]}  G{v_l: 1.229, v_acc: 50.0, c_acc: 96.9}\n","STEP:548, D{v_l: 0.603, v_acc: [65.6| 65.6| 65.6], c_acc: [75.0| 81.2]}  G{v_l: 1.030, v_acc: 65.6, c_acc: 96.9}\n","STEP:549, D{v_l: 0.645, v_acc: [71.9| 68.8| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 1.079, v_acc: 57.8, c_acc: 96.9}\n","STEP:550, D{v_l: 0.692, v_acc: [65.6| 78.1| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.185, v_acc: 48.4, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.9010 - valid_loss: 0.7394 - class_loss: 2.7557 - valid_acc: 0.5059 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 0.9718 - valid_loss: 0.5406 - class_loss: 0.0253 - valid_acc: 0.6471 - class_acc: 1.0000\n","average v_acc: 57.647, three class acc: 51.765, two class acc: 55.294\n","====================================================================================================\n","Epoch: 50\n","====================================================================================================\n","STEP:551, D{v_l: 0.483, v_acc: [65.8| 81.2| 73.5], c_acc: [98.3| 100.0]}  G{v_l: 1.342, v_acc: 42.2, c_acc: 98.4}\n","STEP:552, D{v_l: 0.691, v_acc: [68.8| 56.2| 62.5], c_acc: [87.5| 96.9]}  G{v_l: 1.152, v_acc: 50.0, c_acc: 98.4}\n","STEP:553, D{v_l: 0.633, v_acc: [71.9| 75.0| 73.4], c_acc: [84.4| 96.9]}  G{v_l: 1.054, v_acc: 57.8, c_acc: 95.3}\n","STEP:554, D{v_l: 0.583, v_acc: [81.2| 68.8| 75.0], c_acc: [96.9| 96.9]}  G{v_l: 1.046, v_acc: 51.6, c_acc: 98.4}\n","STEP:555, D{v_l: 0.633, v_acc: [75.0| 71.9| 73.4], c_acc: [90.6| 93.8]}  G{v_l: 1.215, v_acc: 45.3, c_acc: 87.5}\n","STEP:556, D{v_l: 0.574, v_acc: [65.6| 75.0| 70.3], c_acc: [93.8| 100.0]}  G{v_l: 1.031, v_acc: 51.6, c_acc: 92.2}\n","STEP:557, D{v_l: 0.557, v_acc: [84.4| 71.9| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 1.070, v_acc: 45.3, c_acc: 92.2}\n","STEP:558, D{v_l: 0.418, v_acc: [90.6| 78.1| 84.4], c_acc: [81.2| 100.0]}  G{v_l: 0.839, v_acc: 59.4, c_acc: 93.8}\n","STEP:559, D{v_l: 0.708, v_acc: [59.4| 84.4| 71.9], c_acc: [78.1| 96.9]}  G{v_l: 1.077, v_acc: 48.4, c_acc: 96.9}\n","STEP:560, D{v_l: 0.442, v_acc: [68.8| 81.2| 75.0], c_acc: [84.4| 100.0]}  G{v_l: 0.926, v_acc: 56.2, c_acc: 95.3}\n","STEP:561, D{v_l: 0.629, v_acc: [65.6| 75.0| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 0.954, v_acc: 54.7, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7580 - valid_loss: 0.5602 - class_loss: 1.7920 - valid_acc: 0.7765 - class_acc: 0.5059\n","3/3 [==============================] - 0s 43ms/step - loss: 0.9379 - valid_loss: 0.5163 - class_loss: 0.0158 - valid_acc: 0.7176 - class_acc: 1.0000\n","average v_acc: 74.706, three class acc: 50.588, two class acc: 61.176\n","====================================================================================================\n","STEP:562, D{v_l: 0.547, v_acc: [66.7| 84.4| 75.5], c_acc: [95.7| 100.0]}  G{v_l: 1.309, v_acc: 37.5, c_acc: 98.4}\n","STEP:563, D{v_l: 0.652, v_acc: [65.6| 71.9| 68.8], c_acc: [84.4| 90.6]}  G{v_l: 0.954, v_acc: 53.1, c_acc: 93.8}\n","STEP:564, D{v_l: 0.534, v_acc: [71.9| 68.8| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.170, v_acc: 50.0, c_acc: 96.9}\n","STEP:565, D{v_l: 0.516, v_acc: [68.8| 84.4| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 0.898, v_acc: 51.6, c_acc: 92.2}\n","STEP:566, D{v_l: 0.591, v_acc: [62.5| 71.9| 67.2], c_acc: [90.6| 90.6]}  G{v_l: 1.107, v_acc: 43.8, c_acc: 96.9}\n","STEP:567, D{v_l: 0.584, v_acc: [59.4| 90.6| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.029, v_acc: 57.8, c_acc: 98.4}\n","STEP:568, D{v_l: 0.602, v_acc: [62.5| 75.0| 68.8], c_acc: [90.6| 93.8]}  G{v_l: 1.063, v_acc: 45.3, c_acc: 96.9}\n","STEP:569, D{v_l: 0.683, v_acc: [62.5| 65.6| 64.1], c_acc: [84.4| 100.0]}  G{v_l: 0.840, v_acc: 57.8, c_acc: 96.9}\n","STEP:570, D{v_l: 0.477, v_acc: [81.2| 68.8| 75.0], c_acc: [87.5| 93.8]}  G{v_l: 0.899, v_acc: 51.6, c_acc: 78.1}\n","STEP:571, D{v_l: 0.675, v_acc: [65.6| 53.1| 59.4], c_acc: [90.6| 93.8]}  G{v_l: 0.992, v_acc: 48.4, c_acc: 81.2}\n","STEP:572, D{v_l: 0.665, v_acc: [75.0| 62.5| 68.8], c_acc: [90.6| 100.0]}  G{v_l: 0.955, v_acc: 53.1, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.8999 - valid_loss: 0.3892 - class_loss: 2.1049 - valid_acc: 0.9765 - class_acc: 0.4941\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1436 - valid_loss: 0.5701 - class_loss: 0.1677 - valid_acc: 0.7059 - class_acc: 0.9529\n","average v_acc: 84.118, three class acc: 49.412, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0572.h5\n","STEP:573, D{v_l: 0.594, v_acc: [67.5| 71.9| 69.7], c_acc: [94.0| 96.9]}  G{v_l: 1.192, v_acc: 34.4, c_acc: 87.5}\n","STEP:574, D{v_l: 0.610, v_acc: [87.5| 62.5| 75.0], c_acc: [65.6| 100.0]}  G{v_l: 1.084, v_acc: 53.1, c_acc: 93.8}\n","STEP:575, D{v_l: 0.515, v_acc: [71.9| 78.1| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 0.993, v_acc: 50.0, c_acc: 96.9}\n","STEP:576, D{v_l: 0.698, v_acc: [75.0| 59.4| 67.2], c_acc: [81.2| 96.9]}  G{v_l: 1.070, v_acc: 50.0, c_acc: 98.4}\n","STEP:577, D{v_l: 0.638, v_acc: [65.6| 75.0| 70.3], c_acc: [90.6| 96.9]}  G{v_l: 1.004, v_acc: 50.0, c_acc: 96.9}\n","STEP:578, D{v_l: 0.688, v_acc: [75.0| 81.2| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 1.083, v_acc: 48.4, c_acc: 93.8}\n","STEP:579, D{v_l: 0.789, v_acc: [68.8| 65.6| 67.2], c_acc: [87.5| 100.0]}  G{v_l: 1.114, v_acc: 40.6, c_acc: 93.8}\n","STEP:580, D{v_l: 0.593, v_acc: [71.9| 84.4| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 1.162, v_acc: 40.6, c_acc: 96.9}\n","STEP:581, D{v_l: 0.435, v_acc: [78.1| 81.2| 79.7], c_acc: [71.9| 96.9]}  G{v_l: 0.953, v_acc: 53.1, c_acc: 95.3}\n","STEP:582, D{v_l: 0.624, v_acc: [68.8| 68.8| 68.8], c_acc: [96.9| 96.9]}  G{v_l: 1.244, v_acc: 39.1, c_acc: 96.9}\n","STEP:583, D{v_l: 0.428, v_acc: [71.9| 87.5| 79.7], c_acc: [81.2| 96.9]}  G{v_l: 1.043, v_acc: 54.7, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.7389 - valid_loss: 0.5395 - class_loss: 1.7936 - valid_acc: 0.7529 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9837 - valid_loss: 0.5575 - class_loss: 0.0205 - valid_acc: 0.5765 - class_acc: 1.0000\n","average v_acc: 66.471, three class acc: 51.765, two class acc: 63.529\n","====================================================================================================\n","STEP:584, D{v_l: 0.618, v_acc: [63.2| 62.5| 62.9], c_acc: [95.7| 93.8]}  G{v_l: 1.004, v_acc: 50.0, c_acc: 96.9}\n","STEP:585, D{v_l: 0.610, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 93.8]}  G{v_l: 0.995, v_acc: 60.9, c_acc: 93.8}\n","STEP:586, D{v_l: 0.484, v_acc: [75.0| 78.1| 76.6], c_acc: [81.2| 96.9]}  G{v_l: 0.851, v_acc: 57.8, c_acc: 93.8}\n","STEP:587, D{v_l: 0.601, v_acc: [59.4| 68.8| 64.1], c_acc: [93.8| 96.9]}  G{v_l: 0.889, v_acc: 54.7, c_acc: 100.0}\n","STEP:588, D{v_l: 0.606, v_acc: [78.1| 59.4| 68.8], c_acc: [84.4| 96.9]}  G{v_l: 1.032, v_acc: 45.3, c_acc: 100.0}\n","STEP:589, D{v_l: 0.477, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 0.988, v_acc: 51.6, c_acc: 95.3}\n","STEP:590, D{v_l: 0.659, v_acc: [53.1| 75.0| 64.1], c_acc: [84.4| 96.9]}  G{v_l: 1.015, v_acc: 50.0, c_acc: 96.9}\n","STEP:591, D{v_l: 0.523, v_acc: [84.4| 75.0| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 1.010, v_acc: 59.4, c_acc: 93.8}\n","STEP:592, D{v_l: 0.466, v_acc: [84.4| 78.1| 81.2], c_acc: [84.4| 100.0]}  G{v_l: 1.371, v_acc: 39.1, c_acc: 92.2}\n","STEP:593, D{v_l: 0.489, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 93.8]}  G{v_l: 1.205, v_acc: 53.1, c_acc: 93.8}\n","STEP:594, D{v_l: 0.526, v_acc: [68.8| 71.9| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 0.988, v_acc: 65.6, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.6577 - valid_loss: 0.5491 - class_loss: 1.7030 - valid_acc: 0.8235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1057 - valid_loss: 0.6498 - class_loss: 0.0502 - valid_acc: 0.4941 - class_acc: 0.9765\n","average v_acc: 65.882, three class acc: 51.765, two class acc: 62.353\n","====================================================================================================\n","STEP:595, D{v_l: 0.649, v_acc: [59.0| 81.2| 70.1], c_acc: [98.3| 96.9]}  G{v_l: 0.918, v_acc: 57.8, c_acc: 93.8}\n","STEP:596, D{v_l: 0.698, v_acc: [68.8| 84.4| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.113, v_acc: 48.4, c_acc: 96.9}\n","STEP:597, D{v_l: 0.703, v_acc: [59.4| 65.6| 62.5], c_acc: [81.2| 96.9]}  G{v_l: 0.737, v_acc: 60.9, c_acc: 98.4}\n","STEP:598, D{v_l: 0.611, v_acc: [62.5| 78.1| 70.3], c_acc: [81.2| 93.8]}  G{v_l: 0.873, v_acc: 48.4, c_acc: 96.9}\n","STEP:599, D{v_l: 0.632, v_acc: [71.9| 71.9| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.253, v_acc: 48.4, c_acc: 98.4}\n","STEP:600, D{v_l: 0.636, v_acc: [75.0| 90.6| 82.8], c_acc: [84.4| 100.0]}  G{v_l: 0.991, v_acc: 54.7, c_acc: 93.8}\n","STEP:601, D{v_l: 0.420, v_acc: [81.2| 84.4| 82.8], c_acc: [81.2| 100.0]}  G{v_l: 1.186, v_acc: 42.2, c_acc: 87.5}\n","STEP:602, D{v_l: 0.621, v_acc: [78.1| 65.6| 71.9], c_acc: [84.4| 96.9]}  G{v_l: 1.002, v_acc: 57.8, c_acc: 90.6}\n","STEP:603, D{v_l: 0.494, v_acc: [81.2| 75.0| 78.1], c_acc: [84.4| 90.6]}  G{v_l: 1.128, v_acc: 48.4, c_acc: 90.6}\n","STEP:604, D{v_l: 0.666, v_acc: [62.5| 78.1| 70.3], c_acc: [87.5| 90.6]}  G{v_l: 1.159, v_acc: 48.4, c_acc: 89.1}\n","STEP:605, D{v_l: 0.803, v_acc: [62.5| 71.9| 67.2], c_acc: [81.2| 100.0]}  G{v_l: 1.071, v_acc: 43.8, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.9298 - valid_loss: 0.5720 - class_loss: 1.9522 - valid_acc: 0.7294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 1.1008 - valid_loss: 0.6321 - class_loss: 0.0631 - valid_acc: 0.5176 - class_acc: 0.9882\n","average v_acc: 62.353, three class acc: 52.941, two class acc: 62.353\n","====================================================================================================\n","STEP:606, D{v_l: 0.674, v_acc: [60.7| 71.9| 66.3], c_acc: [97.4| 100.0]}  G{v_l: 1.021, v_acc: 46.9, c_acc: 98.4}\n","STEP:607, D{v_l: 0.492, v_acc: [62.5| 87.5| 75.0], c_acc: [87.5| 100.0]}  G{v_l: 0.919, v_acc: 43.8, c_acc: 95.3}\n","STEP:608, D{v_l: 0.472, v_acc: [75.0| 78.1| 76.6], c_acc: [81.2| 93.8]}  G{v_l: 0.973, v_acc: 56.2, c_acc: 92.2}\n","STEP:609, D{v_l: 0.567, v_acc: [81.2| 78.1| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.095, v_acc: 56.2, c_acc: 95.3}\n","STEP:610, D{v_l: 0.709, v_acc: [65.6| 65.6| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.072, v_acc: 53.1, c_acc: 81.2}\n","STEP:611, D{v_l: 0.779, v_acc: [59.4| 71.9| 65.6], c_acc: [93.8| 96.9]}  G{v_l: 1.047, v_acc: 53.1, c_acc: 95.3}\n","STEP:612, D{v_l: 0.497, v_acc: [68.8| 78.1| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 0.995, v_acc: 42.2, c_acc: 96.9}\n","STEP:613, D{v_l: 0.521, v_acc: [71.9| 78.1| 75.0], c_acc: [84.4| 96.9]}  G{v_l: 0.886, v_acc: 59.4, c_acc: 96.9}\n","STEP:614, D{v_l: 0.549, v_acc: [65.6| 62.5| 64.1], c_acc: [93.8| 100.0]}  G{v_l: 1.032, v_acc: 46.9, c_acc: 93.8}\n","STEP:615, D{v_l: 0.473, v_acc: [68.8| 84.4| 76.6], c_acc: [96.9| 100.0]}  G{v_l: 1.078, v_acc: 46.9, c_acc: 92.2}\n","STEP:616, D{v_l: 0.508, v_acc: [75.0| 78.1| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.049, v_acc: 45.3, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.5546 - valid_loss: 0.5304 - class_loss: 1.6187 - valid_acc: 0.8824 - class_acc: 0.5059\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0147 - valid_loss: 0.5842 - class_loss: 0.0250 - valid_acc: 0.6235 - class_acc: 0.9882\n","average v_acc: 75.294, three class acc: 50.588, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0616.h5\n","STEP:617, D{v_l: 0.645, v_acc: [61.5| 65.6| 63.6], c_acc: [95.7| 90.6]}  G{v_l: 0.868, v_acc: 59.4, c_acc: 96.9}\n","STEP:618, D{v_l: 0.613, v_acc: [62.5| 68.8| 65.6], c_acc: [84.4| 100.0]}  G{v_l: 0.723, v_acc: 70.3, c_acc: 95.3}\n","STEP:619, D{v_l: 0.640, v_acc: [65.6| 65.6| 65.6], c_acc: [87.5| 96.9]}  G{v_l: 1.004, v_acc: 50.0, c_acc: 95.3}\n","STEP:620, D{v_l: 0.568, v_acc: [81.2| 62.5| 71.9], c_acc: [90.6| 93.8]}  G{v_l: 0.870, v_acc: 60.9, c_acc: 96.9}\n","STEP:621, D{v_l: 0.575, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 1.034, v_acc: 54.7, c_acc: 96.9}\n","STEP:622, D{v_l: 0.619, v_acc: [81.2| 65.6| 73.4], c_acc: [90.6| 90.6]}  G{v_l: 1.002, v_acc: 45.3, c_acc: 98.4}\n","STEP:623, D{v_l: 0.530, v_acc: [65.6| 75.0| 70.3], c_acc: [90.6| 93.8]}  G{v_l: 1.097, v_acc: 54.7, c_acc: 98.4}\n","STEP:624, D{v_l: 0.598, v_acc: [65.6| 81.2| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.099, v_acc: 51.6, c_acc: 96.9}\n","STEP:625, D{v_l: 0.694, v_acc: [71.9| 62.5| 67.2], c_acc: [87.5| 100.0]}  G{v_l: 1.000, v_acc: 51.6, c_acc: 95.3}\n","STEP:626, D{v_l: 0.483, v_acc: [71.9| 81.2| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.850, v_acc: 53.1, c_acc: 96.9}\n","STEP:627, D{v_l: 0.444, v_acc: [84.4| 84.4| 84.4], c_acc: [87.5| 93.8]}  G{v_l: 0.940, v_acc: 51.6, c_acc: 79.7}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.7673 - valid_loss: 0.5237 - class_loss: 1.8381 - valid_acc: 0.8118 - class_acc: 0.5176\n","3/3 [==============================] - 0s 43ms/step - loss: 1.1410 - valid_loss: 0.6284 - class_loss: 0.1071 - valid_acc: 0.6471 - class_acc: 0.9294\n","average v_acc: 72.941, three class acc: 51.765, two class acc: 64.706\n","====================================================================================================\n","STEP:628, D{v_l: 0.526, v_acc: [65.8| 75.0| 70.4], c_acc: [92.3| 90.6]}  G{v_l: 1.135, v_acc: 35.9, c_acc: 92.2}\n","STEP:629, D{v_l: 0.693, v_acc: [62.5| 65.6| 64.1], c_acc: [81.2| 90.6]}  G{v_l: 0.885, v_acc: 50.0, c_acc: 92.2}\n","STEP:630, D{v_l: 0.597, v_acc: [71.9| 71.9| 71.9], c_acc: [90.6| 93.8]}  G{v_l: 1.002, v_acc: 56.2, c_acc: 89.1}\n","STEP:631, D{v_l: 0.649, v_acc: [75.0| 75.0| 75.0], c_acc: [78.1| 96.9]}  G{v_l: 1.037, v_acc: 50.0, c_acc: 85.9}\n","STEP:632, D{v_l: 0.708, v_acc: [53.1| 68.8| 60.9], c_acc: [90.6| 100.0]}  G{v_l: 1.048, v_acc: 48.4, c_acc: 87.5}\n","STEP:633, D{v_l: 0.448, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 1.262, v_acc: 53.1, c_acc: 95.3}\n","STEP:634, D{v_l: 0.466, v_acc: [87.5| 75.0| 81.2], c_acc: [81.2| 100.0]}  G{v_l: 0.923, v_acc: 68.8, c_acc: 90.6}\n","STEP:635, D{v_l: 0.587, v_acc: [62.5| 71.9| 67.2], c_acc: [93.8| 100.0]}  G{v_l: 0.976, v_acc: 56.2, c_acc: 95.3}\n","STEP:636, D{v_l: 0.687, v_acc: [71.9| 59.4| 65.6], c_acc: [84.4| 100.0]}  G{v_l: 0.809, v_acc: 56.2, c_acc: 92.2}\n","STEP:637, D{v_l: 0.596, v_acc: [59.4| 78.1| 68.8], c_acc: [93.8| 100.0]}  G{v_l: 1.210, v_acc: 39.1, c_acc: 95.3}\n","STEP:638, D{v_l: 0.484, v_acc: [78.1| 87.5| 82.8], c_acc: [81.2| 93.8]}  G{v_l: 1.068, v_acc: 46.9, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.6825 - valid_loss: 0.5364 - class_loss: 1.7407 - valid_acc: 0.8353 - class_acc: 0.4235\n","3/3 [==============================] - 0s 49ms/step - loss: 1.2272 - valid_loss: 0.5907 - class_loss: 0.2311 - valid_acc: 0.6235 - class_acc: 0.9412\n","average v_acc: 72.941, three class acc: 42.353, two class acc: 61.176\n","====================================================================================================\n","STEP:639, D{v_l: 0.618, v_acc: [65.0| 71.9| 68.4], c_acc: [93.2| 100.0]}  G{v_l: 0.773, v_acc: 59.4, c_acc: 82.8}\n","STEP:640, D{v_l: 0.467, v_acc: [78.1| 84.4| 81.2], c_acc: [75.0| 96.9]}  G{v_l: 1.245, v_acc: 48.4, c_acc: 92.2}\n","STEP:641, D{v_l: 0.688, v_acc: [71.9| 65.6| 68.8], c_acc: [90.6| 100.0]}  G{v_l: 1.176, v_acc: 45.3, c_acc: 71.9}\n","STEP:642, D{v_l: 0.579, v_acc: [71.9| 78.1| 75.0], c_acc: [96.9| 96.9]}  G{v_l: 1.015, v_acc: 46.9, c_acc: 81.2}\n","STEP:643, D{v_l: 0.621, v_acc: [65.6| 71.9| 68.8], c_acc: [81.2| 84.4]}  G{v_l: 1.237, v_acc: 54.7, c_acc: 82.8}\n","STEP:644, D{v_l: 0.467, v_acc: [68.8| 81.2| 75.0], c_acc: [93.8| 96.9]}  G{v_l: 1.379, v_acc: 46.9, c_acc: 79.7}\n","STEP:645, D{v_l: 0.649, v_acc: [65.6| 75.0| 70.3], c_acc: [93.8| 100.0]}  G{v_l: 1.173, v_acc: 54.7, c_acc: 71.9}\n","STEP:646, D{v_l: 0.487, v_acc: [65.6| 84.4| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 1.063, v_acc: 54.7, c_acc: 93.8}\n","STEP:647, D{v_l: 0.641, v_acc: [81.2| 75.0| 78.1], c_acc: [81.2| 93.8]}  G{v_l: 1.133, v_acc: 59.4, c_acc: 96.9}\n","STEP:648, D{v_l: 0.687, v_acc: [75.0| 68.8| 71.9], c_acc: [78.1| 96.9]}  G{v_l: 1.123, v_acc: 45.3, c_acc: 100.0}\n","STEP:649, D{v_l: 0.452, v_acc: [71.9| 84.4| 78.1], c_acc: [90.6| 90.6]}  G{v_l: 1.179, v_acc: 50.0, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.1044 - valid_loss: 0.6747 - class_loss: 2.0244 - valid_acc: 0.5529 - class_acc: 0.5059\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9937 - valid_loss: 0.4903 - class_loss: 0.0980 - valid_acc: 0.6706 - class_acc: 0.9529\n","average v_acc: 61.176, three class acc: 50.588, two class acc: 60.000\n","====================================================================================================\n","STEP:650, D{v_l: 0.547, v_acc: [69.2| 75.0| 72.1], c_acc: [92.3| 96.9]}  G{v_l: 1.011, v_acc: 51.6, c_acc: 90.6}\n","STEP:651, D{v_l: 0.529, v_acc: [81.2| 75.0| 78.1], c_acc: [84.4| 84.4]}  G{v_l: 1.247, v_acc: 48.4, c_acc: 98.4}\n","STEP:652, D{v_l: 0.533, v_acc: [53.1| 90.6| 71.9], c_acc: [93.8| 96.9]}  G{v_l: 1.152, v_acc: 40.6, c_acc: 93.8}\n","STEP:653, D{v_l: 0.565, v_acc: [75.0| 78.1| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 1.245, v_acc: 43.8, c_acc: 95.3}\n","STEP:654, D{v_l: 0.752, v_acc: [65.6| 59.4| 62.5], c_acc: [93.8| 96.9]}  G{v_l: 1.089, v_acc: 51.6, c_acc: 84.4}\n","STEP:655, D{v_l: 0.416, v_acc: [78.1| 81.2| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.980, v_acc: 56.2, c_acc: 87.5}\n","STEP:656, D{v_l: 0.500, v_acc: [87.5| 71.9| 79.7], c_acc: [81.2| 96.9]}  G{v_l: 1.208, v_acc: 48.4, c_acc: 85.9}\n","STEP:657, D{v_l: 0.525, v_acc: [75.0| 75.0| 75.0], c_acc: [84.4| 96.9]}  G{v_l: 1.075, v_acc: 48.4, c_acc: 81.2}\n","STEP:658, D{v_l: 0.553, v_acc: [71.9| 78.1| 75.0], c_acc: [100.0| 100.0]}  G{v_l: 0.999, v_acc: 53.1, c_acc: 92.2}\n","STEP:659, D{v_l: 0.623, v_acc: [81.2| 68.8| 75.0], c_acc: [93.8| 96.9]}  G{v_l: 1.214, v_acc: 53.1, c_acc: 95.3}\n","STEP:660, D{v_l: 0.691, v_acc: [68.8| 68.8| 68.8], c_acc: [93.8| 90.6]}  G{v_l: 1.016, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.7979 - valid_loss: 0.6378 - class_loss: 2.7548 - valid_acc: 0.6118 - class_acc: 0.4941\n","3/3 [==============================] - 0s 42ms/step - loss: 1.0210 - valid_loss: 0.5977 - class_loss: 0.0180 - valid_acc: 0.5176 - class_acc: 1.0000\n","average v_acc: 56.471, three class acc: 49.412, two class acc: 52.941\n","====================================================================================================\n","Epoch: 60\n","====================================================================================================\n","STEP:661, D{v_l: 0.628, v_acc: [60.7| 62.5| 61.6], c_acc: [99.1| 96.9]}  G{v_l: 1.216, v_acc: 59.4, c_acc: 100.0}\n","STEP:662, D{v_l: 0.565, v_acc: [65.6| 84.4| 75.0], c_acc: [96.9| 90.6]}  G{v_l: 1.265, v_acc: 54.7, c_acc: 93.8}\n","STEP:663, D{v_l: 0.578, v_acc: [81.2| 65.6| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 1.315, v_acc: 40.6, c_acc: 93.8}\n","STEP:664, D{v_l: 0.584, v_acc: [62.5| 78.1| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.269, v_acc: 51.6, c_acc: 90.6}\n","STEP:665, D{v_l: 0.495, v_acc: [78.1| 84.4| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 0.946, v_acc: 62.5, c_acc: 95.3}\n","STEP:666, D{v_l: 0.495, v_acc: [87.5| 75.0| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.158, v_acc: 59.4, c_acc: 96.9}\n","STEP:667, D{v_l: 0.477, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.048, v_acc: 43.8, c_acc: 95.3}\n","STEP:668, D{v_l: 0.445, v_acc: [75.0| 84.4| 79.7], c_acc: [84.4| 100.0]}  G{v_l: 0.924, v_acc: 57.8, c_acc: 95.3}\n","STEP:669, D{v_l: 0.556, v_acc: [65.6| 81.2| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 0.992, v_acc: 56.2, c_acc: 95.3}\n","STEP:670, D{v_l: 0.497, v_acc: [78.1| 75.0| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.112, v_acc: 43.8, c_acc: 96.9}\n","STEP:671, D{v_l: 0.529, v_acc: [65.6| 84.4| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 1.164, v_acc: 50.0, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.7838 - valid_loss: 0.5514 - class_loss: 1.8272 - valid_acc: 0.7529 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0152 - valid_loss: 0.5649 - class_loss: 0.0450 - valid_acc: 0.6235 - class_acc: 0.9882\n","average v_acc: 68.824, three class acc: 50.588, two class acc: 70.588\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0671.h5\n","STEP:672, D{v_l: 0.549, v_acc: [65.8| 75.0| 70.4], c_acc: [97.4| 100.0]}  G{v_l: 1.272, v_acc: 50.0, c_acc: 96.9}\n","STEP:673, D{v_l: 0.517, v_acc: [78.1| 75.0| 76.6], c_acc: [96.9| 100.0]}  G{v_l: 1.136, v_acc: 50.0, c_acc: 96.9}\n","STEP:674, D{v_l: 0.575, v_acc: [75.0| 65.6| 70.3], c_acc: [75.0| 100.0]}  G{v_l: 1.079, v_acc: 51.6, c_acc: 89.1}\n","STEP:675, D{v_l: 0.442, v_acc: [75.0| 84.4| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.380, v_acc: 43.8, c_acc: 98.4}\n","STEP:676, D{v_l: 0.404, v_acc: [75.0| 87.5| 81.2], c_acc: [81.2| 96.9]}  G{v_l: 1.028, v_acc: 45.3, c_acc: 96.9}\n","STEP:677, D{v_l: 0.531, v_acc: [78.1| 84.4| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.004, v_acc: 48.4, c_acc: 100.0}\n","STEP:678, D{v_l: 0.456, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 93.8]}  G{v_l: 1.242, v_acc: 50.0, c_acc: 98.4}\n","STEP:679, D{v_l: 0.409, v_acc: [75.0| 75.0| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 1.247, v_acc: 51.6, c_acc: 100.0}\n","STEP:680, D{v_l: 0.549, v_acc: [75.0| 81.2| 78.1], c_acc: [100.0| 100.0]}  G{v_l: 1.434, v_acc: 25.0, c_acc: 98.4}\n","STEP:681, D{v_l: 0.583, v_acc: [62.5| 81.2| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 1.251, v_acc: 42.2, c_acc: 100.0}\n","STEP:682, D{v_l: 0.595, v_acc: [71.9| 59.4| 65.6], c_acc: [93.8| 100.0]}  G{v_l: 1.108, v_acc: 50.0, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.2173 - valid_loss: 0.6385 - class_loss: 2.1736 - valid_acc: 0.6235 - class_acc: 0.4824\n","3/3 [==============================] - 0s 43ms/step - loss: 0.9426 - valid_loss: 0.5256 - class_loss: 0.0118 - valid_acc: 0.6706 - class_acc: 1.0000\n","average v_acc: 64.706, three class acc: 48.235, two class acc: 58.824\n","====================================================================================================\n","STEP:683, D{v_l: 0.469, v_acc: [71.8| 84.4| 78.1], c_acc: [97.4| 100.0]}  G{v_l: 1.252, v_acc: 42.2, c_acc: 95.3}\n","STEP:684, D{v_l: 0.357, v_acc: [87.5| 78.1| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 1.070, v_acc: 46.9, c_acc: 95.3}\n","STEP:685, D{v_l: 0.603, v_acc: [59.4| 87.5| 73.4], c_acc: [96.9| 100.0]}  G{v_l: 0.884, v_acc: 53.1, c_acc: 96.9}\n","STEP:686, D{v_l: 0.460, v_acc: [75.0| 81.2| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 1.226, v_acc: 34.4, c_acc: 93.8}\n","STEP:687, D{v_l: 0.716, v_acc: [71.9| 78.1| 75.0], c_acc: [87.5| 96.9]}  G{v_l: 0.919, v_acc: 51.6, c_acc: 95.3}\n","STEP:688, D{v_l: 0.575, v_acc: [59.4| 87.5| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.147, v_acc: 53.1, c_acc: 96.9}\n","STEP:689, D{v_l: 0.627, v_acc: [62.5| 78.1| 70.3], c_acc: [96.9| 96.9]}  G{v_l: 1.036, v_acc: 56.2, c_acc: 92.2}\n","STEP:690, D{v_l: 0.507, v_acc: [78.1| 65.6| 71.9], c_acc: [84.4| 90.6]}  G{v_l: 0.981, v_acc: 50.0, c_acc: 93.8}\n","STEP:691, D{v_l: 0.398, v_acc: [71.9| 81.2| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 0.862, v_acc: 42.2, c_acc: 95.3}\n","STEP:692, D{v_l: 0.459, v_acc: [78.1| 75.0| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.171, v_acc: 40.6, c_acc: 95.3}\n","STEP:693, D{v_l: 0.419, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 1.097, v_acc: 46.9, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.9085 - valid_loss: 0.5361 - class_loss: 1.9674 - valid_acc: 0.7882 - class_acc: 0.4824\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0193 - valid_loss: 0.5602 - class_loss: 0.0540 - valid_acc: 0.8118 - class_acc: 0.9882\n","average v_acc: 80.000, three class acc: 48.235, two class acc: 60.000\n","====================================================================================================\n","STEP:694, D{v_l: 0.525, v_acc: [80.3| 81.2| 80.8], c_acc: [99.1| 96.9]}  G{v_l: 1.057, v_acc: 42.2, c_acc: 89.1}\n","STEP:695, D{v_l: 0.557, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 0.860, v_acc: 51.6, c_acc: 93.8}\n","STEP:696, D{v_l: 0.463, v_acc: [71.9| 75.0| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.091, v_acc: 50.0, c_acc: 96.9}\n","STEP:697, D{v_l: 0.584, v_acc: [84.4| 68.8| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 0.926, v_acc: 51.6, c_acc: 93.8}\n","STEP:698, D{v_l: 0.473, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 100.0]}  G{v_l: 0.961, v_acc: 51.6, c_acc: 95.3}\n","STEP:699, D{v_l: 0.522, v_acc: [81.2| 71.9| 76.6], c_acc: [87.5| 100.0]}  G{v_l: 0.879, v_acc: 56.2, c_acc: 96.9}\n","STEP:700, D{v_l: 0.462, v_acc: [71.9| 75.0| 73.4], c_acc: [96.9| 96.9]}  G{v_l: 1.032, v_acc: 59.4, c_acc: 98.4}\n","STEP:701, D{v_l: 0.818, v_acc: [62.5| 59.4| 60.9], c_acc: [90.6| 90.6]}  G{v_l: 0.993, v_acc: 46.9, c_acc: 95.3}\n","STEP:702, D{v_l: 0.447, v_acc: [87.5| 65.6| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 0.935, v_acc: 54.7, c_acc: 96.9}\n","STEP:703, D{v_l: 0.442, v_acc: [87.5| 78.1| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 0.911, v_acc: 51.6, c_acc: 95.3}\n","STEP:704, D{v_l: 0.530, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.135, v_acc: 56.2, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.8694 - valid_loss: 0.5180 - class_loss: 1.9463 - valid_acc: 0.7647 - class_acc: 0.5059\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0267 - valid_loss: 0.5797 - class_loss: 0.0420 - valid_acc: 0.6588 - class_acc: 0.9765\n","average v_acc: 71.176, three class acc: 50.588, two class acc: 67.059\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0704.h5\n","STEP:705, D{v_l: 0.502, v_acc: [65.0| 78.1| 71.5], c_acc: [95.7| 96.9]}  G{v_l: 1.015, v_acc: 51.6, c_acc: 98.4}\n","STEP:706, D{v_l: 0.498, v_acc: [68.8| 78.1| 73.4], c_acc: [96.9| 100.0]}  G{v_l: 1.047, v_acc: 60.9, c_acc: 95.3}\n","STEP:707, D{v_l: 0.694, v_acc: [75.0| 71.9| 73.4], c_acc: [93.8| 93.8]}  G{v_l: 0.897, v_acc: 43.8, c_acc: 95.3}\n","STEP:708, D{v_l: 0.564, v_acc: [68.8| 68.8| 68.8], c_acc: [87.5| 90.6]}  G{v_l: 1.049, v_acc: 46.9, c_acc: 95.3}\n","STEP:709, D{v_l: 0.633, v_acc: [68.8| 81.2| 75.0], c_acc: [87.5| 100.0]}  G{v_l: 0.942, v_acc: 46.9, c_acc: 95.3}\n","STEP:710, D{v_l: 0.370, v_acc: [84.4| 68.8| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 0.955, v_acc: 56.2, c_acc: 93.8}\n","STEP:711, D{v_l: 0.565, v_acc: [68.8| 71.9| 70.3], c_acc: [87.5| 100.0]}  G{v_l: 1.033, v_acc: 51.6, c_acc: 98.4}\n","STEP:712, D{v_l: 0.455, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.063, v_acc: 57.8, c_acc: 98.4}\n","STEP:713, D{v_l: 0.492, v_acc: [68.8| 81.2| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 0.959, v_acc: 59.4, c_acc: 95.3}\n","STEP:714, D{v_l: 0.517, v_acc: [78.1| 71.9| 75.0], c_acc: [90.6| 93.8]}  G{v_l: 1.083, v_acc: 54.7, c_acc: 98.4}\n","STEP:715, D{v_l: 0.325, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.051, v_acc: 48.4, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.6457 - valid_loss: 0.5018 - class_loss: 1.7390 - valid_acc: 0.7882 - class_acc: 0.5059\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0536 - valid_loss: 0.5706 - class_loss: 0.0781 - valid_acc: 0.7059 - class_acc: 0.9765\n","average v_acc: 74.706, three class acc: 50.588, two class acc: 70.588\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0715.h5\n","STEP:716, D{v_l: 0.470, v_acc: [76.9| 81.2| 79.1], c_acc: [96.6| 90.6]}  G{v_l: 0.901, v_acc: 60.9, c_acc: 100.0}\n","STEP:717, D{v_l: 0.568, v_acc: [75.0| 68.8| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 1.150, v_acc: 56.2, c_acc: 87.5}\n","STEP:718, D{v_l: 0.463, v_acc: [75.0| 78.1| 76.6], c_acc: [90.6| 90.6]}  G{v_l: 0.690, v_acc: 68.8, c_acc: 93.8}\n","STEP:719, D{v_l: 0.619, v_acc: [75.0| 68.8| 71.9], c_acc: [93.8| 100.0]}  G{v_l: 0.791, v_acc: 59.4, c_acc: 85.9}\n","STEP:720, D{v_l: 0.407, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 0.836, v_acc: 56.2, c_acc: 85.9}\n","STEP:721, D{v_l: 0.515, v_acc: [71.9| 81.2| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.067, v_acc: 54.7, c_acc: 96.9}\n","STEP:722, D{v_l: 0.488, v_acc: [62.5| 96.9| 79.7], c_acc: [81.2| 96.9]}  G{v_l: 0.920, v_acc: 53.1, c_acc: 90.6}\n","STEP:723, D{v_l: 0.576, v_acc: [71.9| 84.4| 78.1], c_acc: [93.8| 93.8]}  G{v_l: 1.237, v_acc: 43.8, c_acc: 85.9}\n","STEP:724, D{v_l: 0.415, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 0.826, v_acc: 56.2, c_acc: 98.4}\n","STEP:725, D{v_l: 0.801, v_acc: [65.6| 71.9| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 0.912, v_acc: 53.1, c_acc: 96.9}\n","STEP:726, D{v_l: 0.554, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.203, v_acc: 43.8, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 56ms/step - loss: 2.8067 - valid_loss: 0.5184 - class_loss: 1.8834 - valid_acc: 0.8118 - class_acc: 0.5059\n","3/3 [==============================] - 0s 49ms/step - loss: 0.9721 - valid_loss: 0.5260 - class_loss: 0.0412 - valid_acc: 0.7882 - class_acc: 0.9882\n","average v_acc: 80.000, three class acc: 50.588, two class acc: 67.059\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0726.h5\n","STEP:727, D{v_l: 0.463, v_acc: [76.1| 84.4| 80.2], c_acc: [97.4| 100.0]}  G{v_l: 0.995, v_acc: 51.6, c_acc: 92.2}\n","STEP:728, D{v_l: 0.583, v_acc: [71.9| 71.9| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 1.168, v_acc: 40.6, c_acc: 87.5}\n","STEP:729, D{v_l: 0.594, v_acc: [78.1| 65.6| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 1.028, v_acc: 56.2, c_acc: 96.9}\n","STEP:730, D{v_l: 0.557, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.072, v_acc: 45.3, c_acc: 92.2}\n","STEP:731, D{v_l: 0.524, v_acc: [68.8| 71.9| 70.3], c_acc: [90.6| 87.5]}  G{v_l: 1.015, v_acc: 57.8, c_acc: 95.3}\n","STEP:732, D{v_l: 0.495, v_acc: [68.8| 78.1| 73.4], c_acc: [93.8| 96.9]}  G{v_l: 1.300, v_acc: 48.4, c_acc: 92.2}\n","STEP:733, D{v_l: 0.571, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 1.264, v_acc: 56.2, c_acc: 89.1}\n","STEP:734, D{v_l: 0.416, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 1.263, v_acc: 43.8, c_acc: 81.2}\n","STEP:735, D{v_l: 0.372, v_acc: [71.9| 93.8| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 1.258, v_acc: 46.9, c_acc: 93.8}\n","STEP:736, D{v_l: 0.488, v_acc: [75.0| 71.9| 73.4], c_acc: [90.6| 93.8]}  G{v_l: 1.366, v_acc: 43.8, c_acc: 98.4}\n","STEP:737, D{v_l: 0.605, v_acc: [78.1| 78.1| 78.1], c_acc: [87.5| 100.0]}  G{v_l: 1.159, v_acc: 51.6, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.7875 - valid_loss: 0.5566 - class_loss: 1.8261 - valid_acc: 0.7412 - class_acc: 0.4941\n","3/3 [==============================] - 0s 46ms/step - loss: 0.9914 - valid_loss: 0.5707 - class_loss: 0.0158 - valid_acc: 0.5647 - class_acc: 1.0000\n","average v_acc: 65.294, three class acc: 49.412, two class acc: 63.529\n","====================================================================================================\n","STEP:738, D{v_l: 0.394, v_acc: [64.1| 93.8| 78.9], c_acc: [99.1| 100.0]}  G{v_l: 1.061, v_acc: 62.5, c_acc: 98.4}\n","STEP:739, D{v_l: 0.611, v_acc: [65.6| 71.9| 68.8], c_acc: [84.4| 96.9]}  G{v_l: 0.702, v_acc: 67.2, c_acc: 96.9}\n","STEP:740, D{v_l: 0.434, v_acc: [84.4| 75.0| 79.7], c_acc: [87.5| 93.8]}  G{v_l: 1.074, v_acc: 53.1, c_acc: 96.9}\n","STEP:741, D{v_l: 0.473, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 0.907, v_acc: 54.7, c_acc: 98.4}\n","STEP:742, D{v_l: 0.559, v_acc: [71.9| 75.0| 73.4], c_acc: [93.8| 100.0]}  G{v_l: 1.010, v_acc: 54.7, c_acc: 98.4}\n","STEP:743, D{v_l: 0.423, v_acc: [87.5| 78.1| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.158, v_acc: 56.2, c_acc: 100.0}\n","STEP:744, D{v_l: 0.495, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 90.6]}  G{v_l: 1.042, v_acc: 57.8, c_acc: 95.3}\n","STEP:745, D{v_l: 0.511, v_acc: [75.0| 71.9| 73.4], c_acc: [100.0| 96.9]}  G{v_l: 1.113, v_acc: 50.0, c_acc: 100.0}\n","STEP:746, D{v_l: 0.545, v_acc: [78.1| 71.9| 75.0], c_acc: [93.8| 87.5]}  G{v_l: 1.212, v_acc: 43.8, c_acc: 100.0}\n","STEP:747, D{v_l: 0.297, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 1.020, v_acc: 62.5, c_acc: 96.9}\n","STEP:748, D{v_l: 0.499, v_acc: [71.9| 68.8| 70.3], c_acc: [81.2| 93.8]}  G{v_l: 1.364, v_acc: 46.9, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9924 - valid_loss: 0.5697 - class_loss: 2.0180 - valid_acc: 0.7882 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9940 - valid_loss: 0.5662 - class_loss: 0.0230 - valid_acc: 0.6588 - class_acc: 0.9882\n","average v_acc: 72.353, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","STEP:749, D{v_l: 0.487, v_acc: [66.7| 81.2| 74.0], c_acc: [94.9| 100.0]}  G{v_l: 1.005, v_acc: 51.6, c_acc: 93.8}\n","STEP:750, D{v_l: 0.435, v_acc: [65.6| 84.4| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 0.845, v_acc: 59.4, c_acc: 95.3}\n","STEP:751, D{v_l: 0.505, v_acc: [81.2| 84.4| 82.8], c_acc: [87.5| 96.9]}  G{v_l: 1.206, v_acc: 45.3, c_acc: 98.4}\n","STEP:752, D{v_l: 0.461, v_acc: [75.0| 87.5| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.140, v_acc: 43.8, c_acc: 96.9}\n","STEP:753, D{v_l: 0.568, v_acc: [81.2| 75.0| 78.1], c_acc: [100.0| 100.0]}  G{v_l: 1.683, v_acc: 40.6, c_acc: 96.9}\n","STEP:754, D{v_l: 0.392, v_acc: [78.1| 87.5| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.124, v_acc: 57.8, c_acc: 98.4}\n","STEP:755, D{v_l: 0.510, v_acc: [71.9| 84.4| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.038, v_acc: 42.2, c_acc: 100.0}\n","STEP:756, D{v_l: 0.551, v_acc: [81.2| 62.5| 71.9], c_acc: [90.6| 100.0]}  G{v_l: 1.229, v_acc: 54.7, c_acc: 95.3}\n","STEP:757, D{v_l: 0.427, v_acc: [71.9| 84.4| 78.1], c_acc: [90.6| 90.6]}  G{v_l: 0.987, v_acc: 43.8, c_acc: 93.8}\n","STEP:758, D{v_l: 0.632, v_acc: [75.0| 75.0| 75.0], c_acc: [84.4| 96.9]}  G{v_l: 1.030, v_acc: 50.0, c_acc: 96.9}\n","STEP:759, D{v_l: 0.447, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 93.8]}  G{v_l: 0.934, v_acc: 56.2, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 4.7056 - valid_loss: 0.8306 - class_loss: 3.4703 - valid_acc: 0.4588 - class_acc: 0.5176\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0305 - valid_loss: 0.5855 - class_loss: 0.0403 - valid_acc: 0.4941 - class_acc: 0.9882\n","average v_acc: 47.647, three class acc: 51.765, two class acc: 55.294\n","====================================================================================================\n","STEP:760, D{v_l: 0.469, v_acc: [58.1| 81.2| 69.7], c_acc: [97.4| 87.5]}  G{v_l: 0.940, v_acc: 46.9, c_acc: 93.8}\n","STEP:761, D{v_l: 0.566, v_acc: [75.0| 78.1| 76.6], c_acc: [100.0| 96.9]}  G{v_l: 1.023, v_acc: 46.9, c_acc: 89.1}\n","STEP:762, D{v_l: 0.709, v_acc: [62.5| 78.1| 70.3], c_acc: [90.6| 93.8]}  G{v_l: 0.928, v_acc: 60.9, c_acc: 95.3}\n","STEP:763, D{v_l: 0.391, v_acc: [84.4| 87.5| 85.9], c_acc: [87.5| 100.0]}  G{v_l: 0.744, v_acc: 64.1, c_acc: 95.3}\n","STEP:764, D{v_l: 0.604, v_acc: [71.9| 68.8| 70.3], c_acc: [96.9| 100.0]}  G{v_l: 0.978, v_acc: 51.6, c_acc: 96.9}\n","STEP:765, D{v_l: 0.360, v_acc: [90.6| 81.2| 85.9], c_acc: [90.6| 90.6]}  G{v_l: 1.423, v_acc: 43.8, c_acc: 87.5}\n","STEP:766, D{v_l: 0.619, v_acc: [81.2| 71.9| 76.6], c_acc: [100.0| 96.9]}  G{v_l: 0.986, v_acc: 48.4, c_acc: 51.6}\n","STEP:767, D{v_l: 0.578, v_acc: [84.4| 75.0| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 1.298, v_acc: 51.6, c_acc: 79.7}\n","STEP:768, D{v_l: 0.550, v_acc: [75.0| 75.0| 75.0], c_acc: [87.5| 100.0]}  G{v_l: 0.896, v_acc: 59.4, c_acc: 87.5}\n","STEP:769, D{v_l: 0.434, v_acc: [75.0| 81.2| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 1.133, v_acc: 50.0, c_acc: 95.3}\n","STEP:770, D{v_l: 0.549, v_acc: [65.6| 84.4| 75.0], c_acc: [93.8| 90.6]}  G{v_l: 0.879, v_acc: 54.7, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 4.4460 - valid_loss: 0.7260 - class_loss: 3.3154 - valid_acc: 0.5412 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1634 - valid_loss: 0.6396 - class_loss: 0.1192 - valid_acc: 0.5647 - class_acc: 0.9647\n","average v_acc: 55.294, three class acc: 49.412, two class acc: 56.471\n","====================================================================================================\n","Epoch: 70\n","====================================================================================================\n","STEP:771, D{v_l: 0.484, v_acc: [63.2| 87.5| 75.4], c_acc: [95.7| 93.8]}  G{v_l: 1.016, v_acc: 54.7, c_acc: 95.3}\n","STEP:772, D{v_l: 0.454, v_acc: [81.2| 78.1| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 1.318, v_acc: 39.1, c_acc: 100.0}\n","STEP:773, D{v_l: 0.292, v_acc: [87.5| 84.4| 85.9], c_acc: [87.5| 93.8]}  G{v_l: 1.261, v_acc: 45.3, c_acc: 96.9}\n","STEP:774, D{v_l: 0.517, v_acc: [81.2| 56.2| 68.8], c_acc: [93.8| 96.9]}  G{v_l: 1.142, v_acc: 51.6, c_acc: 96.9}\n","STEP:775, D{v_l: 0.491, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 0.860, v_acc: 67.2, c_acc: 95.3}\n","STEP:776, D{v_l: 0.557, v_acc: [71.9| 87.5| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 0.875, v_acc: 56.2, c_acc: 96.9}\n","STEP:777, D{v_l: 0.472, v_acc: [68.8| 84.4| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.172, v_acc: 53.1, c_acc: 89.1}\n","STEP:778, D{v_l: 0.378, v_acc: [93.8| 68.8| 81.2], c_acc: [96.9| 90.6]}  G{v_l: 0.851, v_acc: 60.9, c_acc: 93.8}\n","STEP:779, D{v_l: 0.420, v_acc: [81.2| 75.0| 78.1], c_acc: [100.0| 100.0]}  G{v_l: 1.213, v_acc: 40.6, c_acc: 96.9}\n","STEP:780, D{v_l: 0.453, v_acc: [75.0| 81.2| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 1.103, v_acc: 60.9, c_acc: 96.9}\n","STEP:781, D{v_l: 0.378, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.150, v_acc: 46.9, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.1927 - valid_loss: 0.7340 - class_loss: 2.0542 - valid_acc: 0.5529 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1031 - valid_loss: 0.6677 - class_loss: 0.0308 - valid_acc: 0.4588 - class_acc: 1.0000\n","average v_acc: 50.588, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:782, D{v_l: 0.654, v_acc: [51.3| 75.0| 63.1], c_acc: [98.3| 90.6]}  G{v_l: 0.983, v_acc: 48.4, c_acc: 96.9}\n","STEP:783, D{v_l: 0.543, v_acc: [78.1| 68.8| 73.4], c_acc: [93.8| 100.0]}  G{v_l: 1.008, v_acc: 56.2, c_acc: 93.8}\n","STEP:784, D{v_l: 0.453, v_acc: [84.4| 71.9| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 0.720, v_acc: 64.1, c_acc: 92.2}\n","STEP:785, D{v_l: 0.456, v_acc: [71.9| 78.1| 75.0], c_acc: [93.8| 93.8]}  G{v_l: 0.960, v_acc: 54.7, c_acc: 95.3}\n","STEP:786, D{v_l: 0.406, v_acc: [81.2| 87.5| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 1.034, v_acc: 53.1, c_acc: 93.8}\n","STEP:787, D{v_l: 0.297, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.418, v_acc: 50.0, c_acc: 98.4}\n","STEP:788, D{v_l: 0.448, v_acc: [68.8| 81.2| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 0.853, v_acc: 62.5, c_acc: 100.0}\n","STEP:789, D{v_l: 0.529, v_acc: [84.4| 75.0| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 1.053, v_acc: 53.1, c_acc: 95.3}\n","STEP:790, D{v_l: 0.465, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.346, v_acc: 39.1, c_acc: 92.2}\n","STEP:791, D{v_l: 0.345, v_acc: [84.4| 78.1| 81.2], c_acc: [84.4| 96.9]}  G{v_l: 1.073, v_acc: 45.3, c_acc: 92.2}\n","STEP:792, D{v_l: 0.457, v_acc: [68.8| 78.1| 73.4], c_acc: [96.9| 96.9]}  G{v_l: 1.045, v_acc: 39.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.9870 - valid_loss: 0.4521 - class_loss: 2.1304 - valid_acc: 0.8471 - class_acc: 0.5412\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1655 - valid_loss: 0.5420 - class_loss: 0.2191 - valid_acc: 0.8000 - class_acc: 0.9412\n","average v_acc: 82.353, three class acc: 54.118, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0792.h5\n","STEP:793, D{v_l: 0.550, v_acc: [78.6| 68.8| 73.7], c_acc: [94.0| 96.9]}  G{v_l: 1.269, v_acc: 50.0, c_acc: 90.6}\n","STEP:794, D{v_l: 0.364, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 87.5]}  G{v_l: 1.170, v_acc: 51.6, c_acc: 96.9}\n","STEP:795, D{v_l: 0.360, v_acc: [87.5| 90.6| 89.1], c_acc: [100.0| 93.8]}  G{v_l: 1.108, v_acc: 43.8, c_acc: 98.4}\n","STEP:796, D{v_l: 0.402, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.322, v_acc: 46.9, c_acc: 90.6}\n","STEP:797, D{v_l: 0.498, v_acc: [68.8| 78.1| 73.4], c_acc: [96.9| 93.8]}  G{v_l: 0.967, v_acc: 51.6, c_acc: 92.2}\n","STEP:798, D{v_l: 0.512, v_acc: [93.8| 71.9| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 0.895, v_acc: 57.8, c_acc: 95.3}\n","STEP:799, D{v_l: 0.411, v_acc: [84.4| 71.9| 78.1], c_acc: [100.0| 96.9]}  G{v_l: 1.075, v_acc: 43.8, c_acc: 95.3}\n","STEP:800, D{v_l: 0.464, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 0.921, v_acc: 43.8, c_acc: 93.8}\n","STEP:801, D{v_l: 0.455, v_acc: [71.9| 84.4| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 1.045, v_acc: 48.4, c_acc: 100.0}\n","STEP:802, D{v_l: 0.364, v_acc: [90.6| 81.2| 85.9], c_acc: [81.2| 100.0]}  G{v_l: 1.004, v_acc: 50.0, c_acc: 98.4}\n","STEP:803, D{v_l: 0.380, v_acc: [90.6| 78.1| 84.4], c_acc: [87.5| 96.9]}  G{v_l: 0.940, v_acc: 57.8, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.5068 - valid_loss: 0.6136 - class_loss: 2.4888 - valid_acc: 0.6588 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9725 - valid_loss: 0.5174 - class_loss: 0.0507 - valid_acc: 0.6824 - class_acc: 0.9882\n","average v_acc: 67.059, three class acc: 51.765, two class acc: 56.471\n","====================================================================================================\n","STEP:804, D{v_l: 0.478, v_acc: [72.6| 68.8| 70.7], c_acc: [95.7| 96.9]}  G{v_l: 1.045, v_acc: 50.0, c_acc: 100.0}\n","STEP:805, D{v_l: 0.460, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 87.5]}  G{v_l: 1.002, v_acc: 53.1, c_acc: 96.9}\n","STEP:806, D{v_l: 0.621, v_acc: [90.6| 71.9| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 1.041, v_acc: 40.6, c_acc: 100.0}\n","STEP:807, D{v_l: 0.502, v_acc: [75.0| 90.6| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.063, v_acc: 45.3, c_acc: 96.9}\n","STEP:808, D{v_l: 0.609, v_acc: [68.8| 75.0| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 1.267, v_acc: 42.2, c_acc: 89.1}\n","STEP:809, D{v_l: 0.316, v_acc: [81.2| 78.1| 79.7], c_acc: [81.2| 100.0]}  G{v_l: 1.051, v_acc: 40.6, c_acc: 85.9}\n","STEP:810, D{v_l: 0.388, v_acc: [78.1| 78.1| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 0.946, v_acc: 60.9, c_acc: 92.2}\n","STEP:811, D{v_l: 0.649, v_acc: [68.8| 84.4| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.015, v_acc: 53.1, c_acc: 93.8}\n","STEP:812, D{v_l: 0.453, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 1.059, v_acc: 46.9, c_acc: 98.4}\n","STEP:813, D{v_l: 0.349, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 0.867, v_acc: 50.0, c_acc: 98.4}\n","STEP:814, D{v_l: 0.565, v_acc: [75.0| 75.0| 75.0], c_acc: [90.6| 100.0]}  G{v_l: 0.964, v_acc: 46.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7903 - valid_loss: 0.4565 - class_loss: 1.9295 - valid_acc: 0.7882 - class_acc: 0.4706\n","3/3 [==============================] - 0s 50ms/step - loss: 0.9825 - valid_loss: 0.5655 - class_loss: 0.0127 - valid_acc: 0.7412 - class_acc: 1.0000\n","average v_acc: 76.471, three class acc: 47.059, two class acc: 63.529\n","====================================================================================================\n","STEP:815, D{v_l: 0.496, v_acc: [77.8| 78.1| 78.0], c_acc: [99.1| 96.9]}  G{v_l: 1.017, v_acc: 48.4, c_acc: 95.3}\n","STEP:816, D{v_l: 0.401, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.006, v_acc: 50.0, c_acc: 96.9}\n","STEP:817, D{v_l: 0.590, v_acc: [71.9| 75.0| 73.4], c_acc: [84.4| 90.6]}  G{v_l: 0.915, v_acc: 62.5, c_acc: 98.4}\n","STEP:818, D{v_l: 0.330, v_acc: [81.2| 78.1| 79.7], c_acc: [87.5| 100.0]}  G{v_l: 1.075, v_acc: 42.2, c_acc: 89.1}\n","STEP:819, D{v_l: 0.636, v_acc: [84.4| 75.0| 79.7], c_acc: [87.5| 90.6]}  G{v_l: 0.973, v_acc: 48.4, c_acc: 95.3}\n","STEP:820, D{v_l: 0.396, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 96.9]}  G{v_l: 1.099, v_acc: 39.1, c_acc: 87.5}\n","STEP:821, D{v_l: 0.520, v_acc: [75.0| 81.2| 78.1], c_acc: [84.4| 100.0]}  G{v_l: 0.914, v_acc: 60.9, c_acc: 96.9}\n","STEP:822, D{v_l: 0.336, v_acc: [84.4| 75.0| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.056, v_acc: 51.6, c_acc: 95.3}\n","STEP:823, D{v_l: 0.411, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 93.8]}  G{v_l: 1.134, v_acc: 34.4, c_acc: 89.1}\n","STEP:824, D{v_l: 0.389, v_acc: [71.9| 81.2| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 0.989, v_acc: 50.0, c_acc: 89.1}\n","STEP:825, D{v_l: 0.469, v_acc: [84.4| 81.2| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 1.066, v_acc: 37.5, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.6700 - valid_loss: 0.4970 - class_loss: 1.7687 - valid_acc: 0.7294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1812 - valid_loss: 0.5756 - class_loss: 0.2013 - valid_acc: 0.7059 - class_acc: 0.9176\n","average v_acc: 71.765, three class acc: 52.941, two class acc: 64.706\n","====================================================================================================\n","STEP:826, D{v_l: 0.511, v_acc: [73.5| 71.9| 72.7], c_acc: [92.3| 100.0]}  G{v_l: 0.943, v_acc: 54.7, c_acc: 92.2}\n","STEP:827, D{v_l: 0.407, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 0.923, v_acc: 46.9, c_acc: 92.2}\n","STEP:828, D{v_l: 0.472, v_acc: [84.4| 71.9| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 0.922, v_acc: 48.4, c_acc: 100.0}\n","STEP:829, D{v_l: 0.459, v_acc: [87.5| 68.8| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 1.027, v_acc: 50.0, c_acc: 96.9}\n","STEP:830, D{v_l: 0.402, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 93.8]}  G{v_l: 1.039, v_acc: 51.6, c_acc: 95.3}\n","STEP:831, D{v_l: 0.271, v_acc: [90.6| 87.5| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 1.050, v_acc: 48.4, c_acc: 92.2}\n","STEP:832, D{v_l: 0.572, v_acc: [68.8| 78.1| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.003, v_acc: 43.8, c_acc: 96.9}\n","STEP:833, D{v_l: 0.480, v_acc: [87.5| 65.6| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 1.011, v_acc: 50.0, c_acc: 93.8}\n","STEP:834, D{v_l: 0.353, v_acc: [75.0| 87.5| 81.2], c_acc: [87.5| 100.0]}  G{v_l: 1.029, v_acc: 37.5, c_acc: 98.4}\n","STEP:835, D{v_l: 0.373, v_acc: [87.5| 78.1| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.003, v_acc: 48.4, c_acc: 98.4}\n","STEP:836, D{v_l: 0.808, v_acc: [59.4| 65.6| 62.5], c_acc: [100.0| 78.1]}  G{v_l: 1.217, v_acc: 56.2, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 53ms/step - loss: 3.3194 - valid_loss: 0.5396 - class_loss: 2.3756 - valid_acc: 0.7176 - class_acc: 0.4824\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1607 - valid_loss: 0.6041 - class_loss: 0.1524 - valid_acc: 0.5059 - class_acc: 0.9647\n","average v_acc: 61.176, three class acc: 48.235, two class acc: 57.647\n","====================================================================================================\n","STEP:837, D{v_l: 0.573, v_acc: [61.5| 78.1| 69.8], c_acc: [96.6| 96.9]}  G{v_l: 1.036, v_acc: 54.7, c_acc: 89.1}\n","STEP:838, D{v_l: 0.403, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 93.8]}  G{v_l: 1.324, v_acc: 43.8, c_acc: 93.8}\n","STEP:839, D{v_l: 0.351, v_acc: [93.8| 78.1| 85.9], c_acc: [100.0| 96.9]}  G{v_l: 0.873, v_acc: 53.1, c_acc: 98.4}\n","STEP:840, D{v_l: 0.496, v_acc: [81.2| 75.0| 78.1], c_acc: [96.9| 100.0]}  G{v_l: 1.256, v_acc: 43.8, c_acc: 100.0}\n","STEP:841, D{v_l: 0.503, v_acc: [75.0| 71.9| 73.4], c_acc: [93.8| 90.6]}  G{v_l: 1.035, v_acc: 46.9, c_acc: 96.9}\n","STEP:842, D{v_l: 0.354, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.782, v_acc: 54.7, c_acc: 92.2}\n","STEP:843, D{v_l: 0.370, v_acc: [75.0| 84.4| 79.7], c_acc: [93.8| 93.8]}  G{v_l: 1.116, v_acc: 50.0, c_acc: 89.1}\n","STEP:844, D{v_l: 0.389, v_acc: [81.2| 81.2| 81.2], c_acc: [100.0| 93.8]}  G{v_l: 1.092, v_acc: 48.4, c_acc: 100.0}\n","STEP:845, D{v_l: 0.431, v_acc: [87.5| 75.0| 81.2], c_acc: [81.2| 90.6]}  G{v_l: 0.994, v_acc: 64.1, c_acc: 98.4}\n","STEP:846, D{v_l: 0.478, v_acc: [81.2| 75.0| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.209, v_acc: 48.4, c_acc: 96.9}\n","STEP:847, D{v_l: 0.372, v_acc: [87.5| 78.1| 82.8], c_acc: [100.0| 87.5]}  G{v_l: 1.119, v_acc: 56.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.3090 - valid_loss: 0.5921 - class_loss: 2.3128 - valid_acc: 0.6824 - class_acc: 0.5059\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9591 - valid_loss: 0.5347 - class_loss: 0.0203 - valid_acc: 0.6471 - class_acc: 1.0000\n","average v_acc: 66.471, three class acc: 50.588, two class acc: 60.000\n","====================================================================================================\n","STEP:848, D{v_l: 0.373, v_acc: [69.2| 90.6| 79.9], c_acc: [97.4| 96.9]}  G{v_l: 0.858, v_acc: 57.8, c_acc: 96.9}\n","STEP:849, D{v_l: 0.488, v_acc: [71.9| 78.1| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 1.196, v_acc: 48.4, c_acc: 95.3}\n","STEP:850, D{v_l: 0.623, v_acc: [65.6| 59.4| 62.5], c_acc: [87.5| 87.5]}  G{v_l: 1.046, v_acc: 53.1, c_acc: 96.9}\n","STEP:851, D{v_l: 0.625, v_acc: [87.5| 71.9| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 0.910, v_acc: 53.1, c_acc: 95.3}\n","STEP:852, D{v_l: 0.654, v_acc: [78.1| 65.6| 71.9], c_acc: [93.8| 93.8]}  G{v_l: 0.872, v_acc: 46.9, c_acc: 92.2}\n","STEP:853, D{v_l: 0.766, v_acc: [81.2| 75.0| 78.1], c_acc: [87.5| 100.0]}  G{v_l: 1.012, v_acc: 43.8, c_acc: 95.3}\n","STEP:854, D{v_l: 0.413, v_acc: [78.1| 81.2| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 2.006, v_acc: 43.8, c_acc: 90.6}\n","STEP:855, D{v_l: 0.515, v_acc: [75.0| 68.8| 71.9], c_acc: [93.8| 96.9]}  G{v_l: 1.228, v_acc: 53.1, c_acc: 93.8}\n","STEP:856, D{v_l: 0.478, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.065, v_acc: 62.5, c_acc: 98.4}\n","STEP:857, D{v_l: 0.414, v_acc: [78.1| 84.4| 81.2], c_acc: [84.4| 100.0]}  G{v_l: 1.164, v_acc: 43.8, c_acc: 95.3}\n","STEP:858, D{v_l: 0.470, v_acc: [68.8| 87.5| 78.1], c_acc: [96.9| 100.0]}  G{v_l: 0.797, v_acc: 64.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9862 - valid_loss: 0.4418 - class_loss: 2.1404 - valid_acc: 0.8471 - class_acc: 0.4353\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0326 - valid_loss: 0.5775 - class_loss: 0.0509 - valid_acc: 0.6353 - class_acc: 0.9882\n","average v_acc: 74.118, three class acc: 43.529, two class acc: 62.353\n","====================================================================================================\n","STEP:859, D{v_l: 0.428, v_acc: [69.2| 84.4| 76.8], c_acc: [98.3| 100.0]}  G{v_l: 0.829, v_acc: 56.2, c_acc: 98.4}\n","STEP:860, D{v_l: 0.437, v_acc: [84.4| 87.5| 85.9], c_acc: [84.4| 87.5]}  G{v_l: 0.999, v_acc: 45.3, c_acc: 75.0}\n","STEP:861, D{v_l: 0.457, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 90.6]}  G{v_l: 1.077, v_acc: 39.1, c_acc: 79.7}\n","STEP:862, D{v_l: 0.559, v_acc: [84.4| 71.9| 78.1], c_acc: [96.9| 87.5]}  G{v_l: 1.106, v_acc: 46.9, c_acc: 85.9}\n","STEP:863, D{v_l: 0.293, v_acc: [71.9| 90.6| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.106, v_acc: 48.4, c_acc: 84.4}\n","STEP:864, D{v_l: 0.408, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.122, v_acc: 46.9, c_acc: 90.6}\n","STEP:865, D{v_l: 0.611, v_acc: [65.6| 81.2| 73.4], c_acc: [90.6| 100.0]}  G{v_l: 1.216, v_acc: 54.7, c_acc: 93.8}\n","STEP:866, D{v_l: 0.507, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.111, v_acc: 51.6, c_acc: 98.4}\n","STEP:867, D{v_l: 0.428, v_acc: [75.0| 81.2| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 0.966, v_acc: 54.7, c_acc: 95.3}\n","STEP:868, D{v_l: 0.480, v_acc: [84.4| 71.9| 78.1], c_acc: [93.8| 93.8]}  G{v_l: 0.906, v_acc: 62.5, c_acc: 96.9}\n","STEP:869, D{v_l: 0.377, v_acc: [75.0| 84.4| 79.7], c_acc: [87.5| 100.0]}  G{v_l: 1.039, v_acc: 54.7, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.8375 - valid_loss: 0.4425 - class_loss: 1.9910 - valid_acc: 0.7765 - class_acc: 0.4471\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0607 - valid_loss: 0.5511 - class_loss: 0.1056 - valid_acc: 0.6824 - class_acc: 0.9765\n","average v_acc: 72.941, three class acc: 44.706, two class acc: 62.353\n","====================================================================================================\n","STEP:870, D{v_l: 0.530, v_acc: [72.6| 71.9| 72.3], c_acc: [96.6| 96.9]}  G{v_l: 1.060, v_acc: 59.4, c_acc: 93.8}\n","STEP:871, D{v_l: 0.279, v_acc: [87.5| 96.9| 92.2], c_acc: [93.8| 100.0]}  G{v_l: 0.951, v_acc: 59.4, c_acc: 96.9}\n","STEP:872, D{v_l: 0.400, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 1.204, v_acc: 42.2, c_acc: 92.2}\n","STEP:873, D{v_l: 0.497, v_acc: [81.2| 75.0| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.063, v_acc: 57.8, c_acc: 90.6}\n","STEP:874, D{v_l: 0.377, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.082, v_acc: 56.2, c_acc: 90.6}\n","STEP:875, D{v_l: 0.510, v_acc: [78.1| 87.5| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 0.908, v_acc: 56.2, c_acc: 90.6}\n","STEP:876, D{v_l: 0.515, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.261, v_acc: 54.7, c_acc: 96.9}\n","STEP:877, D{v_l: 0.393, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 1.128, v_acc: 50.0, c_acc: 100.0}\n","STEP:878, D{v_l: 0.298, v_acc: [87.5| 90.6| 89.1], c_acc: [90.6| 100.0]}  G{v_l: 1.192, v_acc: 46.9, c_acc: 100.0}\n","STEP:879, D{v_l: 0.716, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 0.966, v_acc: 64.1, c_acc: 98.4}\n","STEP:880, D{v_l: 0.428, v_acc: [68.8| 90.6| 79.7], c_acc: [96.9| 93.8]}  G{v_l: 1.049, v_acc: 53.1, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.8394 - valid_loss: 0.4524 - class_loss: 1.9831 - valid_acc: 0.8235 - class_acc: 0.4824\n","3/3 [==============================] - 0s 44ms/step - loss: 0.9405 - valid_loss: 0.5283 - class_loss: 0.0082 - valid_acc: 0.6353 - class_acc: 1.0000\n","average v_acc: 72.941, three class acc: 48.235, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0880.h5\n","Epoch: 80\n","====================================================================================================\n","STEP:881, D{v_l: 0.416, v_acc: [68.4| 84.4| 76.4], c_acc: [98.3| 100.0]}  G{v_l: 0.982, v_acc: 48.4, c_acc: 100.0}\n","STEP:882, D{v_l: 0.325, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 0.894, v_acc: 50.0, c_acc: 93.8}\n","STEP:883, D{v_l: 0.368, v_acc: [93.8| 81.2| 87.5], c_acc: [87.5| 96.9]}  G{v_l: 1.312, v_acc: 45.3, c_acc: 92.2}\n","STEP:884, D{v_l: 0.444, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 100.0]}  G{v_l: 0.956, v_acc: 54.7, c_acc: 90.6}\n","STEP:885, D{v_l: 0.543, v_acc: [75.0| 68.8| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 0.898, v_acc: 45.3, c_acc: 93.8}\n","STEP:886, D{v_l: 0.392, v_acc: [75.0| 75.0| 75.0], c_acc: [90.6| 100.0]}  G{v_l: 1.008, v_acc: 48.4, c_acc: 100.0}\n","STEP:887, D{v_l: 0.360, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 0.730, v_acc: 59.4, c_acc: 96.9}\n","STEP:888, D{v_l: 0.417, v_acc: [78.1| 81.2| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 0.887, v_acc: 57.8, c_acc: 96.9}\n","STEP:889, D{v_l: 0.443, v_acc: [78.1| 78.1| 78.1], c_acc: [90.6| 90.6]}  G{v_l: 0.733, v_acc: 60.9, c_acc: 96.9}\n","STEP:890, D{v_l: 0.467, v_acc: [81.2| 75.0| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 0.924, v_acc: 48.4, c_acc: 98.4}\n","STEP:891, D{v_l: 0.401, v_acc: [78.1| 90.6| 84.4], c_acc: [100.0| 90.6]}  G{v_l: 1.032, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.9089 - valid_loss: 0.4488 - class_loss: 2.0562 - valid_acc: 0.8353 - class_acc: 0.4824\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1051 - valid_loss: 0.6536 - class_loss: 0.0475 - valid_acc: 0.4824 - class_acc: 0.9882\n","average v_acc: 65.882, three class acc: 48.235, two class acc: 64.706\n","====================================================================================================\n","STEP:892, D{v_l: 0.400, v_acc: [58.1| 84.4| 71.2], c_acc: [97.4| 93.8]}  G{v_l: 1.122, v_acc: 46.9, c_acc: 92.2}\n","STEP:893, D{v_l: 0.426, v_acc: [90.6| 81.2| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 1.145, v_acc: 43.8, c_acc: 92.2}\n","STEP:894, D{v_l: 0.304, v_acc: [93.8| 84.4| 89.1], c_acc: [84.4| 90.6]}  G{v_l: 0.834, v_acc: 60.9, c_acc: 96.9}\n","STEP:895, D{v_l: 0.429, v_acc: [75.0| 84.4| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 1.084, v_acc: 51.6, c_acc: 96.9}\n","STEP:896, D{v_l: 0.446, v_acc: [71.9| 93.8| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.044, v_acc: 50.0, c_acc: 95.3}\n","STEP:897, D{v_l: 0.352, v_acc: [87.5| 71.9| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 0.845, v_acc: 51.6, c_acc: 96.9}\n","STEP:898, D{v_l: 0.318, v_acc: [84.4| 90.6| 87.5], c_acc: [100.0| 100.0]}  G{v_l: 0.903, v_acc: 56.2, c_acc: 96.9}\n","STEP:899, D{v_l: 0.301, v_acc: [90.6| 81.2| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.068, v_acc: 50.0, c_acc: 98.4}\n","STEP:900, D{v_l: 0.510, v_acc: [84.4| 68.8| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 1.058, v_acc: 56.2, c_acc: 100.0}\n","STEP:901, D{v_l: 0.378, v_acc: [81.2| 90.6| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 0.962, v_acc: 48.4, c_acc: 95.3}\n","STEP:902, D{v_l: 0.375, v_acc: [81.2| 84.4| 82.8], c_acc: [100.0| 100.0]}  G{v_l: 1.019, v_acc: 46.9, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 2.9919 - valid_loss: 0.4497 - class_loss: 2.1383 - valid_acc: 0.8353 - class_acc: 0.4824\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1202 - valid_loss: 0.6993 - class_loss: 0.0171 - valid_acc: 0.4471 - class_acc: 1.0000\n","average v_acc: 64.118, three class acc: 48.235, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0902.h5\n","STEP:903, D{v_l: 0.469, v_acc: [57.3| 78.1| 67.7], c_acc: [98.3| 100.0]}  G{v_l: 0.769, v_acc: 59.4, c_acc: 98.4}\n","STEP:904, D{v_l: 0.507, v_acc: [71.9| 78.1| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 0.819, v_acc: 51.6, c_acc: 96.9}\n","STEP:905, D{v_l: 0.319, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.692, v_acc: 56.2, c_acc: 96.9}\n","STEP:906, D{v_l: 0.551, v_acc: [78.1| 53.1| 65.6], c_acc: [90.6| 96.9]}  G{v_l: 0.638, v_acc: 62.5, c_acc: 93.8}\n","STEP:907, D{v_l: 0.264, v_acc: [87.5| 93.8| 90.6], c_acc: [90.6| 96.9]}  G{v_l: 0.920, v_acc: 51.6, c_acc: 98.4}\n","STEP:908, D{v_l: 0.319, v_acc: [78.1| 90.6| 84.4], c_acc: [84.4| 100.0]}  G{v_l: 0.924, v_acc: 54.7, c_acc: 93.8}\n","STEP:909, D{v_l: 0.387, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 87.5]}  G{v_l: 1.327, v_acc: 51.6, c_acc: 96.9}\n","STEP:910, D{v_l: 0.397, v_acc: [78.1| 87.5| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.997, v_acc: 48.4, c_acc: 92.2}\n","STEP:911, D{v_l: 0.479, v_acc: [75.0| 68.8| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 0.920, v_acc: 53.1, c_acc: 100.0}\n","STEP:912, D{v_l: 0.348, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.862, v_acc: 56.2, c_acc: 90.6}\n","STEP:913, D{v_l: 0.342, v_acc: [84.4| 90.6| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 0.978, v_acc: 51.6, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 3.5704 - valid_loss: 0.5411 - class_loss: 2.6255 - valid_acc: 0.7059 - class_acc: 0.4706\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0296 - valid_loss: 0.6091 - class_loss: 0.0168 - valid_acc: 0.5529 - class_acc: 1.0000\n","average v_acc: 62.941, three class acc: 47.059, two class acc: 61.176\n","====================================================================================================\n","STEP:914, D{v_l: 0.426, v_acc: [64.1| 87.5| 75.8], c_acc: [98.3| 100.0]}  G{v_l: 1.040, v_acc: 51.6, c_acc: 100.0}\n","STEP:915, D{v_l: 0.532, v_acc: [78.1| 81.2| 79.7], c_acc: [84.4| 100.0]}  G{v_l: 0.935, v_acc: 51.6, c_acc: 100.0}\n","STEP:916, D{v_l: 0.541, v_acc: [81.2| 71.9| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 1.212, v_acc: 39.1, c_acc: 96.9}\n","STEP:917, D{v_l: 0.593, v_acc: [68.8| 71.9| 70.3], c_acc: [90.6| 100.0]}  G{v_l: 0.910, v_acc: 46.9, c_acc: 92.2}\n","STEP:918, D{v_l: 0.609, v_acc: [75.0| 75.0| 75.0], c_acc: [96.9| 96.9]}  G{v_l: 1.036, v_acc: 40.6, c_acc: 98.4}\n","STEP:919, D{v_l: 0.481, v_acc: [75.0| 90.6| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.102, v_acc: 46.9, c_acc: 92.2}\n","STEP:920, D{v_l: 0.417, v_acc: [78.1| 78.1| 78.1], c_acc: [84.4| 96.9]}  G{v_l: 1.328, v_acc: 35.9, c_acc: 92.2}\n","STEP:921, D{v_l: 0.381, v_acc: [96.9| 78.1| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.855, v_acc: 53.1, c_acc: 95.3}\n","STEP:922, D{v_l: 0.410, v_acc: [75.0| 81.2| 78.1], c_acc: [96.9| 100.0]}  G{v_l: 0.880, v_acc: 53.1, c_acc: 92.2}\n","STEP:923, D{v_l: 0.309, v_acc: [96.9| 84.4| 90.6], c_acc: [93.8| 100.0]}  G{v_l: 1.104, v_acc: 46.9, c_acc: 92.2}\n","STEP:924, D{v_l: 0.461, v_acc: [78.1| 71.9| 75.0], c_acc: [100.0| 96.9]}  G{v_l: 0.896, v_acc: 51.6, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.5117 - valid_loss: 0.4029 - class_loss: 2.7051 - valid_acc: 0.8235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0483 - valid_loss: 0.6035 - class_loss: 0.0411 - valid_acc: 0.6000 - class_acc: 0.9882\n","average v_acc: 71.176, three class acc: 51.765, two class acc: 67.059\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_0924.h5\n","STEP:925, D{v_l: 0.437, v_acc: [66.7| 84.4| 75.5], c_acc: [97.4| 100.0]}  G{v_l: 0.981, v_acc: 50.0, c_acc: 98.4}\n","STEP:926, D{v_l: 0.463, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 0.781, v_acc: 68.8, c_acc: 98.4}\n","STEP:927, D{v_l: 0.289, v_acc: [96.9| 75.0| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 0.946, v_acc: 50.0, c_acc: 100.0}\n","STEP:928, D{v_l: 0.496, v_acc: [87.5| 75.0| 81.2], c_acc: [100.0| 93.8]}  G{v_l: 0.813, v_acc: 57.8, c_acc: 96.9}\n","STEP:929, D{v_l: 0.371, v_acc: [87.5| 78.1| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 0.890, v_acc: 57.8, c_acc: 98.4}\n","STEP:930, D{v_l: 0.352, v_acc: [78.1| 90.6| 84.4], c_acc: [90.6| 87.5]}  G{v_l: 1.056, v_acc: 43.8, c_acc: 95.3}\n","STEP:931, D{v_l: 0.361, v_acc: [71.9| 87.5| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.908, v_acc: 57.8, c_acc: 95.3}\n","STEP:932, D{v_l: 0.337, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 87.5]}  G{v_l: 0.987, v_acc: 48.4, c_acc: 93.8}\n","STEP:933, D{v_l: 0.607, v_acc: [75.0| 78.1| 76.6], c_acc: [96.9| 100.0]}  G{v_l: 0.953, v_acc: 62.5, c_acc: 96.9}\n","STEP:934, D{v_l: 0.497, v_acc: [75.0| 71.9| 73.4], c_acc: [96.9| 100.0]}  G{v_l: 1.106, v_acc: 40.6, c_acc: 100.0}\n","STEP:935, D{v_l: 0.313, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 0.989, v_acc: 54.7, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 4.4633 - valid_loss: 0.7097 - class_loss: 3.3500 - valid_acc: 0.5529 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1704 - valid_loss: 0.7252 - class_loss: 0.0416 - valid_acc: 0.3882 - class_acc: 0.9765\n","average v_acc: 47.059, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:936, D{v_l: 0.559, v_acc: [51.3| 81.2| 66.3], c_acc: [96.6| 96.9]}  G{v_l: 1.058, v_acc: 50.0, c_acc: 100.0}\n","STEP:937, D{v_l: 0.368, v_acc: [93.8| 75.0| 84.4], c_acc: [100.0| 100.0]}  G{v_l: 0.845, v_acc: 64.1, c_acc: 98.4}\n","STEP:938, D{v_l: 0.606, v_acc: [71.9| 68.8| 70.3], c_acc: [93.8| 96.9]}  G{v_l: 1.129, v_acc: 51.6, c_acc: 98.4}\n","STEP:939, D{v_l: 0.571, v_acc: [65.6| 84.4| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 1.028, v_acc: 57.8, c_acc: 98.4}\n","STEP:940, D{v_l: 0.469, v_acc: [87.5| 71.9| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.029, v_acc: 53.1, c_acc: 98.4}\n","STEP:941, D{v_l: 0.436, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 0.929, v_acc: 45.3, c_acc: 100.0}\n","STEP:942, D{v_l: 0.249, v_acc: [90.6| 93.8| 92.2], c_acc: [90.6| 100.0]}  G{v_l: 0.826, v_acc: 62.5, c_acc: 95.3}\n","STEP:943, D{v_l: 0.396, v_acc: [81.2| 84.4| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 0.824, v_acc: 50.0, c_acc: 96.9}\n","STEP:944, D{v_l: 0.334, v_acc: [87.5| 84.4| 85.9], c_acc: [84.4| 84.4]}  G{v_l: 1.036, v_acc: 51.6, c_acc: 100.0}\n","STEP:945, D{v_l: 0.377, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 93.8]}  G{v_l: 0.994, v_acc: 46.9, c_acc: 96.9}\n","STEP:946, D{v_l: 0.419, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 93.8]}  G{v_l: 0.986, v_acc: 46.9, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.3526 - valid_loss: 0.6547 - class_loss: 3.2944 - valid_acc: 0.6353 - class_acc: 0.5176\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0246 - valid_loss: 0.5975 - class_loss: 0.0236 - valid_acc: 0.5294 - class_acc: 0.9882\n","average v_acc: 58.235, three class acc: 51.765, two class acc: 58.824\n","====================================================================================================\n","STEP:947, D{v_l: 0.513, v_acc: [62.4| 78.1| 70.3], c_acc: [98.3| 100.0]}  G{v_l: 1.075, v_acc: 45.3, c_acc: 95.3}\n","STEP:948, D{v_l: 0.352, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 0.871, v_acc: 62.5, c_acc: 92.2}\n","STEP:949, D{v_l: 0.401, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.363, v_acc: 35.9, c_acc: 85.9}\n","STEP:950, D{v_l: 0.365, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.986, v_acc: 45.3, c_acc: 93.8}\n","STEP:951, D{v_l: 0.556, v_acc: [81.2| 71.9| 76.6], c_acc: [96.9| 93.8]}  G{v_l: 1.195, v_acc: 48.4, c_acc: 93.8}\n","STEP:952, D{v_l: 0.417, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 1.250, v_acc: 39.1, c_acc: 87.5}\n","STEP:953, D{v_l: 0.306, v_acc: [87.5| 84.4| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.089, v_acc: 54.7, c_acc: 85.9}\n","STEP:954, D{v_l: 0.443, v_acc: [71.9| 81.2| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.247, v_acc: 40.6, c_acc: 92.2}\n","STEP:955, D{v_l: 0.467, v_acc: [87.5| 78.1| 82.8], c_acc: [100.0| 100.0]}  G{v_l: 0.865, v_acc: 54.7, c_acc: 95.3}\n","STEP:956, D{v_l: 0.246, v_acc: [90.6| 100.0| 95.3], c_acc: [100.0| 81.2]}  G{v_l: 0.908, v_acc: 53.1, c_acc: 92.2}\n","STEP:957, D{v_l: 0.446, v_acc: [81.2| 71.9| 76.6], c_acc: [93.8| 84.4]}  G{v_l: 0.757, v_acc: 57.8, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.5298 - valid_loss: 0.8056 - class_loss: 3.3208 - valid_acc: 0.5059 - class_acc: 0.5412\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0031 - valid_loss: 0.5735 - class_loss: 0.0262 - valid_acc: 0.6471 - class_acc: 1.0000\n","average v_acc: 57.647, three class acc: 54.118, two class acc: 61.176\n","====================================================================================================\n","STEP:958, D{v_l: 0.485, v_acc: [70.1| 75.0| 72.5], c_acc: [99.1| 90.6]}  G{v_l: 1.083, v_acc: 53.1, c_acc: 96.9}\n","STEP:959, D{v_l: 0.268, v_acc: [93.8| 90.6| 92.2], c_acc: [90.6| 93.8]}  G{v_l: 1.423, v_acc: 35.9, c_acc: 95.3}\n","STEP:960, D{v_l: 0.433, v_acc: [90.6| 75.0| 82.8], c_acc: [96.9| 93.8]}  G{v_l: 0.796, v_acc: 56.2, c_acc: 90.6}\n","STEP:961, D{v_l: 0.278, v_acc: [87.5| 93.8| 90.6], c_acc: [96.9| 93.8]}  G{v_l: 0.993, v_acc: 48.4, c_acc: 98.4}\n","STEP:962, D{v_l: 0.361, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 84.4]}  G{v_l: 1.004, v_acc: 46.9, c_acc: 95.3}\n","STEP:963, D{v_l: 0.472, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 84.4]}  G{v_l: 0.874, v_acc: 59.4, c_acc: 98.4}\n","STEP:964, D{v_l: 0.389, v_acc: [84.4| 93.8| 89.1], c_acc: [100.0| 100.0]}  G{v_l: 1.392, v_acc: 42.2, c_acc: 93.8}\n","STEP:965, D{v_l: 0.374, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 1.050, v_acc: 42.2, c_acc: 96.9}\n","STEP:966, D{v_l: 0.386, v_acc: [81.2| 90.6| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 1.007, v_acc: 50.0, c_acc: 87.5}\n","STEP:967, D{v_l: 0.391, v_acc: [84.4| 84.4| 84.4], c_acc: [100.0| 100.0]}  G{v_l: 0.894, v_acc: 59.4, c_acc: 87.5}\n","STEP:968, D{v_l: 0.404, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.149, v_acc: 53.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 4.7940 - valid_loss: 0.9230 - class_loss: 3.4676 - valid_acc: 0.4353 - class_acc: 0.5529\n","3/3 [==============================] - 0s 51ms/step - loss: 1.3137 - valid_loss: 0.7634 - class_loss: 0.1469 - valid_acc: 0.4353 - class_acc: 0.9412\n","average v_acc: 43.529, three class acc: 55.294, two class acc: 58.824\n","====================================================================================================\n","STEP:969, D{v_l: 0.489, v_acc: [54.7| 84.4| 69.5], c_acc: [94.9| 100.0]}  G{v_l: 0.868, v_acc: 56.2, c_acc: 85.9}\n","STEP:970, D{v_l: 0.265, v_acc: [87.5| 93.8| 90.6], c_acc: [93.8| 96.9]}  G{v_l: 0.892, v_acc: 48.4, c_acc: 95.3}\n","STEP:971, D{v_l: 0.432, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 1.043, v_acc: 56.2, c_acc: 90.6}\n","STEP:972, D{v_l: 0.503, v_acc: [81.2| 75.0| 78.1], c_acc: [93.8| 93.8]}  G{v_l: 1.002, v_acc: 48.4, c_acc: 92.2}\n","STEP:973, D{v_l: 0.367, v_acc: [90.6| 81.2| 85.9], c_acc: [93.8| 84.4]}  G{v_l: 0.947, v_acc: 46.9, c_acc: 96.9}\n","STEP:974, D{v_l: 0.351, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 0.913, v_acc: 57.8, c_acc: 98.4}\n","STEP:975, D{v_l: 0.482, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 0.814, v_acc: 64.1, c_acc: 98.4}\n","STEP:976, D{v_l: 0.251, v_acc: [96.9| 90.6| 93.8], c_acc: [93.8| 90.6]}  G{v_l: 0.841, v_acc: 59.4, c_acc: 100.0}\n","STEP:977, D{v_l: 0.352, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 1.023, v_acc: 50.0, c_acc: 98.4}\n","STEP:978, D{v_l: 0.285, v_acc: [96.9| 81.2| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 0.868, v_acc: 56.2, c_acc: 98.4}\n","STEP:979, D{v_l: 0.413, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 90.6]}  G{v_l: 0.790, v_acc: 62.5, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.1131 - valid_loss: 0.7375 - class_loss: 2.9724 - valid_acc: 0.5765 - class_acc: 0.5529\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0853 - valid_loss: 0.6192 - class_loss: 0.0629 - valid_acc: 0.5176 - class_acc: 0.9882\n","average v_acc: 54.706, three class acc: 55.294, two class acc: 64.706\n","====================================================================================================\n","STEP:980, D{v_l: 0.490, v_acc: [63.2| 78.1| 70.7], c_acc: [97.4| 90.6]}  G{v_l: 0.797, v_acc: 59.4, c_acc: 100.0}\n","STEP:981, D{v_l: 0.450, v_acc: [68.8| 87.5| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 0.865, v_acc: 53.1, c_acc: 98.4}\n","STEP:982, D{v_l: 0.348, v_acc: [100.0| 78.1| 89.1], c_acc: [87.5| 87.5]}  G{v_l: 1.203, v_acc: 50.0, c_acc: 100.0}\n","STEP:983, D{v_l: 0.260, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 84.4]}  G{v_l: 0.990, v_acc: 68.8, c_acc: 87.5}\n","STEP:984, D{v_l: 0.335, v_acc: [84.4| 84.4| 84.4], c_acc: [100.0| 90.6]}  G{v_l: 0.945, v_acc: 53.1, c_acc: 93.8}\n","STEP:985, D{v_l: 0.340, v_acc: [78.1| 90.6| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.849, v_acc: 48.4, c_acc: 95.3}\n","STEP:986, D{v_l: 0.396, v_acc: [90.6| 71.9| 81.2], c_acc: [87.5| 87.5]}  G{v_l: 1.170, v_acc: 46.9, c_acc: 98.4}\n","STEP:987, D{v_l: 0.507, v_acc: [78.1| 71.9| 75.0], c_acc: [87.5| 96.9]}  G{v_l: 1.049, v_acc: 46.9, c_acc: 98.4}\n","STEP:988, D{v_l: 0.384, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.801, v_acc: 70.3, c_acc: 95.3}\n","STEP:989, D{v_l: 0.346, v_acc: [75.0| 90.6| 82.8], c_acc: [96.9| 87.5]}  G{v_l: 1.250, v_acc: 50.0, c_acc: 89.1}\n","STEP:990, D{v_l: 0.371, v_acc: [81.2| 84.4| 82.8], c_acc: [84.4| 96.9]}  G{v_l: 0.912, v_acc: 60.9, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.2828 - valid_loss: 0.6179 - class_loss: 3.2616 - valid_acc: 0.6471 - class_acc: 0.5059\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1198 - valid_loss: 0.6493 - class_loss: 0.0673 - valid_acc: 0.5294 - class_acc: 0.9765\n","average v_acc: 58.824, three class acc: 50.588, two class acc: 57.647\n","====================================================================================================\n","Epoch: 90\n","====================================================================================================\n","STEP:991, D{v_l: 0.436, v_acc: [62.4| 87.5| 74.9], c_acc: [98.3| 93.8]}  G{v_l: 1.044, v_acc: 54.7, c_acc: 93.8}\n","STEP:992, D{v_l: 0.440, v_acc: [90.6| 78.1| 84.4], c_acc: [100.0| 100.0]}  G{v_l: 1.097, v_acc: 51.6, c_acc: 95.3}\n","STEP:993, D{v_l: 0.390, v_acc: [84.4| 75.0| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 1.106, v_acc: 56.2, c_acc: 96.9}\n","STEP:994, D{v_l: 0.276, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 1.395, v_acc: 40.6, c_acc: 92.2}\n","STEP:995, D{v_l: 0.399, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 1.223, v_acc: 51.6, c_acc: 93.8}\n","STEP:996, D{v_l: 0.459, v_acc: [87.5| 68.8| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 1.143, v_acc: 48.4, c_acc: 95.3}\n","STEP:997, D{v_l: 0.261, v_acc: [100.0| 87.5| 93.8], c_acc: [100.0| 96.9]}  G{v_l: 1.225, v_acc: 60.9, c_acc: 96.9}\n","STEP:998, D{v_l: 0.268, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 1.254, v_acc: 42.2, c_acc: 100.0}\n","STEP:999, D{v_l: 0.475, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.238, v_acc: 39.1, c_acc: 90.6}\n","STEP:1000, D{v_l: 0.249, v_acc: [90.6| 87.5| 89.1], c_acc: [93.8| 93.8]}  G{v_l: 1.192, v_acc: 40.6, c_acc: 92.2}\n","STEP:1001, D{v_l: 0.346, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.037, v_acc: 50.0, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.4428 - valid_loss: 0.7062 - class_loss: 2.3335 - valid_acc: 0.6000 - class_acc: 0.5412\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9048 - valid_loss: 0.4395 - class_loss: 0.0622 - valid_acc: 0.9059 - class_acc: 0.9765\n","average v_acc: 75.294, three class acc: 54.118, two class acc: 65.882\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_1001.h5\n","STEP:1002, D{v_l: 0.509, v_acc: [88.0| 78.1| 83.1], c_acc: [97.4| 100.0]}  G{v_l: 1.170, v_acc: 35.9, c_acc: 95.3}\n","STEP:1003, D{v_l: 0.545, v_acc: [71.9| 71.9| 71.9], c_acc: [96.9| 100.0]}  G{v_l: 1.003, v_acc: 39.1, c_acc: 95.3}\n","STEP:1004, D{v_l: 0.376, v_acc: [87.5| 78.1| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 1.086, v_acc: 42.2, c_acc: 96.9}\n","STEP:1005, D{v_l: 0.475, v_acc: [68.8| 87.5| 78.1], c_acc: [87.5| 100.0]}  G{v_l: 1.103, v_acc: 35.9, c_acc: 95.3}\n","STEP:1006, D{v_l: 0.375, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 1.160, v_acc: 34.4, c_acc: 95.3}\n","STEP:1007, D{v_l: 0.441, v_acc: [71.9| 90.6| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.257, v_acc: 28.1, c_acc: 96.9}\n","STEP:1008, D{v_l: 0.350, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.946, v_acc: 51.6, c_acc: 98.4}\n","STEP:1009, D{v_l: 0.342, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 1.236, v_acc: 43.8, c_acc: 96.9}\n","STEP:1010, D{v_l: 0.391, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 1.289, v_acc: 42.2, c_acc: 92.2}\n","STEP:1011, D{v_l: 0.425, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.235, v_acc: 48.4, c_acc: 89.1}\n","STEP:1012, D{v_l: 0.319, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 100.0]}  G{v_l: 1.098, v_acc: 37.5, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 3.2023 - valid_loss: 0.6771 - class_loss: 2.1220 - valid_acc: 0.5882 - class_acc: 0.5765\n","3/3 [==============================] - 0s 50ms/step - loss: 0.9965 - valid_loss: 0.4710 - class_loss: 0.1224 - valid_acc: 0.8941 - class_acc: 0.9647\n","average v_acc: 74.118, three class acc: 57.647, two class acc: 72.941\n","====================================================================================================\n",">Saved: AC_Brain/mode1/weights/d_model_1012.h5\n","STEP:1013, D{v_l: 0.428, v_acc: [88.9| 75.0| 81.9], c_acc: [94.9| 84.4]}  G{v_l: 0.926, v_acc: 46.9, c_acc: 92.2}\n","STEP:1014, D{v_l: 0.375, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.081, v_acc: 45.3, c_acc: 79.7}\n","STEP:1015, D{v_l: 0.347, v_acc: [93.8| 75.0| 84.4], c_acc: [90.6| 90.6]}  G{v_l: 1.099, v_acc: 40.6, c_acc: 96.9}\n","STEP:1016, D{v_l: 0.260, v_acc: [96.9| 78.1| 87.5], c_acc: [93.8| 90.6]}  G{v_l: 1.301, v_acc: 35.9, c_acc: 92.2}\n","STEP:1017, D{v_l: 0.226, v_acc: [90.6| 90.6| 90.6], c_acc: [87.5| 96.9]}  G{v_l: 1.066, v_acc: 48.4, c_acc: 92.2}\n","STEP:1018, D{v_l: 0.290, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 1.084, v_acc: 43.8, c_acc: 92.2}\n","STEP:1019, D{v_l: 0.396, v_acc: [87.5| 71.9| 79.7], c_acc: [100.0| 93.8]}  G{v_l: 0.987, v_acc: 53.1, c_acc: 92.2}\n","STEP:1020, D{v_l: 0.350, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.152, v_acc: 46.9, c_acc: 100.0}\n","STEP:1021, D{v_l: 0.487, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 96.9]}  G{v_l: 1.124, v_acc: 45.3, c_acc: 96.9}\n","STEP:1022, D{v_l: 0.296, v_acc: [96.9| 87.5| 92.2], c_acc: [84.4| 96.9]}  G{v_l: 0.933, v_acc: 56.2, c_acc: 98.4}\n","STEP:1023, D{v_l: 0.499, v_acc: [75.0| 71.9| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 1.083, v_acc: 59.4, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.3209 - valid_loss: 0.7402 - class_loss: 3.1777 - valid_acc: 0.5294 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1051 - valid_loss: 0.6377 - class_loss: 0.0644 - valid_acc: 0.5176 - class_acc: 0.9647\n","average v_acc: 52.353, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:1024, D{v_l: 0.401, v_acc: [61.5| 90.6| 76.1], c_acc: [96.6| 100.0]}  G{v_l: 1.229, v_acc: 46.9, c_acc: 92.2}\n","STEP:1025, D{v_l: 0.433, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 0.934, v_acc: 54.7, c_acc: 93.8}\n","STEP:1026, D{v_l: 0.383, v_acc: [84.4| 78.1| 81.2], c_acc: [96.9| 90.6]}  G{v_l: 1.287, v_acc: 51.6, c_acc: 92.2}\n","STEP:1027, D{v_l: 0.377, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 1.163, v_acc: 42.2, c_acc: 95.3}\n","STEP:1028, D{v_l: 0.296, v_acc: [93.8| 78.1| 85.9], c_acc: [100.0| 96.9]}  G{v_l: 0.878, v_acc: 51.6, c_acc: 90.6}\n","STEP:1029, D{v_l: 0.448, v_acc: [87.5| 71.9| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 0.794, v_acc: 64.1, c_acc: 90.6}\n","STEP:1030, D{v_l: 0.239, v_acc: [90.6| 87.5| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.848, v_acc: 65.6, c_acc: 90.6}\n","STEP:1031, D{v_l: 0.488, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 87.5]}  G{v_l: 1.058, v_acc: 45.3, c_acc: 96.9}\n","STEP:1032, D{v_l: 0.262, v_acc: [90.6| 87.5| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 1.088, v_acc: 53.1, c_acc: 96.9}\n","STEP:1033, D{v_l: 0.305, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.076, v_acc: 43.8, c_acc: 95.3}\n","STEP:1034, D{v_l: 0.345, v_acc: [84.4| 90.6| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 1.011, v_acc: 51.6, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.0982 - valid_loss: 0.5574 - class_loss: 2.1379 - valid_acc: 0.6941 - class_acc: 0.4941\n","3/3 [==============================] - 0s 55ms/step - loss: 1.0248 - valid_loss: 0.5851 - class_loss: 0.0367 - valid_acc: 0.5882 - class_acc: 0.9882\n","average v_acc: 64.118, three class acc: 49.412, two class acc: 62.353\n","====================================================================================================\n","STEP:1035, D{v_l: 0.378, v_acc: [66.7| 87.5| 77.1], c_acc: [97.4| 100.0]}  G{v_l: 0.900, v_acc: 56.2, c_acc: 96.9}\n","STEP:1036, D{v_l: 0.410, v_acc: [78.1| 78.1| 78.1], c_acc: [96.9| 93.8]}  G{v_l: 1.083, v_acc: 46.9, c_acc: 96.9}\n","STEP:1037, D{v_l: 0.364, v_acc: [96.9| 81.2| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 0.869, v_acc: 46.9, c_acc: 90.6}\n","STEP:1038, D{v_l: 0.282, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 1.049, v_acc: 50.0, c_acc: 93.8}\n","STEP:1039, D{v_l: 0.507, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.219, v_acc: 45.3, c_acc: 96.9}\n","STEP:1040, D{v_l: 0.308, v_acc: [90.6| 93.8| 92.2], c_acc: [93.8| 100.0]}  G{v_l: 0.933, v_acc: 53.1, c_acc: 95.3}\n","STEP:1041, D{v_l: 0.356, v_acc: [90.6| 75.0| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 0.901, v_acc: 59.4, c_acc: 96.9}\n","STEP:1042, D{v_l: 0.295, v_acc: [87.5| 84.4| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 1.268, v_acc: 48.4, c_acc: 95.3}\n","STEP:1043, D{v_l: 0.368, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 96.9]}  G{v_l: 1.032, v_acc: 56.2, c_acc: 93.8}\n","STEP:1044, D{v_l: 0.313, v_acc: [84.4| 93.8| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 1.004, v_acc: 46.9, c_acc: 96.9}\n","STEP:1045, D{v_l: 0.287, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 0.749, v_acc: 71.9, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.8278 - valid_loss: 0.6983 - class_loss: 2.7266 - valid_acc: 0.5882 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 1.2661 - valid_loss: 0.8269 - class_loss: 0.0363 - valid_acc: 0.3647 - class_acc: 0.9882\n","average v_acc: 47.647, three class acc: 50.588, two class acc: 60.000\n","====================================================================================================\n","STEP:1046, D{v_l: 0.503, v_acc: [50.4| 87.5| 69.0], c_acc: [98.3| 96.9]}  G{v_l: 0.734, v_acc: 53.1, c_acc: 96.9}\n","STEP:1047, D{v_l: 0.332, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 87.5]}  G{v_l: 0.912, v_acc: 59.4, c_acc: 98.4}\n","STEP:1048, D{v_l: 0.328, v_acc: [81.2| 90.6| 85.9], c_acc: [87.5| 90.6]}  G{v_l: 0.993, v_acc: 46.9, c_acc: 92.2}\n","STEP:1049, D{v_l: 0.247, v_acc: [87.5| 93.8| 90.6], c_acc: [90.6| 93.8]}  G{v_l: 0.896, v_acc: 57.8, c_acc: 100.0}\n","STEP:1050, D{v_l: 0.418, v_acc: [93.8| 71.9| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 1.043, v_acc: 45.3, c_acc: 93.8}\n","STEP:1051, D{v_l: 0.292, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 1.093, v_acc: 54.7, c_acc: 90.6}\n","STEP:1052, D{v_l: 0.374, v_acc: [84.4| 87.5| 85.9], c_acc: [100.0| 93.8]}  G{v_l: 1.105, v_acc: 54.7, c_acc: 98.4}\n","STEP:1053, D{v_l: 0.295, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 84.4]}  G{v_l: 0.799, v_acc: 62.5, c_acc: 95.3}\n","STEP:1054, D{v_l: 0.287, v_acc: [84.4| 78.1| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.019, v_acc: 51.6, c_acc: 90.6}\n","STEP:1055, D{v_l: 0.316, v_acc: [90.6| 78.1| 84.4], c_acc: [96.9| 90.6]}  G{v_l: 0.925, v_acc: 54.7, c_acc: 89.1}\n","STEP:1056, D{v_l: 0.427, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 0.909, v_acc: 54.7, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.6333 - valid_loss: 0.7124 - class_loss: 2.5180 - valid_acc: 0.5765 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 1.3284 - valid_loss: 0.8518 - class_loss: 0.0739 - valid_acc: 0.3529 - class_acc: 0.9647\n","average v_acc: 46.471, three class acc: 51.765, two class acc: 64.706\n","====================================================================================================\n","STEP:1057, D{v_l: 0.521, v_acc: [48.7| 84.4| 66.5], c_acc: [96.6| 90.6]}  G{v_l: 0.720, v_acc: 67.2, c_acc: 95.3}\n","STEP:1058, D{v_l: 0.294, v_acc: [90.6| 81.2| 85.9], c_acc: [100.0| 78.1]}  G{v_l: 0.986, v_acc: 57.8, c_acc: 89.1}\n","STEP:1059, D{v_l: 0.311, v_acc: [93.8| 84.4| 89.1], c_acc: [93.8| 87.5]}  G{v_l: 0.994, v_acc: 56.2, c_acc: 96.9}\n","STEP:1060, D{v_l: 0.501, v_acc: [71.9| 81.2| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 0.907, v_acc: 64.1, c_acc: 89.1}\n","STEP:1061, D{v_l: 0.371, v_acc: [84.4| 84.4| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 0.970, v_acc: 57.8, c_acc: 93.8}\n","STEP:1062, D{v_l: 0.400, v_acc: [75.0| 84.4| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 0.810, v_acc: 64.1, c_acc: 87.5}\n","STEP:1063, D{v_l: 0.211, v_acc: [90.6| 96.9| 93.8], c_acc: [100.0| 93.8]}  G{v_l: 1.148, v_acc: 53.1, c_acc: 90.6}\n","STEP:1064, D{v_l: 0.223, v_acc: [93.8| 90.6| 92.2], c_acc: [90.6| 100.0]}  G{v_l: 0.939, v_acc: 65.6, c_acc: 98.4}\n","STEP:1065, D{v_l: 0.310, v_acc: [93.8| 84.4| 89.1], c_acc: [100.0| 96.9]}  G{v_l: 1.161, v_acc: 51.6, c_acc: 98.4}\n","STEP:1066, D{v_l: 0.404, v_acc: [84.4| 71.9| 78.1], c_acc: [84.4| 87.5]}  G{v_l: 0.866, v_acc: 70.3, c_acc: 96.9}\n","STEP:1067, D{v_l: 0.360, v_acc: [90.6| 68.8| 79.7], c_acc: [93.8| 87.5]}  G{v_l: 0.798, v_acc: 62.5, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 5.1630 - valid_loss: 1.0263 - class_loss: 3.7340 - valid_acc: 0.3529 - class_acc: 0.5412\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1714 - valid_loss: 0.7316 - class_loss: 0.0369 - valid_acc: 0.4588 - class_acc: 0.9882\n","average v_acc: 40.588, three class acc: 54.118, two class acc: 60.000\n","====================================================================================================\n","STEP:1068, D{v_l: 0.431, v_acc: [57.3| 87.5| 72.4], c_acc: [99.1| 93.8]}  G{v_l: 0.560, v_acc: 78.1, c_acc: 87.5}\n","STEP:1069, D{v_l: 0.323, v_acc: [81.2| 90.6| 85.9], c_acc: [84.4| 100.0]}  G{v_l: 0.886, v_acc: 56.2, c_acc: 92.2}\n","STEP:1070, D{v_l: 0.362, v_acc: [87.5| 78.1| 82.8], c_acc: [96.9| 96.9]}  G{v_l: 1.041, v_acc: 54.7, c_acc: 92.2}\n","STEP:1071, D{v_l: 0.347, v_acc: [90.6| 78.1| 84.4], c_acc: [87.5| 96.9]}  G{v_l: 0.903, v_acc: 57.8, c_acc: 89.1}\n","STEP:1072, D{v_l: 0.280, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 100.0]}  G{v_l: 0.781, v_acc: 57.8, c_acc: 90.6}\n","STEP:1073, D{v_l: 0.461, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 0.953, v_acc: 57.8, c_acc: 89.1}\n","STEP:1074, D{v_l: 0.248, v_acc: [96.9| 81.2| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 0.857, v_acc: 62.5, c_acc: 96.9}\n","STEP:1075, D{v_l: 0.317, v_acc: [87.5| 75.0| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 0.885, v_acc: 56.2, c_acc: 95.3}\n","STEP:1076, D{v_l: 0.380, v_acc: [84.4| 87.5| 85.9], c_acc: [87.5| 96.9]}  G{v_l: 1.398, v_acc: 35.9, c_acc: 92.2}\n","STEP:1077, D{v_l: 0.337, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 0.925, v_acc: 68.8, c_acc: 95.3}\n","STEP:1078, D{v_l: 0.291, v_acc: [78.1| 90.6| 84.4], c_acc: [100.0| 96.9]}  G{v_l: 1.022, v_acc: 56.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.8227 - valid_loss: 0.9951 - class_loss: 3.4248 - valid_acc: 0.4118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 50ms/step - loss: 1.1521 - valid_loss: 0.6982 - class_loss: 0.0512 - valid_acc: 0.3765 - class_acc: 0.9647\n","average v_acc: 39.412, three class acc: 52.941, two class acc: 60.000\n","====================================================================================================\n","STEP:1079, D{v_l: 0.467, v_acc: [50.4| 84.4| 67.4], c_acc: [95.7| 96.9]}  G{v_l: 1.279, v_acc: 51.6, c_acc: 98.4}\n","STEP:1080, D{v_l: 0.423, v_acc: [81.2| 78.1| 79.7], c_acc: [90.6| 87.5]}  G{v_l: 1.098, v_acc: 60.9, c_acc: 98.4}\n","STEP:1081, D{v_l: 0.264, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 93.8]}  G{v_l: 1.237, v_acc: 50.0, c_acc: 90.6}\n","STEP:1082, D{v_l: 0.310, v_acc: [87.5| 81.2| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.160, v_acc: 57.8, c_acc: 96.9}\n","STEP:1083, D{v_l: 0.332, v_acc: [84.4| 84.4| 84.4], c_acc: [100.0| 100.0]}  G{v_l: 0.713, v_acc: 59.4, c_acc: 96.9}\n","STEP:1084, D{v_l: 0.335, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 1.086, v_acc: 64.1, c_acc: 96.9}\n","STEP:1085, D{v_l: 0.354, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.077, v_acc: 48.4, c_acc: 89.1}\n","STEP:1086, D{v_l: 0.368, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 1.080, v_acc: 50.0, c_acc: 90.6}\n","STEP:1087, D{v_l: 0.271, v_acc: [87.5| 96.9| 92.2], c_acc: [93.8| 100.0]}  G{v_l: 0.980, v_acc: 51.6, c_acc: 93.8}\n","STEP:1088, D{v_l: 0.219, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 90.6]}  G{v_l: 0.989, v_acc: 62.5, c_acc: 95.3}\n","STEP:1089, D{v_l: 0.473, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 1.049, v_acc: 42.2, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.9300 - valid_loss: 0.7898 - class_loss: 3.7375 - valid_acc: 0.5176 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0537 - valid_loss: 0.5664 - class_loss: 0.0847 - valid_acc: 0.6235 - class_acc: 0.9647\n","average v_acc: 57.059, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:1090, D{v_l: 0.490, v_acc: [68.4| 84.4| 76.4], c_acc: [97.4| 100.0]}  G{v_l: 1.093, v_acc: 43.8, c_acc: 89.1}\n","STEP:1091, D{v_l: 0.263, v_acc: [90.6| 87.5| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 1.094, v_acc: 50.0, c_acc: 92.2}\n","STEP:1092, D{v_l: 0.427, v_acc: [93.8| 81.2| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.473, v_acc: 35.9, c_acc: 89.1}\n","STEP:1093, D{v_l: 0.510, v_acc: [65.6| 93.8| 79.7], c_acc: [100.0| 93.8]}  G{v_l: 1.243, v_acc: 56.2, c_acc: 85.9}\n","STEP:1094, D{v_l: 0.324, v_acc: [87.5| 87.5| 87.5], c_acc: [100.0| 96.9]}  G{v_l: 0.933, v_acc: 56.2, c_acc: 87.5}\n","STEP:1095, D{v_l: 0.222, v_acc: [87.5| 96.9| 92.2], c_acc: [93.8| 96.9]}  G{v_l: 1.257, v_acc: 45.3, c_acc: 93.8}\n","STEP:1096, D{v_l: 0.379, v_acc: [93.8| 81.2| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 0.951, v_acc: 42.2, c_acc: 90.6}\n","STEP:1097, D{v_l: 0.247, v_acc: [93.8| 87.5| 90.6], c_acc: [87.5| 100.0]}  G{v_l: 1.072, v_acc: 48.4, c_acc: 98.4}\n","STEP:1098, D{v_l: 0.399, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 1.131, v_acc: 48.4, c_acc: 90.6}\n","STEP:1099, D{v_l: 0.309, v_acc: [87.5| 84.4| 85.9], c_acc: [100.0| 100.0]}  G{v_l: 1.030, v_acc: 45.3, c_acc: 95.3}\n","STEP:1100, D{v_l: 0.365, v_acc: [84.4| 93.8| 89.1], c_acc: [87.5| 100.0]}  G{v_l: 1.080, v_acc: 45.3, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.0369 - valid_loss: 0.6153 - class_loss: 3.0191 - valid_acc: 0.5882 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0937 - valid_loss: 0.5768 - class_loss: 0.1143 - valid_acc: 0.6588 - class_acc: 0.9412\n","average v_acc: 62.353, three class acc: 50.588, two class acc: 60.000\n","====================================================================================================\n","Epoch: 100\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ob42SPvoHxs7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621397840434,"user_tz":-480,"elapsed":3240,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"9a0e4d5f-7e4d-483d-c3b8-2550c6a3d500"},"source":["# # load data\n","# train_data, val_data, test_data = load_real_samples()\n","\n","model_path = '/weights/d_model_1001.h5'\n","test(LATENT_DIM, test_data, model_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 56ms/step - loss: 3.3217 - valid_loss: 0.5815 - class_loss: 2.3370 - valid_acc: 0.6731 - class_acc: 0.5213\n","test: 53.488\n","average v_acc: 67.442, three class acc: 53.488, two class acc: 63.953\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0       0.66      0.76      0.70        49\n","     class 1       0.35      0.27      0.30        26\n","     class 2       0.20      0.18      0.19        11\n","\n","    accuracy                           0.53        86\n","   macro avg       0.40      0.40      0.40        86\n","weighted avg       0.51      0.53      0.52        86\n","\n","AUC:  0.5916901459758602\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0       0.66      0.76      0.70        49\n","     class 1       0.60      0.49      0.54        37\n","\n","    accuracy                           0.64        86\n","   macro avg       0.63      0.62      0.62        86\n","weighted avg       0.63      0.64      0.63        86\n","\n","specificity: 0.7551020408163265\n","AUC:  0.5841147269718698\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-sNThj1KfcR2"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"Qb2ythFlffSu"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(latent_dim, test_dataset, pathway):\n","  # load model\n","  path = 'ACGAN/mode1'\n","\n","  d_model, _, _ = all_model(LATENT_DIM)\n","  d_model.load_weights(path + pathway)\n","\n","  X_test, labels_test, codes_test = test_dataset\n","  num_test = X_test.shape[0]\n","  y_test = ones((num_test, 1))\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = d_model.evaluate([X_test, codes_test], [y_test, labels_test], verbose=1)\n","  v_acc = 100 * test_metrics[3]\n","  three_c_acc = 100 * test_metrics[4]\n","\n","  # two class accuracy\n","  _, temp_pred = d_model.predict([X_test, codes_test])\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names))\n","\n","  # calculate AUC]\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GRf04_klYjg"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples()\n","\n","test(LATENT_DIM, test_data)"],"execution_count":null,"outputs":[]}]}