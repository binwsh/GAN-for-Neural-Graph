{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_AC_mode2.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","GI_kANkKEnmQ","_lIT_ZxfE1mZ","xaIOGJ22LzA6","cLWWWfE6L20n","fK7NGsGKL5Ts"],"authorship_tag":"ABX9TyNqF860pmz5rE0qK0qRdkBw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621218270303,"user_tz":-480,"elapsed":28942,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"0dfcd96c-a81b-482c-ebe3-8d0c87412651"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621218282397,"user_tz":-480,"elapsed":1013,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"fe641f54-073d-473a-ed46-7105837123ea"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621218282397,"user_tz":-480,"elapsed":1009,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"000b3d61-f304-41cc-919a-4bdcb11dcfe1"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.27251995 0.        ]\n"," [1.         0.28189535 1.        ]\n"," [2.         0.31851007 0.        ]\n"," [1.         0.4686431  1.        ]\n"," [0.         0.3294058  1.        ]\n"," [1.         0.38312429 1.        ]\n"," [0.         0.40973014 0.        ]\n"," [0.         0.51007222 0.        ]\n"," [0.         0.55036108 0.        ]\n"," [0.         0.36754086 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621218282398,"user_tz":-480,"elapsed":1002,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"589835c4-de4b-41f2-cbd0-2f60db3c0b5e"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[1.         0.         0.         0.27251995 0.        ]\n"," [0.         1.         0.         0.28189535 1.        ]\n"," [0.         0.         1.         0.31851007 0.        ]\n"," [0.         1.         0.         0.4686431  1.        ]\n"," [1.         0.         0.         0.3294058  1.        ]\n"," [0.         1.         0.         0.38312429 1.        ]\n"," [1.         0.         0.         0.40973014 0.        ]\n"," [1.         0.         0.         0.51007222 0.        ]\n"," [1.         0.         0.         0.55036108 0.        ]\n"," [1.         0.         0.         0.36754086 0.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1621219992360,"user_tz":-480,"elapsed":825,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"be72d3c5-bbef-4981-e437-a496b04e60af"},"source":["# Discriminator\n","DECAY = 0.0005\n","ALPHA = 0.33\n","LR_D = 0.0001\n","BETA_D = 0.5\n","FE_CHANNEL = 128\n","CODE_CHANNEL = 16\n","MERGE_CHANNEL = 64\n","\n","# Generator\n","D = 10\n","STD = 0.02\n","\n","# GAN\n","LR_G = 0.0001\n","BETA_G = 0.5\n","\n","# Loss weights\n","LOSS_WEIGHTS = [1.0, 1.0]\n","\n","# Train function\n","LATENT_DIM = 50\n","BATCH_SIZE = 64\n","\n","'''\n","The number of E2E layers\n","Channel size of E2E layers\n","Dropout\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\n'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"_lIT_ZxfE1mZ"},"source":["#Model function"]},{"cell_type":"code","metadata":{"id":"kYW-Fke9E5tT"},"source":["# define E2E layer\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.utils import conv_utils\n","\n","class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaIOGJ22LzA6"},"source":["# define D"]},{"cell_type":"code","metadata":{"id":"ySQCRi_RFACM"},"source":["# define the standalone discriminator model\n","def define_discriminator(image_shape=(190,190,1), n_classes=3):\n","  # weight regularization\n","  reg = regularizers.l2(DECAY)\n","  # weight initialization\n","  kernel_init = initializers.he_uniform()\n","  # image input\n","  in_image = Input(shape=image_shape, name='in_image')\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(in_image)  \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 64, (2, 190), kernel_regularizer=reg)(fe)     \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(128, (1, 190), kernel_regularizer=reg, name='row')(fe)  \n","  temp2 = Conv2D(128, (190, 1), kernel_regularizer=reg, name='column')(fe)\n","  temp2 = Reshape((190, 1, 128))(temp2)\n","  fe = Add()([temp1, temp2])\n","  fe = BatchNormalization()(fe)                          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(256, (190, 1), kernel_regularizer=reg)(fe) \n","  fe = BatchNormalization()(fe)          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # code input\n","  code_shape = (1,)\n","  in_code = Input(shape=code_shape, name='in_code')\n","\n","  code = Dense(CODE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(in_code)\n","  code = LeakyReLU(alpha=ALPHA)(code)\n","  code = Dropout(0.5)(code)\n","\n","  # concatenate image and code\n","  merge = Concatenate()([fe, code])\n","\n","  # # concatenate image and code\n","  # merge = Concatenate()([fe, in_code])\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(merge)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(0.5)(merge)\n","\n","  # real/fake output\n","  out1 = Dense(1, activation='sigmoid', name='valid')(merge)\n","  # class label output\n","  out2 = Dense(n_classes, activation='softmax', name='class')(merge)\n","  # define model\n","  model = Model([in_image, in_code], [out1, out2], name=\"Discriminator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLWWWfE6L20n"},"source":["# define G"]},{"cell_type":"code","metadata":{"id":"feTOreTCFQEr"},"source":["# define the standalone generator model\n","def define_generator(latent_dim=50, n_classes=3, d=D):\n","  #Initailize Weights\n","  init = RandomNormal(stddev=STD)\n","    \n","  #Take in noise as input\n","  in_z = keras.Input(shape=(latent_dim,))\n","  print(f\"Shape of Noise Vector: {in_z.shape}\")\n","  \n","  #Create a dense layer\n","  dense = keras.layers.Dense(190*d, activation=\"relu\", kernel_initializer = init)\n","  \n","  X = dense(in_z)\n","  X = keras.layers.Reshape((190,d))(X)\n","  print(f\"Shape of X: {X.shape}\")\n","\n","  A = keras.layers.Dot(axes=(2, 2))([X,X])\n","  A = keras.backend.expand_dims(A, axis = -1)\n","  \n","  A = Activation('tanh')(A)\n","  print(f\"Shape of A: {A.shape}\")\n","  \n","  # define model\n","  model = Model(in_z, A, name=\"Generator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK7NGsGKL5Ts"},"source":["#define GAN"]},{"cell_type":"code","metadata":{"id":"bzf_8DlyHJGD"},"source":["def all_model(latent_dim=LATENT_DIM):\n","  # define D & G\n","  d_model = define_discriminator()\n","  g_model = define_generator(latent_dim)\n","\n","  # compile D\n","  opt = optimizers.Adam(lr=LR_D, beta_1=BETA_D)\n","  d_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  # define GAN\n","  d_model.trainable = False\n"," \n","  in_noise = keras.Input(shape=(latent_dim,))\n","  img = g_model(in_noise)\n","\n","  in_code = keras.Input(shape=(1,))\n","  valid, label = d_model([img, in_code])\n","  gan_model = Model([in_noise, in_code], [valid, label], name=\"GAN\")\n","\n","  opt = optimizers.Adam(lr=LR_G, beta_1=BETA_G)\n","  gan_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  return d_model, g_model, gan_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8CEB6VkKsQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621219996933,"user_tz":-480,"elapsed":1599,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"28d5f65b-a1b1-4b24-c79f-b4fde263030a"},"source":["d_model, g_model, gan_model = all_model(LATENT_DIM)\n","d_model.summary()\n","g_model.summary()\n","gan_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","in_image (InputLayer)           [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv_4 (E2E_conv)           (None, 190, 190, 32) 12160       in_image[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 190, 190, 32) 128         e2e_conv_4[0][0]                 \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, 190, 190, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","e2e_conv_5 (E2E_conv)           (None, 190, 190, 64) 778240      leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 190, 190, 64) 256         e2e_conv_5[0][0]                 \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 190, 190, 64) 0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 190, 190, 64) 0           leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 128)  1556608     dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 128)  1556608     dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 190, 1, 128)  0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 190, 1, 128)  0           row[0][0]                        \n","                                                                 reshape_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 190, 1, 128)  512         add_2[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)      (None, 190, 1, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 190, 1, 128)  0           leaky_re_lu_16[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 1, 1, 256)    6226176     dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 1, 1, 256)    1024        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 1, 1, 256)    0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 1, 1, 256)    0           leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 256)          0           dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","in_code (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 64)           16448       flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 16)           32          in_code[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 64)           0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 16)           0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 64)           0           leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 16)           0           leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 80)           0           dropout_15[0][0]                 \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 32)           2592        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 32)           0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 32)           0           leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","valid (Dense)                   (None, 1)            33          dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 3)            99          dropout_17[0][0]                 \n","==================================================================================================\n","Total params: 10,150,916\n","Trainable params: 0\n","Non-trainable params: 10,150,916\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 1900)         96900       input_7[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_5 (Reshape)             (None, 190, 10)      0           dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","dot_2 (Dot)                     (None, 190, 190)     0           reshape_5[0][0]                  \n","                                                                 reshape_5[0][0]                  \n","__________________________________________________________________________________________________\n","tf.expand_dims_2 (TFOpLambda)   (None, 190, 190, 1)  0           dot_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 190, 190, 1)  0           tf.expand_dims_2[0][0]           \n","==================================================================================================\n","Total params: 96,900\n","Trainable params: 96,900\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","Generator (Functional)          (None, 190, 190, 1)  96900       input_8[0][0]                    \n","__________________________________________________________________________________________________\n","input_9 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Discriminator (Functional)      [(None, 1), (None, 3 10150916    Generator[0][0]                  \n","                                                                 input_9[0][0]                    \n","==================================================================================================\n","Total params: 10,247,816\n","Trainable params: 96,900\n","Non-trainable params: 10,150,916\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zm7qDbXsMJcD"},"source":["#Auxiliary function"]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, combine_val, combine_test = train_test_split(X_remain, combine_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  # seperate label, age, gender\n","  y_train = combine_train[:, 0]\n","  y_test = combine_test[:, 0]\n","  y_val = combine_val[:, 0]\n","  as_train = combine_train[:, 1:] \n","  as_test = combine_test[:, 1:]  \n","  as_val = combine_val[:, 1:]\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}, as shape: {as_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}, as shape: {as_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}, as shape: {as_test.shape}\")\n","\n","  output = [X_train, y_train, as_train[:, 1]],[X_val, y_val, as_val[:, 1]],[X_test, y_test, as_test[:, 1]]\n","  print(f\"Code_train shape: {as_train[:, 1].shape}\")\n","\n","  return output\n","\n","# select real samples\n","def generate_real_samples(dataset, n_samples):\n","  # split into images and labels\n","  images, labels, codes = dataset\n","  # choose random instances\n","  ix = np.random.randint(0, images.shape[0], n_samples)\n","  # select images and labels and codes\n","  y = np.ones((n_samples, 1))\n","  X, label, code = images[ix], labels[ix], codes[ix]\n","  return [X, code], [y, label]\n","\n","def generate_random_ecodings(n_samples):\n","  enc_idx = np.arange(0, len(encoded_data))\n","  sample_idx = np.random.choice(enc_idx, size = n_samples)\n","  samples = []\n","  labels = []\n","\n","  for idx in sample_idx:\n","    samples.append(encoded_data[idx])\n","    label = encoded_data[idx][:3]\n","    if label[0]==1:\n","        labels.append(0)\n","    elif label[1]==1:\n","        labels.append(1)\n","    else:\n","        labels.append(2)\n","  \n","  samples = np.array(samples)\n","  label = samples[:, :3]\n","  sex = samples[:, 4].reshape(-1,1)\n","  samples = np.concatenate([label, sex], axis=1)\n","  codes = sex\n","  return [samples, codes], labels\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, n_classes=3):\n","  #Generate noise, n_code dimension + label dimension \n","  n = 4      \n","  z_noise = np.random.normal(0, 1, size=[n_samples,latent_dim-n])   # Gaussian distribution\n","  #Generate encoding of 5 dimensions\n","  [z_encoding, codes], labels = generate_random_ecodings(n_samples)\n","  #Concatenate z_noise and z_encoding to create input of latent_dim\n","  z_input = np.concatenate((z_noise, z_encoding), axis = 1)\n","  labels = np.array(labels)\n","  return [z_input, codes], labels\n","\n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","  # generate points in latent space\n","  [z_input, codes], labels_input = generate_latent_points(latent_dim, n_samples)\n","  # predict outputs\n","  images = generator.predict(z_input)\n","  y = np.zeros((n_samples, 1))           \n","  return [images, codes], [y, labels_input]\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, d_model):\n","  path = 'ACGAN/mode2'\n","  filename1 = path + '/weights/d_model_%04d.h5' % (step+1)\n","  d_model.save_weights(filename1)\n","  print('>Saved: %s' % filename1)\n","\n","# create a line plot of loss for the gan and save to file\n","def plot_history(train_hist, validation_hist):\n","  path = 'ACGAN/mode2'\n","  # dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = train_hist\n","  # # plot train_data loss\n","  # pyplot.plot(dr_v_loss1, label='D-validity-real')\n","  # pyplot.plot(df_v_loss1, label='D-validity-fake')\n","  # pyplot.plot(g_v_loss1, label='G-validity')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_loss.pdf')\n","  # pyplot.close()\n"," \n","  # # plot train_datad accuracy\n","  # pyplot.plot(dr_v_acc1, label='validity-real')\n","  # pyplot.plot(df_v_acc1, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_valid_acc.pdf')\n","  # pyplot.close()\n","\n","  # pyplot.plot(dr_c_acc1, label='class-real')\n","  # pyplot.plot(df_c_acc1, label='class-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_class_acc.pdf')\n","  # pyplot.close()\n"," \n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = validation_hist\n","  # # plot validation_data loss\n","  # pyplot.plot(dr_v_loss2, label='validity-real')\n","  # pyplot.plot(df_v_loss2, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_validation_loss.pdf')\n","  # pyplot.close()\n","\n","  # plot validation_data accuracy\n","  pyplot.plot(dr_v_acc2, label='validity-real')\n","  pyplot.plot(df_v_acc2, label='validity-fake')\n","  pyplot.plot(dr_c_acc2, label='class-real')\n","  pyplot.legend()\n","  pyplot.savefig(path + '/plot_validation_acc.pdf')\n","  pyplot.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_aFGLeJHxs5"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"T9RhPPnOHxs6"},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, val_dataset, n_epochs=300, latent_dim=LATENT_DIM, n_batch=BATCH_SIZE):\n","  epoch=0\n","  # calculate the number of batches per training epoch\n","  bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","  # calculate the number of training iterations\n","  n_steps = bat_per_epo * n_epochs\n","  # calculate the real/fake batch_size\n","  half_batch = int(n_batch / 2)\n","  # prepare lists for train_data hist\n","  dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = list(), list(), list(), list(), list(), list(), list()\n","  # prepare lists for validation_data hist\n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = list(), list(), list(), list(), list()\n","\n","  # manually enumerate epochs\n","  for i in range(n_steps):\n","    #----------------------------------------\n","    # update discriminator model weights\n","    #----------------------------------------\n","\n","    # get randomly selected 'real' samples\n","    [X_real, code_real], [y_real, labels_real] = generate_real_samples(dataset, half_batch)\n","    dr_metrics = d_model.train_on_batch([X_real, code_real], [y_real, labels_real])\n","    # generate 'fake' \n","    [X_fake, code_fake], [y_fake, labels_fake] = generate_fake_samples(g_model, latent_dim, half_batch)\n","    df_metrics = d_model.train_on_batch([X_fake, code_fake], [y_fake, labels_fake])\n","\n","    # summarize the loss and accuracy\n","    d_metrics = 0.5 * np.add(dr_metrics, df_metrics)\n","\n","    #----------------------------------------\n","    # update the generator via the discriminator's error\n","    #----------------------------------------\n","\n","    # prepare points in latent space as input for the generator\n","    [z_input, codes_input], z_labels = generate_latent_points(latent_dim, n_batch)   \n","    y_gan = np.ones((n_batch, 1)) \n","    g_metrics = gan_model.train_on_batch([z_input, codes_input], [y_gan, z_labels])\n","\n","    # summarize loss on this batch\n","    print('STEP:%d, D{v_l: %.3f, v_acc: [%.1f| %.1f| %.1f], c_acc: [%.1f| %.1f]}  G{v_l: %.3f, v_acc: %.1f, c_acc: %.1f}'\n","        % (i+1, d_metrics[1], 100*dr_metrics[3], 100*df_metrics[3], 100*d_metrics[3], 100*dr_metrics[4], 100*df_metrics[4], \n","          g_metrics[1], 100*g_metrics[3], 100*g_metrics[4]))\n","    # metrics[0]: loss, metrics[1]: validity_loss, metrics[2]: classification_loss, metrics[3]: validity_accuracy, metrics[4]: classification_accuracy\n","\n","    # record history\n","    dr_v_loss1.append(dr_metrics[1])\n","    df_v_loss1.append(df_metrics[1])\n","    g_v_loss1.append(g_metrics[1])\n","    dr_v_acc1.append(dr_metrics[3])\n","    df_v_acc1.append(df_metrics[3])\n","    dr_c_acc1.append(dr_metrics[4])\n","    df_c_acc1.append(df_metrics[4])\n","\n","    #----------------------------------------\n","    # evaluation\n","    #----------------------------------------\n","    if (i+1) % (bat_per_epo) == 0:\n","      epoch+=1\n","      # generate real validation data\n","      X_r_val, labels_r_val, codes_r_val = val_dataset\n","      num_test = X_r_val.shape[0]\n","      # generate fake validation data\n","      y_r_val = ones((num_test, 1))\n","      [X_f_val, codes_f_val], [y_f_val, labels_f_val] = generate_fake_samples(g_model, latent_dim, num_test)\n","\n","      print(f\"\\nValidation Metrics of Discriminator:\")\n","      # evaluate both real and fake valid_dataset\n","      valid_metrics_r = d_model.evaluate([X_r_val, codes_r_val], [y_r_val, labels_r_val], verbose=1)\n","      valid_metrics_f = d_model.evaluate([X_f_val, codes_f_val], [y_f_val, labels_f_val], verbose=1)\n","\n","      v_acc = 50 * (valid_metrics_r[3] + valid_metrics_f[3])   \n","      three_c_acc = 100 * valid_metrics_r[4]\n","\n","      # two class accuracy\n","      _, labels_pred = d_model.predict([X_r_val, codes_r_val])\n","      labels_pred = np.argmax(labels_pred, axis=1)\n","      # print('val {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_r_val==0), np.sum(labels_r_val==1), np.sum(labels_r_val==2)))\n","      # print('pred {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_pred==0), np.sum(labels_pred==1), np.sum(labels_pred==2)))\n","      labels_2_val, labels_2_pred = labels_r_val.copy(), labels_pred.copy()\n","      # classify 2 as 1\n","      labels_2_val[labels_2_val==2] = 1\n","      labels_2_pred[labels_2_pred==2] = 1\n","      # calculate the accuracy \n","      correct = np.sum(labels_2_val==labels_2_pred)\n","      two_c_acc = correct / num_test * 100\n","\n","      print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","      print(\"=\"*100)\n","      # save good models\n","      # if (40 < v_acc < 60) and (three_c_acc > 63):\n","      if three_c_acc >60 or two_c_acc > 65:\n","        summarize_performance(i, d_model)\n","\n","      # record history\n","      dr_v_loss2.append(valid_metrics_r[1])\n","      df_v_loss2.append(valid_metrics_f[1])\n","      dr_v_acc2.append(valid_metrics_r[3])\n","      df_v_acc2.append(valid_metrics_f[3])\n","      dr_c_acc2.append(valid_metrics_r[4])\n","\n","    # print epoch\n","    if (i+1) % (bat_per_epo * 10) == 0:\n","      print(f\"Epoch: {epoch}\")\n","      print(\"=\"*100)\n","      \n","      # plot history\n","      train_hist = [dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1]\n","      validation_hist = [dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      plot_history(train_hist, validation_hist)\n","      point = [dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      np.save('ACGAN/mode2/point_0', point)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHWEBxezHxs6","executionInfo":{"status":"ok","timestamp":1621218535385,"user_tz":-480,"elapsed":1026,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"7b4a470a-bfb6-412d-a0dc-c040093ede21"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,), as shape: (758, 2)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,), as shape: (85, 2)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,), as shape: (86, 2)\n","Code_train shape: (758,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"t5Eitw1JHxs7","executionInfo":{"status":"error","timestamp":1621218569609,"user_tz":-480,"elapsed":35246,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"4ddc8d3a-8989-4ee1-f310-ba1de356c5c3"},"source":["epochs = 100\n","\n","# define model\n","discriminator, generator, gan_model = all_model(LATENT_DIM)\n","# train model\n","train(generator, discriminator, gan_model, train_data, val_data, n_epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","STEP:1, D{v_l: 1.771, v_acc: [31.2| 46.9| 39.1], c_acc: [40.6| 28.1]}  G{v_l: 0.914, v_acc: 28.1, c_acc: 31.2}\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ac11d2e14011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-0035f6500246>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, val_dataset, n_epochs, latent_dim, n_batch)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# generate 'fake'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_fake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_fake\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_fake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_fake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# summarize the loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"-sNThj1KfcR2"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"Qb2ythFlffSu"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(latent_dim, test_dataset, pathway):\n","  # load model\n","  path = 'ACGAN/mode2'\n","\n","  d_model, _, _ = all_model(LATENT_DIM)\n","  d_model.load_weights(path + pathway)\n","\n","  X_test, labels_test, codes_test = test_dataset\n","  num_test = X_test.shape[0]\n","  y_test = ones((num_test, 1))\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = d_model.evaluate([X_test, codes_test], [y_test, labels_test], verbose=1)\n","  v_acc = 100 * test_metrics[3]\n","  three_c_acc = 100 * test_metrics[4]\n","\n","  # two class accuracy\n","  _, temp_pred = d_model.predict([X_test, codes_test])\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names))\n","\n","  # calculate AUC]\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GRf04_klYjg"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples()\n","\n","test(LATENT_DIM, test_data)"],"execution_count":null,"outputs":[]}]}