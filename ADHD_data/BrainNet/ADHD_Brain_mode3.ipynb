{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_Brain_mode3.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","vkPKyA_EnJus","Qtzgq8Anm_Qc"],"authorship_tag":"ABX9TyMJqEOFr2vyc30OdbgAH08W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621413405784,"user_tz":-480,"elapsed":22636,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"b3e84b13-9ca3-46a2-9553-a1851646c68f"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'BrainNet',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413425665,"user_tz":-480,"elapsed":6671,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"d504d785-5f20-4281-d4ef-f22dfb4253ba"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621413425666,"user_tz":-480,"elapsed":6668,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"8ae0cbcb-ae0f-4561-a221-56b83dd69942"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.45267959 0.        ]\n"," [0.         0.5963512  0.        ]\n"," [0.         0.4895477  1.        ]\n"," [0.         0.37058153 0.        ]\n"," [2.         0.41695173 1.        ]\n"," [0.         0.29190422 0.        ]\n"," [0.         0.70049411 1.        ]\n"," [0.         0.45458001 0.        ]\n"," [0.         0.56708476 1.        ]\n"," [1.         0.50665146 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621413425667,"user_tz":-480,"elapsed":6663,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"783e8e47-c6cd-4899-8b14-b887564d0ae3"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[1.         0.         0.         0.45267959 0.        ]\n"," [1.         0.         0.         0.5963512  0.        ]\n"," [1.         0.         0.         0.4895477  1.        ]\n"," [1.         0.         0.         0.37058153 0.        ]\n"," [0.         0.         1.         0.41695173 1.        ]\n"," [1.         0.         0.         0.29190422 0.        ]\n"," [1.         0.         0.         0.70049411 1.        ]\n"," [1.         0.         0.         0.45458001 0.        ]\n"," [1.         0.         0.         0.56708476 1.        ]\n"," [0.         1.         0.         0.50665146 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","\n","  y_train = combine_train[:, 0]\n","  y_remain = combine_remain[:, 0]\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, y_val, y_test = train_test_split(X_remain, y_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}\")\n","\n","  return [X_train, y_train],[X_val, y_val],[X_test, y_test]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkPKyA_EnJus"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"0Wxk5EiwnL6G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413425668,"user_tz":-480,"elapsed":5451,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"dfbc22b2-f6ab-4210-a9aa-45c68d1525f3"},"source":["DROPOUT = 0.5\n","MOMENTUM = 0.9\n","LR = 0.001  \n","DECAY = 0.0005\n","ALPHA = 0.33\n","FE_CHANNEL = 64\n","MERGE_CHANNEL = 32\n","BATCH_SIZE = 32\n","\n","'''\n","The number of E2E layers\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Qtzgq8Anm_Qc"},"source":["#Build Model"]},{"cell_type":"code","metadata":{"id":"GQnmpA-znDOP"},"source":["class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7G8B4M4oO6x"},"source":["def define_E2E(in_shape=(190,190,1), n_classes=3):\n","  # Setting l2_norm regularizer\n","  reg = regularizers.l2(DECAY)\n","  # kernel initialization\n","  kernel_init = initializers.he_uniform()\n","  in_image = Input(shape=in_shape)\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 16, (2, 190), kernel_regularizer=reg)(in_image) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(fe) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(64, (1, 190), kernel_regularizer=reg, name='row')(fe)   \n","  temp2 = Conv2D(64, (190, 1), kernel_regularizer=reg, name='column')(fe) \n","  temp2 = Reshape((190, 1, 64))(temp2)\n","  fe = Add()([temp1, temp2])                    \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(128, (190, 1), kernel_regularizer=reg)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(DROPOUT)(fe)\n","  \n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(DROPOUT)(merge)\n","\n","  out = Dense(n_classes, activation='softmax', name='out')(merge)\n","    \n","  # define model\n","  model = Model(in_image, out)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuQssoINq2Jd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413431508,"user_tz":-480,"elapsed":10487,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"f550d161-0c42-4281-b9f0-f303f3224934"},"source":["BrainNetCNN = define_E2E()\n","BrainNetCNN.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 16) 6080        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 16) 0           e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 32) 194560      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 32) 0           e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 64)   0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 64)   0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 64)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 128)    1556608     leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 128)    0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 128)          0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 64)           8256        flatten[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 64)           0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 64)           0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 32)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 32)           0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","out (Dense)                     (None, 3)            99          dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 2,546,051\n","Trainable params: 2,546,051\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UyIRcJy2hxMX"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rd_o2htT2Jz","executionInfo":{"status":"ok","timestamp":1621413441546,"user_tz":-480,"elapsed":1009,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"9c62a98b-e5ab-41c7-c7d4-59f7f4a6b51b"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)\n","X_train, y_train = train_data\n","X_val, y_val = val_data\n","X_test, y_test = test_data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9m8iJp4eq3Cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414646419,"user_tz":-480,"elapsed":84402,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"fb73ac5c-7468-46c3-a0a9-25f780a417dc"},"source":["path = \"./BrainNet/mode3/epoch_30.h5\"\n","batch_size = BATCH_SIZE\n","\n","opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","checkpoint = ModelCheckpoint(path, monitor='val_acc', verbose=0, save_best_only=True)\n","earlystopping = EarlyStopping(patience=10)\n","callbacks_list = [checkpoint,earlystopping]\n","\n","# define model\n","model_1 = define_E2E()\n","model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","\n","# train\n","history = model_1.fit(X_train, y_train,\n","              epochs=100,\n","              batch_size=batch_size,\n","              validation_data=(X_val, y_val),\n","              callbacks=callbacks_list,\n","              shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","24/24 [==============================] - 5s 140ms/step - loss: 1.2797 - acc: 0.4949 - val_loss: 1.2365 - val_acc: 0.5294\n","Epoch 2/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.1908 - acc: 0.6161 - val_loss: 1.2079 - val_acc: 0.5294\n","Epoch 3/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.1438 - acc: 0.6207 - val_loss: 1.2144 - val_acc: 0.5294\n","Epoch 4/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.1371 - acc: 0.6350 - val_loss: 1.2022 - val_acc: 0.5294\n","Epoch 5/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.1261 - acc: 0.6271 - val_loss: 1.2040 - val_acc: 0.5294\n","Epoch 6/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.1263 - acc: 0.6216 - val_loss: 1.2054 - val_acc: 0.5294\n","Epoch 7/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.1271 - acc: 0.6223 - val_loss: 1.2032 - val_acc: 0.5294\n","Epoch 8/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.1024 - acc: 0.6377 - val_loss: 1.1966 - val_acc: 0.5294\n","Epoch 9/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.1018 - acc: 0.6401 - val_loss: 1.1930 - val_acc: 0.5294\n","Epoch 10/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.0845 - acc: 0.6403 - val_loss: 1.1995 - val_acc: 0.5294\n","Epoch 11/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.0807 - acc: 0.6335 - val_loss: 1.2093 - val_acc: 0.5294\n","Epoch 12/100\n","24/24 [==============================] - 3s 125ms/step - loss: 1.0716 - acc: 0.6358 - val_loss: 1.1862 - val_acc: 0.5294\n","Epoch 13/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.0852 - acc: 0.6235 - val_loss: 1.1665 - val_acc: 0.5294\n","Epoch 14/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.0251 - acc: 0.6331 - val_loss: 1.1580 - val_acc: 0.5294\n","Epoch 15/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.0337 - acc: 0.6394 - val_loss: 1.1521 - val_acc: 0.5294\n","Epoch 16/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.0395 - acc: 0.6212 - val_loss: 1.1622 - val_acc: 0.5294\n","Epoch 17/100\n","24/24 [==============================] - 3s 123ms/step - loss: 0.9986 - acc: 0.6245 - val_loss: 1.1358 - val_acc: 0.5294\n","Epoch 18/100\n","24/24 [==============================] - 3s 123ms/step - loss: 0.9759 - acc: 0.6372 - val_loss: 1.1503 - val_acc: 0.5294\n","Epoch 19/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.8956 - acc: 0.6626 - val_loss: 1.1443 - val_acc: 0.5529\n","Epoch 20/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.8903 - acc: 0.6801 - val_loss: 1.2031 - val_acc: 0.5059\n","Epoch 21/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.8319 - acc: 0.6949 - val_loss: 1.2599 - val_acc: 0.5294\n","Epoch 22/100\n","24/24 [==============================] - 3s 123ms/step - loss: 0.8136 - acc: 0.7051 - val_loss: 1.2089 - val_acc: 0.5647\n","Epoch 23/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.7899 - acc: 0.7353 - val_loss: 1.2308 - val_acc: 0.5059\n","Epoch 24/100\n","24/24 [==============================] - 3s 124ms/step - loss: 1.0511 - acc: 0.5906 - val_loss: 1.1934 - val_acc: 0.5294\n","Epoch 25/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.8692 - acc: 0.6183 - val_loss: 1.3945 - val_acc: 0.5294\n","Epoch 26/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.7848 - acc: 0.6734 - val_loss: 1.1954 - val_acc: 0.5294\n","Epoch 27/100\n","24/24 [==============================] - 3s 124ms/step - loss: 0.7159 - acc: 0.7487 - val_loss: 1.2976 - val_acc: 0.5882\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R49IOGksbLN5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414647703,"user_tz":-480,"elapsed":55778,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"d1ab7d31-2837-45ed-a87d-45c49c7ad507"},"source":["test_data = [X_test, y_test]\n","test(test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 20ms/step - loss: 1.4374 - acc: 0.5526\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4bf60e0320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","test: 53.488\n","three class acc: 53.488, two class acc: 61.628\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6538    0.6939    0.6733        49\n","     class 1     0.3529    0.4615    0.4000        26\n","     class 2     0.0000    0.0000    0.0000        11\n","\n","    accuracy                         0.5349        86\n","   macro avg     0.3356    0.3851    0.3578        86\n","weighted avg     0.4792    0.5349    0.5045        86\n","\n","AUC:  0.6536427857856429\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6538    0.6939    0.6733        49\n","     class 1     0.5588    0.5135    0.5352        37\n","\n","    accuracy                         0.6163        86\n","   macro avg     0.6063    0.6037    0.6042        86\n","weighted avg     0.6130    0.6163    0.6139        86\n","\n","specificity: 0.6938775510204082\n","AUC:  0.6530612244897959\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zh38Vf_nrYKk"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_learning_curves(history,epoch,min_val,max_val):\n","        pd.DataFrame(history.history).plot(figsize=(8,5))\n","        plt.grid(True)\n","        plt.axis([0, epoch, min_val, max_val])\n","        plt.show()\n","plot_learning_curves(history,5,0,2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X70XqBemjGDD"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"xPBbaCfhe6XB"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","\n","def test(test_dataset):\n","  # load model\n","  path = \"./BrainNet/mode3/epoch_30.h5\"\n","  model_1 = define_E2E()\n","  opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","  model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","  model_1.load_weights(path)\n","\n","  X_test, labels_test = test_dataset\n","  num_test = X_test.shape[0]\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = model_1.evaluate(X_test, labels_test, verbose=1)\n","  three_c_acc = 100 * test_metrics[1]\n","\n","  # two class accuracy\n","  temp_pred = model_1.predict(X_test)\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('three class acc: %.3f, two class acc: %.3f' % (three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names, digits=4))\n","\n","  # calculate AUC\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names, digits=4))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DhuhxEeiX9X"},"source":["test_data = [X_test, y_test]\n","test(test_data)"],"execution_count":null,"outputs":[]}]}