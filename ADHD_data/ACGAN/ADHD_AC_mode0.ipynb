{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_AC_mode0.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","GI_kANkKEnmQ","_lIT_ZxfE1mZ","xaIOGJ22LzA6","cLWWWfE6L20n","fK7NGsGKL5Ts"],"authorship_tag":"ABX9TyP7apeHtYuKGxaL1x3W6dkD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621303129962,"user_tz":-480,"elapsed":18726,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"d69a6e51-b73a-413c-e557-5960f26071cc"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'BrainNet',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621303141537,"user_tz":-480,"elapsed":5290,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"9cfaf26a-2fc2-4990-8ac1-c512e13fb917"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621303141537,"user_tz":-480,"elapsed":5286,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"a286c9da-8d05-48cf-ef76-93324bd68bf5"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1.         0.79399468 1.        ]\n"," [0.         0.55758267 1.        ]\n"," [2.         0.44279742 1.        ]\n"," [0.         0.51615355 1.        ]\n"," [0.         0.36602052 1.        ]\n"," [0.         0.3154694  1.        ]\n"," [0.         0.40288864 0.        ]\n"," [0.         0.42759407 1.        ]\n"," [0.         0.60623337 0.        ]\n"," [2.         0.39262638 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5"},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621303141538,"user_tz":-480,"elapsed":5282,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"592acef9-9a82-41c0-bfee-abab10cd97be"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[0.         1.         0.         0.79399468 1.        ]\n"," [1.         0.         0.         0.55758267 1.        ]\n"," [0.         0.         1.         0.44279742 1.        ]\n"," [1.         0.         0.         0.51615355 1.        ]\n"," [1.         0.         0.         0.36602052 1.        ]\n"," [1.         0.         0.         0.3154694  1.        ]\n"," [1.         0.         0.         0.40288864 0.        ]\n"," [1.         0.         0.         0.42759407 1.        ]\n"," [1.         0.         0.         0.60623337 0.        ]\n"," [0.         0.         1.         0.39262638 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621303143907,"user_tz":-480,"elapsed":819,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"ccb2215e-32e8-407e-d796-50db5339eee5"},"source":["# Discriminator\n","DECAY = 0.0005\n","ALPHA = 0.33\n","LR_D = 0.0001\n","BETA_D = 0.5\n","\n","FE_CHANNEL = 128\n","CODE_CHANNEL = 32\n","MERGE_CHANNEL = 64\n","\n","\n","# Generator\n","D = 10   # Generator embeddings\n","STD = 0.02\n","\n","# GAN\n","LR_G = 0.0001\n","BETA_G = 0.5\n","\n","# Loss weights\n","LOSS_WEIGHTS = [1.0, 1.0]\n","\n","# Train function\n","LATENT_DIM = 50\n","BATCH_SIZE = 64\n","\n","'''\n","The number of E2E layers\n","Channel size of E2E layers\n","Dropout\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\nChannel size of E2E layers\\nDropout\\n'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"leybXMq6RMB9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_lIT_ZxfE1mZ"},"source":["#Model function"]},{"cell_type":"code","metadata":{"id":"kYW-Fke9E5tT"},"source":["# define E2E layer\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.utils import conv_utils\n","\n","class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaIOGJ22LzA6"},"source":["# define D"]},{"cell_type":"code","metadata":{"id":"ySQCRi_RFACM"},"source":["# define the standalone discriminator model\n","def define_discriminator(image_shape=(190,190,1), n_classes=3):\n","  # weight regularization\n","  reg = regularizers.l2(DECAY)\n","  # weight initialization\n","  kernel_init = initializers.he_uniform()\n","  # image input\n","  in_image = Input(shape=image_shape, name='in_image')\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(in_image)  \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 64, (2, 190), kernel_regularizer=reg)(fe)     \n","  fe = BatchNormalization()(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(128, (1, 190), kernel_regularizer=reg, name='row')(fe)  \n","  temp2 = Conv2D(128, (190, 1), kernel_regularizer=reg, name='column')(fe)\n","  temp2 = Reshape((190, 1, 128))(temp2)\n","  fe = Add()([temp1, temp2])\n","  fe = BatchNormalization()(fe)                          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(256, (190, 1), kernel_regularizer=reg)(fe) \n","  fe = BatchNormalization()(fe)          \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(0.5)(fe)\n","\n","  # code input\n","  code_shape = (2,)  # sex  16\n","  in_code = Input(shape=code_shape, name='in_code')\n","\n","  code = Dense(CODE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(in_code)\n","  code = LeakyReLU(alpha=ALPHA)(code)\n","  code = Dropout(0.5)(code)\n","\n","  # concatenate image and code\n","  merge = Concatenate()([fe, code])\n","\n","  # # concatenate image and code\n","  # merge = Concatenate()([fe, in_code])\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(merge)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(0.5)(merge)\n","\n","  # real/fake output\n","  out1 = Dense(1, activation='sigmoid', name='valid')(merge)\n","  # class label output\n","  out2 = Dense(n_classes, activation='softmax', name='class')(merge)\n","  # define model\n","  model = Model([in_image, in_code], [out1, out2], name=\"Discriminator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLWWWfE6L20n"},"source":["# define G"]},{"cell_type":"code","metadata":{"id":"feTOreTCFQEr"},"source":["# define the standalone generator model\n","def define_generator(latent_dim=50, n_classes=3, d=D):\n","  #Initailize Weights\n","  init = RandomNormal(stddev=STD)\n","    \n","  #Take in noise as input\n","  in_z = keras.Input(shape=(latent_dim,))\n","  print(f\"Shape of Noise Vector: {in_z.shape}\")\n","  \n","  #Create a dense layer\n","  dense = keras.layers.Dense(190*d, activation=\"relu\", kernel_initializer = init)\n","  \n","  X = dense(in_z)\n","  X = keras.layers.Reshape((190,d))(X)\n","  print(f\"Shape of X: {X.shape}\")\n","\n","  A = keras.layers.Dot(axes=(2, 2))([X,X])\n","  A = keras.backend.expand_dims(A, axis = -1)\n","\n","  A = Activation('tanh')(A)\n","  print(f\"Shape of A: {A.shape}\")\n","  \n","  # define model\n","  model = Model(in_z, A, name=\"Generator\")\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK7NGsGKL5Ts"},"source":["#define GAN"]},{"cell_type":"code","metadata":{"id":"bzf_8DlyHJGD"},"source":["def all_model(latent_dim=LATENT_DIM):\n","  # define D & G\n","  d_model = define_discriminator()\n","  g_model = define_generator(latent_dim)\n","\n","  # compile D\n","  opt = optimizers.Adam(lr=LR_D, beta_1=BETA_D)\n","  d_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  # define GAN\n","  d_model.trainable = False\n"," \n","  in_noise = keras.Input(shape=(latent_dim,))\n","  img = g_model(in_noise)\n","\n","  in_code = keras.Input(shape=(2,))\n","  # in_code = keras.Input(shape=(1,))\n","  valid, label = d_model([img, in_code])\n","  gan_model = Model([in_noise, in_code], [valid, label], name=\"GAN\")\n","\n","  opt = optimizers.Adam(lr=LR_G, beta_1=BETA_G)\n","  gan_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], loss_weights=LOSS_WEIGHTS, optimizer=opt, metrics=['acc'])\n","\n","  return d_model, g_model, gan_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8CEB6VkKsQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621303152896,"user_tz":-480,"elapsed":6665,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"393dead8-84b7-4b6d-8f7f-3b4ab4a9542c"},"source":["d_model, g_model, gan_model = all_model(LATENT_DIM)\n","d_model.summary()\n","g_model.summary()\n","gan_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","in_image (InputLayer)           [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 32) 12160       in_image[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 190, 190, 32) 128         e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 64) 778240      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 190, 190, 64) 256         e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 190, 190, 64) 0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 128)  1556608     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 128)  0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 128)  0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 190, 1, 128)  512         add[0][0]                        \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 190, 1, 128)  0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 256)    6226176     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 1, 1, 256)    1024        conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 256)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1, 1, 256)    0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 256)          0           dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","in_code (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          32896       flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 32)           96          in_code[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 32)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32)           0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 160)          0           dropout_3[0][0]                  \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           10304       concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 64)           0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","valid (Dense)                   (None, 1)            65          dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 3)            195         dropout_5[0][0]                  \n","==================================================================================================\n","Total params: 10,175,268\n","Trainable params: 0\n","Non-trainable params: 10,175,268\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1900)         96900       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 190, 10)      0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 190, 190)     0           reshape_1[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","tf.expand_dims (TFOpLambda)     (None, 190, 190, 1)  0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 190, 190, 1)  0           tf.expand_dims[0][0]             \n","==================================================================================================\n","Total params: 96,900\n","Trainable params: 96,900\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","Generator (Functional)          (None, 190, 190, 1)  96900       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","Discriminator (Functional)      [(None, 1), (None, 3 10175268    Generator[0][0]                  \n","                                                                 input_3[0][0]                    \n","==================================================================================================\n","Total params: 10,272,168\n","Trainable params: 96,900\n","Non-trainable params: 10,175,268\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zm7qDbXsMJcD"},"source":["#Auxiliary function"]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ"},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, combine_val, combine_test = train_test_split(X_remain, combine_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  # seperate label, age, gender\n","  y_train = combine_train[:, 0]\n","  y_test = combine_test[:, 0]\n","  y_val = combine_val[:, 0]\n","  as_train = combine_train[:, 1:] \n","  as_test = combine_test[:, 1:]  \n","  as_val = combine_val[:, 1:]\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}, as shape: {as_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}, as shape: {as_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}, as shape: {as_test.shape}\")\n","\n","  output = [X_train, y_train, as_train],[X_val, y_val, as_val],[X_test, y_test, as_test]\n","  print(f\"Code_train shape: {as_train.shape}\")\n","\n","  return output\n","\n","# select real samples\n","def generate_real_samples(dataset, n_samples):\n","  # split into images and labels\n","  images, labels, codes = dataset\n","  # choose random instances\n","  ix = np.random.randint(0, images.shape[0], n_samples)\n","  # select images and labels and codes\n","  y = np.ones((n_samples, 1))\n","  X, label, code = images[ix], labels[ix], codes[ix]\n","  return [X, code], [y, label]\n","\n","def generate_random_ecodings(n_samples):\n","  enc_idx = np.arange(0, len(encoded_data))\n","  sample_idx = np.random.choice(enc_idx, size = n_samples)\n","  samples = []\n","  labels = []\n","\n","  for idx in sample_idx:\n","    samples.append(encoded_data[idx])\n","    label = encoded_data[idx][:3]\n","    if label[0]==1:\n","        labels.append(0)\n","    elif label[1]==1:\n","        labels.append(1)\n","    else:\n","        labels.append(2)\n","  \n","  samples = np.array(samples)\n","  label = samples[:, :3]\n","  age = samples[:, 3].reshape(-1,1)\n","  sex = samples[:, 4].reshape(-1,1)\n","  codes = np.concatenate([age, sex], axis=1)\n","  return [samples, codes], labels\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, n_classes=3):\n","  #Generate noise, n_code dimension + label dimension \n","  n = 5       # 2 + 3\n","  z_noise = np.random.normal(0, 1, size=[n_samples,latent_dim-n])   # Gaussian distribution\n","  #Generate encoding of 5 dimensions\n","  [z_encoding, codes], labels = generate_random_ecodings(n_samples)\n","  #Concatenate z_noise and z_encoding to create input of latent_dim\n","  z_input = np.concatenate((z_noise, z_encoding), axis = 1)\n","  labels = np.array(labels)\n","  return [z_input, codes], labels\n","\n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","  # generate points in latent space\n","  [z_input, codes], labels_input = generate_latent_points(latent_dim, n_samples)\n","  # predict outputs\n","  images = generator.predict(z_input)\n","  y = np.zeros((n_samples, 1))           \n","  return [images, codes], [y, labels_input]\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, d_model):\n","  path = 'ACGAN/mode0'\n","  filename1 = path + '/weights/d_model_%04d.h5' % (step+1)\n","  d_model.save_weights(filename1)\n","  print('>Saved: %s' % filename1)\n","\n","# create a line plot of loss for the gan and save to file\n","def plot_history(train_hist, validation_hist):\n","  path = 'ACGAN/mode0'\n","  # dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = train_hist\n","  # # plot train_data loss\n","  # pyplot.plot(dr_v_loss1, label='D-validity-real')\n","  # pyplot.plot(df_v_loss1, label='D-validity-fake')\n","  # pyplot.plot(g_v_loss1, label='G-validity')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_loss.pdf')\n","  # pyplot.close()\n"," \n","  # # plot train_datad accuracy\n","  # pyplot.plot(dr_v_acc1, label='validity-real')\n","  # pyplot.plot(df_v_acc1, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_valid_acc.pdf')\n","  # pyplot.close()\n","\n","  # pyplot.plot(dr_c_acc1, label='class-real')\n","  # pyplot.plot(df_c_acc1, label='class-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_train_class_acc.pdf')\n","  # pyplot.close()\n"," \n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = validation_hist\n","  # # plot validation_data loss\n","  # pyplot.plot(dr_v_loss2, label='validity-real')\n","  # pyplot.plot(df_v_loss2, label='validity-fake')\n","  # pyplot.legend()\n","  # pyplot.savefig(path + '/plot_validation_loss.pdf')\n","  # pyplot.close()\n","\n","  # plot validation_data accuracy\n","  pyplot.plot(dr_v_acc2, label='validity-real')\n","  pyplot.plot(df_v_acc2, label='validity-fake')\n","  pyplot.plot(dr_c_acc2, label='class-real')\n","  pyplot.legend()\n","  pyplot.savefig(path + '/val_acc.pdf')\n","  pyplot.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i4q7BrEyjTh2"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"ad0hvdDOjO96"},"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, val_dataset, n_epochs=300, latent_dim=LATENT_DIM, n_batch=BATCH_SIZE):\n","  epoch=0\n","  # calculate the number of batches per training epoch\n","  bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","  # calculate the number of training iterations\n","  n_steps = bat_per_epo * n_epochs\n","  # calculate the real/fake batch_size\n","  half_batch = int(n_batch / 2)\n","  # prepare lists for train_data hist\n","  dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1 = list(), list(), list(), list(), list(), list(), list()\n","  # prepare lists for validation_data hist\n","  dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2 = list(), list(), list(), list(), list()\n","\n","  # manually enumerate epochs\n","  for i in range(n_steps):\n","    #----------------------------------------\n","    # update discriminator model weights\n","    #----------------------------------------\n","\n","    # get randomly selected 'real' samples\n","    [X_real, code_real], [y_real, labels_real] = generate_real_samples(dataset, half_batch)\n","    dr_metrics = d_model.train_on_batch([X_real, code_real], [y_real, labels_real])\n","    # generate 'fake' \n","    [X_fake, code_fake], [y_fake, labels_fake] = generate_fake_samples(g_model, latent_dim, half_batch)\n","    df_metrics = d_model.train_on_batch([X_fake, code_fake], [y_fake, labels_fake])\n","\n","    # summarize the loss and accuracy\n","    d_metrics = 0.5 * np.add(dr_metrics, df_metrics)\n","\n","    #----------------------------------------\n","    # update the generator via the discriminator's error\n","    #----------------------------------------\n","\n","    # prepare points in latent space as input for the generator\n","    [z_input, codes_input], z_labels = generate_latent_points(latent_dim, n_batch)   \n","    y_gan = np.ones((n_batch, 1)) \n","    g_metrics = gan_model.train_on_batch([z_input, codes_input], [y_gan, z_labels])\n","\n","    # summarize loss on this batch\n","    print('STEP:%d, D{v_l: %.3f, v_acc: [%.1f| %.1f| %.1f], c_acc: [%.1f| %.1f]}  G{v_l: %.3f, v_acc: %.1f, c_acc: %.1f}'\n","        % (i+1, d_metrics[1], 100*dr_metrics[3], 100*df_metrics[3], 100*d_metrics[3], 100*dr_metrics[4], 100*df_metrics[4], \n","          g_metrics[1], 100*g_metrics[3], 100*g_metrics[4]))\n","    # metrics[0]: loss, metrics[1]: validity_loss, metrics[2]: classification_loss, metrics[3]: validity_accuracy, metrics[4]: classification_accuracy\n","\n","    # record history\n","    dr_v_loss1.append(dr_metrics[1])\n","    df_v_loss1.append(df_metrics[1])\n","    g_v_loss1.append(g_metrics[1])\n","    dr_v_acc1.append(dr_metrics[3])\n","    df_v_acc1.append(df_metrics[3])\n","    dr_c_acc1.append(dr_metrics[4])\n","    df_c_acc1.append(df_metrics[4])\n","\n","    #----------------------------------------\n","    # evaluation\n","    #----------------------------------------\n","    if (i+1) % (bat_per_epo) == 0:\n","      epoch+=1\n","      # generate real validation data\n","      X_r_val, labels_r_val, codes_r_val = val_dataset\n","      num_test = X_r_val.shape[0]\n","      # generate fake validation data\n","      y_r_val = ones((num_test, 1))\n","      [X_f_val, codes_f_val], [y_f_val, labels_f_val] = generate_fake_samples(g_model, latent_dim, num_test)\n","\n","      print(f\"\\nValidation Metrics of Discriminator:\")\n","      # evaluate both real and fake valid_dataset\n","      valid_metrics_r = d_model.evaluate([X_r_val, codes_r_val], [y_r_val, labels_r_val], verbose=1)\n","      valid_metrics_f = d_model.evaluate([X_f_val, codes_f_val], [y_f_val, labels_f_val], verbose=1)\n","\n","      v_acc = 50 * (valid_metrics_r[3] + valid_metrics_f[3])   \n","      three_c_acc = 100 * valid_metrics_r[4]\n","\n","      # two class accuracy\n","      _, labels_pred = d_model.predict([X_r_val, codes_r_val])\n","      labels_pred = np.argmax(labels_pred, axis=1)\n","      # print('val {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_r_val==0), np.sum(labels_r_val==1), np.sum(labels_r_val==2)))\n","      # print('pred {class_0: %d, class_1: %d, class_2: %d}' % (np.sum(labels_pred==0), np.sum(labels_pred==1), np.sum(labels_pred==2)))\n","      labels_2_val, labels_2_pred = labels_r_val.copy(), labels_pred.copy()\n","      # classify 2 as 1\n","      labels_2_val[labels_2_val==2] = 1\n","      labels_2_pred[labels_2_pred==2] = 1\n","      # calculate the accuracy \n","      correct = np.sum(labels_2_val==labels_2_pred)\n","      two_c_acc = correct / num_test * 100\n","\n","      print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","      print(\"=\"*100)\n","      # save good models\n","      # if (40 < v_acc < 60) and (three_c_acc > 63):\n","      if three_c_acc >57 or two_c_acc > 65:\n","        summarize_performance(i, d_model)\n","\n","      # record history\n","      dr_v_loss2.append(valid_metrics_r[1])\n","      df_v_loss2.append(valid_metrics_f[1])\n","      dr_v_acc2.append(valid_metrics_r[3])\n","      df_v_acc2.append(valid_metrics_f[3])\n","      dr_c_acc2.append(valid_metrics_r[4])\n","\n","    # print epoch\n","    if (i+1) % (bat_per_epo * 10) == 0:\n","      print(f\"Epoch: {epoch}\")\n","      print(\"=\"*100)\n","      \n","      # plot history\n","      train_hist = [dr_v_loss1, df_v_loss1, g_v_loss1, dr_v_acc1, df_v_acc1, dr_c_acc1, df_c_acc1]\n","      validation_hist = [dr_v_loss2, df_v_loss2, dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      plot_history(train_hist, validation_hist)\n","      point = [dr_v_acc2, df_v_acc2, dr_c_acc2]\n","      np.save('ACGANACGAN/mode0/point_0', point)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vASCtweCg0H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621303153272,"user_tz":-480,"elapsed":3669,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"91c4e379-c4f1-456c-ff3a-bc88a67279f6"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,), as shape: (758, 2)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,), as shape: (85, 2)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,), as shape: (86, 2)\n","Code_train shape: (758, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d7SzbdH3qCS2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621304366300,"user_tz":-480,"elapsed":1151778,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"576b6b56-565f-4a11-ea5e-549f6597d190"},"source":["epochs = 100\n","\n","# define model\n","discriminator, generator, gan_model = all_model(LATENT_DIM)\n","# train model\n","train(generator, discriminator, gan_model, train_data, val_data, n_epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["STEP:1, D{v_l: 1.178, v_acc: [59.4| 28.1| 43.8], c_acc: [34.4| 40.6]}  G{v_l: 0.867, v_acc: 40.6, c_acc: 28.1}\n","STEP:2, D{v_l: 1.172, v_acc: [75.0| 34.4| 54.7], c_acc: [34.4| 46.9]}  G{v_l: 0.741, v_acc: 51.6, c_acc: 26.6}\n","STEP:3, D{v_l: 1.053, v_acc: [62.5| 62.5| 62.5], c_acc: [28.1| 25.0]}  G{v_l: 0.759, v_acc: 48.4, c_acc: 26.6}\n","STEP:4, D{v_l: 1.113, v_acc: [68.8| 31.2| 50.0], c_acc: [37.5| 28.1]}  G{v_l: 0.728, v_acc: 56.2, c_acc: 29.7}\n","STEP:5, D{v_l: 1.054, v_acc: [50.0| 50.0| 50.0], c_acc: [43.8| 28.1]}  G{v_l: 0.777, v_acc: 56.2, c_acc: 25.0}\n","STEP:6, D{v_l: 1.413, v_acc: [59.4| 31.2| 45.3], c_acc: [31.2| 46.9]}  G{v_l: 0.771, v_acc: 59.4, c_acc: 29.7}\n","STEP:7, D{v_l: 1.319, v_acc: [40.6| 43.8| 42.2], c_acc: [25.0| 28.1]}  G{v_l: 0.771, v_acc: 48.4, c_acc: 28.1}\n","STEP:8, D{v_l: 1.305, v_acc: [62.5| 50.0| 56.2], c_acc: [50.0| 28.1]}  G{v_l: 0.705, v_acc: 51.6, c_acc: 23.4}\n","STEP:9, D{v_l: 0.997, v_acc: [65.6| 40.6| 53.1], c_acc: [34.4| 37.5]}  G{v_l: 0.785, v_acc: 54.7, c_acc: 26.6}\n","STEP:10, D{v_l: 1.278, v_acc: [56.2| 37.5| 46.9], c_acc: [28.1| 43.8]}  G{v_l: 0.731, v_acc: 59.4, c_acc: 25.0}\n","STEP:11, D{v_l: 1.576, v_acc: [53.1| 37.5| 45.3], c_acc: [43.8| 46.9]}  G{v_l: 0.746, v_acc: 54.7, c_acc: 18.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 287ms/step - loss: 2.2253 - valid_loss: 0.6749 - class_loss: 1.1358 - valid_acc: 0.4000 - class_acc: 0.2941\n","3/3 [==============================] - 1s 46ms/step - loss: 2.3094 - valid_loss: 0.7093 - class_loss: 1.1855 - valid_acc: 0.5882 - class_acc: 0.2235\n","average v_acc: 49.412, three class acc: 29.412, two class acc: 47.059\n","====================================================================================================\n","STEP:12, D{v_l: 0.914, v_acc: [58.1| 37.5| 47.8], c_acc: [26.5| 50.0]}  G{v_l: 0.742, v_acc: 50.0, c_acc: 39.1}\n","STEP:13, D{v_l: 1.376, v_acc: [56.2| 37.5| 46.9], c_acc: [28.1| 34.4]}  G{v_l: 0.767, v_acc: 48.4, c_acc: 31.2}\n","STEP:14, D{v_l: 1.485, v_acc: [59.4| 53.1| 56.2], c_acc: [43.8| 40.6]}  G{v_l: 0.726, v_acc: 51.6, c_acc: 32.8}\n","STEP:15, D{v_l: 1.515, v_acc: [50.0| 31.2| 40.6], c_acc: [43.8| 53.1]}  G{v_l: 0.785, v_acc: 56.2, c_acc: 34.4}\n","STEP:16, D{v_l: 1.666, v_acc: [43.8| 34.4| 39.1], c_acc: [31.2| 37.5]}  G{v_l: 0.762, v_acc: 48.4, c_acc: 29.7}\n","STEP:17, D{v_l: 1.311, v_acc: [43.8| 56.2| 50.0], c_acc: [34.4| 37.5]}  G{v_l: 0.754, v_acc: 54.7, c_acc: 25.0}\n","STEP:18, D{v_l: 1.798, v_acc: [34.4| 40.6| 37.5], c_acc: [28.1| 28.1]}  G{v_l: 0.729, v_acc: 59.4, c_acc: 29.7}\n","STEP:19, D{v_l: 1.416, v_acc: [59.4| 34.4| 46.9], c_acc: [37.5| 34.4]}  G{v_l: 0.562, v_acc: 75.0, c_acc: 39.1}\n","STEP:20, D{v_l: 1.247, v_acc: [59.4| 46.9| 53.1], c_acc: [34.4| 37.5]}  G{v_l: 0.697, v_acc: 65.6, c_acc: 39.1}\n","STEP:21, D{v_l: 1.218, v_acc: [50.0| 43.8| 46.9], c_acc: [50.0| 62.5]}  G{v_l: 0.760, v_acc: 59.4, c_acc: 34.4}\n","STEP:22, D{v_l: 0.963, v_acc: [50.0| 62.5| 56.2], c_acc: [34.4| 40.6]}  G{v_l: 0.592, v_acc: 67.2, c_acc: 26.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.1106 - valid_loss: 0.5765 - class_loss: 1.1189 - valid_acc: 1.0000 - class_acc: 0.2941\n","3/3 [==============================] - 0s 45ms/step - loss: 2.3955 - valid_loss: 0.8543 - class_loss: 1.1260 - valid_acc: 0.0000e+00 - class_acc: 0.2706\n","average v_acc: 50.000, three class acc: 29.412, two class acc: 47.059\n","====================================================================================================\n","STEP:23, D{v_l: 0.907, v_acc: [16.2| 56.2| 36.2], c_acc: [29.1| 37.5]}  G{v_l: 0.653, v_acc: 67.2, c_acc: 32.8}\n","STEP:24, D{v_l: 1.234, v_acc: [56.2| 46.9| 51.6], c_acc: [28.1| 50.0]}  G{v_l: 0.635, v_acc: 68.8, c_acc: 29.7}\n","STEP:25, D{v_l: 1.464, v_acc: [43.8| 50.0| 46.9], c_acc: [50.0| 43.8]}  G{v_l: 0.634, v_acc: 62.5, c_acc: 31.2}\n","STEP:26, D{v_l: 1.200, v_acc: [50.0| 53.1| 51.6], c_acc: [28.1| 40.6]}  G{v_l: 0.568, v_acc: 67.2, c_acc: 32.8}\n","STEP:27, D{v_l: 1.433, v_acc: [37.5| 40.6| 39.1], c_acc: [43.8| 50.0]}  G{v_l: 0.610, v_acc: 64.1, c_acc: 29.7}\n","STEP:28, D{v_l: 1.434, v_acc: [56.2| 37.5| 46.9], c_acc: [43.8| 31.2]}  G{v_l: 0.653, v_acc: 62.5, c_acc: 43.8}\n","STEP:29, D{v_l: 0.998, v_acc: [59.4| 53.1| 56.2], c_acc: [40.6| 53.1]}  G{v_l: 0.642, v_acc: 65.6, c_acc: 43.8}\n","STEP:30, D{v_l: 1.490, v_acc: [43.8| 46.9| 45.3], c_acc: [56.2| 59.4]}  G{v_l: 0.567, v_acc: 79.7, c_acc: 37.5}\n","STEP:31, D{v_l: 1.376, v_acc: [50.0| 53.1| 51.6], c_acc: [37.5| 46.9]}  G{v_l: 0.675, v_acc: 59.4, c_acc: 37.5}\n","STEP:32, D{v_l: 1.435, v_acc: [40.6| 50.0| 45.3], c_acc: [56.2| 40.6]}  G{v_l: 0.644, v_acc: 59.4, c_acc: 39.1}\n","STEP:33, D{v_l: 1.188, v_acc: [50.0| 50.0| 50.0], c_acc: [56.2| 46.9]}  G{v_l: 0.612, v_acc: 68.8, c_acc: 37.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0478 - valid_loss: 0.5785 - class_loss: 1.0536 - valid_acc: 1.0000 - class_acc: 0.5059\n","3/3 [==============================] - 0s 43ms/step - loss: 2.3297 - valid_loss: 0.8975 - class_loss: 1.0165 - valid_acc: 0.0000e+00 - class_acc: 0.6941\n","average v_acc: 50.000, three class acc: 50.588, two class acc: 61.176\n","====================================================================================================\n","STEP:34, D{v_l: 1.151, v_acc: [12.8| 65.6| 39.2], c_acc: [60.7| 62.5]}  G{v_l: 0.599, v_acc: 75.0, c_acc: 46.9}\n","STEP:35, D{v_l: 1.036, v_acc: [56.2| 50.0| 53.1], c_acc: [40.6| 50.0]}  G{v_l: 0.631, v_acc: 65.6, c_acc: 45.3}\n","STEP:36, D{v_l: 1.091, v_acc: [59.4| 62.5| 60.9], c_acc: [56.2| 50.0]}  G{v_l: 0.650, v_acc: 64.1, c_acc: 39.1}\n","STEP:37, D{v_l: 1.297, v_acc: [56.2| 50.0| 53.1], c_acc: [46.9| 50.0]}  G{v_l: 0.682, v_acc: 64.1, c_acc: 35.9}\n","STEP:38, D{v_l: 1.305, v_acc: [65.6| 37.5| 51.6], c_acc: [50.0| 59.4]}  G{v_l: 0.716, v_acc: 59.4, c_acc: 42.2}\n","STEP:39, D{v_l: 1.344, v_acc: [62.5| 56.2| 59.4], c_acc: [37.5| 46.9]}  G{v_l: 0.612, v_acc: 73.4, c_acc: 51.6}\n","STEP:40, D{v_l: 1.413, v_acc: [46.9| 50.0| 48.4], c_acc: [53.1| 53.1]}  G{v_l: 0.652, v_acc: 62.5, c_acc: 39.1}\n","STEP:41, D{v_l: 0.970, v_acc: [46.9| 50.0| 48.4], c_acc: [50.0| 50.0]}  G{v_l: 0.674, v_acc: 59.4, c_acc: 37.5}\n","STEP:42, D{v_l: 1.264, v_acc: [53.1| 40.6| 46.9], c_acc: [46.9| 46.9]}  G{v_l: 0.624, v_acc: 68.8, c_acc: 39.1}\n","STEP:43, D{v_l: 1.234, v_acc: [50.0| 46.9| 48.4], c_acc: [46.9| 43.8]}  G{v_l: 0.608, v_acc: 67.2, c_acc: 43.8}\n","STEP:44, D{v_l: 1.269, v_acc: [50.0| 50.0| 50.0], c_acc: [53.1| 50.0]}  G{v_l: 0.697, v_acc: 57.8, c_acc: 37.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0465 - valid_loss: 0.6132 - class_loss: 1.0173 - valid_acc: 1.0000 - class_acc: 0.5059\n","3/3 [==============================] - 0s 44ms/step - loss: 2.3124 - valid_loss: 0.8945 - class_loss: 1.0019 - valid_acc: 0.0000e+00 - class_acc: 0.6706\n","average v_acc: 50.000, three class acc: 50.588, two class acc: 56.471\n","====================================================================================================\n","STEP:45, D{v_l: 1.027, v_acc: [13.7| 46.9| 30.3], c_acc: [61.5| 62.5]}  G{v_l: 0.697, v_acc: 57.8, c_acc: 40.6}\n","STEP:46, D{v_l: 1.601, v_acc: [50.0| 43.8| 46.9], c_acc: [50.0| 71.9]}  G{v_l: 0.620, v_acc: 64.1, c_acc: 43.8}\n","STEP:47, D{v_l: 1.100, v_acc: [50.0| 59.4| 54.7], c_acc: [43.8| 43.8]}  G{v_l: 0.656, v_acc: 57.8, c_acc: 34.4}\n","STEP:48, D{v_l: 1.261, v_acc: [53.1| 37.5| 45.3], c_acc: [43.8| 43.8]}  G{v_l: 0.756, v_acc: 56.2, c_acc: 53.1}\n","STEP:49, D{v_l: 1.301, v_acc: [25.0| 68.8| 46.9], c_acc: [34.4| 65.6]}  G{v_l: 0.548, v_acc: 70.3, c_acc: 40.6}\n","STEP:50, D{v_l: 1.069, v_acc: [46.9| 59.4| 53.1], c_acc: [50.0| 56.2]}  G{v_l: 0.828, v_acc: 56.2, c_acc: 50.0}\n","STEP:51, D{v_l: 1.258, v_acc: [50.0| 53.1| 51.6], c_acc: [43.8| 59.4]}  G{v_l: 0.628, v_acc: 67.2, c_acc: 45.3}\n","STEP:52, D{v_l: 1.190, v_acc: [50.0| 56.2| 53.1], c_acc: [40.6| 62.5]}  G{v_l: 0.752, v_acc: 60.9, c_acc: 46.9}\n","STEP:53, D{v_l: 1.216, v_acc: [46.9| 46.9| 46.9], c_acc: [31.2| 56.2]}  G{v_l: 0.685, v_acc: 56.2, c_acc: 45.3}\n","STEP:54, D{v_l: 1.236, v_acc: [62.5| 43.8| 53.1], c_acc: [43.8| 65.6]}  G{v_l: 0.710, v_acc: 56.2, c_acc: 50.0}\n","STEP:55, D{v_l: 1.425, v_acc: [56.2| 50.0| 53.1], c_acc: [56.2| 56.2]}  G{v_l: 0.712, v_acc: 62.5, c_acc: 35.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.0834 - valid_loss: 0.6396 - class_loss: 1.0274 - valid_acc: 0.9059 - class_acc: 0.4824\n","3/3 [==============================] - 0s 47ms/step - loss: 2.1726 - valid_loss: 0.8482 - class_loss: 0.9081 - valid_acc: 0.0000e+00 - class_acc: 0.7412\n","average v_acc: 45.294, three class acc: 48.235, two class acc: 57.647\n","====================================================================================================\n","STEP:56, D{v_l: 1.327, v_acc: [15.4| 40.6| 28.0], c_acc: [65.0| 62.5]}  G{v_l: 0.612, v_acc: 67.2, c_acc: 46.9}\n","STEP:57, D{v_l: 1.207, v_acc: [53.1| 46.9| 50.0], c_acc: [43.8| 59.4]}  G{v_l: 0.580, v_acc: 70.3, c_acc: 42.2}\n","STEP:58, D{v_l: 1.276, v_acc: [40.6| 53.1| 46.9], c_acc: [59.4| 56.2]}  G{v_l: 0.715, v_acc: 54.7, c_acc: 37.5}\n","STEP:59, D{v_l: 1.236, v_acc: [50.0| 34.4| 42.2], c_acc: [50.0| 56.2]}  G{v_l: 0.679, v_acc: 62.5, c_acc: 50.0}\n","STEP:60, D{v_l: 1.187, v_acc: [40.6| 37.5| 39.1], c_acc: [50.0| 65.6]}  G{v_l: 0.709, v_acc: 64.1, c_acc: 40.6}\n","STEP:61, D{v_l: 1.220, v_acc: [56.2| 53.1| 54.7], c_acc: [65.6| 71.9]}  G{v_l: 0.650, v_acc: 57.8, c_acc: 60.9}\n","STEP:62, D{v_l: 1.304, v_acc: [43.8| 46.9| 45.3], c_acc: [46.9| 65.6]}  G{v_l: 0.679, v_acc: 65.6, c_acc: 59.4}\n","STEP:63, D{v_l: 0.948, v_acc: [46.9| 53.1| 50.0], c_acc: [37.5| 68.8]}  G{v_l: 0.670, v_acc: 60.9, c_acc: 53.1}\n","STEP:64, D{v_l: 1.177, v_acc: [59.4| 59.4| 59.4], c_acc: [56.2| 59.4]}  G{v_l: 0.678, v_acc: 68.8, c_acc: 48.4}\n","STEP:65, D{v_l: 1.116, v_acc: [50.0| 56.2| 53.1], c_acc: [65.6| 62.5]}  G{v_l: 0.631, v_acc: 67.2, c_acc: 54.7}\n","STEP:66, D{v_l: 0.989, v_acc: [46.9| 56.2| 51.6], c_acc: [56.2| 65.6]}  G{v_l: 0.706, v_acc: 62.5, c_acc: 51.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0826 - valid_loss: 0.6583 - class_loss: 1.0077 - valid_acc: 0.7176 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 2.1718 - valid_loss: 0.8503 - class_loss: 0.9050 - valid_acc: 0.0000e+00 - class_acc: 0.5529\n","average v_acc: 35.882, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:67, D{v_l: 1.068, v_acc: [14.5| 43.8| 29.1], c_acc: [55.6| 75.0]}  G{v_l: 0.616, v_acc: 65.6, c_acc: 53.1}\n","STEP:68, D{v_l: 1.102, v_acc: [40.6| 46.9| 43.8], c_acc: [56.2| 75.0]}  G{v_l: 0.743, v_acc: 56.2, c_acc: 54.7}\n","STEP:69, D{v_l: 1.053, v_acc: [65.6| 43.8| 54.7], c_acc: [34.4| 59.4]}  G{v_l: 0.726, v_acc: 60.9, c_acc: 54.7}\n","STEP:70, D{v_l: 1.322, v_acc: [40.6| 59.4| 50.0], c_acc: [65.6| 71.9]}  G{v_l: 0.744, v_acc: 56.2, c_acc: 50.0}\n","STEP:71, D{v_l: 1.290, v_acc: [50.0| 34.4| 42.2], c_acc: [31.2| 65.6]}  G{v_l: 0.714, v_acc: 62.5, c_acc: 42.2}\n","STEP:72, D{v_l: 1.146, v_acc: [53.1| 50.0| 51.6], c_acc: [59.4| 75.0]}  G{v_l: 0.720, v_acc: 60.9, c_acc: 62.5}\n","STEP:73, D{v_l: 0.999, v_acc: [56.2| 50.0| 53.1], c_acc: [50.0| 62.5]}  G{v_l: 0.662, v_acc: 62.5, c_acc: 57.8}\n","STEP:74, D{v_l: 1.051, v_acc: [50.0| 46.9| 48.4], c_acc: [56.2| 71.9]}  G{v_l: 0.770, v_acc: 48.4, c_acc: 53.1}\n","STEP:75, D{v_l: 0.876, v_acc: [50.0| 65.6| 57.8], c_acc: [53.1| 75.0]}  G{v_l: 0.726, v_acc: 62.5, c_acc: 60.9}\n","STEP:76, D{v_l: 1.183, v_acc: [56.2| 59.4| 57.8], c_acc: [59.4| 81.2]}  G{v_l: 0.711, v_acc: 62.5, c_acc: 53.1}\n","STEP:77, D{v_l: 1.057, v_acc: [40.6| 59.4| 50.0], c_acc: [56.2| 81.2]}  G{v_l: 0.649, v_acc: 59.4, c_acc: 62.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.0773 - valid_loss: 0.6593 - class_loss: 1.0012 - valid_acc: 0.5882 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 2.0486 - valid_loss: 0.8224 - class_loss: 0.8095 - valid_acc: 0.0000e+00 - class_acc: 0.5647\n","average v_acc: 29.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:78, D{v_l: 0.933, v_acc: [18.8| 56.2| 37.5], c_acc: [58.1| 84.4]}  G{v_l: 0.846, v_acc: 53.1, c_acc: 45.3}\n","STEP:79, D{v_l: 1.354, v_acc: [40.6| 37.5| 39.1], c_acc: [59.4| 71.9]}  G{v_l: 0.651, v_acc: 67.2, c_acc: 65.6}\n","STEP:80, D{v_l: 1.056, v_acc: [56.2| 40.6| 48.4], c_acc: [40.6| 65.6]}  G{v_l: 0.861, v_acc: 50.0, c_acc: 48.4}\n","STEP:81, D{v_l: 1.061, v_acc: [56.2| 37.5| 46.9], c_acc: [78.1| 84.4]}  G{v_l: 0.783, v_acc: 50.0, c_acc: 62.5}\n","STEP:82, D{v_l: 1.263, v_acc: [28.1| 53.1| 40.6], c_acc: [50.0| 65.6]}  G{v_l: 0.717, v_acc: 60.9, c_acc: 48.4}\n","STEP:83, D{v_l: 0.817, v_acc: [59.4| 56.2| 57.8], c_acc: [43.8| 65.6]}  G{v_l: 0.713, v_acc: 60.9, c_acc: 65.6}\n","STEP:84, D{v_l: 1.186, v_acc: [40.6| 43.8| 42.2], c_acc: [50.0| 81.2]}  G{v_l: 0.815, v_acc: 53.1, c_acc: 56.2}\n","STEP:85, D{v_l: 0.865, v_acc: [65.6| 50.0| 57.8], c_acc: [46.9| 75.0]}  G{v_l: 0.682, v_acc: 62.5, c_acc: 56.2}\n","STEP:86, D{v_l: 1.232, v_acc: [53.1| 43.8| 48.4], c_acc: [53.1| 56.2]}  G{v_l: 0.849, v_acc: 50.0, c_acc: 53.1}\n","STEP:87, D{v_l: 1.114, v_acc: [65.6| 37.5| 51.6], c_acc: [65.6| 78.1]}  G{v_l: 0.605, v_acc: 68.8, c_acc: 60.9}\n","STEP:88, D{v_l: 1.033, v_acc: [56.2| 37.5| 46.9], c_acc: [68.8| 71.9]}  G{v_l: 0.938, v_acc: 46.9, c_acc: 53.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.2972 - valid_loss: 0.7902 - class_loss: 1.0901 - valid_acc: 0.1176 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.9324 - valid_loss: 0.7432 - class_loss: 0.7723 - valid_acc: 0.1647 - class_acc: 0.6588\n","average v_acc: 14.118, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:89, D{v_l: 1.049, v_acc: [29.1| 46.9| 38.0], c_acc: [64.1| 65.6]}  G{v_l: 0.842, v_acc: 59.4, c_acc: 50.0}\n","STEP:90, D{v_l: 1.377, v_acc: [56.2| 40.6| 48.4], c_acc: [53.1| 75.0]}  G{v_l: 0.839, v_acc: 50.0, c_acc: 57.8}\n","STEP:91, D{v_l: 0.975, v_acc: [53.1| 43.8| 48.4], c_acc: [59.4| 84.4]}  G{v_l: 0.862, v_acc: 46.9, c_acc: 51.6}\n","STEP:92, D{v_l: 1.430, v_acc: [37.5| 37.5| 37.5], c_acc: [53.1| 87.5]}  G{v_l: 0.716, v_acc: 57.8, c_acc: 60.9}\n","STEP:93, D{v_l: 1.202, v_acc: [40.6| 46.9| 43.8], c_acc: [43.8| 78.1]}  G{v_l: 0.750, v_acc: 46.9, c_acc: 62.5}\n","STEP:94, D{v_l: 1.204, v_acc: [46.9| 56.2| 51.6], c_acc: [56.2| 84.4]}  G{v_l: 0.801, v_acc: 53.1, c_acc: 62.5}\n","STEP:95, D{v_l: 1.131, v_acc: [50.0| 59.4| 54.7], c_acc: [59.4| 84.4]}  G{v_l: 0.695, v_acc: 62.5, c_acc: 67.2}\n","STEP:96, D{v_l: 1.289, v_acc: [46.9| 50.0| 48.4], c_acc: [53.1| 75.0]}  G{v_l: 0.804, v_acc: 53.1, c_acc: 57.8}\n","STEP:97, D{v_l: 1.074, v_acc: [62.5| 43.8| 53.1], c_acc: [46.9| 75.0]}  G{v_l: 0.701, v_acc: 64.1, c_acc: 60.9}\n","STEP:98, D{v_l: 1.255, v_acc: [40.6| 53.1| 46.9], c_acc: [46.9| 78.1]}  G{v_l: 0.720, v_acc: 51.6, c_acc: 62.5}\n","STEP:99, D{v_l: 1.102, v_acc: [46.9| 56.2| 51.6], c_acc: [43.8| 81.2]}  G{v_l: 0.773, v_acc: 64.1, c_acc: 59.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.3550 - valid_loss: 0.7835 - class_loss: 1.1545 - valid_acc: 0.1412 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.8556 - valid_loss: 0.7480 - class_loss: 0.6905 - valid_acc: 0.1882 - class_acc: 0.6471\n","average v_acc: 16.471, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:100, D{v_l: 0.940, v_acc: [27.4| 50.0| 38.7], c_acc: [63.2| 81.2]}  G{v_l: 0.854, v_acc: 50.0, c_acc: 54.7}\n","STEP:101, D{v_l: 0.910, v_acc: [68.8| 65.6| 67.2], c_acc: [46.9| 68.8]}  G{v_l: 0.727, v_acc: 62.5, c_acc: 67.2}\n","STEP:102, D{v_l: 1.224, v_acc: [40.6| 50.0| 45.3], c_acc: [56.2| 71.9]}  G{v_l: 0.815, v_acc: 51.6, c_acc: 57.8}\n","STEP:103, D{v_l: 0.976, v_acc: [50.0| 65.6| 57.8], c_acc: [56.2| 68.8]}  G{v_l: 0.834, v_acc: 53.1, c_acc: 67.2}\n","STEP:104, D{v_l: 1.157, v_acc: [46.9| 59.4| 53.1], c_acc: [59.4| 78.1]}  G{v_l: 0.678, v_acc: 56.2, c_acc: 53.1}\n","STEP:105, D{v_l: 0.875, v_acc: [78.1| 56.2| 67.2], c_acc: [56.2| 68.8]}  G{v_l: 0.618, v_acc: 68.8, c_acc: 56.2}\n","STEP:106, D{v_l: 0.808, v_acc: [53.1| 65.6| 59.4], c_acc: [65.6| 90.6]}  G{v_l: 0.609, v_acc: 68.8, c_acc: 62.5}\n","STEP:107, D{v_l: 1.034, v_acc: [59.4| 59.4| 59.4], c_acc: [53.1| 78.1]}  G{v_l: 0.632, v_acc: 60.9, c_acc: 53.1}\n","STEP:108, D{v_l: 0.942, v_acc: [53.1| 75.0| 64.1], c_acc: [65.6| 81.2]}  G{v_l: 0.712, v_acc: 56.2, c_acc: 62.5}\n","STEP:109, D{v_l: 1.103, v_acc: [62.5| 46.9| 54.7], c_acc: [43.8| 84.4]}  G{v_l: 0.702, v_acc: 65.6, c_acc: 64.1}\n","STEP:110, D{v_l: 1.050, v_acc: [56.2| 59.4| 57.8], c_acc: [59.4| 87.5]}  G{v_l: 0.788, v_acc: 56.2, c_acc: 57.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.3567 - valid_loss: 0.7711 - class_loss: 1.1685 - valid_acc: 0.1647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.9547 - valid_loss: 0.8363 - class_loss: 0.7012 - valid_acc: 0.0000e+00 - class_acc: 0.6588\n","average v_acc: 8.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 10\n","====================================================================================================\n","STEP:111, D{v_l: 0.844, v_acc: [14.5| 59.4| 37.0], c_acc: [64.1| 65.6]}  G{v_l: 0.665, v_acc: 62.5, c_acc: 62.5}\n","STEP:112, D{v_l: 1.103, v_acc: [53.1| 50.0| 51.6], c_acc: [59.4| 81.2]}  G{v_l: 0.699, v_acc: 62.5, c_acc: 51.6}\n","STEP:113, D{v_l: 1.215, v_acc: [53.1| 59.4| 56.2], c_acc: [59.4| 90.6]}  G{v_l: 0.705, v_acc: 64.1, c_acc: 68.8}\n","STEP:114, D{v_l: 1.104, v_acc: [40.6| 71.9| 56.2], c_acc: [56.2| 81.2]}  G{v_l: 0.787, v_acc: 60.9, c_acc: 73.4}\n","STEP:115, D{v_l: 1.214, v_acc: [56.2| 50.0| 53.1], c_acc: [56.2| 75.0]}  G{v_l: 0.795, v_acc: 51.6, c_acc: 57.8}\n","STEP:116, D{v_l: 1.079, v_acc: [65.6| 59.4| 62.5], c_acc: [50.0| 78.1]}  G{v_l: 0.710, v_acc: 56.2, c_acc: 62.5}\n","STEP:117, D{v_l: 0.978, v_acc: [50.0| 65.6| 57.8], c_acc: [68.8| 78.1]}  G{v_l: 0.745, v_acc: 57.8, c_acc: 57.8}\n","STEP:118, D{v_l: 1.256, v_acc: [37.5| 50.0| 43.8], c_acc: [68.8| 90.6]}  G{v_l: 0.749, v_acc: 56.2, c_acc: 64.1}\n","STEP:119, D{v_l: 1.229, v_acc: [56.2| 59.4| 57.8], c_acc: [62.5| 84.4]}  G{v_l: 0.726, v_acc: 64.1, c_acc: 60.9}\n","STEP:120, D{v_l: 1.138, v_acc: [43.8| 65.6| 54.7], c_acc: [50.0| 90.6]}  G{v_l: 0.610, v_acc: 67.2, c_acc: 59.4}\n","STEP:121, D{v_l: 1.088, v_acc: [56.2| 65.6| 60.9], c_acc: [75.0| 90.6]}  G{v_l: 0.675, v_acc: 56.2, c_acc: 64.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.4231 - valid_loss: 0.7339 - class_loss: 1.2719 - valid_acc: 0.2941 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.9983 - valid_loss: 0.8402 - class_loss: 0.7408 - valid_acc: 0.0118 - class_acc: 0.6118\n","average v_acc: 15.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:122, D{v_l: 0.973, v_acc: [13.7| 50.0| 31.8], c_acc: [62.4| 71.9]}  G{v_l: 0.691, v_acc: 60.9, c_acc: 53.1}\n","STEP:123, D{v_l: 1.134, v_acc: [71.9| 43.8| 57.8], c_acc: [59.4| 81.2]}  G{v_l: 0.636, v_acc: 60.9, c_acc: 51.6}\n","STEP:124, D{v_l: 1.074, v_acc: [53.1| 62.5| 57.8], c_acc: [59.4| 78.1]}  G{v_l: 0.601, v_acc: 64.1, c_acc: 67.2}\n","STEP:125, D{v_l: 0.772, v_acc: [65.6| 56.2| 60.9], c_acc: [68.8| 78.1]}  G{v_l: 0.741, v_acc: 53.1, c_acc: 54.7}\n","STEP:126, D{v_l: 1.015, v_acc: [59.4| 46.9| 53.1], c_acc: [53.1| 81.2]}  G{v_l: 0.785, v_acc: 59.4, c_acc: 62.5}\n","STEP:127, D{v_l: 0.939, v_acc: [59.4| 59.4| 59.4], c_acc: [59.4| 84.4]}  G{v_l: 0.752, v_acc: 54.7, c_acc: 60.9}\n","STEP:128, D{v_l: 1.042, v_acc: [37.5| 59.4| 48.4], c_acc: [40.6| 81.2]}  G{v_l: 0.764, v_acc: 60.9, c_acc: 53.1}\n","STEP:129, D{v_l: 0.958, v_acc: [56.2| 50.0| 53.1], c_acc: [62.5| 78.1]}  G{v_l: 0.951, v_acc: 46.9, c_acc: 64.1}\n","STEP:130, D{v_l: 1.088, v_acc: [53.1| 53.1| 53.1], c_acc: [56.2| 71.9]}  G{v_l: 0.844, v_acc: 54.7, c_acc: 73.4}\n","STEP:131, D{v_l: 1.092, v_acc: [50.0| 56.2| 53.1], c_acc: [62.5| 96.9]}  G{v_l: 0.703, v_acc: 64.1, c_acc: 67.2}\n","STEP:132, D{v_l: 1.069, v_acc: [56.2| 56.2| 56.2], c_acc: [62.5| 68.8]}  G{v_l: 0.706, v_acc: 59.4, c_acc: 59.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.4808 - valid_loss: 0.8246 - class_loss: 1.2388 - valid_acc: 0.0353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.9427 - valid_loss: 0.7672 - class_loss: 0.7581 - valid_acc: 0.0706 - class_acc: 0.6235\n","average v_acc: 5.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:133, D{v_l: 0.798, v_acc: [18.8| 65.6| 42.2], c_acc: [62.4| 81.2]}  G{v_l: 0.718, v_acc: 59.4, c_acc: 59.4}\n","STEP:134, D{v_l: 1.177, v_acc: [56.2| 53.1| 54.7], c_acc: [56.2| 87.5]}  G{v_l: 0.778, v_acc: 57.8, c_acc: 62.5}\n","STEP:135, D{v_l: 0.677, v_acc: [59.4| 81.2| 70.3], c_acc: [53.1| 90.6]}  G{v_l: 0.866, v_acc: 43.8, c_acc: 54.7}\n","STEP:136, D{v_l: 0.956, v_acc: [50.0| 53.1| 51.6], c_acc: [53.1| 90.6]}  G{v_l: 0.736, v_acc: 60.9, c_acc: 62.5}\n","STEP:137, D{v_l: 1.041, v_acc: [50.0| 65.6| 57.8], c_acc: [53.1| 93.8]}  G{v_l: 0.893, v_acc: 42.2, c_acc: 67.2}\n","STEP:138, D{v_l: 0.875, v_acc: [65.6| 56.2| 60.9], c_acc: [59.4| 87.5]}  G{v_l: 0.960, v_acc: 42.2, c_acc: 51.6}\n","STEP:139, D{v_l: 1.122, v_acc: [40.6| 46.9| 43.8], c_acc: [56.2| 81.2]}  G{v_l: 0.850, v_acc: 51.6, c_acc: 64.1}\n","STEP:140, D{v_l: 1.111, v_acc: [53.1| 65.6| 59.4], c_acc: [65.6| 81.2]}  G{v_l: 0.866, v_acc: 43.8, c_acc: 65.6}\n","STEP:141, D{v_l: 1.201, v_acc: [46.9| 62.5| 54.7], c_acc: [68.8| 87.5]}  G{v_l: 0.874, v_acc: 43.8, c_acc: 64.1}\n","STEP:142, D{v_l: 1.060, v_acc: [59.4| 59.4| 59.4], c_acc: [50.0| 62.5]}  G{v_l: 0.899, v_acc: 39.1, c_acc: 79.7}\n","STEP:143, D{v_l: 1.090, v_acc: [53.1| 43.8| 48.4], c_acc: [62.5| 90.6]}  G{v_l: 0.824, v_acc: 54.7, c_acc: 62.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.7964 - valid_loss: 0.8812 - class_loss: 1.4976 - valid_acc: 0.0118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 43ms/step - loss: 1.9041 - valid_loss: 0.8034 - class_loss: 0.6832 - valid_acc: 0.0588 - class_acc: 0.5647\n","average v_acc: 3.529, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:144, D{v_l: 0.877, v_acc: [18.8| 65.6| 42.2], c_acc: [52.1| 78.1]}  G{v_l: 0.762, v_acc: 59.4, c_acc: 59.4}\n","STEP:145, D{v_l: 0.880, v_acc: [62.5| 71.9| 67.2], c_acc: [50.0| 87.5]}  G{v_l: 0.805, v_acc: 48.4, c_acc: 57.8}\n","STEP:146, D{v_l: 1.355, v_acc: [37.5| 53.1| 45.3], c_acc: [59.4| 87.5]}  G{v_l: 0.961, v_acc: 40.6, c_acc: 67.2}\n","STEP:147, D{v_l: 0.905, v_acc: [65.6| 53.1| 59.4], c_acc: [56.2| 87.5]}  G{v_l: 0.694, v_acc: 62.5, c_acc: 65.6}\n","STEP:148, D{v_l: 0.634, v_acc: [56.2| 71.9| 64.1], c_acc: [71.9| 90.6]}  G{v_l: 0.806, v_acc: 53.1, c_acc: 71.9}\n","STEP:149, D{v_l: 0.870, v_acc: [62.5| 56.2| 59.4], c_acc: [50.0| 87.5]}  G{v_l: 0.706, v_acc: 62.5, c_acc: 60.9}\n","STEP:150, D{v_l: 1.116, v_acc: [59.4| 46.9| 53.1], c_acc: [81.2| 87.5]}  G{v_l: 1.031, v_acc: 43.8, c_acc: 65.6}\n","STEP:151, D{v_l: 0.950, v_acc: [62.5| 46.9| 54.7], c_acc: [46.9| 81.2]}  G{v_l: 0.866, v_acc: 57.8, c_acc: 75.0}\n","STEP:152, D{v_l: 0.832, v_acc: [71.9| 50.0| 60.9], c_acc: [56.2| 81.2]}  G{v_l: 0.881, v_acc: 51.6, c_acc: 64.1}\n","STEP:153, D{v_l: 0.730, v_acc: [53.1| 75.0| 64.1], c_acc: [56.2| 93.8]}  G{v_l: 0.819, v_acc: 53.1, c_acc: 67.2}\n","STEP:154, D{v_l: 1.112, v_acc: [40.6| 59.4| 50.0], c_acc: [53.1| 90.6]}  G{v_l: 0.818, v_acc: 46.9, c_acc: 73.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.8719 - valid_loss: 0.9354 - class_loss: 1.5189 - valid_acc: 0.0118 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.6565 - valid_loss: 0.7356 - class_loss: 0.5032 - valid_acc: 0.1765 - class_acc: 0.7765\n","average v_acc: 9.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:155, D{v_l: 0.839, v_acc: [31.6| 53.1| 42.4], c_acc: [72.6| 93.8]}  G{v_l: 1.066, v_acc: 37.5, c_acc: 59.4}\n","STEP:156, D{v_l: 1.023, v_acc: [37.5| 50.0| 43.8], c_acc: [81.2| 93.8]}  G{v_l: 0.896, v_acc: 50.0, c_acc: 70.3}\n","STEP:157, D{v_l: 1.351, v_acc: [31.2| 40.6| 35.9], c_acc: [68.8| 87.5]}  G{v_l: 0.854, v_acc: 64.1, c_acc: 62.5}\n","STEP:158, D{v_l: 0.936, v_acc: [50.0| 59.4| 54.7], c_acc: [71.9| 93.8]}  G{v_l: 0.951, v_acc: 43.8, c_acc: 71.9}\n","STEP:159, D{v_l: 0.836, v_acc: [50.0| 59.4| 54.7], c_acc: [65.6| 93.8]}  G{v_l: 0.854, v_acc: 50.0, c_acc: 68.8}\n","STEP:160, D{v_l: 0.935, v_acc: [56.2| 62.5| 59.4], c_acc: [65.6| 81.2]}  G{v_l: 0.968, v_acc: 35.9, c_acc: 70.3}\n","STEP:161, D{v_l: 1.060, v_acc: [53.1| 59.4| 56.2], c_acc: [62.5| 81.2]}  G{v_l: 0.861, v_acc: 50.0, c_acc: 79.7}\n","STEP:162, D{v_l: 0.775, v_acc: [59.4| 59.4| 59.4], c_acc: [50.0| 87.5]}  G{v_l: 0.831, v_acc: 48.4, c_acc: 76.6}\n","STEP:163, D{v_l: 1.113, v_acc: [50.0| 50.0| 50.0], c_acc: [62.5| 100.0]}  G{v_l: 0.901, v_acc: 54.7, c_acc: 70.3}\n","STEP:164, D{v_l: 0.810, v_acc: [71.9| 59.4| 65.6], c_acc: [62.5| 84.4]}  G{v_l: 0.875, v_acc: 54.7, c_acc: 73.4}\n","STEP:165, D{v_l: 0.892, v_acc: [56.2| 40.6| 48.4], c_acc: [68.8| 78.1]}  G{v_l: 0.920, v_acc: 48.4, c_acc: 62.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9347 - valid_loss: 1.0130 - class_loss: 1.5040 - valid_acc: 0.0000e+00 - class_acc: 0.5176\n","3/3 [==============================] - 0s 46ms/step - loss: 1.5438 - valid_loss: 0.6633 - class_loss: 0.4629 - valid_acc: 0.5176 - class_acc: 0.8118\n","average v_acc: 25.882, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:166, D{v_l: 0.930, v_acc: [53.0| 46.9| 49.9], c_acc: [76.9| 84.4]}  G{v_l: 0.958, v_acc: 45.3, c_acc: 81.2}\n","STEP:167, D{v_l: 0.808, v_acc: [46.9| 68.8| 57.8], c_acc: [53.1| 90.6]}  G{v_l: 0.862, v_acc: 50.0, c_acc: 65.6}\n","STEP:168, D{v_l: 1.066, v_acc: [53.1| 37.5| 45.3], c_acc: [53.1| 87.5]}  G{v_l: 0.763, v_acc: 56.2, c_acc: 81.2}\n","STEP:169, D{v_l: 0.923, v_acc: [56.2| 65.6| 60.9], c_acc: [68.8| 93.8]}  G{v_l: 0.836, v_acc: 51.6, c_acc: 68.8}\n","STEP:170, D{v_l: 0.718, v_acc: [59.4| 75.0| 67.2], c_acc: [62.5| 93.8]}  G{v_l: 1.026, v_acc: 43.8, c_acc: 71.9}\n","STEP:171, D{v_l: 0.760, v_acc: [56.2| 65.6| 60.9], c_acc: [68.8| 93.8]}  G{v_l: 0.826, v_acc: 46.9, c_acc: 73.4}\n","STEP:172, D{v_l: 0.995, v_acc: [62.5| 50.0| 56.2], c_acc: [59.4| 84.4]}  G{v_l: 0.984, v_acc: 42.2, c_acc: 68.8}\n","STEP:173, D{v_l: 0.933, v_acc: [43.8| 62.5| 53.1], c_acc: [68.8| 96.9]}  G{v_l: 0.918, v_acc: 48.4, c_acc: 65.6}\n","STEP:174, D{v_l: 0.870, v_acc: [53.1| 59.4| 56.2], c_acc: [68.8| 93.8]}  G{v_l: 0.879, v_acc: 56.2, c_acc: 76.6}\n","STEP:175, D{v_l: 0.665, v_acc: [62.5| 78.1| 70.3], c_acc: [56.2| 93.8]}  G{v_l: 1.055, v_acc: 35.9, c_acc: 78.1}\n","STEP:176, D{v_l: 0.759, v_acc: [59.4| 62.5| 60.9], c_acc: [68.8| 93.8]}  G{v_l: 1.054, v_acc: 42.2, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.8823 - valid_loss: 0.9352 - class_loss: 1.5295 - valid_acc: 0.0000e+00 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.4390 - valid_loss: 0.6495 - class_loss: 0.3719 - valid_acc: 0.6471 - class_acc: 0.8824\n","average v_acc: 32.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:177, D{v_l: 0.685, v_acc: [61.5| 65.6| 63.6], c_acc: [82.9| 90.6]}  G{v_l: 0.914, v_acc: 53.1, c_acc: 65.6}\n","STEP:178, D{v_l: 0.801, v_acc: [71.9| 59.4| 65.6], c_acc: [68.8| 93.8]}  G{v_l: 0.916, v_acc: 51.6, c_acc: 76.6}\n","STEP:179, D{v_l: 0.748, v_acc: [46.9| 62.5| 54.7], c_acc: [71.9| 90.6]}  G{v_l: 0.965, v_acc: 45.3, c_acc: 81.2}\n","STEP:180, D{v_l: 1.189, v_acc: [46.9| 59.4| 53.1], c_acc: [50.0| 84.4]}  G{v_l: 0.950, v_acc: 54.7, c_acc: 64.1}\n","STEP:181, D{v_l: 0.898, v_acc: [53.1| 56.2| 54.7], c_acc: [65.6| 93.8]}  G{v_l: 1.024, v_acc: 40.6, c_acc: 70.3}\n","STEP:182, D{v_l: 0.899, v_acc: [53.1| 53.1| 53.1], c_acc: [71.9| 84.4]}  G{v_l: 1.022, v_acc: 37.5, c_acc: 82.8}\n","STEP:183, D{v_l: 0.667, v_acc: [71.9| 62.5| 67.2], c_acc: [53.1| 90.6]}  G{v_l: 0.827, v_acc: 48.4, c_acc: 62.5}\n","STEP:184, D{v_l: 0.808, v_acc: [62.5| 62.5| 62.5], c_acc: [68.8| 96.9]}  G{v_l: 1.166, v_acc: 28.1, c_acc: 82.8}\n","STEP:185, D{v_l: 0.794, v_acc: [59.4| 59.4| 59.4], c_acc: [56.2| 90.6]}  G{v_l: 0.926, v_acc: 48.4, c_acc: 82.8}\n","STEP:186, D{v_l: 1.076, v_acc: [43.8| 53.1| 48.4], c_acc: [71.9| 87.5]}  G{v_l: 0.991, v_acc: 51.6, c_acc: 78.1}\n","STEP:187, D{v_l: 0.705, v_acc: [56.2| 62.5| 59.4], c_acc: [56.2| 93.8]}  G{v_l: 0.950, v_acc: 43.8, c_acc: 75.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.7038 - valid_loss: 0.8696 - class_loss: 1.4165 - valid_acc: 0.0118 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 1.3720 - valid_loss: 0.6098 - class_loss: 0.3445 - valid_acc: 0.7529 - class_acc: 0.8353\n","average v_acc: 38.235, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:188, D{v_l: 0.681, v_acc: [70.1| 62.5| 66.3], c_acc: [79.5| 93.8]}  G{v_l: 0.968, v_acc: 50.0, c_acc: 76.6}\n","STEP:189, D{v_l: 0.944, v_acc: [53.1| 50.0| 51.6], c_acc: [71.9| 87.5]}  G{v_l: 1.077, v_acc: 34.4, c_acc: 70.3}\n","STEP:190, D{v_l: 0.934, v_acc: [50.0| 62.5| 56.2], c_acc: [65.6| 84.4]}  G{v_l: 1.041, v_acc: 35.9, c_acc: 76.6}\n","STEP:191, D{v_l: 0.828, v_acc: [46.9| 62.5| 54.7], c_acc: [59.4| 93.8]}  G{v_l: 1.064, v_acc: 50.0, c_acc: 70.3}\n","STEP:192, D{v_l: 0.808, v_acc: [56.2| 81.2| 68.8], c_acc: [62.5| 100.0]}  G{v_l: 0.836, v_acc: 60.9, c_acc: 71.9}\n","STEP:193, D{v_l: 0.811, v_acc: [65.6| 78.1| 71.9], c_acc: [53.1| 87.5]}  G{v_l: 1.183, v_acc: 39.1, c_acc: 78.1}\n","STEP:194, D{v_l: 1.054, v_acc: [37.5| 53.1| 45.3], c_acc: [56.2| 93.8]}  G{v_l: 1.014, v_acc: 45.3, c_acc: 89.1}\n","STEP:195, D{v_l: 0.700, v_acc: [68.8| 71.9| 70.3], c_acc: [78.1| 93.8]}  G{v_l: 0.896, v_acc: 43.8, c_acc: 79.7}\n","STEP:196, D{v_l: 0.700, v_acc: [65.6| 68.8| 67.2], c_acc: [65.6| 84.4]}  G{v_l: 1.065, v_acc: 34.4, c_acc: 71.9}\n","STEP:197, D{v_l: 1.011, v_acc: [46.9| 59.4| 53.1], c_acc: [56.2| 100.0]}  G{v_l: 1.026, v_acc: 40.6, c_acc: 84.4}\n","STEP:198, D{v_l: 0.828, v_acc: [65.6| 71.9| 68.8], c_acc: [62.5| 100.0]}  G{v_l: 0.842, v_acc: 54.7, c_acc: 79.7}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.0203 - valid_loss: 0.9287 - class_loss: 1.6740 - valid_acc: 0.0235 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.3310 - valid_loss: 0.6251 - class_loss: 0.2882 - valid_acc: 0.7294 - class_acc: 0.9412\n","average v_acc: 37.647, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:199, D{v_l: 0.791, v_acc: [69.2| 53.1| 61.2], c_acc: [84.6| 96.9]}  G{v_l: 0.776, v_acc: 50.0, c_acc: 85.9}\n","STEP:200, D{v_l: 0.682, v_acc: [65.6| 75.0| 70.3], c_acc: [62.5| 100.0]}  G{v_l: 1.191, v_acc: 37.5, c_acc: 81.2}\n","STEP:201, D{v_l: 0.741, v_acc: [53.1| 62.5| 57.8], c_acc: [62.5| 87.5]}  G{v_l: 1.100, v_acc: 40.6, c_acc: 81.2}\n","STEP:202, D{v_l: 0.499, v_acc: [65.6| 81.2| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 1.241, v_acc: 31.2, c_acc: 87.5}\n","STEP:203, D{v_l: 0.739, v_acc: [59.4| 62.5| 60.9], c_acc: [59.4| 93.8]}  G{v_l: 0.923, v_acc: 43.8, c_acc: 82.8}\n","STEP:204, D{v_l: 0.751, v_acc: [59.4| 68.8| 64.1], c_acc: [62.5| 93.8]}  G{v_l: 0.931, v_acc: 43.8, c_acc: 87.5}\n","STEP:205, D{v_l: 0.851, v_acc: [50.0| 71.9| 60.9], c_acc: [62.5| 90.6]}  G{v_l: 1.005, v_acc: 37.5, c_acc: 93.8}\n","STEP:206, D{v_l: 0.717, v_acc: [59.4| 68.8| 64.1], c_acc: [53.1| 90.6]}  G{v_l: 0.815, v_acc: 46.9, c_acc: 79.7}\n","STEP:207, D{v_l: 0.766, v_acc: [62.5| 62.5| 62.5], c_acc: [62.5| 87.5]}  G{v_l: 1.030, v_acc: 45.3, c_acc: 84.4}\n","STEP:208, D{v_l: 0.742, v_acc: [71.9| 53.1| 62.5], c_acc: [65.6| 93.8]}  G{v_l: 0.869, v_acc: 48.4, c_acc: 73.4}\n","STEP:209, D{v_l: 0.886, v_acc: [50.0| 68.8| 59.4], c_acc: [75.0| 96.9]}  G{v_l: 0.934, v_acc: 51.6, c_acc: 79.7}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.0838 - valid_loss: 0.9878 - class_loss: 1.6783 - valid_acc: 0.0000e+00 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.3358 - valid_loss: 0.6493 - class_loss: 0.2688 - valid_acc: 0.5529 - class_acc: 0.9529\n","average v_acc: 27.647, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:210, D{v_l: 0.675, v_acc: [55.6| 68.8| 62.2], c_acc: [88.0| 96.9]}  G{v_l: 0.857, v_acc: 42.2, c_acc: 87.5}\n","STEP:211, D{v_l: 0.954, v_acc: [65.6| 59.4| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 0.863, v_acc: 51.6, c_acc: 84.4}\n","STEP:212, D{v_l: 0.665, v_acc: [62.5| 71.9| 67.2], c_acc: [56.2| 87.5]}  G{v_l: 0.823, v_acc: 56.2, c_acc: 85.9}\n","STEP:213, D{v_l: 0.952, v_acc: [62.5| 68.8| 65.6], c_acc: [78.1| 90.6]}  G{v_l: 1.002, v_acc: 40.6, c_acc: 81.2}\n","STEP:214, D{v_l: 1.188, v_acc: [50.0| 50.0| 50.0], c_acc: [71.9| 90.6]}  G{v_l: 0.910, v_acc: 46.9, c_acc: 82.8}\n","STEP:215, D{v_l: 0.680, v_acc: [68.8| 78.1| 73.4], c_acc: [81.2| 100.0]}  G{v_l: 0.832, v_acc: 53.1, c_acc: 84.4}\n","STEP:216, D{v_l: 1.029, v_acc: [50.0| 62.5| 56.2], c_acc: [81.2| 93.8]}  G{v_l: 0.835, v_acc: 48.4, c_acc: 87.5}\n","STEP:217, D{v_l: 0.787, v_acc: [62.5| 62.5| 62.5], c_acc: [71.9| 87.5]}  G{v_l: 0.949, v_acc: 46.9, c_acc: 87.5}\n","STEP:218, D{v_l: 0.778, v_acc: [53.1| 65.6| 59.4], c_acc: [62.5| 90.6]}  G{v_l: 0.835, v_acc: 48.4, c_acc: 85.9}\n","STEP:219, D{v_l: 0.757, v_acc: [75.0| 56.2| 65.6], c_acc: [59.4| 87.5]}  G{v_l: 1.083, v_acc: 31.2, c_acc: 82.8}\n","STEP:220, D{v_l: 0.865, v_acc: [56.2| 68.8| 62.5], c_acc: [71.9| 96.9]}  G{v_l: 0.879, v_acc: 45.3, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 2.9859 - valid_loss: 0.9121 - class_loss: 1.6561 - valid_acc: 0.0471 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.2265 - valid_loss: 0.6240 - class_loss: 0.1848 - valid_acc: 0.6118 - class_acc: 0.9882\n","average v_acc: 32.941, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","Epoch: 20\n","====================================================================================================\n","STEP:221, D{v_l: 0.678, v_acc: [64.1| 68.8| 66.4], c_acc: [90.6| 84.4]}  G{v_l: 1.020, v_acc: 35.9, c_acc: 82.8}\n","STEP:222, D{v_l: 0.772, v_acc: [59.4| 65.6| 62.5], c_acc: [62.5| 90.6]}  G{v_l: 0.968, v_acc: 35.9, c_acc: 82.8}\n","STEP:223, D{v_l: 0.689, v_acc: [62.5| 71.9| 67.2], c_acc: [59.4| 93.8]}  G{v_l: 0.940, v_acc: 50.0, c_acc: 89.1}\n","STEP:224, D{v_l: 0.633, v_acc: [59.4| 75.0| 67.2], c_acc: [75.0| 90.6]}  G{v_l: 0.921, v_acc: 50.0, c_acc: 81.2}\n","STEP:225, D{v_l: 0.726, v_acc: [62.5| 68.8| 65.6], c_acc: [65.6| 96.9]}  G{v_l: 0.992, v_acc: 40.6, c_acc: 87.5}\n","STEP:226, D{v_l: 0.902, v_acc: [62.5| 59.4| 60.9], c_acc: [84.4| 96.9]}  G{v_l: 1.084, v_acc: 51.6, c_acc: 81.2}\n","STEP:227, D{v_l: 1.178, v_acc: [50.0| 56.2| 53.1], c_acc: [78.1| 81.2]}  G{v_l: 0.988, v_acc: 45.3, c_acc: 85.9}\n","STEP:228, D{v_l: 0.557, v_acc: [78.1| 68.8| 73.4], c_acc: [59.4| 96.9]}  G{v_l: 1.179, v_acc: 43.8, c_acc: 84.4}\n","STEP:229, D{v_l: 1.009, v_acc: [59.4| 56.2| 57.8], c_acc: [71.9| 90.6]}  G{v_l: 1.107, v_acc: 48.4, c_acc: 92.2}\n","STEP:230, D{v_l: 0.718, v_acc: [50.0| 75.0| 62.5], c_acc: [50.0| 90.6]}  G{v_l: 1.055, v_acc: 45.3, c_acc: 93.8}\n","STEP:231, D{v_l: 1.089, v_acc: [50.0| 62.5| 56.2], c_acc: [65.6| 87.5]}  G{v_l: 0.962, v_acc: 46.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 3.0920 - valid_loss: 0.8348 - class_loss: 1.8394 - valid_acc: 0.0941 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1890 - valid_loss: 0.6134 - class_loss: 0.1580 - valid_acc: 0.6118 - class_acc: 0.9647\n","average v_acc: 35.294, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:232, D{v_l: 0.681, v_acc: [60.7| 62.5| 61.6], c_acc: [88.0| 100.0]}  G{v_l: 1.119, v_acc: 43.8, c_acc: 87.5}\n","STEP:233, D{v_l: 0.526, v_acc: [68.8| 71.9| 70.3], c_acc: [59.4| 93.8]}  G{v_l: 1.050, v_acc: 42.2, c_acc: 90.6}\n","STEP:234, D{v_l: 0.949, v_acc: [50.0| 68.8| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 1.101, v_acc: 42.2, c_acc: 87.5}\n","STEP:235, D{v_l: 0.882, v_acc: [56.2| 59.4| 57.8], c_acc: [71.9| 100.0]}  G{v_l: 1.029, v_acc: 40.6, c_acc: 93.8}\n","STEP:236, D{v_l: 0.613, v_acc: [71.9| 71.9| 71.9], c_acc: [68.8| 93.8]}  G{v_l: 0.944, v_acc: 51.6, c_acc: 92.2}\n","STEP:237, D{v_l: 1.085, v_acc: [53.1| 50.0| 51.6], c_acc: [75.0| 96.9]}  G{v_l: 0.914, v_acc: 51.6, c_acc: 89.1}\n","STEP:238, D{v_l: 1.163, v_acc: [56.2| 50.0| 53.1], c_acc: [62.5| 93.8]}  G{v_l: 0.889, v_acc: 51.6, c_acc: 89.1}\n","STEP:239, D{v_l: 0.775, v_acc: [53.1| 68.8| 60.9], c_acc: [71.9| 90.6]}  G{v_l: 0.916, v_acc: 53.1, c_acc: 89.1}\n","STEP:240, D{v_l: 0.884, v_acc: [56.2| 59.4| 57.8], c_acc: [65.6| 96.9]}  G{v_l: 1.023, v_acc: 42.2, c_acc: 90.6}\n","STEP:241, D{v_l: 0.997, v_acc: [46.9| 56.2| 51.6], c_acc: [78.1| 96.9]}  G{v_l: 0.855, v_acc: 51.6, c_acc: 87.5}\n","STEP:242, D{v_l: 0.828, v_acc: [34.4| 78.1| 56.2], c_acc: [75.0| 96.9]}  G{v_l: 1.123, v_acc: 40.6, c_acc: 82.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.3522 - valid_loss: 0.8806 - class_loss: 2.0539 - valid_acc: 0.0706 - class_acc: 0.5294\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1154 - valid_loss: 0.6024 - class_loss: 0.0953 - valid_acc: 0.7059 - class_acc: 1.0000\n","average v_acc: 38.824, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:243, D{v_l: 0.730, v_acc: [69.2| 59.4| 64.3], c_acc: [90.6| 84.4]}  G{v_l: 0.985, v_acc: 53.1, c_acc: 87.5}\n","STEP:244, D{v_l: 0.671, v_acc: [71.9| 62.5| 67.2], c_acc: [56.2| 96.9]}  G{v_l: 1.009, v_acc: 48.4, c_acc: 90.6}\n","STEP:245, D{v_l: 0.690, v_acc: [50.0| 75.0| 62.5], c_acc: [62.5| 90.6]}  G{v_l: 1.004, v_acc: 42.2, c_acc: 92.2}\n","STEP:246, D{v_l: 0.815, v_acc: [59.4| 62.5| 60.9], c_acc: [59.4| 96.9]}  G{v_l: 0.957, v_acc: 51.6, c_acc: 93.8}\n","STEP:247, D{v_l: 0.784, v_acc: [59.4| 78.1| 68.8], c_acc: [65.6| 100.0]}  G{v_l: 1.018, v_acc: 50.0, c_acc: 92.2}\n","STEP:248, D{v_l: 0.761, v_acc: [65.6| 68.8| 67.2], c_acc: [65.6| 90.6]}  G{v_l: 0.975, v_acc: 40.6, c_acc: 90.6}\n","STEP:249, D{v_l: 0.895, v_acc: [43.8| 65.6| 54.7], c_acc: [75.0| 96.9]}  G{v_l: 0.969, v_acc: 53.1, c_acc: 92.2}\n","STEP:250, D{v_l: 0.652, v_acc: [62.5| 68.8| 65.6], c_acc: [62.5| 93.8]}  G{v_l: 0.885, v_acc: 46.9, c_acc: 87.5}\n","STEP:251, D{v_l: 0.824, v_acc: [62.5| 59.4| 60.9], c_acc: [56.2| 93.8]}  G{v_l: 1.029, v_acc: 48.4, c_acc: 87.5}\n","STEP:252, D{v_l: 0.979, v_acc: [65.6| 56.2| 60.9], c_acc: [75.0| 87.5]}  G{v_l: 0.983, v_acc: 50.0, c_acc: 92.2}\n","STEP:253, D{v_l: 0.877, v_acc: [59.4| 68.8| 64.1], c_acc: [90.6| 93.8]}  G{v_l: 1.052, v_acc: 48.4, c_acc: 81.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.9524 - valid_loss: 0.8445 - class_loss: 1.6902 - valid_acc: 0.0941 - class_acc: 0.5059\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0770 - valid_loss: 0.5679 - class_loss: 0.0914 - valid_acc: 0.8353 - class_acc: 1.0000\n","average v_acc: 46.471, three class acc: 50.588, two class acc: 50.588\n","====================================================================================================\n","STEP:254, D{v_l: 0.758, v_acc: [78.6| 59.4| 69.0], c_acc: [91.5| 90.6]}  G{v_l: 0.998, v_acc: 43.8, c_acc: 92.2}\n","STEP:255, D{v_l: 0.720, v_acc: [56.2| 65.6| 60.9], c_acc: [62.5| 100.0]}  G{v_l: 1.157, v_acc: 35.9, c_acc: 96.9}\n","STEP:256, D{v_l: 0.842, v_acc: [53.1| 62.5| 57.8], c_acc: [78.1| 87.5]}  G{v_l: 1.085, v_acc: 48.4, c_acc: 92.2}\n","STEP:257, D{v_l: 0.833, v_acc: [56.2| 53.1| 54.7], c_acc: [81.2| 96.9]}  G{v_l: 1.069, v_acc: 45.3, c_acc: 87.5}\n","STEP:258, D{v_l: 0.744, v_acc: [59.4| 78.1| 68.8], c_acc: [78.1| 96.9]}  G{v_l: 1.189, v_acc: 45.3, c_acc: 90.6}\n","STEP:259, D{v_l: 0.771, v_acc: [65.6| 62.5| 64.1], c_acc: [75.0| 90.6]}  G{v_l: 0.958, v_acc: 43.8, c_acc: 89.1}\n","STEP:260, D{v_l: 0.823, v_acc: [65.6| 62.5| 64.1], c_acc: [68.8| 100.0]}  G{v_l: 1.119, v_acc: 42.2, c_acc: 90.6}\n","STEP:261, D{v_l: 0.695, v_acc: [59.4| 71.9| 65.6], c_acc: [62.5| 100.0]}  G{v_l: 0.959, v_acc: 54.7, c_acc: 85.9}\n","STEP:262, D{v_l: 0.709, v_acc: [59.4| 62.5| 60.9], c_acc: [62.5| 96.9]}  G{v_l: 0.980, v_acc: 50.0, c_acc: 96.9}\n","STEP:263, D{v_l: 0.776, v_acc: [65.6| 68.8| 67.2], c_acc: [68.8| 87.5]}  G{v_l: 1.104, v_acc: 51.6, c_acc: 82.8}\n","STEP:264, D{v_l: 0.796, v_acc: [65.6| 68.8| 67.2], c_acc: [71.9| 93.8]}  G{v_l: 1.158, v_acc: 35.9, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.1199 - valid_loss: 0.8690 - class_loss: 1.8332 - valid_acc: 0.1412 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0081 - valid_loss: 0.4883 - class_loss: 0.1022 - valid_acc: 0.8824 - class_acc: 0.9765\n","average v_acc: 51.176, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:265, D{v_l: 0.808, v_acc: [83.8| 71.9| 77.8], c_acc: [89.7| 96.9]}  G{v_l: 0.944, v_acc: 54.7, c_acc: 89.1}\n","STEP:266, D{v_l: 0.599, v_acc: [59.4| 68.8| 64.1], c_acc: [68.8| 100.0]}  G{v_l: 0.997, v_acc: 45.3, c_acc: 92.2}\n","STEP:267, D{v_l: 0.556, v_acc: [56.2| 78.1| 67.2], c_acc: [71.9| 96.9]}  G{v_l: 1.019, v_acc: 48.4, c_acc: 90.6}\n","STEP:268, D{v_l: 0.795, v_acc: [65.6| 53.1| 59.4], c_acc: [71.9| 90.6]}  G{v_l: 0.950, v_acc: 50.0, c_acc: 93.8}\n","STEP:269, D{v_l: 0.597, v_acc: [56.2| 75.0| 65.6], c_acc: [75.0| 96.9]}  G{v_l: 1.124, v_acc: 42.2, c_acc: 93.8}\n","STEP:270, D{v_l: 0.912, v_acc: [46.9| 59.4| 53.1], c_acc: [75.0| 96.9]}  G{v_l: 1.304, v_acc: 37.5, c_acc: 82.8}\n","STEP:271, D{v_l: 0.672, v_acc: [62.5| 75.0| 68.8], c_acc: [68.8| 100.0]}  G{v_l: 1.263, v_acc: 42.2, c_acc: 92.2}\n","STEP:272, D{v_l: 0.780, v_acc: [43.8| 78.1| 60.9], c_acc: [65.6| 96.9]}  G{v_l: 1.059, v_acc: 35.9, c_acc: 89.1}\n","STEP:273, D{v_l: 0.712, v_acc: [68.8| 59.4| 64.1], c_acc: [81.2| 93.8]}  G{v_l: 1.157, v_acc: 40.6, c_acc: 92.2}\n","STEP:274, D{v_l: 0.701, v_acc: [75.0| 53.1| 64.1], c_acc: [59.4| 100.0]}  G{v_l: 1.249, v_acc: 48.4, c_acc: 90.6}\n","STEP:275, D{v_l: 0.927, v_acc: [71.9| 75.0| 73.4], c_acc: [62.5| 90.6]}  G{v_l: 1.011, v_acc: 50.0, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.1718 - valid_loss: 0.8143 - class_loss: 1.9398 - valid_acc: 0.1647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0055 - valid_loss: 0.5141 - class_loss: 0.0738 - valid_acc: 0.8353 - class_acc: 1.0000\n","average v_acc: 50.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:276, D{v_l: 0.600, v_acc: [72.6| 71.9| 72.3], c_acc: [92.3| 90.6]}  G{v_l: 1.062, v_acc: 46.9, c_acc: 96.9}\n","STEP:277, D{v_l: 0.772, v_acc: [62.5| 62.5| 62.5], c_acc: [75.0| 87.5]}  G{v_l: 0.848, v_acc: 56.2, c_acc: 95.3}\n","STEP:278, D{v_l: 0.668, v_acc: [56.2| 65.6| 60.9], c_acc: [65.6| 87.5]}  G{v_l: 1.118, v_acc: 50.0, c_acc: 93.8}\n","STEP:279, D{v_l: 0.536, v_acc: [71.9| 78.1| 75.0], c_acc: [68.8| 96.9]}  G{v_l: 1.229, v_acc: 40.6, c_acc: 98.4}\n","STEP:280, D{v_l: 0.568, v_acc: [68.8| 75.0| 71.9], c_acc: [68.8| 96.9]}  G{v_l: 1.150, v_acc: 40.6, c_acc: 93.8}\n","STEP:281, D{v_l: 0.760, v_acc: [62.5| 84.4| 73.4], c_acc: [56.2| 90.6]}  G{v_l: 1.313, v_acc: 40.6, c_acc: 89.1}\n","STEP:282, D{v_l: 0.852, v_acc: [53.1| 68.8| 60.9], c_acc: [68.8| 90.6]}  G{v_l: 1.148, v_acc: 40.6, c_acc: 95.3}\n","STEP:283, D{v_l: 0.886, v_acc: [46.9| 56.2| 51.6], c_acc: [68.8| 90.6]}  G{v_l: 1.140, v_acc: 42.2, c_acc: 85.9}\n","STEP:284, D{v_l: 0.722, v_acc: [62.5| 65.6| 64.1], c_acc: [71.9| 96.9]}  G{v_l: 1.151, v_acc: 32.8, c_acc: 96.9}\n","STEP:285, D{v_l: 0.642, v_acc: [71.9| 81.2| 76.6], c_acc: [75.0| 100.0]}  G{v_l: 0.875, v_acc: 51.6, c_acc: 92.2}\n","STEP:286, D{v_l: 0.681, v_acc: [68.8| 78.1| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 0.956, v_acc: 53.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.0536 - valid_loss: 0.8224 - class_loss: 1.8136 - valid_acc: 0.1882 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0480 - valid_loss: 0.4991 - class_loss: 0.1313 - valid_acc: 0.8824 - class_acc: 0.9412\n","average v_acc: 53.529, three class acc: 51.765, two class acc: 52.941\n","====================================================================================================\n","STEP:287, D{v_l: 0.710, v_acc: [81.2| 50.0| 65.6], c_acc: [89.7| 87.5]}  G{v_l: 0.908, v_acc: 50.0, c_acc: 93.8}\n","STEP:288, D{v_l: 0.620, v_acc: [65.6| 68.8| 67.2], c_acc: [84.4| 96.9]}  G{v_l: 1.060, v_acc: 37.5, c_acc: 93.8}\n","STEP:289, D{v_l: 0.690, v_acc: [53.1| 75.0| 64.1], c_acc: [68.8| 93.8]}  G{v_l: 1.041, v_acc: 53.1, c_acc: 93.8}\n","STEP:290, D{v_l: 0.712, v_acc: [59.4| 56.2| 57.8], c_acc: [65.6| 96.9]}  G{v_l: 1.093, v_acc: 45.3, c_acc: 95.3}\n","STEP:291, D{v_l: 0.852, v_acc: [53.1| 62.5| 57.8], c_acc: [71.9| 93.8]}  G{v_l: 1.182, v_acc: 45.3, c_acc: 93.8}\n","STEP:292, D{v_l: 0.840, v_acc: [59.4| 59.4| 59.4], c_acc: [75.0| 100.0]}  G{v_l: 1.122, v_acc: 45.3, c_acc: 93.8}\n","STEP:293, D{v_l: 0.765, v_acc: [65.6| 71.9| 68.8], c_acc: [81.2| 96.9]}  G{v_l: 1.015, v_acc: 35.9, c_acc: 95.3}\n","STEP:294, D{v_l: 0.684, v_acc: [68.8| 71.9| 70.3], c_acc: [75.0| 100.0]}  G{v_l: 0.957, v_acc: 53.1, c_acc: 96.9}\n","STEP:295, D{v_l: 0.571, v_acc: [65.6| 68.8| 67.2], c_acc: [65.6| 93.8]}  G{v_l: 0.883, v_acc: 62.5, c_acc: 96.9}\n","STEP:296, D{v_l: 0.734, v_acc: [71.9| 59.4| 65.6], c_acc: [65.6| 100.0]}  G{v_l: 1.165, v_acc: 46.9, c_acc: 93.8}\n","STEP:297, D{v_l: 0.740, v_acc: [53.1| 78.1| 65.6], c_acc: [78.1| 90.6]}  G{v_l: 1.013, v_acc: 54.7, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.1038 - valid_loss: 0.7342 - class_loss: 1.9519 - valid_acc: 0.3647 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0469 - valid_loss: 0.5593 - class_loss: 0.0699 - valid_acc: 0.7412 - class_acc: 1.0000\n","average v_acc: 55.294, three class acc: 50.588, two class acc: 51.765\n","====================================================================================================\n","STEP:298, D{v_l: 0.704, v_acc: [70.1| 62.5| 66.3], c_acc: [91.5| 96.9]}  G{v_l: 1.232, v_acc: 46.9, c_acc: 90.6}\n","STEP:299, D{v_l: 0.804, v_acc: [43.8| 75.0| 59.4], c_acc: [71.9| 96.9]}  G{v_l: 0.996, v_acc: 53.1, c_acc: 95.3}\n","STEP:300, D{v_l: 0.634, v_acc: [65.6| 62.5| 64.1], c_acc: [68.8| 100.0]}  G{v_l: 1.233, v_acc: 43.8, c_acc: 93.8}\n","STEP:301, D{v_l: 0.708, v_acc: [71.9| 71.9| 71.9], c_acc: [78.1| 90.6]}  G{v_l: 1.141, v_acc: 48.4, c_acc: 96.9}\n","STEP:302, D{v_l: 0.658, v_acc: [71.9| 53.1| 62.5], c_acc: [71.9| 93.8]}  G{v_l: 0.971, v_acc: 51.6, c_acc: 92.2}\n","STEP:303, D{v_l: 0.723, v_acc: [62.5| 81.2| 71.9], c_acc: [68.8| 96.9]}  G{v_l: 0.999, v_acc: 43.8, c_acc: 93.8}\n","STEP:304, D{v_l: 1.160, v_acc: [59.4| 56.2| 57.8], c_acc: [65.6| 93.8]}  G{v_l: 1.170, v_acc: 39.1, c_acc: 93.8}\n","STEP:305, D{v_l: 0.727, v_acc: [62.5| 62.5| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 1.094, v_acc: 51.6, c_acc: 96.9}\n","STEP:306, D{v_l: 0.783, v_acc: [53.1| 62.5| 57.8], c_acc: [75.0| 96.9]}  G{v_l: 1.190, v_acc: 37.5, c_acc: 89.1}\n","STEP:307, D{v_l: 0.842, v_acc: [62.5| 56.2| 59.4], c_acc: [68.8| 100.0]}  G{v_l: 1.060, v_acc: 48.4, c_acc: 92.2}\n","STEP:308, D{v_l: 0.937, v_acc: [65.6| 62.5| 64.1], c_acc: [75.0| 100.0]}  G{v_l: 0.927, v_acc: 45.3, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.5253 - valid_loss: 0.7548 - class_loss: 2.3528 - valid_acc: 0.3882 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 0.9961 - valid_loss: 0.5104 - class_loss: 0.0680 - valid_acc: 0.8824 - class_acc: 1.0000\n","average v_acc: 63.529, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","STEP:309, D{v_l: 0.606, v_acc: [81.2| 68.8| 75.0], c_acc: [94.0| 93.8]}  G{v_l: 0.977, v_acc: 51.6, c_acc: 92.2}\n","STEP:310, D{v_l: 0.630, v_acc: [62.5| 71.9| 67.2], c_acc: [84.4| 96.9]}  G{v_l: 0.933, v_acc: 45.3, c_acc: 98.4}\n","STEP:311, D{v_l: 0.903, v_acc: [53.1| 59.4| 56.2], c_acc: [78.1| 90.6]}  G{v_l: 1.005, v_acc: 43.8, c_acc: 95.3}\n","STEP:312, D{v_l: 0.793, v_acc: [56.2| 71.9| 64.1], c_acc: [84.4| 90.6]}  G{v_l: 1.134, v_acc: 40.6, c_acc: 98.4}\n","STEP:313, D{v_l: 0.899, v_acc: [75.0| 59.4| 67.2], c_acc: [78.1| 90.6]}  G{v_l: 0.827, v_acc: 53.1, c_acc: 90.6}\n","STEP:314, D{v_l: 0.667, v_acc: [62.5| 56.2| 59.4], c_acc: [65.6| 100.0]}  G{v_l: 1.025, v_acc: 50.0, c_acc: 95.3}\n","STEP:315, D{v_l: 0.630, v_acc: [62.5| 68.8| 65.6], c_acc: [87.5| 100.0]}  G{v_l: 1.029, v_acc: 46.9, c_acc: 96.9}\n","STEP:316, D{v_l: 0.713, v_acc: [81.2| 62.5| 71.9], c_acc: [78.1| 96.9]}  G{v_l: 1.426, v_acc: 35.9, c_acc: 95.3}\n","STEP:317, D{v_l: 0.756, v_acc: [56.2| 71.9| 64.1], c_acc: [78.1| 87.5]}  G{v_l: 1.199, v_acc: 39.1, c_acc: 95.3}\n","STEP:318, D{v_l: 0.805, v_acc: [46.9| 56.2| 51.6], c_acc: [75.0| 96.9]}  G{v_l: 1.211, v_acc: 39.1, c_acc: 95.3}\n","STEP:319, D{v_l: 0.595, v_acc: [71.9| 78.1| 75.0], c_acc: [75.0| 90.6]}  G{v_l: 0.923, v_acc: 53.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.2543 - valid_loss: 0.7395 - class_loss: 2.0971 - valid_acc: 0.3647 - class_acc: 0.5294\n","3/3 [==============================] - 0s 50ms/step - loss: 0.9801 - valid_loss: 0.5251 - class_loss: 0.0373 - valid_acc: 0.8235 - class_acc: 1.0000\n","average v_acc: 59.412, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:320, D{v_l: 0.663, v_acc: [76.9| 68.8| 72.8], c_acc: [94.0| 93.8]}  G{v_l: 1.340, v_acc: 23.4, c_acc: 93.8}\n","STEP:321, D{v_l: 0.660, v_acc: [56.2| 81.2| 68.8], c_acc: [84.4| 93.8]}  G{v_l: 0.938, v_acc: 56.2, c_acc: 92.2}\n","STEP:322, D{v_l: 0.557, v_acc: [78.1| 78.1| 78.1], c_acc: [87.5| 84.4]}  G{v_l: 1.203, v_acc: 48.4, c_acc: 100.0}\n","STEP:323, D{v_l: 0.573, v_acc: [62.5| 75.0| 68.8], c_acc: [59.4| 100.0]}  G{v_l: 1.035, v_acc: 57.8, c_acc: 85.9}\n","STEP:324, D{v_l: 0.511, v_acc: [78.1| 78.1| 78.1], c_acc: [68.8| 96.9]}  G{v_l: 0.913, v_acc: 56.2, c_acc: 92.2}\n","STEP:325, D{v_l: 0.824, v_acc: [62.5| 59.4| 60.9], c_acc: [71.9| 100.0]}  G{v_l: 0.831, v_acc: 57.8, c_acc: 93.8}\n","STEP:326, D{v_l: 0.789, v_acc: [62.5| 71.9| 67.2], c_acc: [71.9| 84.4]}  G{v_l: 0.831, v_acc: 48.4, c_acc: 96.9}\n","STEP:327, D{v_l: 0.766, v_acc: [56.2| 50.0| 53.1], c_acc: [75.0| 93.8]}  G{v_l: 1.054, v_acc: 40.6, c_acc: 96.9}\n","STEP:328, D{v_l: 0.850, v_acc: [78.1| 62.5| 70.3], c_acc: [71.9| 87.5]}  G{v_l: 1.099, v_acc: 46.9, c_acc: 95.3}\n","STEP:329, D{v_l: 0.626, v_acc: [71.9| 75.0| 73.4], c_acc: [78.1| 90.6]}  G{v_l: 1.060, v_acc: 48.4, c_acc: 96.9}\n","STEP:330, D{v_l: 0.992, v_acc: [53.1| 65.6| 59.4], c_acc: [87.5| 93.8]}  G{v_l: 1.077, v_acc: 51.6, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.2056 - valid_loss: 0.9984 - class_loss: 2.7895 - valid_acc: 0.1647 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 0.9738 - valid_loss: 0.5104 - class_loss: 0.0457 - valid_acc: 0.8706 - class_acc: 0.9882\n","average v_acc: 51.765, three class acc: 51.765, two class acc: 51.765\n","====================================================================================================\n","Epoch: 30\n","====================================================================================================\n","STEP:331, D{v_l: 0.580, v_acc: [84.6| 75.0| 79.8], c_acc: [93.2| 93.8]}  G{v_l: 1.170, v_acc: 40.6, c_acc: 90.6}\n","STEP:332, D{v_l: 0.778, v_acc: [56.2| 78.1| 67.2], c_acc: [68.8| 96.9]}  G{v_l: 0.964, v_acc: 46.9, c_acc: 98.4}\n","STEP:333, D{v_l: 1.138, v_acc: [53.1| 46.9| 50.0], c_acc: [78.1| 100.0]}  G{v_l: 1.042, v_acc: 46.9, c_acc: 95.3}\n","STEP:334, D{v_l: 1.001, v_acc: [59.4| 65.6| 62.5], c_acc: [81.2| 90.6]}  G{v_l: 0.830, v_acc: 46.9, c_acc: 96.9}\n","STEP:335, D{v_l: 1.098, v_acc: [59.4| 50.0| 54.7], c_acc: [84.4| 81.2]}  G{v_l: 1.014, v_acc: 56.2, c_acc: 93.8}\n","STEP:336, D{v_l: 0.671, v_acc: [56.2| 71.9| 64.1], c_acc: [78.1| 100.0]}  G{v_l: 1.121, v_acc: 57.8, c_acc: 89.1}\n","STEP:337, D{v_l: 1.133, v_acc: [53.1| 59.4| 56.2], c_acc: [75.0| 96.9]}  G{v_l: 1.040, v_acc: 51.6, c_acc: 93.8}\n","STEP:338, D{v_l: 0.689, v_acc: [59.4| 59.4| 59.4], c_acc: [90.6| 100.0]}  G{v_l: 0.956, v_acc: 56.2, c_acc: 85.9}\n","STEP:339, D{v_l: 0.605, v_acc: [75.0| 75.0| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 1.009, v_acc: 43.8, c_acc: 92.2}\n","STEP:340, D{v_l: 0.692, v_acc: [65.6| 43.8| 54.7], c_acc: [81.2| 96.9]}  G{v_l: 0.981, v_acc: 53.1, c_acc: 89.1}\n","STEP:341, D{v_l: 0.730, v_acc: [59.4| 68.8| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 1.030, v_acc: 48.4, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 4.7447 - valid_loss: 1.0097 - class_loss: 3.3174 - valid_acc: 0.2353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0484 - valid_loss: 0.5088 - class_loss: 0.1220 - valid_acc: 0.8118 - class_acc: 0.9647\n","average v_acc: 52.353, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:342, D{v_l: 0.545, v_acc: [73.5| 81.2| 77.4], c_acc: [90.6| 100.0]}  G{v_l: 1.093, v_acc: 50.0, c_acc: 95.3}\n","STEP:343, D{v_l: 0.582, v_acc: [78.1| 68.8| 73.4], c_acc: [81.2| 96.9]}  G{v_l: 1.171, v_acc: 42.2, c_acc: 90.6}\n","STEP:344, D{v_l: 0.686, v_acc: [78.1| 56.2| 67.2], c_acc: [75.0| 96.9]}  G{v_l: 1.109, v_acc: 42.2, c_acc: 93.8}\n","STEP:345, D{v_l: 0.596, v_acc: [46.9| 81.2| 64.1], c_acc: [78.1| 96.9]}  G{v_l: 0.863, v_acc: 51.6, c_acc: 93.8}\n","STEP:346, D{v_l: 0.595, v_acc: [78.1| 81.2| 79.7], c_acc: [71.9| 84.4]}  G{v_l: 1.066, v_acc: 42.2, c_acc: 90.6}\n","STEP:347, D{v_l: 0.578, v_acc: [68.8| 71.9| 70.3], c_acc: [84.4| 93.8]}  G{v_l: 0.983, v_acc: 50.0, c_acc: 90.6}\n","STEP:348, D{v_l: 0.588, v_acc: [65.6| 68.8| 67.2], c_acc: [78.1| 96.9]}  G{v_l: 1.274, v_acc: 45.3, c_acc: 95.3}\n","STEP:349, D{v_l: 0.567, v_acc: [62.5| 81.2| 71.9], c_acc: [71.9| 93.8]}  G{v_l: 0.924, v_acc: 51.6, c_acc: 89.1}\n","STEP:350, D{v_l: 0.783, v_acc: [75.0| 56.2| 65.6], c_acc: [75.0| 100.0]}  G{v_l: 1.224, v_acc: 45.3, c_acc: 95.3}\n","STEP:351, D{v_l: 0.470, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 100.0]}  G{v_l: 0.889, v_acc: 57.8, c_acc: 92.2}\n","STEP:352, D{v_l: 0.480, v_acc: [78.1| 84.4| 81.2], c_acc: [75.0| 96.9]}  G{v_l: 1.286, v_acc: 39.1, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.9132 - valid_loss: 1.0676 - class_loss: 3.4280 - valid_acc: 0.2471 - class_acc: 0.5294\n","3/3 [==============================] - 0s 44ms/step - loss: 1.0208 - valid_loss: 0.5226 - class_loss: 0.0806 - valid_acc: 0.7176 - class_acc: 0.9765\n","average v_acc: 48.235, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:353, D{v_l: 0.528, v_acc: [71.8| 78.1| 75.0], c_acc: [92.3| 90.6]}  G{v_l: 1.237, v_acc: 48.4, c_acc: 93.8}\n","STEP:354, D{v_l: 0.611, v_acc: [68.8| 78.1| 73.4], c_acc: [75.0| 100.0]}  G{v_l: 1.088, v_acc: 48.4, c_acc: 95.3}\n","STEP:355, D{v_l: 0.572, v_acc: [65.6| 81.2| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 1.314, v_acc: 40.6, c_acc: 93.8}\n","STEP:356, D{v_l: 0.571, v_acc: [62.5| 68.8| 65.6], c_acc: [75.0| 100.0]}  G{v_l: 1.079, v_acc: 48.4, c_acc: 96.9}\n","STEP:357, D{v_l: 0.874, v_acc: [65.6| 59.4| 62.5], c_acc: [84.4| 93.8]}  G{v_l: 1.323, v_acc: 45.3, c_acc: 90.6}\n","STEP:358, D{v_l: 0.825, v_acc: [65.6| 53.1| 59.4], c_acc: [71.9| 87.5]}  G{v_l: 1.096, v_acc: 53.1, c_acc: 85.9}\n","STEP:359, D{v_l: 0.826, v_acc: [68.8| 62.5| 65.6], c_acc: [81.2| 90.6]}  G{v_l: 1.218, v_acc: 46.9, c_acc: 92.2}\n","STEP:360, D{v_l: 0.838, v_acc: [59.4| 56.2| 57.8], c_acc: [62.5| 87.5]}  G{v_l: 1.114, v_acc: 53.1, c_acc: 92.2}\n","STEP:361, D{v_l: 0.589, v_acc: [68.8| 78.1| 73.4], c_acc: [75.0| 96.9]}  G{v_l: 1.209, v_acc: 39.1, c_acc: 93.8}\n","STEP:362, D{v_l: 0.596, v_acc: [53.1| 78.1| 65.6], c_acc: [93.8| 93.8]}  G{v_l: 1.337, v_acc: 43.8, c_acc: 93.8}\n","STEP:363, D{v_l: 0.671, v_acc: [56.2| 75.0| 65.6], c_acc: [71.9| 90.6]}  G{v_l: 1.012, v_acc: 53.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.6777 - valid_loss: 0.9820 - class_loss: 3.2781 - valid_acc: 0.3294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 46ms/step - loss: 0.9546 - valid_loss: 0.4523 - class_loss: 0.0847 - valid_acc: 0.8706 - class_acc: 0.9765\n","average v_acc: 60.000, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:364, D{v_l: 0.664, v_acc: [81.2| 62.5| 71.8], c_acc: [89.7| 93.8]}  G{v_l: 1.090, v_acc: 46.9, c_acc: 98.4}\n","STEP:365, D{v_l: 0.789, v_acc: [62.5| 71.9| 67.2], c_acc: [84.4| 93.8]}  G{v_l: 1.246, v_acc: 43.8, c_acc: 98.4}\n","STEP:366, D{v_l: 0.717, v_acc: [65.6| 65.6| 65.6], c_acc: [78.1| 93.8]}  G{v_l: 1.145, v_acc: 48.4, c_acc: 90.6}\n","STEP:367, D{v_l: 0.588, v_acc: [68.8| 68.8| 68.8], c_acc: [68.8| 96.9]}  G{v_l: 0.937, v_acc: 53.1, c_acc: 89.1}\n","STEP:368, D{v_l: 0.675, v_acc: [65.6| 65.6| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.544, v_acc: 29.7, c_acc: 93.8}\n","STEP:369, D{v_l: 0.530, v_acc: [65.6| 81.2| 73.4], c_acc: [75.0| 100.0]}  G{v_l: 1.517, v_acc: 31.2, c_acc: 93.8}\n","STEP:370, D{v_l: 0.659, v_acc: [65.6| 71.9| 68.8], c_acc: [93.8| 93.8]}  G{v_l: 1.125, v_acc: 46.9, c_acc: 98.4}\n","STEP:371, D{v_l: 0.500, v_acc: [68.8| 87.5| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 0.950, v_acc: 46.9, c_acc: 98.4}\n","STEP:372, D{v_l: 0.719, v_acc: [62.5| 84.4| 73.4], c_acc: [84.4| 93.8]}  G{v_l: 1.238, v_acc: 45.3, c_acc: 87.5}\n","STEP:373, D{v_l: 0.579, v_acc: [59.4| 75.0| 67.2], c_acc: [78.1| 90.6]}  G{v_l: 1.090, v_acc: 46.9, c_acc: 93.8}\n","STEP:374, D{v_l: 0.636, v_acc: [59.4| 71.9| 65.6], c_acc: [68.8| 93.8]}  G{v_l: 1.304, v_acc: 45.3, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 3.7660 - valid_loss: 0.7861 - class_loss: 2.5623 - valid_acc: 0.5059 - class_acc: 0.5059\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0053 - valid_loss: 0.4928 - class_loss: 0.0949 - valid_acc: 0.8000 - class_acc: 0.9647\n","average v_acc: 65.294, three class acc: 50.588, two class acc: 51.765\n","====================================================================================================\n","STEP:375, D{v_l: 0.650, v_acc: [76.1| 65.6| 70.8], c_acc: [89.7| 100.0]}  G{v_l: 1.224, v_acc: 43.8, c_acc: 89.1}\n","STEP:376, D{v_l: 0.647, v_acc: [68.8| 68.8| 68.8], c_acc: [78.1| 96.9]}  G{v_l: 1.337, v_acc: 40.6, c_acc: 96.9}\n","STEP:377, D{v_l: 0.728, v_acc: [56.2| 62.5| 59.4], c_acc: [68.8| 84.4]}  G{v_l: 1.264, v_acc: 35.9, c_acc: 95.3}\n","STEP:378, D{v_l: 0.751, v_acc: [81.2| 68.8| 75.0], c_acc: [68.8| 96.9]}  G{v_l: 1.202, v_acc: 50.0, c_acc: 95.3}\n","STEP:379, D{v_l: 0.569, v_acc: [68.8| 68.8| 68.8], c_acc: [84.4| 90.6]}  G{v_l: 1.235, v_acc: 43.8, c_acc: 96.9}\n","STEP:380, D{v_l: 0.749, v_acc: [62.5| 56.2| 59.4], c_acc: [68.8| 96.9]}  G{v_l: 1.279, v_acc: 39.1, c_acc: 98.4}\n","STEP:381, D{v_l: 0.888, v_acc: [71.9| 56.2| 64.1], c_acc: [75.0| 96.9]}  G{v_l: 1.101, v_acc: 48.4, c_acc: 89.1}\n","STEP:382, D{v_l: 0.537, v_acc: [71.9| 78.1| 75.0], c_acc: [81.2| 84.4]}  G{v_l: 1.235, v_acc: 39.1, c_acc: 87.5}\n","STEP:383, D{v_l: 0.621, v_acc: [65.6| 71.9| 68.8], c_acc: [71.9| 93.8]}  G{v_l: 1.113, v_acc: 51.6, c_acc: 93.8}\n","STEP:384, D{v_l: 0.584, v_acc: [65.6| 65.6| 65.6], c_acc: [68.8| 93.8]}  G{v_l: 1.214, v_acc: 48.4, c_acc: 93.8}\n","STEP:385, D{v_l: 0.878, v_acc: [43.8| 68.8| 56.2], c_acc: [68.8| 100.0]}  G{v_l: 1.236, v_acc: 48.4, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.4771 - valid_loss: 0.7265 - class_loss: 2.3331 - valid_acc: 0.5529 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0263 - valid_loss: 0.5567 - class_loss: 0.0520 - valid_acc: 0.6824 - class_acc: 1.0000\n","average v_acc: 61.765, three class acc: 50.588, two class acc: 54.118\n","====================================================================================================\n","STEP:386, D{v_l: 0.586, v_acc: [65.8| 65.6| 65.7], c_acc: [94.9| 100.0]}  G{v_l: 0.888, v_acc: 59.4, c_acc: 89.1}\n","STEP:387, D{v_l: 0.716, v_acc: [75.0| 68.8| 71.9], c_acc: [75.0| 93.8]}  G{v_l: 1.282, v_acc: 48.4, c_acc: 90.6}\n","STEP:388, D{v_l: 0.772, v_acc: [53.1| 62.5| 57.8], c_acc: [84.4| 84.4]}  G{v_l: 1.210, v_acc: 48.4, c_acc: 87.5}\n","STEP:389, D{v_l: 1.011, v_acc: [53.1| 65.6| 59.4], c_acc: [84.4| 81.2]}  G{v_l: 0.917, v_acc: 54.7, c_acc: 90.6}\n","STEP:390, D{v_l: 0.687, v_acc: [62.5| 59.4| 60.9], c_acc: [75.0| 93.8]}  G{v_l: 1.049, v_acc: 48.4, c_acc: 93.8}\n","STEP:391, D{v_l: 0.733, v_acc: [65.6| 59.4| 62.5], c_acc: [75.0| 100.0]}  G{v_l: 1.096, v_acc: 53.1, c_acc: 89.1}\n","STEP:392, D{v_l: 0.737, v_acc: [65.6| 53.1| 59.4], c_acc: [68.8| 93.8]}  G{v_l: 1.193, v_acc: 40.6, c_acc: 89.1}\n","STEP:393, D{v_l: 0.607, v_acc: [84.4| 59.4| 71.9], c_acc: [75.0| 90.6]}  G{v_l: 1.068, v_acc: 46.9, c_acc: 90.6}\n","STEP:394, D{v_l: 0.690, v_acc: [68.8| 68.8| 68.8], c_acc: [71.9| 100.0]}  G{v_l: 1.028, v_acc: 59.4, c_acc: 92.2}\n","STEP:395, D{v_l: 0.839, v_acc: [56.2| 71.9| 64.1], c_acc: [84.4| 96.9]}  G{v_l: 1.148, v_acc: 46.9, c_acc: 87.5}\n","STEP:396, D{v_l: 0.763, v_acc: [65.6| 65.6| 65.6], c_acc: [81.2| 90.6]}  G{v_l: 0.930, v_acc: 64.1, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.0936 - valid_loss: 0.5495 - class_loss: 2.1265 - valid_acc: 0.6471 - class_acc: 0.5412\n","3/3 [==============================] - 0s 51ms/step - loss: 0.9556 - valid_loss: 0.5142 - class_loss: 0.0239 - valid_acc: 0.7529 - class_acc: 1.0000\n","average v_acc: 70.000, three class acc: 54.118, two class acc: 58.824\n","====================================================================================================\n","STEP:397, D{v_l: 0.688, v_acc: [72.6| 62.5| 67.6], c_acc: [95.7| 90.6]}  G{v_l: 1.265, v_acc: 45.3, c_acc: 95.3}\n","STEP:398, D{v_l: 0.910, v_acc: [81.2| 50.0| 65.6], c_acc: [75.0| 93.8]}  G{v_l: 1.281, v_acc: 37.5, c_acc: 95.3}\n","STEP:399, D{v_l: 0.586, v_acc: [59.4| 75.0| 67.2], c_acc: [93.8| 87.5]}  G{v_l: 0.989, v_acc: 46.9, c_acc: 93.8}\n","STEP:400, D{v_l: 0.645, v_acc: [62.5| 75.0| 68.8], c_acc: [81.2| 90.6]}  G{v_l: 1.140, v_acc: 37.5, c_acc: 92.2}\n","STEP:401, D{v_l: 0.646, v_acc: [71.9| 65.6| 68.8], c_acc: [84.4| 93.8]}  G{v_l: 1.121, v_acc: 48.4, c_acc: 89.1}\n","STEP:402, D{v_l: 0.640, v_acc: [56.2| 87.5| 71.9], c_acc: [84.4| 87.5]}  G{v_l: 1.031, v_acc: 56.2, c_acc: 93.8}\n","STEP:403, D{v_l: 0.576, v_acc: [78.1| 62.5| 70.3], c_acc: [87.5| 100.0]}  G{v_l: 1.264, v_acc: 42.2, c_acc: 90.6}\n","STEP:404, D{v_l: 0.594, v_acc: [65.6| 71.9| 68.8], c_acc: [81.2| 93.8]}  G{v_l: 0.979, v_acc: 50.0, c_acc: 81.2}\n","STEP:405, D{v_l: 0.864, v_acc: [56.2| 65.6| 60.9], c_acc: [78.1| 93.8]}  G{v_l: 1.279, v_acc: 35.9, c_acc: 93.8}\n","STEP:406, D{v_l: 0.825, v_acc: [68.8| 65.6| 67.2], c_acc: [87.5| 93.8]}  G{v_l: 0.994, v_acc: 43.8, c_acc: 89.1}\n","STEP:407, D{v_l: 0.781, v_acc: [59.4| 65.6| 62.5], c_acc: [78.1| 81.2]}  G{v_l: 1.201, v_acc: 37.5, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.7886 - valid_loss: 0.5196 - class_loss: 1.8516 - valid_acc: 0.7882 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0607 - valid_loss: 0.4935 - class_loss: 0.1497 - valid_acc: 0.7647 - class_acc: 0.9647\n","average v_acc: 77.647, three class acc: 51.765, two class acc: 56.471\n","====================================================================================================\n","STEP:408, D{v_l: 0.752, v_acc: [73.5| 43.8| 58.6], c_acc: [92.3| 96.9]}  G{v_l: 1.009, v_acc: 51.6, c_acc: 96.9}\n","STEP:409, D{v_l: 0.741, v_acc: [59.4| 65.6| 62.5], c_acc: [78.1| 84.4]}  G{v_l: 1.145, v_acc: 40.6, c_acc: 89.1}\n","STEP:410, D{v_l: 0.733, v_acc: [65.6| 68.8| 67.2], c_acc: [81.2| 90.6]}  G{v_l: 1.351, v_acc: 40.6, c_acc: 98.4}\n","STEP:411, D{v_l: 0.637, v_acc: [59.4| 71.9| 65.6], c_acc: [75.0| 96.9]}  G{v_l: 1.164, v_acc: 32.8, c_acc: 96.9}\n","STEP:412, D{v_l: 0.854, v_acc: [65.6| 59.4| 62.5], c_acc: [81.2| 93.8]}  G{v_l: 1.044, v_acc: 45.3, c_acc: 87.5}\n","STEP:413, D{v_l: 0.696, v_acc: [65.6| 71.9| 68.8], c_acc: [78.1| 93.8]}  G{v_l: 1.145, v_acc: 46.9, c_acc: 96.9}\n","STEP:414, D{v_l: 0.685, v_acc: [75.0| 53.1| 64.1], c_acc: [87.5| 100.0]}  G{v_l: 1.015, v_acc: 43.8, c_acc: 96.9}\n","STEP:415, D{v_l: 0.651, v_acc: [62.5| 75.0| 68.8], c_acc: [75.0| 96.9]}  G{v_l: 0.883, v_acc: 56.2, c_acc: 95.3}\n","STEP:416, D{v_l: 0.867, v_acc: [53.1| 56.2| 54.7], c_acc: [84.4| 96.9]}  G{v_l: 0.938, v_acc: 48.4, c_acc: 93.8}\n","STEP:417, D{v_l: 0.767, v_acc: [59.4| 59.4| 59.4], c_acc: [93.8| 96.9]}  G{v_l: 1.404, v_acc: 31.2, c_acc: 90.6}\n","STEP:418, D{v_l: 0.719, v_acc: [68.8| 71.9| 70.3], c_acc: [75.0| 87.5]}  G{v_l: 0.897, v_acc: 60.9, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.5053 - valid_loss: 0.6779 - class_loss: 2.4099 - valid_acc: 0.6000 - class_acc: 0.5529\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0594 - valid_loss: 0.5610 - class_loss: 0.0809 - valid_acc: 0.6588 - class_acc: 0.9765\n","average v_acc: 62.941, three class acc: 55.294, two class acc: 60.000\n","====================================================================================================\n","STEP:419, D{v_l: 0.551, v_acc: [69.2| 71.9| 70.6], c_acc: [93.2| 87.5]}  G{v_l: 0.899, v_acc: 50.0, c_acc: 85.9}\n","STEP:420, D{v_l: 0.730, v_acc: [56.2| 71.9| 64.1], c_acc: [75.0| 93.8]}  G{v_l: 0.981, v_acc: 54.7, c_acc: 89.1}\n","STEP:421, D{v_l: 0.785, v_acc: [75.0| 56.2| 65.6], c_acc: [84.4| 90.6]}  G{v_l: 1.072, v_acc: 46.9, c_acc: 95.3}\n","STEP:422, D{v_l: 0.653, v_acc: [75.0| 62.5| 68.8], c_acc: [71.9| 93.8]}  G{v_l: 1.365, v_acc: 35.9, c_acc: 93.8}\n","STEP:423, D{v_l: 0.670, v_acc: [62.5| 65.6| 64.1], c_acc: [65.6| 90.6]}  G{v_l: 1.162, v_acc: 50.0, c_acc: 95.3}\n","STEP:424, D{v_l: 0.692, v_acc: [75.0| 65.6| 70.3], c_acc: [81.2| 93.8]}  G{v_l: 1.034, v_acc: 46.9, c_acc: 89.1}\n","STEP:425, D{v_l: 0.703, v_acc: [65.6| 71.9| 68.8], c_acc: [93.8| 100.0]}  G{v_l: 1.029, v_acc: 56.2, c_acc: 95.3}\n","STEP:426, D{v_l: 0.798, v_acc: [65.6| 62.5| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 1.227, v_acc: 46.9, c_acc: 84.4}\n","STEP:427, D{v_l: 0.759, v_acc: [50.0| 75.0| 62.5], c_acc: [90.6| 93.8]}  G{v_l: 1.104, v_acc: 53.1, c_acc: 96.9}\n","STEP:428, D{v_l: 0.595, v_acc: [81.2| 68.8| 75.0], c_acc: [75.0| 93.8]}  G{v_l: 1.142, v_acc: 50.0, c_acc: 82.8}\n","STEP:429, D{v_l: 0.673, v_acc: [68.8| 65.6| 67.2], c_acc: [93.8| 96.9]}  G{v_l: 0.900, v_acc: 60.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 3.3861 - valid_loss: 0.6766 - class_loss: 2.2920 - valid_acc: 0.6471 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1268 - valid_loss: 0.5854 - class_loss: 0.1240 - valid_acc: 0.6118 - class_acc: 0.9529\n","average v_acc: 62.941, three class acc: 51.765, two class acc: 55.294\n","====================================================================================================\n","STEP:430, D{v_l: 0.605, v_acc: [63.2| 59.4| 61.3], c_acc: [91.5| 93.8]}  G{v_l: 1.124, v_acc: 53.1, c_acc: 89.1}\n","STEP:431, D{v_l: 0.558, v_acc: [78.1| 65.6| 71.9], c_acc: [87.5| 93.8]}  G{v_l: 1.085, v_acc: 50.0, c_acc: 93.8}\n","STEP:432, D{v_l: 0.586, v_acc: [78.1| 65.6| 71.9], c_acc: [84.4| 96.9]}  G{v_l: 1.022, v_acc: 54.7, c_acc: 96.9}\n","STEP:433, D{v_l: 0.569, v_acc: [78.1| 78.1| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 1.228, v_acc: 39.1, c_acc: 92.2}\n","STEP:434, D{v_l: 0.621, v_acc: [75.0| 71.9| 73.4], c_acc: [71.9| 93.8]}  G{v_l: 0.958, v_acc: 48.4, c_acc: 93.8}\n","STEP:435, D{v_l: 0.748, v_acc: [59.4| 81.2| 70.3], c_acc: [93.8| 96.9]}  G{v_l: 1.036, v_acc: 45.3, c_acc: 96.9}\n","STEP:436, D{v_l: 0.518, v_acc: [78.1| 68.8| 73.4], c_acc: [81.2| 93.8]}  G{v_l: 0.986, v_acc: 57.8, c_acc: 98.4}\n","STEP:437, D{v_l: 0.768, v_acc: [75.0| 68.8| 71.9], c_acc: [78.1| 90.6]}  G{v_l: 0.907, v_acc: 56.2, c_acc: 95.3}\n","STEP:438, D{v_l: 0.600, v_acc: [59.4| 78.1| 68.8], c_acc: [87.5| 93.8]}  G{v_l: 1.246, v_acc: 48.4, c_acc: 93.8}\n","STEP:439, D{v_l: 0.665, v_acc: [68.8| 65.6| 67.2], c_acc: [78.1| 96.9]}  G{v_l: 0.998, v_acc: 56.2, c_acc: 87.5}\n","STEP:440, D{v_l: 0.715, v_acc: [71.9| 65.6| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 0.938, v_acc: 50.0, c_acc: 85.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.0104 - valid_loss: 0.4807 - class_loss: 2.1123 - valid_acc: 0.7529 - class_acc: 0.5176\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0535 - valid_loss: 0.5010 - class_loss: 0.1351 - valid_acc: 0.7765 - class_acc: 0.9294\n","average v_acc: 76.471, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","Epoch: 40\n","====================================================================================================\n","STEP:441, D{v_l: 0.523, v_acc: [76.9| 75.0| 76.0], c_acc: [91.5| 96.9]}  G{v_l: 0.906, v_acc: 51.6, c_acc: 89.1}\n","STEP:442, D{v_l: 0.659, v_acc: [75.0| 62.5| 68.8], c_acc: [81.2| 96.9]}  G{v_l: 1.056, v_acc: 57.8, c_acc: 81.2}\n","STEP:443, D{v_l: 0.559, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 93.8]}  G{v_l: 1.262, v_acc: 42.2, c_acc: 95.3}\n","STEP:444, D{v_l: 0.699, v_acc: [65.6| 65.6| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.092, v_acc: 50.0, c_acc: 93.8}\n","STEP:445, D{v_l: 0.571, v_acc: [65.6| 75.0| 70.3], c_acc: [84.4| 93.8]}  G{v_l: 1.094, v_acc: 43.8, c_acc: 92.2}\n","STEP:446, D{v_l: 0.695, v_acc: [62.5| 65.6| 64.1], c_acc: [87.5| 90.6]}  G{v_l: 0.991, v_acc: 50.0, c_acc: 93.8}\n","STEP:447, D{v_l: 0.499, v_acc: [78.1| 75.0| 76.6], c_acc: [81.2| 96.9]}  G{v_l: 1.259, v_acc: 42.2, c_acc: 98.4}\n","STEP:448, D{v_l: 0.670, v_acc: [68.8| 68.8| 68.8], c_acc: [90.6| 93.8]}  G{v_l: 1.592, v_acc: 45.3, c_acc: 93.8}\n","STEP:449, D{v_l: 0.636, v_acc: [71.9| 75.0| 73.4], c_acc: [78.1| 93.8]}  G{v_l: 1.212, v_acc: 40.6, c_acc: 95.3}\n","STEP:450, D{v_l: 0.799, v_acc: [81.2| 65.6| 73.4], c_acc: [84.4| 90.6]}  G{v_l: 0.940, v_acc: 48.4, c_acc: 90.6}\n","STEP:451, D{v_l: 0.561, v_acc: [78.1| 62.5| 70.3], c_acc: [78.1| 100.0]}  G{v_l: 1.465, v_acc: 28.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 2.4038 - valid_loss: 0.3915 - class_loss: 1.5949 - valid_acc: 0.8118 - class_acc: 0.4588\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0129 - valid_loss: 0.4767 - class_loss: 0.1189 - valid_acc: 0.8353 - class_acc: 0.9294\n","average v_acc: 82.353, three class acc: 45.882, two class acc: 55.294\n","====================================================================================================\n","STEP:452, D{v_l: 0.485, v_acc: [79.5| 87.5| 83.5], c_acc: [87.2| 93.8]}  G{v_l: 1.636, v_acc: 35.9, c_acc: 96.9}\n","STEP:453, D{v_l: 0.551, v_acc: [78.1| 59.4| 68.8], c_acc: [78.1| 84.4]}  G{v_l: 1.052, v_acc: 40.6, c_acc: 95.3}\n","STEP:454, D{v_l: 0.856, v_acc: [81.2| 68.8| 75.0], c_acc: [65.6| 100.0]}  G{v_l: 1.074, v_acc: 42.2, c_acc: 90.6}\n","STEP:455, D{v_l: 0.811, v_acc: [53.1| 68.8| 60.9], c_acc: [84.4| 75.0]}  G{v_l: 1.027, v_acc: 50.0, c_acc: 92.2}\n","STEP:456, D{v_l: 0.673, v_acc: [71.9| 65.6| 68.8], c_acc: [81.2| 90.6]}  G{v_l: 1.050, v_acc: 43.8, c_acc: 92.2}\n","STEP:457, D{v_l: 0.654, v_acc: [56.2| 68.8| 62.5], c_acc: [87.5| 93.8]}  G{v_l: 1.096, v_acc: 54.7, c_acc: 87.5}\n","STEP:458, D{v_l: 0.683, v_acc: [68.8| 56.2| 62.5], c_acc: [93.8| 96.9]}  G{v_l: 0.861, v_acc: 64.1, c_acc: 90.6}\n","STEP:459, D{v_l: 0.522, v_acc: [59.4| 87.5| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.014, v_acc: 45.3, c_acc: 87.5}\n","STEP:460, D{v_l: 0.558, v_acc: [78.1| 68.8| 73.4], c_acc: [87.5| 90.6]}  G{v_l: 1.226, v_acc: 42.2, c_acc: 98.4}\n","STEP:461, D{v_l: 0.452, v_acc: [78.1| 75.0| 76.6], c_acc: [81.2| 87.5]}  G{v_l: 1.208, v_acc: 39.1, c_acc: 92.2}\n","STEP:462, D{v_l: 0.549, v_acc: [71.9| 65.6| 68.8], c_acc: [81.2| 93.8]}  G{v_l: 1.336, v_acc: 43.8, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.9529 - valid_loss: 0.5369 - class_loss: 1.9986 - valid_acc: 0.6941 - class_acc: 0.4588\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0720 - valid_loss: 0.4397 - class_loss: 0.2150 - valid_acc: 0.8000 - class_acc: 0.9059\n","average v_acc: 74.706, three class acc: 45.882, two class acc: 62.353\n","====================================================================================================\n","STEP:463, D{v_l: 0.504, v_acc: [80.3| 68.8| 74.5], c_acc: [89.7| 93.8]}  G{v_l: 1.402, v_acc: 45.3, c_acc: 89.1}\n","STEP:464, D{v_l: 0.729, v_acc: [62.5| 71.9| 67.2], c_acc: [78.1| 100.0]}  G{v_l: 1.199, v_acc: 46.9, c_acc: 93.8}\n","STEP:465, D{v_l: 0.648, v_acc: [68.8| 84.4| 76.6], c_acc: [81.2| 93.8]}  G{v_l: 0.943, v_acc: 46.9, c_acc: 90.6}\n","STEP:466, D{v_l: 0.899, v_acc: [56.2| 59.4| 57.8], c_acc: [71.9| 100.0]}  G{v_l: 1.034, v_acc: 54.7, c_acc: 85.9}\n","STEP:467, D{v_l: 0.739, v_acc: [62.5| 59.4| 60.9], c_acc: [87.5| 93.8]}  G{v_l: 1.122, v_acc: 39.1, c_acc: 95.3}\n","STEP:468, D{v_l: 0.720, v_acc: [50.0| 75.0| 62.5], c_acc: [87.5| 100.0]}  G{v_l: 0.997, v_acc: 46.9, c_acc: 98.4}\n","STEP:469, D{v_l: 0.616, v_acc: [62.5| 68.8| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 0.933, v_acc: 56.2, c_acc: 92.2}\n","STEP:470, D{v_l: 0.665, v_acc: [71.9| 71.9| 71.9], c_acc: [75.0| 93.8]}  G{v_l: 1.294, v_acc: 39.1, c_acc: 96.9}\n","STEP:471, D{v_l: 0.479, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 1.331, v_acc: 39.1, c_acc: 96.9}\n","STEP:472, D{v_l: 0.675, v_acc: [62.5| 68.8| 65.6], c_acc: [84.4| 71.9]}  G{v_l: 1.249, v_acc: 54.7, c_acc: 92.2}\n","STEP:473, D{v_l: 0.648, v_acc: [65.6| 68.8| 67.2], c_acc: [87.5| 93.8]}  G{v_l: 1.278, v_acc: 46.9, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.9212 - valid_loss: 0.4577 - class_loss: 2.0462 - valid_acc: 0.8000 - class_acc: 0.5176\n","3/3 [==============================] - 0s 51ms/step - loss: 1.0940 - valid_loss: 0.4668 - class_loss: 0.2098 - valid_acc: 0.8353 - class_acc: 0.9412\n","average v_acc: 81.765, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:474, D{v_l: 0.475, v_acc: [81.2| 81.2| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.160, v_acc: 43.8, c_acc: 93.8}\n","STEP:475, D{v_l: 0.517, v_acc: [68.8| 81.2| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 1.093, v_acc: 35.9, c_acc: 98.4}\n","STEP:476, D{v_l: 0.749, v_acc: [59.4| 62.5| 60.9], c_acc: [81.2| 81.2]}  G{v_l: 1.031, v_acc: 54.7, c_acc: 96.9}\n","STEP:477, D{v_l: 0.704, v_acc: [62.5| 68.8| 65.6], c_acc: [84.4| 93.8]}  G{v_l: 1.221, v_acc: 42.2, c_acc: 95.3}\n","STEP:478, D{v_l: 0.504, v_acc: [90.6| 78.1| 84.4], c_acc: [78.1| 96.9]}  G{v_l: 1.413, v_acc: 40.6, c_acc: 84.4}\n","STEP:479, D{v_l: 0.630, v_acc: [71.9| 68.8| 70.3], c_acc: [78.1| 90.6]}  G{v_l: 1.040, v_acc: 46.9, c_acc: 93.8}\n","STEP:480, D{v_l: 0.610, v_acc: [68.8| 75.0| 71.9], c_acc: [81.2| 93.8]}  G{v_l: 1.270, v_acc: 42.2, c_acc: 93.8}\n","STEP:481, D{v_l: 0.582, v_acc: [68.8| 71.9| 70.3], c_acc: [81.2| 87.5]}  G{v_l: 1.248, v_acc: 42.2, c_acc: 93.8}\n","STEP:482, D{v_l: 0.531, v_acc: [71.9| 84.4| 78.1], c_acc: [81.2| 93.8]}  G{v_l: 1.300, v_acc: 42.2, c_acc: 90.6}\n","STEP:483, D{v_l: 0.603, v_acc: [50.0| 78.1| 64.1], c_acc: [96.9| 90.6]}  G{v_l: 1.397, v_acc: 40.6, c_acc: 87.5}\n","STEP:484, D{v_l: 0.778, v_acc: [68.8| 65.6| 67.2], c_acc: [75.0| 93.8]}  G{v_l: 1.336, v_acc: 42.2, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.0956 - valid_loss: 0.5491 - class_loss: 2.1292 - valid_acc: 0.7059 - class_acc: 0.5176\n","3/3 [==============================] - 0s 46ms/step - loss: 0.8961 - valid_loss: 0.4199 - class_loss: 0.0589 - valid_acc: 0.9412 - class_acc: 0.9765\n","average v_acc: 82.353, three class acc: 51.765, two class acc: 58.824\n","====================================================================================================\n","STEP:485, D{v_l: 0.624, v_acc: [86.3| 65.6| 76.0], c_acc: [92.3| 81.2]}  G{v_l: 1.103, v_acc: 50.0, c_acc: 89.1}\n","STEP:486, D{v_l: 0.424, v_acc: [84.4| 87.5| 85.9], c_acc: [81.2| 93.8]}  G{v_l: 1.310, v_acc: 45.3, c_acc: 95.3}\n","STEP:487, D{v_l: 0.619, v_acc: [62.5| 84.4| 73.4], c_acc: [81.2| 90.6]}  G{v_l: 1.156, v_acc: 37.5, c_acc: 98.4}\n","STEP:488, D{v_l: 0.539, v_acc: [75.0| 87.5| 81.2], c_acc: [84.4| 87.5]}  G{v_l: 1.277, v_acc: 48.4, c_acc: 93.8}\n","STEP:489, D{v_l: 0.551, v_acc: [62.5| 78.1| 70.3], c_acc: [90.6| 84.4]}  G{v_l: 0.946, v_acc: 54.7, c_acc: 89.1}\n","STEP:490, D{v_l: 0.734, v_acc: [68.8| 65.6| 67.2], c_acc: [78.1| 90.6]}  G{v_l: 0.874, v_acc: 62.5, c_acc: 73.4}\n","STEP:491, D{v_l: 0.687, v_acc: [71.9| 68.8| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 0.978, v_acc: 46.9, c_acc: 89.1}\n","STEP:492, D{v_l: 0.591, v_acc: [71.9| 71.9| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.159, v_acc: 48.4, c_acc: 92.2}\n","STEP:493, D{v_l: 0.548, v_acc: [68.8| 71.9| 70.3], c_acc: [75.0| 93.8]}  G{v_l: 1.358, v_acc: 43.8, c_acc: 92.2}\n","STEP:494, D{v_l: 0.723, v_acc: [71.9| 68.8| 70.3], c_acc: [84.4| 87.5]}  G{v_l: 0.995, v_acc: 53.1, c_acc: 93.8}\n","STEP:495, D{v_l: 0.363, v_acc: [78.1| 87.5| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 1.019, v_acc: 43.8, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.8857 - valid_loss: 0.3929 - class_loss: 2.0755 - valid_acc: 0.8000 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0467 - valid_loss: 0.4564 - class_loss: 0.1730 - valid_acc: 0.9176 - class_acc: 0.9412\n","average v_acc: 85.882, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:496, D{v_l: 0.650, v_acc: [86.3| 68.8| 77.5], c_acc: [94.0| 96.9]}  G{v_l: 1.109, v_acc: 43.8, c_acc: 92.2}\n","STEP:497, D{v_l: 0.547, v_acc: [68.8| 90.6| 79.7], c_acc: [81.2| 96.9]}  G{v_l: 1.243, v_acc: 48.4, c_acc: 95.3}\n","STEP:498, D{v_l: 0.469, v_acc: [78.1| 68.8| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.122, v_acc: 45.3, c_acc: 87.5}\n","STEP:499, D{v_l: 0.567, v_acc: [75.0| 71.9| 73.4], c_acc: [68.8| 93.8]}  G{v_l: 1.270, v_acc: 31.2, c_acc: 92.2}\n","STEP:500, D{v_l: 0.882, v_acc: [75.0| 59.4| 67.2], c_acc: [75.0| 93.8]}  G{v_l: 1.302, v_acc: 50.0, c_acc: 76.6}\n","STEP:501, D{v_l: 0.493, v_acc: [78.1| 84.4| 81.2], c_acc: [75.0| 93.8]}  G{v_l: 1.636, v_acc: 43.8, c_acc: 78.1}\n","STEP:502, D{v_l: 0.549, v_acc: [78.1| 68.8| 73.4], c_acc: [78.1| 90.6]}  G{v_l: 1.154, v_acc: 56.2, c_acc: 93.8}\n","STEP:503, D{v_l: 0.460, v_acc: [81.2| 75.0| 78.1], c_acc: [78.1| 100.0]}  G{v_l: 1.274, v_acc: 37.5, c_acc: 95.3}\n","STEP:504, D{v_l: 0.421, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.070, v_acc: 37.5, c_acc: 90.6}\n","STEP:505, D{v_l: 0.650, v_acc: [65.6| 65.6| 65.6], c_acc: [71.9| 100.0]}  G{v_l: 1.523, v_acc: 40.6, c_acc: 92.2}\n","STEP:506, D{v_l: 0.617, v_acc: [68.8| 68.8| 68.8], c_acc: [81.2| 90.6]}  G{v_l: 1.372, v_acc: 32.8, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 4.6112 - valid_loss: 0.7562 - class_loss: 3.4376 - valid_acc: 0.5765 - class_acc: 0.5294\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0254 - valid_loss: 0.4601 - class_loss: 0.1480 - valid_acc: 0.8588 - class_acc: 0.9529\n","average v_acc: 71.765, three class acc: 52.941, two class acc: 52.941\n","====================================================================================================\n","STEP:507, D{v_l: 0.642, v_acc: [82.1| 65.6| 73.8], c_acc: [94.9| 96.9]}  G{v_l: 1.383, v_acc: 45.3, c_acc: 90.6}\n","STEP:508, D{v_l: 0.613, v_acc: [65.6| 65.6| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.125, v_acc: 45.3, c_acc: 93.8}\n","STEP:509, D{v_l: 0.438, v_acc: [75.0| 81.2| 78.1], c_acc: [81.2| 96.9]}  G{v_l: 0.960, v_acc: 51.6, c_acc: 90.6}\n","STEP:510, D{v_l: 0.690, v_acc: [65.6| 62.5| 64.1], c_acc: [90.6| 90.6]}  G{v_l: 1.180, v_acc: 50.0, c_acc: 89.1}\n","STEP:511, D{v_l: 0.652, v_acc: [68.8| 62.5| 65.6], c_acc: [84.4| 96.9]}  G{v_l: 1.190, v_acc: 40.6, c_acc: 96.9}\n","STEP:512, D{v_l: 0.525, v_acc: [75.0| 78.1| 76.6], c_acc: [81.2| 93.8]}  G{v_l: 1.231, v_acc: 37.5, c_acc: 96.9}\n","STEP:513, D{v_l: 0.620, v_acc: [68.8| 68.8| 68.8], c_acc: [84.4| 93.8]}  G{v_l: 1.098, v_acc: 40.6, c_acc: 96.9}\n","STEP:514, D{v_l: 0.695, v_acc: [59.4| 65.6| 62.5], c_acc: [87.5| 90.6]}  G{v_l: 1.131, v_acc: 40.6, c_acc: 87.5}\n","STEP:515, D{v_l: 0.664, v_acc: [53.1| 75.0| 64.1], c_acc: [84.4| 100.0]}  G{v_l: 1.131, v_acc: 42.2, c_acc: 87.5}\n","STEP:516, D{v_l: 0.619, v_acc: [68.8| 65.6| 67.2], c_acc: [84.4| 93.8]}  G{v_l: 1.311, v_acc: 48.4, c_acc: 93.8}\n","STEP:517, D{v_l: 0.618, v_acc: [65.6| 75.0| 70.3], c_acc: [90.6| 93.8]}  G{v_l: 1.129, v_acc: 43.8, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.7502 - valid_loss: 0.5628 - class_loss: 2.7701 - valid_acc: 0.6824 - class_acc: 0.5412\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9181 - valid_loss: 0.4293 - class_loss: 0.0715 - valid_acc: 0.8824 - class_acc: 0.9765\n","average v_acc: 78.235, three class acc: 54.118, two class acc: 56.471\n","====================================================================================================\n","STEP:518, D{v_l: 0.542, v_acc: [86.3| 75.0| 80.7], c_acc: [91.5| 100.0]}  G{v_l: 0.999, v_acc: 45.3, c_acc: 89.1}\n","STEP:519, D{v_l: 0.675, v_acc: [75.0| 62.5| 68.8], c_acc: [84.4| 96.9]}  G{v_l: 1.088, v_acc: 54.7, c_acc: 79.7}\n","STEP:520, D{v_l: 0.348, v_acc: [81.2| 87.5| 84.4], c_acc: [75.0| 93.8]}  G{v_l: 1.215, v_acc: 39.1, c_acc: 67.2}\n","STEP:521, D{v_l: 0.574, v_acc: [78.1| 65.6| 71.9], c_acc: [84.4| 90.6]}  G{v_l: 1.282, v_acc: 43.8, c_acc: 89.1}\n","STEP:522, D{v_l: 0.569, v_acc: [75.0| 68.8| 71.9], c_acc: [81.2| 100.0]}  G{v_l: 1.347, v_acc: 37.5, c_acc: 93.8}\n","STEP:523, D{v_l: 0.819, v_acc: [75.0| 71.9| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 1.099, v_acc: 48.4, c_acc: 93.8}\n","STEP:524, D{v_l: 0.600, v_acc: [71.9| 75.0| 73.4], c_acc: [87.5| 100.0]}  G{v_l: 1.106, v_acc: 46.9, c_acc: 92.2}\n","STEP:525, D{v_l: 0.406, v_acc: [90.6| 81.2| 85.9], c_acc: [84.4| 93.8]}  G{v_l: 1.580, v_acc: 32.8, c_acc: 87.5}\n","STEP:526, D{v_l: 0.818, v_acc: [71.9| 78.1| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 1.212, v_acc: 42.2, c_acc: 93.8}\n","STEP:527, D{v_l: 0.492, v_acc: [81.2| 75.0| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 1.387, v_acc: 32.8, c_acc: 92.2}\n","STEP:528, D{v_l: 0.493, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.164, v_acc: 46.9, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 2.8051 - valid_loss: 0.3888 - class_loss: 1.9991 - valid_acc: 0.8353 - class_acc: 0.4706\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0219 - valid_loss: 0.4138 - class_loss: 0.1908 - valid_acc: 0.9059 - class_acc: 0.9294\n","average v_acc: 87.059, three class acc: 47.059, two class acc: 56.471\n","====================================================================================================\n","STEP:529, D{v_l: 0.445, v_acc: [82.1| 84.4| 83.2], c_acc: [92.3| 96.9]}  G{v_l: 1.307, v_acc: 42.2, c_acc: 85.9}\n","STEP:530, D{v_l: 0.533, v_acc: [84.4| 62.5| 73.4], c_acc: [81.2| 93.8]}  G{v_l: 1.039, v_acc: 48.4, c_acc: 90.6}\n","STEP:531, D{v_l: 0.612, v_acc: [75.0| 65.6| 70.3], c_acc: [84.4| 90.6]}  G{v_l: 1.315, v_acc: 45.3, c_acc: 96.9}\n","STEP:532, D{v_l: 0.550, v_acc: [71.9| 68.8| 70.3], c_acc: [71.9| 96.9]}  G{v_l: 1.423, v_acc: 40.6, c_acc: 95.3}\n","STEP:533, D{v_l: 0.585, v_acc: [68.8| 81.2| 75.0], c_acc: [96.9| 93.8]}  G{v_l: 1.040, v_acc: 45.3, c_acc: 90.6}\n","STEP:534, D{v_l: 0.414, v_acc: [84.4| 87.5| 85.9], c_acc: [87.5| 96.9]}  G{v_l: 1.031, v_acc: 39.1, c_acc: 87.5}\n","STEP:535, D{v_l: 1.027, v_acc: [59.4| 62.5| 60.9], c_acc: [84.4| 93.8]}  G{v_l: 1.162, v_acc: 39.1, c_acc: 95.3}\n","STEP:536, D{v_l: 0.331, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 93.8]}  G{v_l: 0.961, v_acc: 53.1, c_acc: 93.8}\n","STEP:537, D{v_l: 0.703, v_acc: [68.8| 68.8| 68.8], c_acc: [87.5| 100.0]}  G{v_l: 0.952, v_acc: 53.1, c_acc: 87.5}\n","STEP:538, D{v_l: 0.753, v_acc: [75.0| 62.5| 68.8], c_acc: [84.4| 96.9]}  G{v_l: 1.231, v_acc: 42.2, c_acc: 93.8}\n","STEP:539, D{v_l: 0.657, v_acc: [65.6| 65.6| 65.6], c_acc: [78.1| 96.9]}  G{v_l: 1.507, v_acc: 45.3, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 2.5696 - valid_loss: 0.3891 - class_loss: 1.7633 - valid_acc: 0.8706 - class_acc: 0.4471\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0654 - valid_loss: 0.5279 - class_loss: 0.1203 - valid_acc: 0.7176 - class_acc: 0.9647\n","average v_acc: 79.412, three class acc: 44.706, two class acc: 61.176\n","====================================================================================================\n","STEP:540, D{v_l: 0.501, v_acc: [69.2| 75.0| 72.1], c_acc: [94.0| 96.9]}  G{v_l: 1.356, v_acc: 53.1, c_acc: 85.9}\n","STEP:541, D{v_l: 0.555, v_acc: [78.1| 65.6| 71.9], c_acc: [84.4| 100.0]}  G{v_l: 0.776, v_acc: 65.6, c_acc: 81.2}\n","STEP:542, D{v_l: 0.552, v_acc: [78.1| 68.8| 73.4], c_acc: [96.9| 100.0]}  G{v_l: 1.374, v_acc: 45.3, c_acc: 89.1}\n","STEP:543, D{v_l: 0.417, v_acc: [81.2| 78.1| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 1.179, v_acc: 51.6, c_acc: 93.8}\n","STEP:544, D{v_l: 0.621, v_acc: [62.5| 75.0| 68.8], c_acc: [78.1| 93.8]}  G{v_l: 1.167, v_acc: 50.0, c_acc: 96.9}\n","STEP:545, D{v_l: 0.455, v_acc: [84.4| 84.4| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.290, v_acc: 42.2, c_acc: 95.3}\n","STEP:546, D{v_l: 0.747, v_acc: [68.8| 65.6| 67.2], c_acc: [93.8| 96.9]}  G{v_l: 1.324, v_acc: 34.4, c_acc: 96.9}\n","STEP:547, D{v_l: 0.537, v_acc: [78.1| 65.6| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.013, v_acc: 54.7, c_acc: 92.2}\n","STEP:548, D{v_l: 0.644, v_acc: [75.0| 65.6| 70.3], c_acc: [87.5| 93.8]}  G{v_l: 1.563, v_acc: 42.2, c_acc: 93.8}\n","STEP:549, D{v_l: 0.524, v_acc: [78.1| 62.5| 70.3], c_acc: [68.8| 93.8]}  G{v_l: 1.088, v_acc: 42.2, c_acc: 93.8}\n","STEP:550, D{v_l: 0.625, v_acc: [65.6| 71.9| 68.8], c_acc: [93.8| 93.8]}  G{v_l: 1.301, v_acc: 42.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 3.4864 - valid_loss: 0.6602 - class_loss: 2.4091 - valid_acc: 0.6471 - class_acc: 0.5176\n","3/3 [==============================] - 0s 53ms/step - loss: 0.9315 - valid_loss: 0.4556 - class_loss: 0.0587 - valid_acc: 0.8941 - class_acc: 0.9765\n","average v_acc: 77.059, three class acc: 51.765, two class acc: 56.471\n","====================================================================================================\n","Epoch: 50\n","====================================================================================================\n","STEP:551, D{v_l: 0.498, v_acc: [85.5| 75.0| 80.2], c_acc: [94.0| 93.8]}  G{v_l: 1.208, v_acc: 43.8, c_acc: 90.6}\n","STEP:552, D{v_l: 0.762, v_acc: [65.6| 78.1| 71.9], c_acc: [81.2| 96.9]}  G{v_l: 1.108, v_acc: 53.1, c_acc: 76.6}\n","STEP:553, D{v_l: 0.588, v_acc: [81.2| 65.6| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.112, v_acc: 35.9, c_acc: 90.6}\n","STEP:554, D{v_l: 0.515, v_acc: [75.0| 62.5| 68.8], c_acc: [81.2| 93.8]}  G{v_l: 1.527, v_acc: 45.3, c_acc: 75.0}\n","STEP:555, D{v_l: 0.666, v_acc: [71.9| 59.4| 65.6], c_acc: [84.4| 93.8]}  G{v_l: 1.618, v_acc: 39.1, c_acc: 89.1}\n","STEP:556, D{v_l: 0.609, v_acc: [75.0| 68.8| 71.9], c_acc: [87.5| 93.8]}  G{v_l: 1.061, v_acc: 50.0, c_acc: 92.2}\n","STEP:557, D{v_l: 0.611, v_acc: [68.8| 75.0| 71.9], c_acc: [87.5| 90.6]}  G{v_l: 1.366, v_acc: 37.5, c_acc: 96.9}\n","STEP:558, D{v_l: 0.715, v_acc: [46.9| 75.0| 60.9], c_acc: [81.2| 100.0]}  G{v_l: 1.218, v_acc: 45.3, c_acc: 93.8}\n","STEP:559, D{v_l: 0.534, v_acc: [75.0| 75.0| 75.0], c_acc: [87.5| 100.0]}  G{v_l: 1.398, v_acc: 37.5, c_acc: 90.6}\n","STEP:560, D{v_l: 0.574, v_acc: [68.8| 75.0| 71.9], c_acc: [78.1| 90.6]}  G{v_l: 1.304, v_acc: 35.9, c_acc: 95.3}\n","STEP:561, D{v_l: 0.611, v_acc: [81.2| 59.4| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 1.201, v_acc: 48.4, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 2.6489 - valid_loss: 0.2676 - class_loss: 1.9641 - valid_acc: 0.9294 - class_acc: 0.3059\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1106 - valid_loss: 0.5770 - class_loss: 0.1164 - valid_acc: 0.6235 - class_acc: 0.9529\n","average v_acc: 77.647, three class acc: 30.588, two class acc: 54.118\n","====================================================================================================\n","STEP:562, D{v_l: 0.547, v_acc: [66.7| 71.9| 69.3], c_acc: [95.7| 90.6]}  G{v_l: 1.174, v_acc: 37.5, c_acc: 89.1}\n","STEP:563, D{v_l: 0.508, v_acc: [75.0| 71.9| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 1.277, v_acc: 45.3, c_acc: 89.1}\n","STEP:564, D{v_l: 0.377, v_acc: [71.9| 84.4| 78.1], c_acc: [84.4| 96.9]}  G{v_l: 1.227, v_acc: 51.6, c_acc: 93.8}\n","STEP:565, D{v_l: 0.634, v_acc: [81.2| 65.6| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.046, v_acc: 48.4, c_acc: 85.9}\n","STEP:566, D{v_l: 0.552, v_acc: [78.1| 68.8| 73.4], c_acc: [87.5| 93.8]}  G{v_l: 1.091, v_acc: 53.1, c_acc: 93.8}\n","STEP:567, D{v_l: 0.722, v_acc: [62.5| 78.1| 70.3], c_acc: [78.1| 90.6]}  G{v_l: 1.496, v_acc: 35.9, c_acc: 93.8}\n","STEP:568, D{v_l: 0.449, v_acc: [84.4| 65.6| 75.0], c_acc: [87.5| 87.5]}  G{v_l: 1.299, v_acc: 51.6, c_acc: 90.6}\n","STEP:569, D{v_l: 0.557, v_acc: [71.9| 84.4| 78.1], c_acc: [87.5| 93.8]}  G{v_l: 1.055, v_acc: 54.7, c_acc: 96.9}\n","STEP:570, D{v_l: 0.647, v_acc: [65.6| 62.5| 64.1], c_acc: [87.5| 96.9]}  G{v_l: 1.258, v_acc: 42.2, c_acc: 96.9}\n","STEP:571, D{v_l: 0.403, v_acc: [87.5| 75.0| 81.2], c_acc: [75.0| 96.9]}  G{v_l: 1.351, v_acc: 43.8, c_acc: 93.8}\n","STEP:572, D{v_l: 0.724, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 1.450, v_acc: 35.9, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 42ms/step - loss: 2.7709 - valid_loss: 0.5062 - class_loss: 1.8476 - valid_acc: 0.7412 - class_acc: 0.5647\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0161 - valid_loss: 0.5057 - class_loss: 0.0933 - valid_acc: 0.8000 - class_acc: 0.9412\n","average v_acc: 77.059, three class acc: 56.471, two class acc: 72.941\n","====================================================================================================\n",">Saved: AC_Brain/mode0/weights/d_model_0572.h5\n","STEP:573, D{v_l: 0.567, v_acc: [78.6| 62.5| 70.6], c_acc: [92.3| 93.8]}  G{v_l: 1.126, v_acc: 48.4, c_acc: 93.8}\n","STEP:574, D{v_l: 0.568, v_acc: [62.5| 68.8| 65.6], c_acc: [84.4| 100.0]}  G{v_l: 1.288, v_acc: 46.9, c_acc: 93.8}\n","STEP:575, D{v_l: 0.677, v_acc: [71.9| 75.0| 73.4], c_acc: [90.6| 96.9]}  G{v_l: 1.106, v_acc: 53.1, c_acc: 90.6}\n","STEP:576, D{v_l: 0.482, v_acc: [75.0| 87.5| 81.2], c_acc: [84.4| 84.4]}  G{v_l: 0.906, v_acc: 51.6, c_acc: 89.1}\n","STEP:577, D{v_l: 0.468, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 93.8]}  G{v_l: 1.067, v_acc: 59.4, c_acc: 84.4}\n","STEP:578, D{v_l: 0.602, v_acc: [56.2| 75.0| 65.6], c_acc: [100.0| 100.0]}  G{v_l: 1.197, v_acc: 34.4, c_acc: 92.2}\n","STEP:579, D{v_l: 0.454, v_acc: [71.9| 87.5| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 1.120, v_acc: 39.1, c_acc: 93.8}\n","STEP:580, D{v_l: 0.427, v_acc: [75.0| 84.4| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.086, v_acc: 45.3, c_acc: 90.6}\n","STEP:581, D{v_l: 0.393, v_acc: [75.0| 84.4| 79.7], c_acc: [90.6| 90.6]}  G{v_l: 0.937, v_acc: 42.2, c_acc: 93.8}\n","STEP:582, D{v_l: 0.512, v_acc: [81.2| 68.8| 75.0], c_acc: [87.5| 90.6]}  G{v_l: 1.090, v_acc: 48.4, c_acc: 92.2}\n","STEP:583, D{v_l: 0.454, v_acc: [68.8| 81.2| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.025, v_acc: 51.6, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.7824 - valid_loss: 0.3832 - class_loss: 1.9821 - valid_acc: 0.8235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.1192 - valid_loss: 0.5576 - class_loss: 0.1445 - valid_acc: 0.7059 - class_acc: 0.9647\n","average v_acc: 76.471, three class acc: 51.765, two class acc: 61.176\n","====================================================================================================\n","STEP:584, D{v_l: 0.613, v_acc: [73.5| 71.9| 72.7], c_acc: [94.0| 100.0]}  G{v_l: 1.045, v_acc: 50.0, c_acc: 95.3}\n","STEP:585, D{v_l: 0.620, v_acc: [65.6| 71.9| 68.8], c_acc: [87.5| 100.0]}  G{v_l: 0.956, v_acc: 46.9, c_acc: 93.8}\n","STEP:586, D{v_l: 0.540, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.083, v_acc: 51.6, c_acc: 95.3}\n","STEP:587, D{v_l: 0.700, v_acc: [62.5| 65.6| 64.1], c_acc: [87.5| 96.9]}  G{v_l: 0.846, v_acc: 59.4, c_acc: 89.1}\n","STEP:588, D{v_l: 0.539, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 93.8]}  G{v_l: 1.309, v_acc: 43.8, c_acc: 92.2}\n","STEP:589, D{v_l: 0.608, v_acc: [78.1| 65.6| 71.9], c_acc: [90.6| 96.9]}  G{v_l: 1.140, v_acc: 40.6, c_acc: 87.5}\n","STEP:590, D{v_l: 0.503, v_acc: [56.2| 87.5| 71.9], c_acc: [90.6| 87.5]}  G{v_l: 1.324, v_acc: 40.6, c_acc: 96.9}\n","STEP:591, D{v_l: 0.573, v_acc: [68.8| 62.5| 65.6], c_acc: [81.2| 87.5]}  G{v_l: 1.058, v_acc: 48.4, c_acc: 95.3}\n","STEP:592, D{v_l: 0.621, v_acc: [62.5| 78.1| 70.3], c_acc: [78.1| 93.8]}  G{v_l: 1.220, v_acc: 43.8, c_acc: 95.3}\n","STEP:593, D{v_l: 0.546, v_acc: [65.6| 78.1| 71.9], c_acc: [96.9| 96.9]}  G{v_l: 1.207, v_acc: 37.5, c_acc: 75.0}\n","STEP:594, D{v_l: 0.592, v_acc: [71.9| 65.6| 68.8], c_acc: [90.6| 87.5]}  G{v_l: 1.484, v_acc: 48.4, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.8478 - valid_loss: 0.5432 - class_loss: 2.8875 - valid_acc: 0.7294 - class_acc: 0.5294\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1487 - valid_loss: 0.5499 - class_loss: 0.1817 - valid_acc: 0.5647 - class_acc: 0.9412\n","average v_acc: 64.706, three class acc: 52.941, two class acc: 57.647\n","====================================================================================================\n","STEP:595, D{v_l: 0.506, v_acc: [64.1| 65.6| 64.9], c_acc: [94.9| 96.9]}  G{v_l: 1.203, v_acc: 48.4, c_acc: 90.6}\n","STEP:596, D{v_l: 0.649, v_acc: [62.5| 71.9| 67.2], c_acc: [87.5| 96.9]}  G{v_l: 1.214, v_acc: 53.1, c_acc: 96.9}\n","STEP:597, D{v_l: 0.679, v_acc: [75.0| 68.8| 71.9], c_acc: [87.5| 84.4]}  G{v_l: 1.128, v_acc: 37.5, c_acc: 93.8}\n","STEP:598, D{v_l: 0.612, v_acc: [65.6| 78.1| 71.9], c_acc: [90.6| 90.6]}  G{v_l: 1.142, v_acc: 46.9, c_acc: 95.3}\n","STEP:599, D{v_l: 0.739, v_acc: [75.0| 65.6| 70.3], c_acc: [90.6| 90.6]}  G{v_l: 1.436, v_acc: 35.9, c_acc: 87.5}\n","STEP:600, D{v_l: 0.503, v_acc: [78.1| 75.0| 76.6], c_acc: [78.1| 100.0]}  G{v_l: 1.017, v_acc: 50.0, c_acc: 85.9}\n","STEP:601, D{v_l: 0.680, v_acc: [71.9| 65.6| 68.8], c_acc: [93.8| 96.9]}  G{v_l: 0.858, v_acc: 45.3, c_acc: 92.2}\n","STEP:602, D{v_l: 0.544, v_acc: [68.8| 78.1| 73.4], c_acc: [81.2| 100.0]}  G{v_l: 1.127, v_acc: 45.3, c_acc: 100.0}\n","STEP:603, D{v_l: 0.552, v_acc: [90.6| 65.6| 78.1], c_acc: [87.5| 100.0]}  G{v_l: 1.002, v_acc: 50.0, c_acc: 85.9}\n","STEP:604, D{v_l: 0.710, v_acc: [81.2| 68.8| 75.0], c_acc: [90.6| 93.8]}  G{v_l: 1.070, v_acc: 35.9, c_acc: 92.2}\n","STEP:605, D{v_l: 0.600, v_acc: [84.4| 62.5| 73.4], c_acc: [87.5| 96.9]}  G{v_l: 1.111, v_acc: 37.5, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.1523 - valid_loss: 0.4456 - class_loss: 2.2898 - valid_acc: 0.7765 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9259 - valid_loss: 0.4475 - class_loss: 0.0614 - valid_acc: 0.8471 - class_acc: 0.9765\n","average v_acc: 81.176, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:606, D{v_l: 0.442, v_acc: [82.9| 78.1| 80.5], c_acc: [94.9| 100.0]}  G{v_l: 1.108, v_acc: 51.6, c_acc: 90.6}\n","STEP:607, D{v_l: 0.666, v_acc: [65.6| 81.2| 73.4], c_acc: [96.9| 90.6]}  G{v_l: 0.836, v_acc: 51.6, c_acc: 95.3}\n","STEP:608, D{v_l: 0.421, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 0.958, v_acc: 50.0, c_acc: 87.5}\n","STEP:609, D{v_l: 0.512, v_acc: [84.4| 78.1| 81.2], c_acc: [84.4| 96.9]}  G{v_l: 1.259, v_acc: 40.6, c_acc: 90.6}\n","STEP:610, D{v_l: 0.542, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 0.978, v_acc: 50.0, c_acc: 81.2}\n","STEP:611, D{v_l: 0.621, v_acc: [75.0| 65.6| 70.3], c_acc: [87.5| 100.0]}  G{v_l: 1.057, v_acc: 43.8, c_acc: 82.8}\n","STEP:612, D{v_l: 0.427, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 84.4]}  G{v_l: 1.328, v_acc: 48.4, c_acc: 93.8}\n","STEP:613, D{v_l: 0.462, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 87.5]}  G{v_l: 0.957, v_acc: 51.6, c_acc: 95.3}\n","STEP:614, D{v_l: 0.522, v_acc: [75.0| 71.9| 73.4], c_acc: [100.0| 100.0]}  G{v_l: 1.059, v_acc: 53.1, c_acc: 93.8}\n","STEP:615, D{v_l: 0.472, v_acc: [75.0| 71.9| 73.4], c_acc: [81.2| 93.8]}  G{v_l: 1.264, v_acc: 46.9, c_acc: 89.1}\n","STEP:616, D{v_l: 0.438, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 1.423, v_acc: 32.8, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 2.7496 - valid_loss: 0.3525 - class_loss: 1.9802 - valid_acc: 0.8353 - class_acc: 0.4706\n","3/3 [==============================] - 0s 52ms/step - loss: 0.9789 - valid_loss: 0.5307 - class_loss: 0.0313 - valid_acc: 0.6824 - class_acc: 1.0000\n","average v_acc: 75.882, three class acc: 47.059, two class acc: 60.000\n","====================================================================================================\n","STEP:617, D{v_l: 0.453, v_acc: [69.2| 81.2| 75.2], c_acc: [97.4| 93.8]}  G{v_l: 1.035, v_acc: 45.3, c_acc: 92.2}\n","STEP:618, D{v_l: 0.547, v_acc: [62.5| 78.1| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 0.989, v_acc: 46.9, c_acc: 84.4}\n","STEP:619, D{v_l: 0.456, v_acc: [78.1| 75.0| 76.6], c_acc: [93.8| 90.6]}  G{v_l: 1.102, v_acc: 53.1, c_acc: 78.1}\n","STEP:620, D{v_l: 0.375, v_acc: [81.2| 90.6| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.079, v_acc: 48.4, c_acc: 92.2}\n","STEP:621, D{v_l: 0.492, v_acc: [78.1| 81.2| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.056, v_acc: 50.0, c_acc: 90.6}\n","STEP:622, D{v_l: 0.594, v_acc: [81.2| 78.1| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 0.974, v_acc: 40.6, c_acc: 93.8}\n","STEP:623, D{v_l: 0.515, v_acc: [75.0| 78.1| 76.6], c_acc: [84.4| 90.6]}  G{v_l: 1.066, v_acc: 48.4, c_acc: 96.9}\n","STEP:624, D{v_l: 0.542, v_acc: [71.9| 81.2| 76.6], c_acc: [81.2| 93.8]}  G{v_l: 1.331, v_acc: 42.2, c_acc: 98.4}\n","STEP:625, D{v_l: 0.475, v_acc: [75.0| 75.0| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.416, v_acc: 40.6, c_acc: 95.3}\n","STEP:626, D{v_l: 0.310, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.139, v_acc: 40.6, c_acc: 95.3}\n","STEP:627, D{v_l: 0.626, v_acc: [75.0| 71.9| 73.4], c_acc: [93.8| 90.6]}  G{v_l: 1.171, v_acc: 37.5, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.8136 - valid_loss: 0.4198 - class_loss: 1.9769 - valid_acc: 0.7765 - class_acc: 0.4706\n","3/3 [==============================] - 0s 52ms/step - loss: 1.0548 - valid_loss: 0.4506 - class_loss: 0.1873 - valid_acc: 0.8824 - class_acc: 0.9647\n","average v_acc: 82.941, three class acc: 47.059, two class acc: 60.000\n","====================================================================================================\n","STEP:628, D{v_l: 0.395, v_acc: [86.3| 87.5| 86.9], c_acc: [92.3| 90.6]}  G{v_l: 1.281, v_acc: 39.1, c_acc: 95.3}\n","STEP:629, D{v_l: 0.462, v_acc: [71.9| 71.9| 71.9], c_acc: [100.0| 96.9]}  G{v_l: 1.404, v_acc: 46.9, c_acc: 95.3}\n","STEP:630, D{v_l: 0.439, v_acc: [81.2| 78.1| 79.7], c_acc: [81.2| 90.6]}  G{v_l: 1.384, v_acc: 37.5, c_acc: 87.5}\n","STEP:631, D{v_l: 0.403, v_acc: [75.0| 87.5| 81.2], c_acc: [71.9| 81.2]}  G{v_l: 1.071, v_acc: 51.6, c_acc: 82.8}\n","STEP:632, D{v_l: 0.449, v_acc: [78.1| 84.4| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.125, v_acc: 43.8, c_acc: 90.6}\n","STEP:633, D{v_l: 0.391, v_acc: [84.4| 87.5| 85.9], c_acc: [84.4| 84.4]}  G{v_l: 1.080, v_acc: 42.2, c_acc: 95.3}\n","STEP:634, D{v_l: 0.535, v_acc: [68.8| 75.0| 71.9], c_acc: [84.4| 100.0]}  G{v_l: 1.166, v_acc: 43.8, c_acc: 98.4}\n","STEP:635, D{v_l: 0.687, v_acc: [62.5| 68.8| 65.6], c_acc: [84.4| 93.8]}  G{v_l: 1.118, v_acc: 42.2, c_acc: 93.8}\n","STEP:636, D{v_l: 0.414, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 93.8]}  G{v_l: 0.985, v_acc: 51.6, c_acc: 93.8}\n","STEP:637, D{v_l: 0.529, v_acc: [84.4| 65.6| 75.0], c_acc: [81.2| 96.9]}  G{v_l: 1.113, v_acc: 45.3, c_acc: 90.6}\n","STEP:638, D{v_l: 0.585, v_acc: [65.6| 84.4| 75.0], c_acc: [96.9| 100.0]}  G{v_l: 1.121, v_acc: 48.4, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.5763 - valid_loss: 0.4873 - class_loss: 3.6722 - valid_acc: 0.7176 - class_acc: 0.5176\n","3/3 [==============================] - 0s 51ms/step - loss: 0.9520 - valid_loss: 0.4493 - class_loss: 0.0858 - valid_acc: 0.9294 - class_acc: 0.9647\n","average v_acc: 82.353, three class acc: 51.765, two class acc: 54.118\n","====================================================================================================\n","STEP:639, D{v_l: 0.410, v_acc: [91.5| 78.1| 84.8], c_acc: [96.6| 100.0]}  G{v_l: 1.064, v_acc: 37.5, c_acc: 92.2}\n","STEP:640, D{v_l: 0.740, v_acc: [78.1| 56.2| 67.2], c_acc: [84.4| 96.9]}  G{v_l: 1.145, v_acc: 39.1, c_acc: 98.4}\n","STEP:641, D{v_l: 0.401, v_acc: [87.5| 71.9| 79.7], c_acc: [100.0| 90.6]}  G{v_l: 1.000, v_acc: 39.1, c_acc: 93.8}\n","STEP:642, D{v_l: 0.434, v_acc: [81.2| 78.1| 79.7], c_acc: [100.0| 93.8]}  G{v_l: 1.214, v_acc: 40.6, c_acc: 87.5}\n","STEP:643, D{v_l: 0.450, v_acc: [84.4| 75.0| 79.7], c_acc: [81.2| 93.8]}  G{v_l: 1.034, v_acc: 43.8, c_acc: 87.5}\n","STEP:644, D{v_l: 0.264, v_acc: [78.1| 93.8| 85.9], c_acc: [78.1| 93.8]}  G{v_l: 1.171, v_acc: 34.4, c_acc: 85.9}\n","STEP:645, D{v_l: 0.519, v_acc: [78.1| 65.6| 71.9], c_acc: [90.6| 96.9]}  G{v_l: 1.409, v_acc: 46.9, c_acc: 87.5}\n","STEP:646, D{v_l: 0.345, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 90.6]}  G{v_l: 1.153, v_acc: 42.2, c_acc: 84.4}\n","STEP:647, D{v_l: 0.416, v_acc: [75.0| 84.4| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 1.349, v_acc: 43.8, c_acc: 89.1}\n","STEP:648, D{v_l: 0.716, v_acc: [65.6| 65.6| 65.6], c_acc: [87.5| 96.9]}  G{v_l: 1.048, v_acc: 42.2, c_acc: 90.6}\n","STEP:649, D{v_l: 0.398, v_acc: [81.2| 68.8| 75.0], c_acc: [84.4| 96.9]}  G{v_l: 1.491, v_acc: 20.3, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.8877 - valid_loss: 0.3051 - class_loss: 2.1659 - valid_acc: 0.8588 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0408 - valid_loss: 0.4192 - class_loss: 0.2049 - valid_acc: 0.9059 - class_acc: 0.8824\n","average v_acc: 88.235, three class acc: 49.412, two class acc: 60.000\n","====================================================================================================\n","STEP:650, D{v_l: 0.403, v_acc: [86.3| 84.4| 85.3], c_acc: [84.6| 93.8]}  G{v_l: 1.434, v_acc: 32.8, c_acc: 82.8}\n","STEP:651, D{v_l: 0.492, v_acc: [84.4| 75.0| 79.7], c_acc: [93.8| 81.2]}  G{v_l: 1.499, v_acc: 34.4, c_acc: 84.4}\n","STEP:652, D{v_l: 0.433, v_acc: [78.1| 81.2| 79.7], c_acc: [81.2| 93.8]}  G{v_l: 0.995, v_acc: 42.2, c_acc: 93.8}\n","STEP:653, D{v_l: 0.437, v_acc: [78.1| 81.2| 79.7], c_acc: [87.5| 93.8]}  G{v_l: 1.373, v_acc: 37.5, c_acc: 90.6}\n","STEP:654, D{v_l: 0.508, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 1.536, v_acc: 37.5, c_acc: 96.9}\n","STEP:655, D{v_l: 0.385, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 87.5]}  G{v_l: 1.053, v_acc: 48.4, c_acc: 95.3}\n","STEP:656, D{v_l: 0.474, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 1.264, v_acc: 43.8, c_acc: 96.9}\n","STEP:657, D{v_l: 0.447, v_acc: [75.0| 87.5| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.221, v_acc: 35.9, c_acc: 96.9}\n","STEP:658, D{v_l: 0.526, v_acc: [81.2| 78.1| 79.7], c_acc: [84.4| 84.4]}  G{v_l: 1.203, v_acc: 43.8, c_acc: 95.3}\n","STEP:659, D{v_l: 0.636, v_acc: [53.1| 78.1| 65.6], c_acc: [81.2| 93.8]}  G{v_l: 1.172, v_acc: 39.1, c_acc: 93.8}\n","STEP:660, D{v_l: 0.400, v_acc: [81.2| 93.8| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.239, v_acc: 39.1, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 2.7596 - valid_loss: 0.2862 - class_loss: 2.0567 - valid_acc: 0.9059 - class_acc: 0.4941\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0356 - valid_loss: 0.4815 - class_loss: 0.1373 - valid_acc: 0.8706 - class_acc: 0.9529\n","average v_acc: 88.824, three class acc: 49.412, two class acc: 60.000\n","====================================================================================================\n","Epoch: 60\n","====================================================================================================\n","STEP:661, D{v_l: 0.447, v_acc: [85.5| 81.2| 83.4], c_acc: [92.3| 96.9]}  G{v_l: 1.252, v_acc: 37.5, c_acc: 89.1}\n","STEP:662, D{v_l: 0.418, v_acc: [78.1| 87.5| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.155, v_acc: 51.6, c_acc: 90.6}\n","STEP:663, D{v_l: 0.502, v_acc: [81.2| 56.2| 68.8], c_acc: [93.8| 81.2]}  G{v_l: 0.998, v_acc: 46.9, c_acc: 90.6}\n","STEP:664, D{v_l: 0.562, v_acc: [78.1| 68.8| 73.4], c_acc: [100.0| 96.9]}  G{v_l: 1.192, v_acc: 51.6, c_acc: 96.9}\n","STEP:665, D{v_l: 0.519, v_acc: [81.2| 71.9| 76.6], c_acc: [84.4| 93.8]}  G{v_l: 1.264, v_acc: 37.5, c_acc: 96.9}\n","STEP:666, D{v_l: 0.526, v_acc: [87.5| 81.2| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.175, v_acc: 45.3, c_acc: 92.2}\n","STEP:667, D{v_l: 0.577, v_acc: [71.9| 65.6| 68.8], c_acc: [87.5| 96.9]}  G{v_l: 1.246, v_acc: 50.0, c_acc: 95.3}\n","STEP:668, D{v_l: 0.422, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 81.2]}  G{v_l: 1.235, v_acc: 34.4, c_acc: 93.8}\n","STEP:669, D{v_l: 0.456, v_acc: [68.8| 81.2| 75.0], c_acc: [93.8| 96.9]}  G{v_l: 1.317, v_acc: 40.6, c_acc: 87.5}\n","STEP:670, D{v_l: 0.403, v_acc: [81.2| 78.1| 79.7], c_acc: [96.9| 93.8]}  G{v_l: 1.296, v_acc: 37.5, c_acc: 95.3}\n","STEP:671, D{v_l: 0.642, v_acc: [78.1| 71.9| 75.0], c_acc: [87.5| 96.9]}  G{v_l: 1.186, v_acc: 37.5, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 2.9869 - valid_loss: 0.2817 - class_loss: 2.2884 - valid_acc: 0.8941 - class_acc: 0.4706\n","3/3 [==============================] - 0s 49ms/step - loss: 0.9126 - valid_loss: 0.4349 - class_loss: 0.0610 - valid_acc: 0.9059 - class_acc: 0.9882\n","average v_acc: 90.000, three class acc: 47.059, two class acc: 57.647\n","====================================================================================================\n","STEP:672, D{v_l: 0.513, v_acc: [85.5| 65.6| 75.5], c_acc: [95.7| 96.9]}  G{v_l: 1.134, v_acc: 40.6, c_acc: 95.3}\n","STEP:673, D{v_l: 0.532, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.135, v_acc: 34.4, c_acc: 93.8}\n","STEP:674, D{v_l: 0.477, v_acc: [81.2| 65.6| 73.4], c_acc: [93.8| 75.0]}  G{v_l: 1.409, v_acc: 43.8, c_acc: 53.1}\n","STEP:675, D{v_l: 0.610, v_acc: [65.6| 75.0| 70.3], c_acc: [87.5| 93.8]}  G{v_l: 2.048, v_acc: 23.4, c_acc: 39.1}\n","STEP:676, D{v_l: 0.713, v_acc: [68.8| 75.0| 71.9], c_acc: [87.5| 93.8]}  G{v_l: 2.028, v_acc: 35.9, c_acc: 56.2}\n","STEP:677, D{v_l: 0.668, v_acc: [81.2| 62.5| 71.9], c_acc: [93.8| 84.4]}  G{v_l: 1.082, v_acc: 46.9, c_acc: 93.8}\n","STEP:678, D{v_l: 0.433, v_acc: [87.5| 71.9| 79.7], c_acc: [90.6| 90.6]}  G{v_l: 1.340, v_acc: 42.2, c_acc: 84.4}\n","STEP:679, D{v_l: 0.496, v_acc: [90.6| 62.5| 76.6], c_acc: [84.4| 96.9]}  G{v_l: 1.179, v_acc: 54.7, c_acc: 87.5}\n","STEP:680, D{v_l: 0.619, v_acc: [65.6| 75.0| 70.3], c_acc: [93.8| 96.9]}  G{v_l: 1.234, v_acc: 51.6, c_acc: 92.2}\n","STEP:681, D{v_l: 0.431, v_acc: [81.2| 84.4| 82.8], c_acc: [71.9| 96.9]}  G{v_l: 1.023, v_acc: 46.9, c_acc: 85.9}\n","STEP:682, D{v_l: 0.375, v_acc: [93.8| 84.4| 89.1], c_acc: [78.1| 90.6]}  G{v_l: 1.388, v_acc: 43.8, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 3.8056 - valid_loss: 0.6042 - class_loss: 2.7847 - valid_acc: 0.6824 - class_acc: 0.5176\n","3/3 [==============================] - 0s 52ms/step - loss: 1.0779 - valid_loss: 0.4476 - class_loss: 0.2136 - valid_acc: 0.8588 - class_acc: 0.9176\n","average v_acc: 77.059, three class acc: 51.765, two class acc: 58.824\n","====================================================================================================\n","STEP:683, D{v_l: 0.532, v_acc: [82.9| 75.0| 79.0], c_acc: [91.5| 90.6]}  G{v_l: 1.331, v_acc: 39.1, c_acc: 85.9}\n","STEP:684, D{v_l: 0.245, v_acc: [90.6| 87.5| 89.1], c_acc: [87.5| 90.6]}  G{v_l: 1.293, v_acc: 40.6, c_acc: 90.6}\n","STEP:685, D{v_l: 0.388, v_acc: [90.6| 78.1| 84.4], c_acc: [93.8| 87.5]}  G{v_l: 1.213, v_acc: 51.6, c_acc: 89.1}\n","STEP:686, D{v_l: 0.603, v_acc: [68.8| 75.0| 71.9], c_acc: [90.6| 100.0]}  G{v_l: 1.476, v_acc: 37.5, c_acc: 96.9}\n","STEP:687, D{v_l: 0.443, v_acc: [78.1| 75.0| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 1.315, v_acc: 43.8, c_acc: 100.0}\n","STEP:688, D{v_l: 0.579, v_acc: [81.2| 78.1| 79.7], c_acc: [87.5| 100.0]}  G{v_l: 1.432, v_acc: 28.1, c_acc: 95.3}\n","STEP:689, D{v_l: 0.542, v_acc: [75.0| 71.9| 73.4], c_acc: [84.4| 81.2]}  G{v_l: 1.330, v_acc: 42.2, c_acc: 98.4}\n","STEP:690, D{v_l: 0.837, v_acc: [75.0| 53.1| 64.1], c_acc: [78.1| 93.8]}  G{v_l: 1.364, v_acc: 31.2, c_acc: 90.6}\n","STEP:691, D{v_l: 0.511, v_acc: [81.2| 78.1| 79.7], c_acc: [68.8| 96.9]}  G{v_l: 1.152, v_acc: 48.4, c_acc: 96.9}\n","STEP:692, D{v_l: 0.453, v_acc: [78.1| 78.1| 78.1], c_acc: [87.5| 96.9]}  G{v_l: 1.240, v_acc: 35.9, c_acc: 96.9}\n","STEP:693, D{v_l: 0.517, v_acc: [71.9| 71.9| 71.9], c_acc: [93.8| 90.6]}  G{v_l: 1.183, v_acc: 56.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.5645 - valid_loss: 0.3382 - class_loss: 2.8096 - valid_acc: 0.8235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0126 - valid_loss: 0.5121 - class_loss: 0.0838 - valid_acc: 0.7412 - class_acc: 0.9765\n","average v_acc: 78.235, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:694, D{v_l: 0.450, v_acc: [73.5| 84.4| 78.9], c_acc: [96.6| 100.0]}  G{v_l: 1.178, v_acc: 43.8, c_acc: 95.3}\n","STEP:695, D{v_l: 0.580, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.994, v_acc: 54.7, c_acc: 95.3}\n","STEP:696, D{v_l: 0.337, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 1.145, v_acc: 53.1, c_acc: 95.3}\n","STEP:697, D{v_l: 0.309, v_acc: [81.2| 93.8| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.128, v_acc: 40.6, c_acc: 95.3}\n","STEP:698, D{v_l: 0.559, v_acc: [71.9| 75.0| 73.4], c_acc: [84.4| 100.0]}  G{v_l: 1.416, v_acc: 32.8, c_acc: 96.9}\n","STEP:699, D{v_l: 0.626, v_acc: [78.1| 71.9| 75.0], c_acc: [93.8| 100.0]}  G{v_l: 0.901, v_acc: 50.0, c_acc: 96.9}\n","STEP:700, D{v_l: 0.409, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.426, v_acc: 31.2, c_acc: 89.1}\n","STEP:701, D{v_l: 0.516, v_acc: [68.8| 75.0| 71.9], c_acc: [87.5| 100.0]}  G{v_l: 1.132, v_acc: 45.3, c_acc: 92.2}\n","STEP:702, D{v_l: 0.492, v_acc: [71.9| 78.1| 75.0], c_acc: [78.1| 87.5]}  G{v_l: 1.013, v_acc: 53.1, c_acc: 82.8}\n","STEP:703, D{v_l: 0.334, v_acc: [87.5| 84.4| 85.9], c_acc: [84.4| 84.4]}  G{v_l: 1.249, v_acc: 37.5, c_acc: 87.5}\n","STEP:704, D{v_l: 0.549, v_acc: [71.9| 78.1| 75.0], c_acc: [96.9| 93.8]}  G{v_l: 0.918, v_acc: 51.6, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 4.6781 - valid_loss: 0.5225 - class_loss: 3.7390 - valid_acc: 0.7412 - class_acc: 0.5059\n","3/3 [==============================] - 0s 52ms/step - loss: 1.1529 - valid_loss: 0.5083 - class_loss: 0.2280 - valid_acc: 0.7765 - class_acc: 0.9059\n","average v_acc: 75.882, three class acc: 50.588, two class acc: 54.118\n","====================================================================================================\n","STEP:705, D{v_l: 0.539, v_acc: [79.5| 65.6| 72.6], c_acc: [90.6| 93.8]}  G{v_l: 0.910, v_acc: 45.3, c_acc: 89.1}\n","STEP:706, D{v_l: 0.537, v_acc: [68.8| 84.4| 76.6], c_acc: [90.6| 93.8]}  G{v_l: 1.024, v_acc: 48.4, c_acc: 95.3}\n","STEP:707, D{v_l: 0.359, v_acc: [84.4| 71.9| 78.1], c_acc: [96.9| 87.5]}  G{v_l: 0.880, v_acc: 43.8, c_acc: 92.2}\n","STEP:708, D{v_l: 0.510, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 96.9]}  G{v_l: 0.906, v_acc: 54.7, c_acc: 95.3}\n","STEP:709, D{v_l: 0.461, v_acc: [78.1| 81.2| 79.7], c_acc: [100.0| 90.6]}  G{v_l: 1.173, v_acc: 39.1, c_acc: 92.2}\n","STEP:710, D{v_l: 0.448, v_acc: [71.9| 90.6| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.131, v_acc: 39.1, c_acc: 76.6}\n","STEP:711, D{v_l: 0.474, v_acc: [84.4| 78.1| 81.2], c_acc: [84.4| 90.6]}  G{v_l: 1.343, v_acc: 26.6, c_acc: 95.3}\n","STEP:712, D{v_l: 0.397, v_acc: [87.5| 90.6| 89.1], c_acc: [87.5| 93.8]}  G{v_l: 1.258, v_acc: 42.2, c_acc: 93.8}\n","STEP:713, D{v_l: 0.341, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 0.948, v_acc: 50.0, c_acc: 96.9}\n","STEP:714, D{v_l: 0.481, v_acc: [78.1| 84.4| 81.2], c_acc: [90.6| 87.5]}  G{v_l: 1.018, v_acc: 40.6, c_acc: 82.8}\n","STEP:715, D{v_l: 0.473, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 87.5]}  G{v_l: 1.251, v_acc: 43.8, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 4.7740 - valid_loss: 0.8194 - class_loss: 3.5381 - valid_acc: 0.5765 - class_acc: 0.5059\n","3/3 [==============================] - 0s 50ms/step - loss: 1.0204 - valid_loss: 0.4963 - class_loss: 0.1075 - valid_acc: 0.7647 - class_acc: 0.9647\n","average v_acc: 67.059, three class acc: 50.588, two class acc: 55.294\n","====================================================================================================\n","STEP:716, D{v_l: 0.404, v_acc: [78.6| 81.2| 79.9], c_acc: [95.7| 93.8]}  G{v_l: 0.945, v_acc: 48.4, c_acc: 93.8}\n","STEP:717, D{v_l: 0.480, v_acc: [78.1| 78.1| 78.1], c_acc: [84.4| 96.9]}  G{v_l: 1.067, v_acc: 48.4, c_acc: 90.6}\n","STEP:718, D{v_l: 0.502, v_acc: [78.1| 71.9| 75.0], c_acc: [93.8| 90.6]}  G{v_l: 1.102, v_acc: 51.6, c_acc: 92.2}\n","STEP:719, D{v_l: 0.428, v_acc: [75.0| 87.5| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.185, v_acc: 45.3, c_acc: 98.4}\n","STEP:720, D{v_l: 0.328, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.189, v_acc: 31.2, c_acc: 95.3}\n","STEP:721, D{v_l: 0.480, v_acc: [71.9| 78.1| 75.0], c_acc: [90.6| 96.9]}  G{v_l: 1.236, v_acc: 39.1, c_acc: 92.2}\n","STEP:722, D{v_l: 0.549, v_acc: [65.6| 84.4| 75.0], c_acc: [100.0| 96.9]}  G{v_l: 1.020, v_acc: 45.3, c_acc: 98.4}\n","STEP:723, D{v_l: 0.517, v_acc: [81.2| 71.9| 76.6], c_acc: [93.8| 90.6]}  G{v_l: 1.280, v_acc: 29.7, c_acc: 92.2}\n","STEP:724, D{v_l: 0.670, v_acc: [65.6| 75.0| 70.3], c_acc: [87.5| 96.9]}  G{v_l: 1.214, v_acc: 40.6, c_acc: 90.6}\n","STEP:725, D{v_l: 0.488, v_acc: [71.9| 81.2| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 0.967, v_acc: 45.3, c_acc: 92.2}\n","STEP:726, D{v_l: 0.410, v_acc: [84.4| 68.8| 76.6], c_acc: [90.6| 90.6]}  G{v_l: 1.148, v_acc: 42.2, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 4.1019 - valid_loss: 0.6729 - class_loss: 3.0124 - valid_acc: 0.6353 - class_acc: 0.5176\n","3/3 [==============================] - 0s 45ms/step - loss: 1.1402 - valid_loss: 0.5380 - class_loss: 0.1857 - valid_acc: 0.7059 - class_acc: 0.9412\n","average v_acc: 67.059, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:727, D{v_l: 0.473, v_acc: [69.2| 78.1| 73.7], c_acc: [93.2| 96.9]}  G{v_l: 1.136, v_acc: 46.9, c_acc: 82.8}\n","STEP:728, D{v_l: 0.479, v_acc: [78.1| 71.9| 75.0], c_acc: [87.5| 93.8]}  G{v_l: 1.079, v_acc: 54.7, c_acc: 89.1}\n","STEP:729, D{v_l: 0.423, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.207, v_acc: 29.7, c_acc: 100.0}\n","STEP:730, D{v_l: 0.567, v_acc: [78.1| 68.8| 73.4], c_acc: [90.6| 81.2]}  G{v_l: 1.421, v_acc: 53.1, c_acc: 87.5}\n","STEP:731, D{v_l: 0.471, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 1.740, v_acc: 57.8, c_acc: 84.4}\n","STEP:732, D{v_l: 0.571, v_acc: [87.5| 71.9| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 1.105, v_acc: 46.9, c_acc: 78.1}\n","STEP:733, D{v_l: 0.289, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 1.351, v_acc: 39.1, c_acc: 89.1}\n","STEP:734, D{v_l: 0.317, v_acc: [81.2| 90.6| 85.9], c_acc: [84.4| 96.9]}  G{v_l: 1.240, v_acc: 34.4, c_acc: 93.8}\n","STEP:735, D{v_l: 0.332, v_acc: [87.5| 81.2| 84.4], c_acc: [84.4| 90.6]}  G{v_l: 1.124, v_acc: 39.1, c_acc: 96.9}\n","STEP:736, D{v_l: 0.382, v_acc: [71.9| 81.2| 76.6], c_acc: [96.9| 93.8]}  G{v_l: 1.315, v_acc: 35.9, c_acc: 89.1}\n","STEP:737, D{v_l: 0.515, v_acc: [65.6| 78.1| 71.9], c_acc: [90.6| 93.8]}  G{v_l: 1.066, v_acc: 46.9, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.4944 - valid_loss: 0.6744 - class_loss: 3.4036 - valid_acc: 0.6353 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0446 - valid_loss: 0.4909 - class_loss: 0.1371 - valid_acc: 0.8353 - class_acc: 0.9412\n","average v_acc: 73.529, three class acc: 51.765, two class acc: 56.471\n","====================================================================================================\n","STEP:738, D{v_l: 0.444, v_acc: [86.3| 84.4| 85.3], c_acc: [92.3| 93.8]}  G{v_l: 1.418, v_acc: 28.1, c_acc: 96.9}\n","STEP:739, D{v_l: 0.484, v_acc: [81.2| 71.9| 76.6], c_acc: [87.5| 87.5]}  G{v_l: 1.122, v_acc: 50.0, c_acc: 95.3}\n","STEP:740, D{v_l: 0.500, v_acc: [84.4| 78.1| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.006, v_acc: 45.3, c_acc: 95.3}\n","STEP:741, D{v_l: 0.451, v_acc: [87.5| 75.0| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 1.297, v_acc: 42.2, c_acc: 93.8}\n","STEP:742, D{v_l: 0.524, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 87.5]}  G{v_l: 1.440, v_acc: 34.4, c_acc: 87.5}\n","STEP:743, D{v_l: 0.491, v_acc: [75.0| 78.1| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.116, v_acc: 56.2, c_acc: 89.1}\n","STEP:744, D{v_l: 0.384, v_acc: [78.1| 75.0| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.174, v_acc: 54.7, c_acc: 92.2}\n","STEP:745, D{v_l: 0.453, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 100.0]}  G{v_l: 0.803, v_acc: 46.9, c_acc: 95.3}\n","STEP:746, D{v_l: 0.501, v_acc: [81.2| 81.2| 81.2], c_acc: [78.1| 87.5]}  G{v_l: 1.094, v_acc: 50.0, c_acc: 90.6}\n","STEP:747, D{v_l: 0.430, v_acc: [90.6| 71.9| 81.2], c_acc: [84.4| 87.5]}  G{v_l: 1.342, v_acc: 53.1, c_acc: 93.8}\n","STEP:748, D{v_l: 0.580, v_acc: [78.1| 75.0| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.180, v_acc: 42.2, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.7314 - valid_loss: 0.5817 - class_loss: 2.7332 - valid_acc: 0.6471 - class_acc: 0.5412\n","3/3 [==============================] - 0s 46ms/step - loss: 1.1393 - valid_loss: 0.5579 - class_loss: 0.1649 - valid_acc: 0.7647 - class_acc: 0.9647\n","average v_acc: 70.588, three class acc: 54.118, two class acc: 60.000\n","====================================================================================================\n","STEP:749, D{v_l: 0.452, v_acc: [77.8| 87.5| 82.6], c_acc: [96.6| 93.8]}  G{v_l: 1.182, v_acc: 43.8, c_acc: 95.3}\n","STEP:750, D{v_l: 0.661, v_acc: [62.5| 78.1| 70.3], c_acc: [81.2| 100.0]}  G{v_l: 1.033, v_acc: 45.3, c_acc: 92.2}\n","STEP:751, D{v_l: 0.612, v_acc: [81.2| 75.0| 78.1], c_acc: [87.5| 84.4]}  G{v_l: 0.723, v_acc: 68.8, c_acc: 73.4}\n","STEP:752, D{v_l: 0.465, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.276, v_acc: 43.8, c_acc: 90.6}\n","STEP:753, D{v_l: 0.493, v_acc: [81.2| 71.9| 76.6], c_acc: [90.6| 100.0]}  G{v_l: 0.864, v_acc: 53.1, c_acc: 82.8}\n","STEP:754, D{v_l: 0.451, v_acc: [84.4| 75.0| 79.7], c_acc: [87.5| 90.6]}  G{v_l: 0.901, v_acc: 43.8, c_acc: 89.1}\n","STEP:755, D{v_l: 0.597, v_acc: [78.1| 78.1| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 1.024, v_acc: 53.1, c_acc: 93.8}\n","STEP:756, D{v_l: 0.507, v_acc: [71.9| 87.5| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 1.226, v_acc: 45.3, c_acc: 98.4}\n","STEP:757, D{v_l: 0.377, v_acc: [75.0| 93.8| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 0.803, v_acc: 57.8, c_acc: 92.2}\n","STEP:758, D{v_l: 0.341, v_acc: [87.5| 81.2| 84.4], c_acc: [87.5| 90.6]}  G{v_l: 0.997, v_acc: 45.3, c_acc: 89.1}\n","STEP:759, D{v_l: 0.435, v_acc: [75.0| 78.1| 76.6], c_acc: [84.4| 100.0]}  G{v_l: 0.968, v_acc: 51.6, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 52ms/step - loss: 5.3372 - valid_loss: 0.7425 - class_loss: 4.1783 - valid_acc: 0.6235 - class_acc: 0.5176\n","3/3 [==============================] - 0s 48ms/step - loss: 1.2244 - valid_loss: 0.5984 - class_loss: 0.2096 - valid_acc: 0.6353 - class_acc: 0.9059\n","average v_acc: 62.941, three class acc: 51.765, two class acc: 54.118\n","====================================================================================================\n","STEP:760, D{v_l: 0.505, v_acc: [64.1| 81.2| 72.7], c_acc: [92.3| 93.8]}  G{v_l: 1.030, v_acc: 51.6, c_acc: 89.1}\n","STEP:761, D{v_l: 0.421, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.050, v_acc: 45.3, c_acc: 92.2}\n","STEP:762, D{v_l: 0.535, v_acc: [75.0| 78.1| 76.6], c_acc: [87.5| 90.6]}  G{v_l: 1.100, v_acc: 42.2, c_acc: 95.3}\n","STEP:763, D{v_l: 0.606, v_acc: [81.2| 65.6| 73.4], c_acc: [93.8| 87.5]}  G{v_l: 0.933, v_acc: 57.8, c_acc: 93.8}\n","STEP:764, D{v_l: 0.460, v_acc: [71.9| 84.4| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 0.926, v_acc: 50.0, c_acc: 93.8}\n","STEP:765, D{v_l: 0.500, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 100.0]}  G{v_l: 1.088, v_acc: 56.2, c_acc: 93.8}\n","STEP:766, D{v_l: 0.524, v_acc: [81.2| 71.9| 76.6], c_acc: [93.8| 90.6]}  G{v_l: 1.042, v_acc: 57.8, c_acc: 93.8}\n","STEP:767, D{v_l: 0.454, v_acc: [78.1| 81.2| 79.7], c_acc: [93.8| 90.6]}  G{v_l: 1.235, v_acc: 37.5, c_acc: 98.4}\n","STEP:768, D{v_l: 0.362, v_acc: [90.6| 81.2| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 0.986, v_acc: 51.6, c_acc: 93.8}\n","STEP:769, D{v_l: 0.457, v_acc: [84.4| 78.1| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 0.981, v_acc: 50.0, c_acc: 92.2}\n","STEP:770, D{v_l: 0.383, v_acc: [90.6| 75.0| 82.8], c_acc: [87.5| 93.8]}  G{v_l: 1.047, v_acc: 43.8, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 4.6109 - valid_loss: 0.6778 - class_loss: 3.5168 - valid_acc: 0.6353 - class_acc: 0.5059\n","3/3 [==============================] - 0s 44ms/step - loss: 1.1423 - valid_loss: 0.6667 - class_loss: 0.0593 - valid_acc: 0.5176 - class_acc: 0.9765\n","average v_acc: 57.647, three class acc: 50.588, two class acc: 54.118\n","====================================================================================================\n","Epoch: 70\n","====================================================================================================\n","STEP:771, D{v_l: 0.481, v_acc: [62.4| 87.5| 74.9], c_acc: [96.6| 100.0]}  G{v_l: 1.196, v_acc: 54.7, c_acc: 89.1}\n","STEP:772, D{v_l: 0.330, v_acc: [90.6| 71.9| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.002, v_acc: 51.6, c_acc: 95.3}\n","STEP:773, D{v_l: 0.478, v_acc: [71.9| 81.2| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.335, v_acc: 42.2, c_acc: 98.4}\n","STEP:774, D{v_l: 0.426, v_acc: [84.4| 81.2| 82.8], c_acc: [100.0| 96.9]}  G{v_l: 1.125, v_acc: 39.1, c_acc: 100.0}\n","STEP:775, D{v_l: 0.339, v_acc: [75.0| 87.5| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.116, v_acc: 46.9, c_acc: 90.6}\n","STEP:776, D{v_l: 0.408, v_acc: [84.4| 81.2| 82.8], c_acc: [81.2| 100.0]}  G{v_l: 1.082, v_acc: 48.4, c_acc: 84.4}\n","STEP:777, D{v_l: 0.378, v_acc: [87.5| 71.9| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.979, v_acc: 53.1, c_acc: 76.6}\n","STEP:778, D{v_l: 0.304, v_acc: [90.6| 78.1| 84.4], c_acc: [84.4| 100.0]}  G{v_l: 0.973, v_acc: 57.8, c_acc: 85.9}\n","STEP:779, D{v_l: 0.405, v_acc: [71.9| 87.5| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.871, v_acc: 56.2, c_acc: 95.3}\n","STEP:780, D{v_l: 0.373, v_acc: [68.8| 87.5| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.007, v_acc: 40.6, c_acc: 95.3}\n","STEP:781, D{v_l: 0.298, v_acc: [84.4| 90.6| 87.5], c_acc: [100.0| 100.0]}  G{v_l: 1.370, v_acc: 45.3, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 3.6600 - valid_loss: 0.4999 - class_loss: 2.7439 - valid_acc: 0.7647 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.1018 - valid_loss: 0.6013 - class_loss: 0.0842 - valid_acc: 0.5529 - class_acc: 0.9765\n","average v_acc: 65.882, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:782, D{v_l: 0.626, v_acc: [58.1| 78.1| 68.1], c_acc: [94.9| 84.4]}  G{v_l: 1.067, v_acc: 43.8, c_acc: 98.4}\n","STEP:783, D{v_l: 0.273, v_acc: [90.6| 87.5| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 1.204, v_acc: 45.3, c_acc: 89.1}\n","STEP:784, D{v_l: 0.374, v_acc: [87.5| 75.0| 81.2], c_acc: [100.0| 96.9]}  G{v_l: 1.191, v_acc: 54.7, c_acc: 95.3}\n","STEP:785, D{v_l: 0.388, v_acc: [90.6| 71.9| 81.2], c_acc: [90.6| 100.0]}  G{v_l: 1.258, v_acc: 42.2, c_acc: 89.1}\n","STEP:786, D{v_l: 0.422, v_acc: [78.1| 75.0| 76.6], c_acc: [96.9| 90.6]}  G{v_l: 1.023, v_acc: 45.3, c_acc: 96.9}\n","STEP:787, D{v_l: 0.343, v_acc: [93.8| 78.1| 85.9], c_acc: [93.8| 90.6]}  G{v_l: 1.081, v_acc: 53.1, c_acc: 92.2}\n","STEP:788, D{v_l: 0.464, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.937, v_acc: 51.6, c_acc: 92.2}\n","STEP:789, D{v_l: 0.353, v_acc: [81.2| 87.5| 84.4], c_acc: [100.0| 100.0]}  G{v_l: 1.227, v_acc: 37.5, c_acc: 95.3}\n","STEP:790, D{v_l: 0.291, v_acc: [87.5| 84.4| 85.9], c_acc: [90.6| 100.0]}  G{v_l: 1.023, v_acc: 32.8, c_acc: 93.8}\n","STEP:791, D{v_l: 0.325, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 84.4]}  G{v_l: 1.052, v_acc: 48.4, c_acc: 84.4}\n","STEP:792, D{v_l: 0.342, v_acc: [90.6| 81.2| 85.9], c_acc: [96.9| 100.0]}  G{v_l: 1.085, v_acc: 54.7, c_acc: 81.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.3240 - valid_loss: 0.3255 - class_loss: 2.5823 - valid_acc: 0.8588 - class_acc: 0.4706\n","3/3 [==============================] - 0s 49ms/step - loss: 1.3789 - valid_loss: 0.4745 - class_loss: 0.4882 - valid_acc: 0.8000 - class_acc: 0.8235\n","average v_acc: 82.941, three class acc: 47.059, two class acc: 58.824\n","====================================================================================================\n","STEP:793, D{v_l: 0.373, v_acc: [82.9| 75.0| 79.0], c_acc: [84.6| 96.9]}  G{v_l: 1.151, v_acc: 51.6, c_acc: 85.9}\n","STEP:794, D{v_l: 0.343, v_acc: [87.5| 78.1| 82.8], c_acc: [90.6| 87.5]}  G{v_l: 1.062, v_acc: 46.9, c_acc: 85.9}\n","STEP:795, D{v_l: 0.433, v_acc: [75.0| 81.2| 78.1], c_acc: [84.4| 90.6]}  G{v_l: 0.988, v_acc: 45.3, c_acc: 81.2}\n","STEP:796, D{v_l: 0.402, v_acc: [75.0| 84.4| 79.7], c_acc: [96.9| 100.0]}  G{v_l: 1.181, v_acc: 45.3, c_acc: 90.6}\n","STEP:797, D{v_l: 0.393, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 0.953, v_acc: 48.4, c_acc: 100.0}\n","STEP:798, D{v_l: 0.603, v_acc: [59.4| 71.9| 65.6], c_acc: [84.4| 87.5]}  G{v_l: 1.009, v_acc: 43.8, c_acc: 93.8}\n","STEP:799, D{v_l: 0.408, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 1.136, v_acc: 43.8, c_acc: 96.9}\n","STEP:800, D{v_l: 0.336, v_acc: [75.0| 87.5| 81.2], c_acc: [96.9| 93.8]}  G{v_l: 1.137, v_acc: 50.0, c_acc: 93.8}\n","STEP:801, D{v_l: 0.349, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.270, v_acc: 34.4, c_acc: 98.4}\n","STEP:802, D{v_l: 0.509, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 1.189, v_acc: 45.3, c_acc: 96.9}\n","STEP:803, D{v_l: 0.679, v_acc: [87.5| 75.0| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 1.184, v_acc: 32.8, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.2293 - valid_loss: 0.6134 - class_loss: 3.1997 - valid_acc: 0.6353 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0650 - valid_loss: 0.5070 - class_loss: 0.1419 - valid_acc: 0.7412 - class_acc: 0.9529\n","average v_acc: 68.824, three class acc: 52.941, two class acc: 60.000\n","====================================================================================================\n","STEP:804, D{v_l: 0.627, v_acc: [77.8| 65.6| 71.7], c_acc: [95.7| 93.8]}  G{v_l: 1.036, v_acc: 48.4, c_acc: 89.1}\n","STEP:805, D{v_l: 0.408, v_acc: [90.6| 75.0| 82.8], c_acc: [90.6| 90.6]}  G{v_l: 1.151, v_acc: 39.1, c_acc: 92.2}\n","STEP:806, D{v_l: 0.502, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 93.8]}  G{v_l: 1.082, v_acc: 46.9, c_acc: 95.3}\n","STEP:807, D{v_l: 0.282, v_acc: [90.6| 93.8| 92.2], c_acc: [93.8| 90.6]}  G{v_l: 1.019, v_acc: 43.8, c_acc: 98.4}\n","STEP:808, D{v_l: 0.543, v_acc: [78.1| 75.0| 76.6], c_acc: [84.4| 96.9]}  G{v_l: 1.084, v_acc: 42.2, c_acc: 92.2}\n","STEP:809, D{v_l: 0.567, v_acc: [78.1| 71.9| 75.0], c_acc: [90.6| 100.0]}  G{v_l: 1.270, v_acc: 42.2, c_acc: 90.6}\n","STEP:810, D{v_l: 0.444, v_acc: [71.9| 84.4| 78.1], c_acc: [93.8| 96.9]}  G{v_l: 1.149, v_acc: 42.2, c_acc: 92.2}\n","STEP:811, D{v_l: 0.394, v_acc: [81.2| 78.1| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 1.238, v_acc: 48.4, c_acc: 89.1}\n","STEP:812, D{v_l: 0.342, v_acc: [78.1| 84.4| 81.2], c_acc: [100.0| 96.9]}  G{v_l: 1.061, v_acc: 43.8, c_acc: 98.4}\n","STEP:813, D{v_l: 0.475, v_acc: [75.0| 87.5| 81.2], c_acc: [87.5| 100.0]}  G{v_l: 0.955, v_acc: 50.0, c_acc: 95.3}\n","STEP:814, D{v_l: 0.355, v_acc: [75.0| 78.1| 76.6], c_acc: [93.8| 100.0]}  G{v_l: 0.953, v_acc: 50.0, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 49ms/step - loss: 3.9942 - valid_loss: 0.2863 - class_loss: 3.2919 - valid_acc: 0.9176 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9967 - valid_loss: 0.5041 - class_loss: 0.0765 - valid_acc: 0.7882 - class_acc: 0.9882\n","average v_acc: 85.294, three class acc: 51.765, two class acc: 56.471\n","====================================================================================================\n","STEP:815, D{v_l: 0.394, v_acc: [76.9| 90.6| 83.8], c_acc: [97.4| 100.0]}  G{v_l: 1.250, v_acc: 40.6, c_acc: 96.9}\n","STEP:816, D{v_l: 0.409, v_acc: [87.5| 75.0| 81.2], c_acc: [96.9| 87.5]}  G{v_l: 1.210, v_acc: 37.5, c_acc: 93.8}\n","STEP:817, D{v_l: 0.475, v_acc: [78.1| 78.1| 78.1], c_acc: [78.1| 100.0]}  G{v_l: 0.970, v_acc: 48.4, c_acc: 92.2}\n","STEP:818, D{v_l: 0.277, v_acc: [90.6| 93.8| 92.2], c_acc: [90.6| 100.0]}  G{v_l: 0.975, v_acc: 51.6, c_acc: 92.2}\n","STEP:819, D{v_l: 0.268, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 1.226, v_acc: 37.5, c_acc: 95.3}\n","STEP:820, D{v_l: 0.382, v_acc: [87.5| 87.5| 87.5], c_acc: [87.5| 93.8]}  G{v_l: 1.103, v_acc: 43.8, c_acc: 90.6}\n","STEP:821, D{v_l: 0.441, v_acc: [81.2| 75.0| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 1.241, v_acc: 35.9, c_acc: 92.2}\n","STEP:822, D{v_l: 0.390, v_acc: [81.2| 81.2| 81.2], c_acc: [84.4| 93.8]}  G{v_l: 1.086, v_acc: 43.8, c_acc: 95.3}\n","STEP:823, D{v_l: 0.397, v_acc: [93.8| 71.9| 82.8], c_acc: [90.6| 100.0]}  G{v_l: 1.161, v_acc: 39.1, c_acc: 100.0}\n","STEP:824, D{v_l: 0.429, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 1.065, v_acc: 39.1, c_acc: 95.3}\n","STEP:825, D{v_l: 0.442, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 87.5]}  G{v_l: 1.032, v_acc: 51.6, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.3260 - valid_loss: 0.7465 - class_loss: 3.1635 - valid_acc: 0.6000 - class_acc: 0.4706\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9850 - valid_loss: 0.4685 - class_loss: 0.1004 - valid_acc: 0.8118 - class_acc: 0.9882\n","average v_acc: 70.588, three class acc: 47.059, two class acc: 54.118\n","====================================================================================================\n","STEP:826, D{v_l: 0.448, v_acc: [83.8| 68.8| 76.3], c_acc: [94.0| 90.6]}  G{v_l: 1.018, v_acc: 51.6, c_acc: 93.8}\n","STEP:827, D{v_l: 0.282, v_acc: [81.2| 87.5| 84.4], c_acc: [90.6| 93.8]}  G{v_l: 1.205, v_acc: 37.5, c_acc: 96.9}\n","STEP:828, D{v_l: 0.403, v_acc: [78.1| 90.6| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 1.104, v_acc: 45.3, c_acc: 93.8}\n","STEP:829, D{v_l: 0.410, v_acc: [81.2| 84.4| 82.8], c_acc: [93.8| 93.8]}  G{v_l: 1.126, v_acc: 40.6, c_acc: 90.6}\n","STEP:830, D{v_l: 0.336, v_acc: [81.2| 84.4| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.337, v_acc: 42.2, c_acc: 93.8}\n","STEP:831, D{v_l: 0.482, v_acc: [81.2| 71.9| 76.6], c_acc: [87.5| 96.9]}  G{v_l: 1.330, v_acc: 29.7, c_acc: 96.9}\n","STEP:832, D{v_l: 0.444, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 1.053, v_acc: 45.3, c_acc: 85.9}\n","STEP:833, D{v_l: 0.391, v_acc: [84.4| 75.0| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 1.185, v_acc: 40.6, c_acc: 90.6}\n","STEP:834, D{v_l: 0.376, v_acc: [84.4| 84.4| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 1.075, v_acc: 42.2, c_acc: 90.6}\n","STEP:835, D{v_l: 0.381, v_acc: [81.2| 81.2| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.431, v_acc: 45.3, c_acc: 78.1}\n","STEP:836, D{v_l: 0.395, v_acc: [81.2| 81.2| 81.2], c_acc: [84.4| 100.0]}  G{v_l: 1.391, v_acc: 54.7, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.6952 - valid_loss: 0.7432 - class_loss: 3.5361 - valid_acc: 0.5529 - class_acc: 0.4824\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1650 - valid_loss: 0.5495 - class_loss: 0.1996 - valid_acc: 0.5882 - class_acc: 0.9176\n","average v_acc: 57.059, three class acc: 48.235, two class acc: 54.118\n","====================================================================================================\n","STEP:837, D{v_l: 0.348, v_acc: [62.4| 96.9| 79.6], c_acc: [91.5| 96.9]}  G{v_l: 1.573, v_acc: 35.9, c_acc: 90.6}\n","STEP:838, D{v_l: 0.672, v_acc: [87.5| 65.6| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.380, v_acc: 37.5, c_acc: 98.4}\n","STEP:839, D{v_l: 0.382, v_acc: [87.5| 84.4| 85.9], c_acc: [87.5| 93.8]}  G{v_l: 1.019, v_acc: 59.4, c_acc: 85.9}\n","STEP:840, D{v_l: 0.304, v_acc: [68.8| 90.6| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 1.068, v_acc: 43.8, c_acc: 92.2}\n","STEP:841, D{v_l: 0.448, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 0.951, v_acc: 57.8, c_acc: 93.8}\n","STEP:842, D{v_l: 0.446, v_acc: [81.2| 75.0| 78.1], c_acc: [90.6| 96.9]}  G{v_l: 0.949, v_acc: 62.5, c_acc: 87.5}\n","STEP:843, D{v_l: 0.460, v_acc: [78.1| 78.1| 78.1], c_acc: [93.8| 93.8]}  G{v_l: 1.123, v_acc: 50.0, c_acc: 89.1}\n","STEP:844, D{v_l: 0.298, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 1.155, v_acc: 37.5, c_acc: 92.2}\n","STEP:845, D{v_l: 0.475, v_acc: [65.6| 84.4| 75.0], c_acc: [90.6| 87.5]}  G{v_l: 1.006, v_acc: 54.7, c_acc: 75.0}\n","STEP:846, D{v_l: 0.476, v_acc: [78.1| 81.2| 79.7], c_acc: [100.0| 93.8]}  G{v_l: 0.957, v_acc: 45.3, c_acc: 71.9}\n","STEP:847, D{v_l: 0.434, v_acc: [75.0| 78.1| 76.6], c_acc: [90.6| 96.9]}  G{v_l: 1.370, v_acc: 39.1, c_acc: 81.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.1840 - valid_loss: 0.7163 - class_loss: 3.0518 - valid_acc: 0.6471 - class_acc: 0.4941\n","3/3 [==============================] - 0s 48ms/step - loss: 1.0630 - valid_loss: 0.5027 - class_loss: 0.1444 - valid_acc: 0.8235 - class_acc: 0.9647\n","average v_acc: 73.529, three class acc: 49.412, two class acc: 56.471\n","====================================================================================================\n","STEP:848, D{v_l: 0.424, v_acc: [80.3| 81.2| 80.8], c_acc: [97.4| 87.5]}  G{v_l: 0.947, v_acc: 32.8, c_acc: 96.9}\n","STEP:849, D{v_l: 0.354, v_acc: [78.1| 81.2| 79.7], c_acc: [100.0| 100.0]}  G{v_l: 1.287, v_acc: 45.3, c_acc: 92.2}\n","STEP:850, D{v_l: 0.413, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 0.948, v_acc: 51.6, c_acc: 93.8}\n","STEP:851, D{v_l: 0.395, v_acc: [87.5| 75.0| 81.2], c_acc: [87.5| 93.8]}  G{v_l: 1.178, v_acc: 42.2, c_acc: 95.3}\n","STEP:852, D{v_l: 0.504, v_acc: [68.8| 62.5| 65.6], c_acc: [93.8| 90.6]}  G{v_l: 1.183, v_acc: 45.3, c_acc: 98.4}\n","STEP:853, D{v_l: 0.378, v_acc: [78.1| 81.2| 79.7], c_acc: [81.2| 96.9]}  G{v_l: 1.064, v_acc: 42.2, c_acc: 93.8}\n","STEP:854, D{v_l: 0.309, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.258, v_acc: 32.8, c_acc: 96.9}\n","STEP:855, D{v_l: 0.414, v_acc: [81.2| 90.6| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 1.157, v_acc: 48.4, c_acc: 93.8}\n","STEP:856, D{v_l: 0.530, v_acc: [68.8| 81.2| 75.0], c_acc: [84.4| 93.8]}  G{v_l: 1.152, v_acc: 50.0, c_acc: 93.8}\n","STEP:857, D{v_l: 0.464, v_acc: [84.4| 71.9| 78.1], c_acc: [93.8| 100.0]}  G{v_l: 0.828, v_acc: 56.2, c_acc: 95.3}\n","STEP:858, D{v_l: 0.295, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 0.950, v_acc: 42.2, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.2754 - valid_loss: 0.6017 - class_loss: 3.2579 - valid_acc: 0.6588 - class_acc: 0.5412\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9467 - valid_loss: 0.4764 - class_loss: 0.0545 - valid_acc: 0.7882 - class_acc: 1.0000\n","average v_acc: 72.353, three class acc: 54.118, two class acc: 61.176\n","====================================================================================================\n","STEP:859, D{v_l: 0.604, v_acc: [79.5| 62.5| 71.0], c_acc: [96.6| 96.9]}  G{v_l: 1.009, v_acc: 40.6, c_acc: 82.8}\n","STEP:860, D{v_l: 0.310, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 90.6]}  G{v_l: 0.971, v_acc: 54.7, c_acc: 84.4}\n","STEP:861, D{v_l: 0.412, v_acc: [78.1| 78.1| 78.1], c_acc: [100.0| 96.9]}  G{v_l: 0.824, v_acc: 51.6, c_acc: 93.8}\n","STEP:862, D{v_l: 0.383, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.262, v_acc: 43.8, c_acc: 92.2}\n","STEP:863, D{v_l: 0.369, v_acc: [81.2| 90.6| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.905, v_acc: 56.2, c_acc: 92.2}\n","STEP:864, D{v_l: 0.451, v_acc: [90.6| 68.8| 79.7], c_acc: [100.0| 100.0]}  G{v_l: 0.931, v_acc: 50.0, c_acc: 92.2}\n","STEP:865, D{v_l: 0.384, v_acc: [84.4| 71.9| 78.1], c_acc: [90.6| 100.0]}  G{v_l: 1.434, v_acc: 50.0, c_acc: 93.8}\n","STEP:866, D{v_l: 0.596, v_acc: [87.5| 75.0| 81.2], c_acc: [96.9| 100.0]}  G{v_l: 1.170, v_acc: 35.9, c_acc: 93.8}\n","STEP:867, D{v_l: 0.324, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 93.8]}  G{v_l: 1.349, v_acc: 34.4, c_acc: 92.2}\n","STEP:868, D{v_l: 0.367, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.311, v_acc: 32.8, c_acc: 92.2}\n","STEP:869, D{v_l: 0.448, v_acc: [75.0| 81.2| 78.1], c_acc: [90.6| 84.4]}  G{v_l: 0.995, v_acc: 48.4, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.4059 - valid_loss: 0.6114 - class_loss: 3.3788 - valid_acc: 0.6706 - class_acc: 0.5059\n","3/3 [==============================] - 0s 45ms/step - loss: 0.8886 - valid_loss: 0.4037 - class_loss: 0.0692 - valid_acc: 0.9529 - class_acc: 1.0000\n","average v_acc: 81.176, three class acc: 50.588, two class acc: 57.647\n","====================================================================================================\n","STEP:870, D{v_l: 0.344, v_acc: [91.5| 90.6| 91.0], c_acc: [97.4| 96.9]}  G{v_l: 1.196, v_acc: 43.8, c_acc: 90.6}\n","STEP:871, D{v_l: 0.414, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 90.6]}  G{v_l: 1.081, v_acc: 42.2, c_acc: 84.4}\n","STEP:872, D{v_l: 0.295, v_acc: [81.2| 87.5| 84.4], c_acc: [93.8| 90.6]}  G{v_l: 1.062, v_acc: 45.3, c_acc: 89.1}\n","STEP:873, D{v_l: 0.364, v_acc: [87.5| 87.5| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 1.029, v_acc: 43.8, c_acc: 92.2}\n","STEP:874, D{v_l: 0.271, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 100.0]}  G{v_l: 1.185, v_acc: 39.1, c_acc: 95.3}\n","STEP:875, D{v_l: 0.353, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 93.8]}  G{v_l: 1.092, v_acc: 45.3, c_acc: 85.9}\n","STEP:876, D{v_l: 0.408, v_acc: [75.0| 84.4| 79.7], c_acc: [90.6| 93.8]}  G{v_l: 1.317, v_acc: 34.4, c_acc: 95.3}\n","STEP:877, D{v_l: 0.684, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 81.2]}  G{v_l: 0.866, v_acc: 54.7, c_acc: 84.4}\n","STEP:878, D{v_l: 0.289, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 1.045, v_acc: 45.3, c_acc: 68.8}\n","STEP:879, D{v_l: 0.243, v_acc: [96.9| 87.5| 92.2], c_acc: [96.9| 90.6]}  G{v_l: 1.008, v_acc: 56.2, c_acc: 96.9}\n","STEP:880, D{v_l: 0.413, v_acc: [87.5| 75.0| 81.2], c_acc: [90.6| 93.8]}  G{v_l: 1.261, v_acc: 48.4, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 4.4359 - valid_loss: 0.5991 - class_loss: 3.4212 - valid_acc: 0.6824 - class_acc: 0.5059\n","3/3 [==============================] - 0s 51ms/step - loss: 1.0396 - valid_loss: 0.5247 - class_loss: 0.0992 - valid_acc: 0.7176 - class_acc: 0.9765\n","average v_acc: 70.000, three class acc: 50.588, two class acc: 56.471\n","====================================================================================================\n","Epoch: 80\n","====================================================================================================\n","STEP:881, D{v_l: 0.330, v_acc: [76.1| 90.6| 83.3], c_acc: [96.6| 96.9]}  G{v_l: 0.909, v_acc: 53.1, c_acc: 90.6}\n","STEP:882, D{v_l: 0.344, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 93.8]}  G{v_l: 1.144, v_acc: 43.8, c_acc: 92.2}\n","STEP:883, D{v_l: 0.474, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 90.6]}  G{v_l: 1.014, v_acc: 51.6, c_acc: 95.3}\n","STEP:884, D{v_l: 0.306, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 0.912, v_acc: 62.5, c_acc: 93.8}\n","STEP:885, D{v_l: 0.336, v_acc: [78.1| 90.6| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 1.123, v_acc: 51.6, c_acc: 78.1}\n","STEP:886, D{v_l: 0.399, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 0.877, v_acc: 45.3, c_acc: 84.4}\n","STEP:887, D{v_l: 0.301, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 0.823, v_acc: 60.9, c_acc: 89.1}\n","STEP:888, D{v_l: 0.477, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 1.107, v_acc: 46.9, c_acc: 93.8}\n","STEP:889, D{v_l: 0.346, v_acc: [90.6| 78.1| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 1.088, v_acc: 46.9, c_acc: 93.8}\n","STEP:890, D{v_l: 0.326, v_acc: [84.4| 90.6| 87.5], c_acc: [87.5| 90.6]}  G{v_l: 1.308, v_acc: 39.1, c_acc: 95.3}\n","STEP:891, D{v_l: 0.370, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 0.965, v_acc: 53.1, c_acc: 87.5}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 5.0014 - valid_loss: 0.9415 - class_loss: 3.6444 - valid_acc: 0.5059 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 1.1274 - valid_loss: 0.5478 - class_loss: 0.1640 - valid_acc: 0.7059 - class_acc: 0.9529\n","average v_acc: 60.588, three class acc: 51.765, two class acc: 58.824\n","====================================================================================================\n","STEP:892, D{v_l: 0.523, v_acc: [76.1| 62.5| 69.3], c_acc: [94.9| 90.6]}  G{v_l: 0.958, v_acc: 50.0, c_acc: 95.3}\n","STEP:893, D{v_l: 0.304, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 87.5]}  G{v_l: 0.852, v_acc: 59.4, c_acc: 92.2}\n","STEP:894, D{v_l: 0.260, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 100.0]}  G{v_l: 1.006, v_acc: 59.4, c_acc: 92.2}\n","STEP:895, D{v_l: 0.504, v_acc: [90.6| 65.6| 78.1], c_acc: [90.6| 84.4]}  G{v_l: 1.064, v_acc: 51.6, c_acc: 84.4}\n","STEP:896, D{v_l: 0.350, v_acc: [87.5| 65.6| 76.6], c_acc: [93.8| 93.8]}  G{v_l: 1.032, v_acc: 48.4, c_acc: 75.0}\n","STEP:897, D{v_l: 0.480, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 100.0]}  G{v_l: 1.173, v_acc: 45.3, c_acc: 85.9}\n","STEP:898, D{v_l: 0.216, v_acc: [90.6| 93.8| 92.2], c_acc: [96.9| 90.6]}  G{v_l: 1.197, v_acc: 42.2, c_acc: 92.2}\n","STEP:899, D{v_l: 0.299, v_acc: [75.0| 93.8| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.094, v_acc: 40.6, c_acc: 82.8}\n","STEP:900, D{v_l: 0.419, v_acc: [90.6| 84.4| 87.5], c_acc: [87.5| 100.0]}  G{v_l: 0.939, v_acc: 48.4, c_acc: 89.1}\n","STEP:901, D{v_l: 0.275, v_acc: [90.6| 90.6| 90.6], c_acc: [100.0| 93.8]}  G{v_l: 1.041, v_acc: 48.4, c_acc: 95.3}\n","STEP:902, D{v_l: 0.365, v_acc: [75.0| 93.8| 84.4], c_acc: [93.8| 100.0]}  G{v_l: 1.106, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 4.6808 - valid_loss: 0.9205 - class_loss: 3.3448 - valid_acc: 0.5059 - class_acc: 0.4941\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9810 - valid_loss: 0.5298 - class_loss: 0.0357 - valid_acc: 0.6471 - class_acc: 1.0000\n","average v_acc: 57.647, three class acc: 49.412, two class acc: 57.647\n","====================================================================================================\n","STEP:903, D{v_l: 0.417, v_acc: [69.2| 81.2| 75.2], c_acc: [97.4| 100.0]}  G{v_l: 1.065, v_acc: 48.4, c_acc: 95.3}\n","STEP:904, D{v_l: 0.422, v_acc: [78.1| 78.1| 78.1], c_acc: [87.5| 87.5]}  G{v_l: 0.871, v_acc: 56.2, c_acc: 90.6}\n","STEP:905, D{v_l: 0.339, v_acc: [96.9| 75.0| 85.9], c_acc: [100.0| 93.8]}  G{v_l: 1.226, v_acc: 40.6, c_acc: 95.3}\n","STEP:906, D{v_l: 0.317, v_acc: [87.5| 93.8| 90.6], c_acc: [87.5| 100.0]}  G{v_l: 1.212, v_acc: 42.2, c_acc: 95.3}\n","STEP:907, D{v_l: 0.190, v_acc: [93.8| 93.8| 93.8], c_acc: [96.9| 93.8]}  G{v_l: 0.968, v_acc: 60.9, c_acc: 95.3}\n","STEP:908, D{v_l: 0.445, v_acc: [78.1| 75.0| 76.6], c_acc: [87.5| 93.8]}  G{v_l: 1.232, v_acc: 39.1, c_acc: 89.1}\n","STEP:909, D{v_l: 0.368, v_acc: [78.1| 81.2| 79.7], c_acc: [96.9| 90.6]}  G{v_l: 1.322, v_acc: 37.5, c_acc: 98.4}\n","STEP:910, D{v_l: 0.379, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 0.950, v_acc: 56.2, c_acc: 92.2}\n","STEP:911, D{v_l: 0.453, v_acc: [84.4| 75.0| 79.7], c_acc: [87.5| 96.9]}  G{v_l: 1.086, v_acc: 39.1, c_acc: 90.6}\n","STEP:912, D{v_l: 0.453, v_acc: [78.1| 78.1| 78.1], c_acc: [100.0| 96.9]}  G{v_l: 0.992, v_acc: 54.7, c_acc: 96.9}\n","STEP:913, D{v_l: 0.439, v_acc: [81.2| 78.1| 79.7], c_acc: [100.0| 96.9]}  G{v_l: 1.093, v_acc: 42.2, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 3.9235 - valid_loss: 0.6046 - class_loss: 2.9035 - valid_acc: 0.6353 - class_acc: 0.4353\n","3/3 [==============================] - 0s 57ms/step - loss: 1.0491 - valid_loss: 0.5169 - class_loss: 0.1168 - valid_acc: 0.7765 - class_acc: 0.9529\n","average v_acc: 70.588, three class acc: 43.529, two class acc: 55.294\n","====================================================================================================\n","STEP:914, D{v_l: 0.515, v_acc: [76.1| 81.2| 78.7], c_acc: [92.3| 96.9]}  G{v_l: 1.082, v_acc: 54.7, c_acc: 96.9}\n","STEP:915, D{v_l: 0.461, v_acc: [84.4| 90.6| 87.5], c_acc: [87.5| 96.9]}  G{v_l: 0.882, v_acc: 45.3, c_acc: 90.6}\n","STEP:916, D{v_l: 0.375, v_acc: [81.2| 71.9| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 0.985, v_acc: 42.2, c_acc: 89.1}\n","STEP:917, D{v_l: 0.309, v_acc: [81.2| 87.5| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 0.858, v_acc: 56.2, c_acc: 92.2}\n","STEP:918, D{v_l: 0.294, v_acc: [90.6| 87.5| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 1.137, v_acc: 40.6, c_acc: 87.5}\n","STEP:919, D{v_l: 0.483, v_acc: [84.4| 71.9| 78.1], c_acc: [96.9| 96.9]}  G{v_l: 1.047, v_acc: 50.0, c_acc: 95.3}\n","STEP:920, D{v_l: 0.458, v_acc: [71.9| 84.4| 78.1], c_acc: [100.0| 81.2]}  G{v_l: 0.974, v_acc: 54.7, c_acc: 90.6}\n","STEP:921, D{v_l: 0.315, v_acc: [90.6| 84.4| 87.5], c_acc: [93.8| 93.8]}  G{v_l: 1.065, v_acc: 56.2, c_acc: 95.3}\n","STEP:922, D{v_l: 0.422, v_acc: [84.4| 81.2| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 1.019, v_acc: 53.1, c_acc: 95.3}\n","STEP:923, D{v_l: 0.372, v_acc: [93.8| 87.5| 90.6], c_acc: [84.4| 96.9]}  G{v_l: 1.070, v_acc: 50.0, c_acc: 85.9}\n","STEP:924, D{v_l: 0.459, v_acc: [68.8| 90.6| 79.7], c_acc: [93.8| 100.0]}  G{v_l: 0.852, v_acc: 56.2, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 5.0466 - valid_loss: 0.7684 - class_loss: 3.8629 - valid_acc: 0.5647 - class_acc: 0.5412\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0162 - valid_loss: 0.4476 - class_loss: 0.1533 - valid_acc: 0.8118 - class_acc: 0.9176\n","average v_acc: 68.824, three class acc: 54.118, two class acc: 60.000\n","====================================================================================================\n","STEP:925, D{v_l: 0.357, v_acc: [82.1| 84.4| 83.2], c_acc: [93.2| 100.0]}  G{v_l: 1.124, v_acc: 39.1, c_acc: 87.5}\n","STEP:926, D{v_l: 0.328, v_acc: [90.6| 75.0| 82.8], c_acc: [100.0| 93.8]}  G{v_l: 0.990, v_acc: 64.1, c_acc: 93.8}\n","STEP:927, D{v_l: 0.244, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 1.229, v_acc: 39.1, c_acc: 96.9}\n","STEP:928, D{v_l: 0.268, v_acc: [87.5| 90.6| 89.1], c_acc: [93.8| 96.9]}  G{v_l: 1.026, v_acc: 48.4, c_acc: 90.6}\n","STEP:929, D{v_l: 0.274, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.129, v_acc: 45.3, c_acc: 92.2}\n","STEP:930, D{v_l: 0.406, v_acc: [84.4| 81.2| 82.8], c_acc: [87.5| 96.9]}  G{v_l: 1.191, v_acc: 43.8, c_acc: 96.9}\n","STEP:931, D{v_l: 0.447, v_acc: [93.8| 78.1| 85.9], c_acc: [96.9| 90.6]}  G{v_l: 1.107, v_acc: 43.8, c_acc: 92.2}\n","STEP:932, D{v_l: 0.281, v_acc: [90.6| 90.6| 90.6], c_acc: [87.5| 96.9]}  G{v_l: 1.328, v_acc: 34.4, c_acc: 96.9}\n","STEP:933, D{v_l: 0.291, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 90.6]}  G{v_l: 1.080, v_acc: 37.5, c_acc: 96.9}\n","STEP:934, D{v_l: 0.335, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 87.5]}  G{v_l: 1.169, v_acc: 40.6, c_acc: 95.3}\n","STEP:935, D{v_l: 0.290, v_acc: [87.5| 87.5| 87.5], c_acc: [87.5| 93.8]}  G{v_l: 1.109, v_acc: 45.3, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 4.5058 - valid_loss: 0.7607 - class_loss: 3.3298 - valid_acc: 0.5529 - class_acc: 0.5294\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0125 - valid_loss: 0.5160 - class_loss: 0.0813 - valid_acc: 0.7412 - class_acc: 0.9765\n","average v_acc: 64.706, three class acc: 52.941, two class acc: 60.000\n","====================================================================================================\n","STEP:936, D{v_l: 0.359, v_acc: [76.1| 96.9| 86.5], c_acc: [96.6| 100.0]}  G{v_l: 0.934, v_acc: 46.9, c_acc: 79.7}\n","STEP:937, D{v_l: 0.413, v_acc: [68.8| 93.8| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 1.117, v_acc: 43.8, c_acc: 92.2}\n","STEP:938, D{v_l: 0.489, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 1.092, v_acc: 45.3, c_acc: 90.6}\n","STEP:939, D{v_l: 0.249, v_acc: [90.6| 90.6| 90.6], c_acc: [100.0| 93.8]}  G{v_l: 1.127, v_acc: 40.6, c_acc: 93.8}\n","STEP:940, D{v_l: 0.347, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 87.5]}  G{v_l: 1.304, v_acc: 42.2, c_acc: 85.9}\n","STEP:941, D{v_l: 0.321, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 96.9]}  G{v_l: 0.903, v_acc: 56.2, c_acc: 92.2}\n","STEP:942, D{v_l: 0.438, v_acc: [96.9| 71.9| 84.4], c_acc: [84.4| 93.8]}  G{v_l: 1.022, v_acc: 51.6, c_acc: 87.5}\n","STEP:943, D{v_l: 0.276, v_acc: [93.8| 90.6| 92.2], c_acc: [100.0| 93.8]}  G{v_l: 1.190, v_acc: 46.9, c_acc: 96.9}\n","STEP:944, D{v_l: 0.236, v_acc: [90.6| 90.6| 90.6], c_acc: [87.5| 93.8]}  G{v_l: 1.097, v_acc: 46.9, c_acc: 84.4}\n","STEP:945, D{v_l: 0.397, v_acc: [87.5| 78.1| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 1.409, v_acc: 40.6, c_acc: 95.3}\n","STEP:946, D{v_l: 0.282, v_acc: [90.6| 90.6| 90.6], c_acc: [84.4| 84.4]}  G{v_l: 1.078, v_acc: 42.2, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 4.2973 - valid_loss: 0.8364 - class_loss: 3.0458 - valid_acc: 0.5765 - class_acc: 0.4941\n","3/3 [==============================] - 0s 45ms/step - loss: 0.9390 - valid_loss: 0.4295 - class_loss: 0.0944 - valid_acc: 0.8118 - class_acc: 0.9882\n","average v_acc: 69.412, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","STEP:947, D{v_l: 0.334, v_acc: [85.5| 84.4| 84.9], c_acc: [96.6| 93.8]}  G{v_l: 1.265, v_acc: 42.2, c_acc: 93.8}\n","STEP:948, D{v_l: 0.327, v_acc: [93.8| 75.0| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 1.202, v_acc: 43.8, c_acc: 90.6}\n","STEP:949, D{v_l: 0.404, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 1.031, v_acc: 48.4, c_acc: 85.9}\n","STEP:950, D{v_l: 0.286, v_acc: [87.5| 75.0| 81.2], c_acc: [90.6| 93.8]}  G{v_l: 1.345, v_acc: 31.2, c_acc: 82.8}\n","STEP:951, D{v_l: 0.255, v_acc: [87.5| 90.6| 89.1], c_acc: [100.0| 100.0]}  G{v_l: 1.657, v_acc: 34.4, c_acc: 82.8}\n","STEP:952, D{v_l: 0.262, v_acc: [87.5| 81.2| 84.4], c_acc: [93.8| 96.9]}  G{v_l: 1.414, v_acc: 40.6, c_acc: 85.9}\n","STEP:953, D{v_l: 0.317, v_acc: [93.8| 75.0| 84.4], c_acc: [100.0| 87.5]}  G{v_l: 1.378, v_acc: 43.8, c_acc: 90.6}\n","STEP:954, D{v_l: 0.413, v_acc: [84.4| 84.4| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 1.386, v_acc: 35.9, c_acc: 70.3}\n","STEP:955, D{v_l: 0.610, v_acc: [62.5| 87.5| 75.0], c_acc: [96.9| 93.8]}  G{v_l: 0.953, v_acc: 60.9, c_acc: 76.6}\n","STEP:956, D{v_l: 0.395, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 1.414, v_acc: 37.5, c_acc: 85.9}\n","STEP:957, D{v_l: 0.371, v_acc: [84.4| 81.2| 82.8], c_acc: [93.8| 96.9]}  G{v_l: 1.247, v_acc: 42.2, c_acc: 84.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 55ms/step - loss: 5.5326 - valid_loss: 1.0648 - class_loss: 4.0527 - valid_acc: 0.4706 - class_acc: 0.5294\n","3/3 [==============================] - 0s 45ms/step - loss: 1.1672 - valid_loss: 0.4925 - class_loss: 0.2596 - valid_acc: 0.7529 - class_acc: 0.8941\n","average v_acc: 61.176, three class acc: 52.941, two class acc: 56.471\n","====================================================================================================\n","STEP:958, D{v_l: 0.500, v_acc: [78.6| 81.2| 79.9], c_acc: [91.5| 87.5]}  G{v_l: 1.356, v_acc: 40.6, c_acc: 93.8}\n","STEP:959, D{v_l: 0.472, v_acc: [87.5| 71.9| 79.7], c_acc: [96.9| 96.9]}  G{v_l: 1.157, v_acc: 42.2, c_acc: 96.9}\n","STEP:960, D{v_l: 0.326, v_acc: [87.5| 78.1| 82.8], c_acc: [78.1| 90.6]}  G{v_l: 1.474, v_acc: 34.4, c_acc: 81.2}\n","STEP:961, D{v_l: 0.268, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.116, v_acc: 42.2, c_acc: 78.1}\n","STEP:962, D{v_l: 0.348, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 100.0]}  G{v_l: 1.225, v_acc: 39.1, c_acc: 90.6}\n","STEP:963, D{v_l: 0.344, v_acc: [78.1| 93.8| 85.9], c_acc: [93.8| 90.6]}  G{v_l: 1.148, v_acc: 37.5, c_acc: 93.8}\n","STEP:964, D{v_l: 0.440, v_acc: [84.4| 84.4| 84.4], c_acc: [93.8| 84.4]}  G{v_l: 1.137, v_acc: 37.5, c_acc: 98.4}\n","STEP:965, D{v_l: 0.263, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 90.6]}  G{v_l: 1.254, v_acc: 39.1, c_acc: 92.2}\n","STEP:966, D{v_l: 0.442, v_acc: [78.1| 84.4| 81.2], c_acc: [87.5| 96.9]}  G{v_l: 1.182, v_acc: 35.9, c_acc: 93.8}\n","STEP:967, D{v_l: 0.339, v_acc: [87.5| 84.4| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 0.961, v_acc: 46.9, c_acc: 98.4}\n","STEP:968, D{v_l: 0.493, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.067, v_acc: 37.5, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 53ms/step - loss: 4.3271 - valid_loss: 0.5443 - class_loss: 3.3678 - valid_acc: 0.6941 - class_acc: 0.4941\n","3/3 [==============================] - 0s 48ms/step - loss: 0.9307 - valid_loss: 0.4429 - class_loss: 0.0727 - valid_acc: 0.8941 - class_acc: 0.9882\n","average v_acc: 79.412, three class acc: 49.412, two class acc: 56.471\n","====================================================================================================\n","STEP:969, D{v_l: 0.301, v_acc: [90.6| 90.6| 90.6], c_acc: [95.7| 96.9]}  G{v_l: 1.147, v_acc: 43.8, c_acc: 92.2}\n","STEP:970, D{v_l: 0.662, v_acc: [81.2| 87.5| 84.4], c_acc: [81.2| 96.9]}  G{v_l: 1.226, v_acc: 39.1, c_acc: 96.9}\n","STEP:971, D{v_l: 0.343, v_acc: [87.5| 81.2| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 1.213, v_acc: 28.1, c_acc: 93.8}\n","STEP:972, D{v_l: 0.348, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 96.9]}  G{v_l: 0.906, v_acc: 40.6, c_acc: 90.6}\n","STEP:973, D{v_l: 0.286, v_acc: [81.2| 90.6| 85.9], c_acc: [96.9| 87.5]}  G{v_l: 1.004, v_acc: 45.3, c_acc: 90.6}\n","STEP:974, D{v_l: 0.290, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 93.8]}  G{v_l: 1.056, v_acc: 42.2, c_acc: 93.8}\n","STEP:975, D{v_l: 0.298, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 1.189, v_acc: 40.6, c_acc: 87.5}\n","STEP:976, D{v_l: 0.307, v_acc: [84.4| 90.6| 87.5], c_acc: [100.0| 93.8]}  G{v_l: 1.016, v_acc: 46.9, c_acc: 98.4}\n","STEP:977, D{v_l: 0.356, v_acc: [87.5| 81.2| 84.4], c_acc: [81.2| 93.8]}  G{v_l: 0.945, v_acc: 48.4, c_acc: 89.1}\n","STEP:978, D{v_l: 0.568, v_acc: [81.2| 68.8| 75.0], c_acc: [100.0| 93.8]}  G{v_l: 0.928, v_acc: 50.0, c_acc: 95.3}\n","STEP:979, D{v_l: 0.389, v_acc: [84.4| 78.1| 81.2], c_acc: [96.9| 78.1]}  G{v_l: 1.113, v_acc: 43.8, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 4.8413 - valid_loss: 0.6556 - class_loss: 3.7707 - valid_acc: 0.6471 - class_acc: 0.5176\n","3/3 [==============================] - 0s 47ms/step - loss: 1.0762 - valid_loss: 0.5013 - class_loss: 0.1599 - valid_acc: 0.7882 - class_acc: 0.9412\n","average v_acc: 71.765, three class acc: 51.765, two class acc: 57.647\n","====================================================================================================\n","STEP:980, D{v_l: 0.386, v_acc: [81.2| 90.6| 85.9], c_acc: [94.9| 96.9]}  G{v_l: 0.999, v_acc: 51.6, c_acc: 93.8}\n","STEP:981, D{v_l: 0.391, v_acc: [75.0| 87.5| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.078, v_acc: 34.4, c_acc: 92.2}\n","STEP:982, D{v_l: 0.200, v_acc: [96.9| 93.8| 95.3], c_acc: [100.0| 93.8]}  G{v_l: 1.346, v_acc: 43.8, c_acc: 98.4}\n","STEP:983, D{v_l: 0.444, v_acc: [78.1| 87.5| 82.8], c_acc: [93.8| 100.0]}  G{v_l: 0.894, v_acc: 46.9, c_acc: 85.9}\n","STEP:984, D{v_l: 0.311, v_acc: [81.2| 81.2| 81.2], c_acc: [96.9| 93.8]}  G{v_l: 1.056, v_acc: 46.9, c_acc: 95.3}\n","STEP:985, D{v_l: 0.374, v_acc: [81.2| 90.6| 85.9], c_acc: [100.0| 93.8]}  G{v_l: 0.900, v_acc: 50.0, c_acc: 95.3}\n","STEP:986, D{v_l: 0.489, v_acc: [71.9| 78.1| 75.0], c_acc: [96.9| 93.8]}  G{v_l: 0.775, v_acc: 54.7, c_acc: 95.3}\n","STEP:987, D{v_l: 0.411, v_acc: [84.4| 90.6| 87.5], c_acc: [93.8| 84.4]}  G{v_l: 1.005, v_acc: 48.4, c_acc: 92.2}\n","STEP:988, D{v_l: 0.330, v_acc: [90.6| 71.9| 81.2], c_acc: [90.6| 96.9]}  G{v_l: 0.725, v_acc: 56.2, c_acc: 89.1}\n","STEP:989, D{v_l: 0.282, v_acc: [78.1| 90.6| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 1.022, v_acc: 45.3, c_acc: 95.3}\n","STEP:990, D{v_l: 0.405, v_acc: [81.2| 75.0| 78.1], c_acc: [93.8| 90.6]}  G{v_l: 1.042, v_acc: 48.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 5.4433 - valid_loss: 0.4666 - class_loss: 4.5617 - valid_acc: 0.7529 - class_acc: 0.5529\n","3/3 [==============================] - 0s 45ms/step - loss: 1.0160 - valid_loss: 0.5531 - class_loss: 0.0479 - valid_acc: 0.6824 - class_acc: 0.9882\n","average v_acc: 71.765, three class acc: 55.294, two class acc: 57.647\n","====================================================================================================\n","Epoch: 90\n","====================================================================================================\n","STEP:991, D{v_l: 0.457, v_acc: [70.9| 90.6| 80.8], c_acc: [99.1| 84.4]}  G{v_l: 1.091, v_acc: 37.5, c_acc: 90.6}\n","STEP:992, D{v_l: 0.283, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 100.0]}  G{v_l: 1.183, v_acc: 42.2, c_acc: 95.3}\n","STEP:993, D{v_l: 0.345, v_acc: [90.6| 81.2| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 1.129, v_acc: 46.9, c_acc: 96.9}\n","STEP:994, D{v_l: 0.281, v_acc: [90.6| 81.2| 85.9], c_acc: [87.5| 96.9]}  G{v_l: 1.023, v_acc: 50.0, c_acc: 96.9}\n","STEP:995, D{v_l: 0.334, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 1.029, v_acc: 48.4, c_acc: 93.8}\n","STEP:996, D{v_l: 0.218, v_acc: [96.9| 93.8| 95.3], c_acc: [90.6| 84.4]}  G{v_l: 1.138, v_acc: 40.6, c_acc: 95.3}\n","STEP:997, D{v_l: 0.334, v_acc: [93.8| 81.2| 87.5], c_acc: [87.5| 93.8]}  G{v_l: 1.097, v_acc: 34.4, c_acc: 82.8}\n","STEP:998, D{v_l: 0.274, v_acc: [93.8| 81.2| 87.5], c_acc: [96.9| 90.6]}  G{v_l: 1.117, v_acc: 39.1, c_acc: 87.5}\n","STEP:999, D{v_l: 0.344, v_acc: [90.6| 78.1| 84.4], c_acc: [84.4| 90.6]}  G{v_l: 0.898, v_acc: 53.1, c_acc: 92.2}\n","STEP:1000, D{v_l: 0.386, v_acc: [78.1| 90.6| 84.4], c_acc: [93.8| 93.8]}  G{v_l: 1.156, v_acc: 39.1, c_acc: 93.8}\n","STEP:1001, D{v_l: 0.309, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 1.219, v_acc: 31.2, c_acc: 98.4}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 50ms/step - loss: 5.6894 - valid_loss: 0.9777 - class_loss: 4.2969 - valid_acc: 0.5412 - class_acc: 0.5529\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0234 - valid_loss: 0.4890 - class_loss: 0.1195 - valid_acc: 0.7529 - class_acc: 0.9765\n","average v_acc: 64.706, three class acc: 55.294, two class acc: 58.824\n","====================================================================================================\n","STEP:1002, D{v_l: 0.464, v_acc: [78.6| 78.1| 78.4], c_acc: [97.4| 93.8]}  G{v_l: 1.172, v_acc: 42.2, c_acc: 96.9}\n","STEP:1003, D{v_l: 0.313, v_acc: [87.5| 81.2| 84.4], c_acc: [84.4| 90.6]}  G{v_l: 1.475, v_acc: 43.8, c_acc: 89.1}\n","STEP:1004, D{v_l: 0.325, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 87.5]}  G{v_l: 1.175, v_acc: 39.1, c_acc: 79.7}\n","STEP:1005, D{v_l: 0.341, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 87.5]}  G{v_l: 1.414, v_acc: 39.1, c_acc: 95.3}\n","STEP:1006, D{v_l: 0.388, v_acc: [87.5| 75.0| 81.2], c_acc: [87.5| 84.4]}  G{v_l: 1.102, v_acc: 45.3, c_acc: 90.6}\n","STEP:1007, D{v_l: 0.210, v_acc: [93.8| 93.8| 93.8], c_acc: [90.6| 96.9]}  G{v_l: 1.227, v_acc: 42.2, c_acc: 98.4}\n","STEP:1008, D{v_l: 0.225, v_acc: [90.6| 93.8| 92.2], c_acc: [90.6| 100.0]}  G{v_l: 0.989, v_acc: 45.3, c_acc: 90.6}\n","STEP:1009, D{v_l: 0.291, v_acc: [75.0| 96.9| 85.9], c_acc: [90.6| 93.8]}  G{v_l: 0.910, v_acc: 46.9, c_acc: 82.8}\n","STEP:1010, D{v_l: 0.311, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 93.8]}  G{v_l: 0.958, v_acc: 48.4, c_acc: 90.6}\n","STEP:1011, D{v_l: 0.277, v_acc: [87.5| 90.6| 89.1], c_acc: [87.5| 90.6]}  G{v_l: 1.201, v_acc: 40.6, c_acc: 87.5}\n","STEP:1012, D{v_l: 0.318, v_acc: [90.6| 90.6| 90.6], c_acc: [96.9| 96.9]}  G{v_l: 0.938, v_acc: 56.2, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 48ms/step - loss: 3.8874 - valid_loss: 0.5265 - class_loss: 2.9461 - valid_acc: 0.7176 - class_acc: 0.3529\n","3/3 [==============================] - 0s 48ms/step - loss: 1.1135 - valid_loss: 0.5928 - class_loss: 0.1058 - valid_acc: 0.6000 - class_acc: 0.9765\n","average v_acc: 65.882, three class acc: 35.294, two class acc: 54.118\n","====================================================================================================\n","STEP:1013, D{v_l: 0.361, v_acc: [70.1| 93.8| 81.9], c_acc: [96.6| 93.8]}  G{v_l: 1.021, v_acc: 51.6, c_acc: 93.8}\n","STEP:1014, D{v_l: 0.461, v_acc: [71.9| 81.2| 76.6], c_acc: [96.9| 96.9]}  G{v_l: 1.174, v_acc: 42.2, c_acc: 89.1}\n","STEP:1015, D{v_l: 0.284, v_acc: [90.6| 81.2| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.095, v_acc: 50.0, c_acc: 87.5}\n","STEP:1016, D{v_l: 0.308, v_acc: [93.8| 87.5| 90.6], c_acc: [90.6| 90.6]}  G{v_l: 1.605, v_acc: 37.5, c_acc: 85.9}\n","STEP:1017, D{v_l: 0.336, v_acc: [78.1| 84.4| 81.2], c_acc: [96.9| 81.2]}  G{v_l: 0.957, v_acc: 42.2, c_acc: 79.7}\n","STEP:1018, D{v_l: 0.257, v_acc: [93.8| 90.6| 92.2], c_acc: [90.6| 90.6]}  G{v_l: 1.030, v_acc: 59.4, c_acc: 87.5}\n","STEP:1019, D{v_l: 0.246, v_acc: [93.8| 87.5| 90.6], c_acc: [93.8| 96.9]}  G{v_l: 1.078, v_acc: 54.7, c_acc: 90.6}\n","STEP:1020, D{v_l: 0.416, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 100.0]}  G{v_l: 1.126, v_acc: 51.6, c_acc: 90.6}\n","STEP:1021, D{v_l: 0.494, v_acc: [84.4| 71.9| 78.1], c_acc: [90.6| 90.6]}  G{v_l: 1.140, v_acc: 51.6, c_acc: 92.2}\n","STEP:1022, D{v_l: 0.317, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 96.9]}  G{v_l: 1.140, v_acc: 45.3, c_acc: 95.3}\n","STEP:1023, D{v_l: 0.651, v_acc: [78.1| 56.2| 67.2], c_acc: [100.0| 90.6]}  G{v_l: 1.318, v_acc: 35.9, c_acc: 92.2}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.2413 - valid_loss: 0.7318 - class_loss: 3.0948 - valid_acc: 0.6471 - class_acc: 0.4824\n","3/3 [==============================] - 0s 49ms/step - loss: 1.0557 - valid_loss: 0.5244 - class_loss: 0.1166 - valid_acc: 0.6588 - class_acc: 0.9647\n","average v_acc: 65.294, three class acc: 48.235, two class acc: 55.294\n","====================================================================================================\n","STEP:1024, D{v_l: 0.339, v_acc: [71.8| 90.6| 81.2], c_acc: [94.0| 96.9]}  G{v_l: 1.024, v_acc: 46.9, c_acc: 87.5}\n","STEP:1025, D{v_l: 0.384, v_acc: [84.4| 81.2| 82.8], c_acc: [90.6| 90.6]}  G{v_l: 1.022, v_acc: 50.0, c_acc: 92.2}\n","STEP:1026, D{v_l: 0.279, v_acc: [84.4| 90.6| 87.5], c_acc: [90.6| 100.0]}  G{v_l: 1.138, v_acc: 50.0, c_acc: 96.9}\n","STEP:1027, D{v_l: 0.332, v_acc: [84.4| 90.6| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 1.009, v_acc: 53.1, c_acc: 92.2}\n","STEP:1028, D{v_l: 0.345, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 0.976, v_acc: 51.6, c_acc: 93.8}\n","STEP:1029, D{v_l: 0.347, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 100.0]}  G{v_l: 1.023, v_acc: 42.2, c_acc: 82.8}\n","STEP:1030, D{v_l: 0.191, v_acc: [90.6| 96.9| 93.8], c_acc: [96.9| 93.8]}  G{v_l: 1.018, v_acc: 39.1, c_acc: 92.2}\n","STEP:1031, D{v_l: 0.239, v_acc: [96.9| 81.2| 89.1], c_acc: [100.0| 93.8]}  G{v_l: 0.919, v_acc: 50.0, c_acc: 90.6}\n","STEP:1032, D{v_l: 0.373, v_acc: [84.4| 93.8| 89.1], c_acc: [100.0| 84.4]}  G{v_l: 1.062, v_acc: 43.8, c_acc: 96.9}\n","STEP:1033, D{v_l: 0.417, v_acc: [78.1| 81.2| 79.7], c_acc: [90.6| 96.9]}  G{v_l: 1.028, v_acc: 59.4, c_acc: 95.3}\n","STEP:1034, D{v_l: 0.185, v_acc: [96.9| 87.5| 92.2], c_acc: [90.6| 96.9]}  G{v_l: 0.879, v_acc: 59.4, c_acc: 95.3}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 51ms/step - loss: 4.7942 - valid_loss: 1.0600 - class_loss: 3.3195 - valid_acc: 0.5059 - class_acc: 0.4941\n","3/3 [==============================] - 0s 47ms/step - loss: 1.2390 - valid_loss: 0.7341 - class_loss: 0.0902 - valid_acc: 0.4353 - class_acc: 0.9765\n","average v_acc: 47.059, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","STEP:1035, D{v_l: 0.465, v_acc: [55.6| 78.1| 66.8], c_acc: [94.9| 96.9]}  G{v_l: 0.942, v_acc: 59.4, c_acc: 92.2}\n","STEP:1036, D{v_l: 0.229, v_acc: [90.6| 93.8| 92.2], c_acc: [100.0| 96.9]}  G{v_l: 0.988, v_acc: 51.6, c_acc: 96.9}\n","STEP:1037, D{v_l: 0.173, v_acc: [96.9| 93.8| 95.3], c_acc: [87.5| 100.0]}  G{v_l: 1.028, v_acc: 56.2, c_acc: 95.3}\n","STEP:1038, D{v_l: 0.415, v_acc: [87.5| 87.5| 87.5], c_acc: [96.9| 93.8]}  G{v_l: 0.839, v_acc: 56.2, c_acc: 87.5}\n","STEP:1039, D{v_l: 0.363, v_acc: [90.6| 78.1| 84.4], c_acc: [100.0| 96.9]}  G{v_l: 0.819, v_acc: 56.2, c_acc: 81.2}\n","STEP:1040, D{v_l: 0.253, v_acc: [93.8| 90.6| 92.2], c_acc: [93.8| 96.9]}  G{v_l: 0.810, v_acc: 64.1, c_acc: 98.4}\n","STEP:1041, D{v_l: 0.213, v_acc: [96.9| 93.8| 95.3], c_acc: [90.6| 100.0]}  G{v_l: 0.973, v_acc: 60.9, c_acc: 98.4}\n","STEP:1042, D{v_l: 0.394, v_acc: [84.4| 78.1| 81.2], c_acc: [93.8| 93.8]}  G{v_l: 1.000, v_acc: 48.4, c_acc: 90.6}\n","STEP:1043, D{v_l: 0.389, v_acc: [81.2| 81.2| 81.2], c_acc: [93.8| 96.9]}  G{v_l: 0.898, v_acc: 57.8, c_acc: 87.5}\n","STEP:1044, D{v_l: 0.205, v_acc: [93.8| 96.9| 95.3], c_acc: [96.9| 100.0]}  G{v_l: 0.979, v_acc: 56.2, c_acc: 95.3}\n","STEP:1045, D{v_l: 0.379, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 90.6]}  G{v_l: 1.004, v_acc: 50.0, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 43ms/step - loss: 4.2415 - valid_loss: 0.9121 - class_loss: 2.9149 - valid_acc: 0.5882 - class_acc: 0.5176\n","3/3 [==============================] - 0s 49ms/step - loss: 1.2245 - valid_loss: 0.7439 - class_loss: 0.0660 - valid_acc: 0.4706 - class_acc: 0.9765\n","average v_acc: 52.941, three class acc: 51.765, two class acc: 60.000\n","====================================================================================================\n","STEP:1046, D{v_l: 0.498, v_acc: [56.4| 81.2| 68.8], c_acc: [96.6| 96.9]}  G{v_l: 0.994, v_acc: 45.3, c_acc: 92.2}\n","STEP:1047, D{v_l: 0.264, v_acc: [93.8| 81.2| 87.5], c_acc: [90.6| 96.9]}  G{v_l: 1.077, v_acc: 45.3, c_acc: 95.3}\n","STEP:1048, D{v_l: 0.445, v_acc: [81.2| 78.1| 79.7], c_acc: [93.8| 96.9]}  G{v_l: 0.954, v_acc: 46.9, c_acc: 85.9}\n","STEP:1049, D{v_l: 0.394, v_acc: [87.5| 81.2| 84.4], c_acc: [100.0| 93.8]}  G{v_l: 0.757, v_acc: 59.4, c_acc: 95.3}\n","STEP:1050, D{v_l: 0.332, v_acc: [87.5| 87.5| 87.5], c_acc: [100.0| 93.8]}  G{v_l: 0.918, v_acc: 56.2, c_acc: 85.9}\n","STEP:1051, D{v_l: 0.304, v_acc: [84.4| 90.6| 87.5], c_acc: [93.8| 100.0]}  G{v_l: 0.823, v_acc: 59.4, c_acc: 85.9}\n","STEP:1052, D{v_l: 0.327, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 100.0]}  G{v_l: 0.872, v_acc: 57.8, c_acc: 96.9}\n","STEP:1053, D{v_l: 0.238, v_acc: [93.8| 87.5| 90.6], c_acc: [96.9| 93.8]}  G{v_l: 0.841, v_acc: 53.1, c_acc: 90.6}\n","STEP:1054, D{v_l: 0.486, v_acc: [75.0| 81.2| 78.1], c_acc: [93.8| 90.6]}  G{v_l: 0.925, v_acc: 57.8, c_acc: 85.9}\n","STEP:1055, D{v_l: 0.344, v_acc: [87.5| 90.6| 89.1], c_acc: [87.5| 96.9]}  G{v_l: 0.760, v_acc: 59.4, c_acc: 93.8}\n","STEP:1056, D{v_l: 0.401, v_acc: [78.1| 87.5| 82.8], c_acc: [96.9| 100.0]}  G{v_l: 1.150, v_acc: 51.6, c_acc: 93.8}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 47ms/step - loss: 4.9995 - valid_loss: 1.0449 - class_loss: 3.5402 - valid_acc: 0.5059 - class_acc: 0.5059\n","3/3 [==============================] - 0s 53ms/step - loss: 1.2190 - valid_loss: 0.7225 - class_loss: 0.0820 - valid_acc: 0.4588 - class_acc: 0.9882\n","average v_acc: 48.235, three class acc: 50.588, two class acc: 57.647\n","====================================================================================================\n","STEP:1057, D{v_l: 0.372, v_acc: [59.8| 93.8| 76.8], c_acc: [97.4| 90.6]}  G{v_l: 1.103, v_acc: 51.6, c_acc: 93.8}\n","STEP:1058, D{v_l: 0.288, v_acc: [90.6| 84.4| 87.5], c_acc: [96.9| 96.9]}  G{v_l: 0.886, v_acc: 54.7, c_acc: 96.9}\n","STEP:1059, D{v_l: 0.375, v_acc: [87.5| 75.0| 81.2], c_acc: [93.8| 90.6]}  G{v_l: 1.042, v_acc: 45.3, c_acc: 95.3}\n","STEP:1060, D{v_l: 0.245, v_acc: [81.2| 90.6| 85.9], c_acc: [93.8| 100.0]}  G{v_l: 1.021, v_acc: 45.3, c_acc: 92.2}\n","STEP:1061, D{v_l: 0.639, v_acc: [87.5| 84.4| 85.9], c_acc: [100.0| 96.9]}  G{v_l: 0.889, v_acc: 48.4, c_acc: 89.1}\n","STEP:1062, D{v_l: 0.419, v_acc: [81.2| 84.4| 82.8], c_acc: [90.6| 96.9]}  G{v_l: 1.037, v_acc: 43.8, c_acc: 87.5}\n","STEP:1063, D{v_l: 0.359, v_acc: [81.2| 87.5| 84.4], c_acc: [96.9| 93.8]}  G{v_l: 0.887, v_acc: 56.2, c_acc: 89.1}\n","STEP:1064, D{v_l: 0.246, v_acc: [93.8| 84.4| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 1.024, v_acc: 53.1, c_acc: 95.3}\n","STEP:1065, D{v_l: 0.305, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 0.924, v_acc: 45.3, c_acc: 90.6}\n","STEP:1066, D{v_l: 0.273, v_acc: [93.8| 87.5| 90.6], c_acc: [93.8| 93.8]}  G{v_l: 1.297, v_acc: 42.2, c_acc: 89.1}\n","STEP:1067, D{v_l: 0.212, v_acc: [90.6| 90.6| 90.6], c_acc: [84.4| 93.8]}  G{v_l: 1.075, v_acc: 54.7, c_acc: 89.1}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 52ms/step - loss: 4.9376 - valid_loss: 1.1028 - class_loss: 3.4204 - valid_acc: 0.5176 - class_acc: 0.5059\n","3/3 [==============================] - 0s 54ms/step - loss: 1.1215 - valid_loss: 0.6478 - class_loss: 0.0593 - valid_acc: 0.5294 - class_acc: 0.9765\n","average v_acc: 52.353, three class acc: 50.588, two class acc: 56.471\n","====================================================================================================\n","STEP:1068, D{v_l: 0.438, v_acc: [60.7| 81.2| 71.0], c_acc: [97.4| 100.0]}  G{v_l: 0.882, v_acc: 53.1, c_acc: 92.2}\n","STEP:1069, D{v_l: 0.225, v_acc: [87.5| 100.0| 93.8], c_acc: [96.9| 100.0]}  G{v_l: 1.102, v_acc: 50.0, c_acc: 90.6}\n","STEP:1070, D{v_l: 0.410, v_acc: [87.5| 81.2| 84.4], c_acc: [96.9| 87.5]}  G{v_l: 0.901, v_acc: 54.7, c_acc: 81.2}\n","STEP:1071, D{v_l: 0.352, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 93.8]}  G{v_l: 0.982, v_acc: 51.6, c_acc: 75.0}\n","STEP:1072, D{v_l: 0.350, v_acc: [84.4| 87.5| 85.9], c_acc: [90.6| 96.9]}  G{v_l: 0.898, v_acc: 46.9, c_acc: 82.8}\n","STEP:1073, D{v_l: 0.312, v_acc: [84.4| 87.5| 85.9], c_acc: [93.8| 96.9]}  G{v_l: 0.933, v_acc: 51.6, c_acc: 92.2}\n","STEP:1074, D{v_l: 0.401, v_acc: [81.2| 84.4| 82.8], c_acc: [96.9| 90.6]}  G{v_l: 1.083, v_acc: 51.6, c_acc: 93.8}\n","STEP:1075, D{v_l: 0.439, v_acc: [81.2| 87.5| 84.4], c_acc: [87.5| 100.0]}  G{v_l: 1.045, v_acc: 53.1, c_acc: 96.9}\n","STEP:1076, D{v_l: 0.337, v_acc: [87.5| 87.5| 87.5], c_acc: [93.8| 96.9]}  G{v_l: 0.847, v_acc: 59.4, c_acc: 93.8}\n","STEP:1077, D{v_l: 0.364, v_acc: [90.6| 81.2| 85.9], c_acc: [93.8| 87.5]}  G{v_l: 1.269, v_acc: 42.2, c_acc: 87.5}\n","STEP:1078, D{v_l: 0.237, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 93.8]}  G{v_l: 1.169, v_acc: 45.3, c_acc: 90.6}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 46ms/step - loss: 3.2729 - valid_loss: 0.3540 - class_loss: 2.5046 - valid_acc: 0.8353 - class_acc: 0.4353\n","3/3 [==============================] - 0s 51ms/step - loss: 1.2032 - valid_loss: 0.6542 - class_loss: 0.1347 - valid_acc: 0.4824 - class_acc: 0.9529\n","average v_acc: 65.882, three class acc: 43.529, two class acc: 56.471\n","====================================================================================================\n","STEP:1079, D{v_l: 0.616, v_acc: [59.0| 78.1| 68.5], c_acc: [95.7| 90.6]}  G{v_l: 1.075, v_acc: 54.7, c_acc: 96.9}\n","STEP:1080, D{v_l: 0.352, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 96.9]}  G{v_l: 1.037, v_acc: 53.1, c_acc: 96.9}\n","STEP:1081, D{v_l: 0.236, v_acc: [84.4| 87.5| 85.9], c_acc: [96.9| 93.8]}  G{v_l: 1.409, v_acc: 45.3, c_acc: 90.6}\n","STEP:1082, D{v_l: 0.229, v_acc: [90.6| 90.6| 90.6], c_acc: [100.0| 90.6]}  G{v_l: 1.282, v_acc: 39.1, c_acc: 95.3}\n","STEP:1083, D{v_l: 0.219, v_acc: [87.5| 90.6| 89.1], c_acc: [81.2| 100.0]}  G{v_l: 1.207, v_acc: 37.5, c_acc: 95.3}\n","STEP:1084, D{v_l: 0.342, v_acc: [87.5| 90.6| 89.1], c_acc: [96.9| 90.6]}  G{v_l: 0.970, v_acc: 56.2, c_acc: 98.4}\n","STEP:1085, D{v_l: 0.198, v_acc: [100.0| 96.9| 98.4], c_acc: [96.9| 100.0]}  G{v_l: 0.949, v_acc: 40.6, c_acc: 95.3}\n","STEP:1086, D{v_l: 0.461, v_acc: [84.4| 78.1| 81.2], c_acc: [100.0| 75.0]}  G{v_l: 1.148, v_acc: 48.4, c_acc: 85.9}\n","STEP:1087, D{v_l: 0.242, v_acc: [87.5| 93.8| 90.6], c_acc: [100.0| 100.0]}  G{v_l: 1.034, v_acc: 53.1, c_acc: 92.2}\n","STEP:1088, D{v_l: 0.413, v_acc: [84.4| 84.4| 84.4], c_acc: [96.9| 96.9]}  G{v_l: 1.099, v_acc: 40.6, c_acc: 84.4}\n","STEP:1089, D{v_l: 0.303, v_acc: [90.6| 84.4| 87.5], c_acc: [90.6| 100.0]}  G{v_l: 1.396, v_acc: 53.1, c_acc: 96.9}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 45ms/step - loss: 3.5839 - valid_loss: 0.3507 - class_loss: 2.8190 - valid_acc: 0.8235 - class_acc: 0.4471\n","3/3 [==============================] - 0s 47ms/step - loss: 0.9990 - valid_loss: 0.5388 - class_loss: 0.0459 - valid_acc: 0.6588 - class_acc: 1.0000\n","average v_acc: 74.118, three class acc: 44.706, two class acc: 60.000\n","====================================================================================================\n","STEP:1090, D{v_l: 0.343, v_acc: [71.8| 90.6| 81.2], c_acc: [96.6| 90.6]}  G{v_l: 0.992, v_acc: 53.1, c_acc: 89.1}\n","STEP:1091, D{v_l: 0.256, v_acc: [90.6| 87.5| 89.1], c_acc: [100.0| 96.9]}  G{v_l: 1.016, v_acc: 54.7, c_acc: 78.1}\n","STEP:1092, D{v_l: 0.206, v_acc: [84.4| 93.8| 89.1], c_acc: [96.9| 100.0]}  G{v_l: 1.239, v_acc: 40.6, c_acc: 92.2}\n","STEP:1093, D{v_l: 0.405, v_acc: [84.4| 90.6| 87.5], c_acc: [96.9| 90.6]}  G{v_l: 1.077, v_acc: 39.1, c_acc: 100.0}\n","STEP:1094, D{v_l: 0.205, v_acc: [96.9| 93.8| 95.3], c_acc: [87.5| 100.0]}  G{v_l: 1.125, v_acc: 50.0, c_acc: 96.9}\n","STEP:1095, D{v_l: 0.285, v_acc: [100.0| 78.1| 89.1], c_acc: [90.6| 87.5]}  G{v_l: 0.955, v_acc: 46.9, c_acc: 90.6}\n","STEP:1096, D{v_l: 0.367, v_acc: [87.5| 81.2| 84.4], c_acc: [90.6| 96.9]}  G{v_l: 1.039, v_acc: 43.8, c_acc: 93.8}\n","STEP:1097, D{v_l: 0.222, v_acc: [81.2| 96.9| 89.1], c_acc: [93.8| 90.6]}  G{v_l: 0.978, v_acc: 43.8, c_acc: 96.9}\n","STEP:1098, D{v_l: 0.236, v_acc: [90.6| 90.6| 90.6], c_acc: [90.6| 93.8]}  G{v_l: 1.232, v_acc: 34.4, c_acc: 92.2}\n","STEP:1099, D{v_l: 0.231, v_acc: [93.8| 93.8| 93.8], c_acc: [100.0| 96.9]}  G{v_l: 1.077, v_acc: 42.2, c_acc: 98.4}\n","STEP:1100, D{v_l: 0.190, v_acc: [93.8| 93.8| 93.8], c_acc: [100.0| 96.9]}  G{v_l: 1.201, v_acc: 40.6, c_acc: 100.0}\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 0s 44ms/step - loss: 3.7866 - valid_loss: 0.3911 - class_loss: 2.9813 - valid_acc: 0.8000 - class_acc: 0.4941\n","3/3 [==============================] - 0s 46ms/step - loss: 1.0051 - valid_loss: 0.5345 - class_loss: 0.0565 - valid_acc: 0.6941 - class_acc: 0.9882\n","average v_acc: 74.706, three class acc: 49.412, two class acc: 55.294\n","====================================================================================================\n","Epoch: 100\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-sNThj1KfcR2"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"Qb2ythFlffSu"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(latent_dim, test_dataset, model_path):\n","  # load model\n","  path = 'ACGAN/mode0'\n","\n","  d_model, _, _ = all_model(LATENT_DIM)\n","  d_model.load_weights(path + model_path)\n","\n","  X_test, labels_test, codes_test = test_dataset\n","  num_test = X_test.shape[0]\n","  y_test = ones((num_test, 1))\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = d_model.evaluate([X_test, codes_test], [y_test, labels_test], verbose=1)\n","  v_acc = 100 * test_metrics[3]\n","  three_c_acc = 100 * test_metrics[4]\n","\n","  # two class accuracy\n","  _, temp_pred = d_model.predict([X_test, codes_test])\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('average v_acc: %.3f, three class acc: %.3f, two class acc: %.3f' % (v_acc, three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names))\n","\n","  # calculate AUC\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GRf04_klYjg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621305135502,"user_tz":-480,"elapsed":3698,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"6d5ec6e8-6514-4f4e-c84b-4eb61210a819"},"source":["# # load data\n","# train_data, val_data, test_data = load_real_samples()\n","\n","model_path = '/weights/d_model_0572.h5'\n","test(LATENT_DIM, test_data, model_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of Noise Vector: (None, 50)\n","Shape of X: (None, 190, 10)\n","Shape of A: (None, 190, 190, 1)\n","\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 309ms/step - loss: 2.7521 - valid_loss: 0.4833 - class_loss: 1.8516 - valid_acc: 0.7665 - class_acc: 0.4981\n","test: 48.837\n","average v_acc: 76.744, three class acc: 48.837, two class acc: 69.767\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0       0.76      0.69      0.72        49\n","     class 1       0.31      0.19      0.24        26\n","     class 2       0.12      0.27      0.17        11\n","\n","    accuracy                           0.49        86\n","   macro avg       0.40      0.39      0.38        86\n","weighted avg       0.54      0.49      0.51        86\n","\n","AUC:  0.6455858020143735\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0       0.76      0.69      0.72        49\n","     class 1       0.63      0.70      0.67        37\n","\n","    accuracy                           0.70        86\n","   macro avg       0.69      0.70      0.70        86\n","weighted avg       0.70      0.70      0.70        86\n","\n","specificity: 0.6938775510204082\n","AUC:  0.7313844456701599\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1beUl49WJeen"},"source":["'''\n","mode0: label + age + gender\n","mode1: label + age\n","mode2: label + gender\n","mode3: label\n","\n","accuracy precision recall f1_score specificity AUC\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSJ3rODTmeqv"},"source":[""],"execution_count":null,"outputs":[]}]}