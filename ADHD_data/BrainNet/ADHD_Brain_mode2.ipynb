{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ADHD_Brain_mode2.ipynb","provenance":[],"collapsed_sections":["STR4M5oLMRML","mnxxkIPgQjmI","GI_kANkKEnmQ","Qtzgq8Anm_Qc","UyIRcJy2hxMX","X70XqBemjGDD"],"authorship_tag":"ABX9TyNc5dTJ8zc1/YARfzifRWjB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1wCm0vIQLiB","executionInfo":{"status":"ok","timestamp":1621412024685,"user_tz":-480,"elapsed":21318,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"bce03932-9f0c-4031-e109-96df5b0cd763"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive/GAN_for_Neural_Graph/ADHD\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ADHD-200_PhenotypicKey.pdf',\n"," 'ADHD200_training_set_80_190x190.mat',\n"," 'ADHD200_testing_set_20_190x190.mat',\n"," 'ADHD_20%_Data_info_all.xlsx',\n"," 'readme.txt',\n"," 'ADHD_80%_Data_info_all.xlsx',\n"," 'Data',\n"," 'AC_Brain',\n"," 'BrainNet',\n"," 'compared_models',\n"," 'Preprocessing.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"STR4M5oLMRML"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"tgniZqPzQe8K","executionInfo":{"status":"ok","timestamp":1621412029890,"user_tz":-480,"elapsed":3478,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import keras\n","import random\n","from numpy import zeros\n","from numpy import ones\n","from numpy import expand_dims\n","from numpy.random import randn\n","from numpy.random import randint\n","from keras import optimizers\n","from keras import backend as K\n","from keras import activations\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import Sequential\n","from keras import backend\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Embedding\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Add\n","from keras.utils import conv_utils\n","from keras.utils import to_categorical\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras.datasets.fashion_mnist import load_data\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import Adam, RMSprop\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from matplotlib import pyplot"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnxxkIPgQjmI"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"8PYguj4zQmAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621412047547,"user_tz":-480,"elapsed":9750,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"ee1db59e-c625-4ea2-f5f8-a899a753eff9"},"source":["train_data = np.load('Data/train_data.npy')\n","test_data = np.load('Data/test_data.npy')\n","train_combine = np.load('Data/train_combine.npy')\n","test_combine = np.load('Data/test_combine.npy')\n","\n","print(train_data.shape, test_data.shape)\n","print(train_combine.shape, test_combine.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(758, 190, 190) (171, 190, 190)\n","(758, 3) (171, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0nAl5WFXEDh","executionInfo":{"status":"ok","timestamp":1621412047547,"user_tz":-480,"elapsed":9746,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"4bd84a3e-d6c8-4d06-dcc4-e2aa6189e559"},"source":["# shuffle\n","index = [i for i in range(train_data.shape[0])]\n","random.shuffle(index)\n","train_data = train_data[index]\n","train_combine = train_combine[index]\n","\n","print(train_combine[:10])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[[0.         0.45305967 1.        ]\n"," [0.         0.34511593 1.        ]\n"," [2.         0.42607374 1.        ]\n"," [0.         0.31965032 0.        ]\n"," [0.         0.5290764  1.        ]\n"," [1.         0.45496009 1.        ]\n"," [2.         0.37932345 1.        ]\n"," [0.         0.36754086 0.        ]\n"," [0.         0.39870772 1.        ]\n"," [2.         0.50361079 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adhn3ZjWVpj5","executionInfo":{"status":"ok","timestamp":1621412047548,"user_tz":-480,"elapsed":9745,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["def loadDataset():\n","  return train_data, train_combine, test_data, test_combine"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kx5jSQghzIE_","executionInfo":{"status":"ok","timestamp":1621412047548,"user_tz":-480,"elapsed":9742,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"82c0e659-f7f3-48e9-deee-b3e11fc28859"},"source":["# create encoded_data\n","temp_encoded = np.concatenate((train_combine, test_combine), axis=0)\n","temp_onehot = to_categorical(temp_encoded[:, 0])\n","print(temp_onehot.shape)\n","\n","encoded_data = np.zeros((929, 5))\n","encoded_data[:, :3] = temp_onehot\n","encoded_data[:, 3:] = temp_encoded[:, 1:]\n","\n","print(encoded_data.shape)\n","print(encoded_data[:10])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(929, 3)\n","(929, 5)\n","[[1.         0.         0.         0.45305967 1.        ]\n"," [1.         0.         0.         0.34511593 1.        ]\n"," [0.         0.         1.         0.42607374 1.        ]\n"," [1.         0.         0.         0.31965032 0.        ]\n"," [1.         0.         0.         0.5290764  1.        ]\n"," [0.         1.         0.         0.45496009 1.        ]\n"," [0.         0.         1.         0.37932345 1.        ]\n"," [1.         0.         0.         0.36754086 0.        ]\n"," [1.         0.         0.         0.39870772 1.        ]\n"," [0.         0.         1.         0.50361079 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gNoZcRz_MOyZ","executionInfo":{"status":"ok","timestamp":1621412047549,"user_tz":-480,"elapsed":9741,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["# load images\n","def load_real_samples(seed):\n","  # load dataset\n","  X_train, combine_train, X_remain, combine_remain= loadDataset()\n","  \n","  # expand to 3d, e.g. add channels\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_remain = np.expand_dims(X_remain, axis=-1)\n","\n","  X_val, X_test, combine_val, combine_test = train_test_split(X_remain, combine_remain, test_size=0.5, random_state=seed, shuffle=True)\n","\n","  # seperate label, age, gender\n","  y_train = combine_train[:, 0]\n","  y_test = combine_test[:, 0]\n","  y_val = combine_val[:, 0]\n","  as_train = combine_train[:, 1:] \n","  as_test = combine_test[:, 1:]  \n","  as_val = combine_val[:, 1:]\n","\n","  print(f\"Training Data, X shape: {X_train.shape}, y shape: {y_train.shape}, as shape: {as_train.shape}\")\n","  print(f\"Validation Data, X shape: {X_val.shape}, y shape: {y_val.shape}, as shape: {as_val.shape}\")\n","  print(f\"Test Data, X shape: {X_test.shape}, y shape: {y_test.shape}, as shape: {as_test.shape}\")\n","\n","  output = [X_train, y_train, as_train[:, 0]],[X_val, y_val, as_val[:, 0]],[X_test, y_test, as_test[:, 0]]\n","  print(f\"Code_train shape: {as_train[:, 0].shape}\")\n","\n","  return output"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GI_kANkKEnmQ"},"source":["#Hyper parameters"]},{"cell_type":"code","metadata":{"id":"bTwq-sLTErXF","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1621412047549,"user_tz":-480,"elapsed":7323,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"a739f818-3550-4a51-9f75-fd0151f1f0a6"},"source":["DROPOUT = 0.5\n","MOMENTUM = 0.9\n","LR = 0.001  \n","DECAY = 0.0005\n","ALPHA = 0.33\n","FE_CHANNEL = 64\n","CODE_CHANNEL = 8\n","MERGE_CHANNEL = 32\n","BATCH_SIZE = 32\n","\n","'''\n","The number of E2E layers\n","'''"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nThe number of E2E layers\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"GQnmpA-znDOP","executionInfo":{"status":"ok","timestamp":1621412047550,"user_tz":-480,"elapsed":7323,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qtzgq8Anm_Qc"},"source":["#Build Model"]},{"cell_type":"code","metadata":{"id":"0KHQQl6ORKLo","executionInfo":{"status":"ok","timestamp":1621412047550,"user_tz":-480,"elapsed":6520,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["class E2E_conv(Layer):\n","  def __init__(self, rank,\n","         filters,\n","         kernel_size,\n","         strides=1,\n","         padding='valid',\n","         activation=None,\n","         kernel_initializer='glorot_uniform',\n","         kernel_regularizer=None,\n","         kernel_constraint=None,\n","         **kwargs):\n","    super(E2E_conv, self).__init__(**kwargs)\n","    self.rank = rank\n","    self.filters = filters\n","    self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.activation = activations.get(activation)\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.input_spec = InputSpec(ndim=self.rank + 2)\n","\n","  def build(self, input_shape):\n","    channel_axis = -1\n","    if input_shape[channel_axis] is None:\n","      raise ValueError('The channel dimension of the inputs'\n","               'should be defined. Found `None`.')\n","    input_dim = input_shape[channel_axis]\n","    kernel_shape = self.kernel_size + (input_dim, self.filters)\n","\n","    self.kernel = self.add_weight(shape=kernel_shape,\n","                    initializer=self.kernel_initializer,\n","                    name='kernel',\n","                    regularizer=self.kernel_regularizer,\n","                    constraint=self.kernel_constraint)\n","    \n","    # Set input spec.\n","    self.input_spec = InputSpec(ndim=self.rank + 2,\n","                   axes={channel_axis:input_dim})\n","    self.built = True\n","\n","  def call(self, inputs):\n","    kernel_shape = K.get_value(self.kernel).shape\n","    d = kernel_shape[1]\n","    kernellxd = K.reshape(self.kernel[0,:], (1, kernel_shape[1], kernel_shape[2], kernel_shape[3]))  # row vector\n","    kerneldxl = K.reshape(self.kernel[1,:], (kernel_shape[1], 1, kernel_shape[2], kernel_shape[3]))  # column vector\n","    convlxd = K.conv2d(\n","        inputs,\n","        kernellxd,\n","        strides=self.strides,\n","        padding=self.padding)\n","    convdxl = K.conv2d(\n","        inputs,\n","        kerneldxl,\n","        strides=self.strides,\n","        padding=self.padding)\n","    concat1 = K.concatenate([convdxl]*d, axis=1)\n","    concat2 = K.concatenate([convlxd]*d, axis=2)\n","    return concat1 + concat2\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n","\n","  def get_config(self):\n","    config = {\n","        'rank': self.rank,\n","        'filters': self.filters,\n","        'kernel_size': self.kernel_size,\n","        'strides': self.strides,\n","        'padding': self.padding,\n","        'activation': activations.serialize(self.activation),\n","        'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","        'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","        'kernel_constraint': constraints.serialize(self.kernel_constraint)\n","    }\n","    base_config = super(E2E_conv, self).get_config()\n","    return dict(list(base_config.items()) + list(config.items()))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7G8B4M4oO6x","executionInfo":{"status":"ok","timestamp":1621412047550,"user_tz":-480,"elapsed":6518,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["def define_E2E(in_shape=(190,190,1), n_classes=3):\n","  # Setting l2_norm regularizer\n","  reg = regularizers.l2(DECAY)\n","  # kernel initialization\n","  kernel_init = initializers.he_uniform()\n","  in_image = Input(shape=in_shape)\n","\n","  # E2E layer\n","  fe = E2E_conv(2, 16, (2, 190), kernel_regularizer=reg)(in_image) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  fe = E2E_conv(2, 32, (2, 190), kernel_regularizer=reg)(fe) \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # E2N layer\n","  temp1 = Conv2D(64, (1, 190), kernel_regularizer=reg, name='row')(fe)   \n","  temp2 = Conv2D(64, (190, 1), kernel_regularizer=reg, name='column')(fe) \n","  temp2 = Reshape((190, 1, 64))(temp2)\n","  fe = Add()([temp1, temp2])                    \n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # N2G layer\n","  fe = Conv2D(128, (190, 1), kernel_regularizer=reg)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","\n","  # flatten feature maps\n","  fe = Flatten()(fe)\n","\n","  fe = Dense(FE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(fe)\n","  fe = LeakyReLU(alpha=ALPHA)(fe)\n","  fe = Dropout(DROPOUT)(fe)\n","\n","  # code input\n","  code_shape = (1,)  \n","  in_code = Input(shape=code_shape, name='in_code')\n","\n","  code = Dense(CODE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(in_code)\n","  code = LeakyReLU(alpha=ALPHA)(code)\n","  code = Dropout(DROPOUT)(code)\n","\n","  # concatenate image and code\n","  merge = Concatenate()([fe, code])\n","\n","  # # concatenate image and code\n","  # merge = Concatenate()([fe, in_code])\n","\n","  merge = Dense(MERGE_CHANNEL, kernel_regularizer=reg, kernel_initializer=kernel_init)(merge)\n","  merge = LeakyReLU(alpha=ALPHA)(merge)\n","  merge = Dropout(DROPOUT)(merge)\n","\n","  out = Dense(n_classes, activation='softmax', name='out')(merge)\n","    \n","  # define model\n","  model = Model([in_image, in_code], out)\n","  return model"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuQssoINq2Jd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621412053077,"user_tz":-480,"elapsed":12041,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"8f8a8205-82cd-480d-f178-325d5f49680e"},"source":["BrainNetCNN = define_E2E()\n","BrainNetCNN.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 190, 190, 1) 0                                            \n","__________________________________________________________________________________________________\n","e2e_conv (E2E_conv)             (None, 190, 190, 16) 6080        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 190, 190, 16) 0           e2e_conv[0][0]                   \n","__________________________________________________________________________________________________\n","e2e_conv_1 (E2E_conv)           (None, 190, 190, 32) 194560      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 190, 190, 32) 0           e2e_conv_1[0][0]                 \n","__________________________________________________________________________________________________\n","column (Conv2D)                 (None, 1, 190, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","row (Conv2D)                    (None, 190, 1, 64)   389184      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 190, 1, 64)   0           column[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 190, 1, 64)   0           row[0][0]                        \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 190, 1, 64)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 1, 1, 128)    1556608     leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 1, 1, 128)    0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 128)          0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","in_code (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 64)           8256        flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 8)            16          in_code[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 64)           0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 8)            0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 64)           0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 8)            0           leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 72)           0           dropout[0][0]                    \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 32)           2336        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 32)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32)           0           leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","out (Dense)                     (None, 3)            99          dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 2,546,323\n","Trainable params: 2,546,323\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UyIRcJy2hxMX"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"inVRFCBByAYA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621412053078,"user_tz":-480,"elapsed":9175,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"bda5c0ab-8c20-4c6d-87ef-c389a4d00a09"},"source":["# load data\n","train_data, val_data, test_data = load_real_samples(42)\n","X_train, y_train, code_train = train_data\n","X_val, y_val, code_val = val_data\n","X_test, y_test, code_test = test_data"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Training Data, X shape: (758, 190, 190, 1), y shape: (758,), as shape: (758, 2)\n","Validation Data, X shape: (85, 190, 190, 1), y shape: (85,), as shape: (85, 2)\n","Test Data, X shape: (86, 190, 190, 1), y shape: (86,), as shape: (86, 2)\n","Code_train shape: (758,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9m8iJp4eq3Cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413308643,"user_tz":-480,"elapsed":134183,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"ae4b9c29-a780-49e5-e46e-c19ff7ee0742"},"source":["path = \"./BrainNet/mode2/epoch_30.h5\"\n","batch_size = 32\n","\n","opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","checkpoint = ModelCheckpoint(path, monitor='val_acc', verbose=0, save_best_only=True)\n","earlystopping = EarlyStopping(patience=10)\n","callbacks_list = [checkpoint,earlystopping]\n","\n","# define model\n","model_1 = define_E2E()\n","model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","\n","# train\n","history = model_1.fit([X_train, code_train], y_train,\n","              epochs=100,\n","              batch_size=batch_size,\n","              validation_data=([X_val, code_val], y_val),\n","              callbacks=callbacks_list,\n","              shuffle=True)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","24/24 [==============================] - 7s 183ms/step - loss: 1.2348 - acc: 0.4706 - val_loss: 1.2161 - val_acc: 0.5294\n","Epoch 2/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.2152 - acc: 0.5343 - val_loss: 1.2242 - val_acc: 0.5294\n","Epoch 3/100\n","24/24 [==============================] - 4s 163ms/step - loss: 1.1617 - acc: 0.6045 - val_loss: 1.2253 - val_acc: 0.5294\n","Epoch 4/100\n","24/24 [==============================] - 4s 165ms/step - loss: 1.1824 - acc: 0.6125 - val_loss: 1.2225 - val_acc: 0.5294\n","Epoch 5/100\n","24/24 [==============================] - 4s 165ms/step - loss: 1.1844 - acc: 0.6052 - val_loss: 1.2226 - val_acc: 0.5294\n","Epoch 6/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1841 - acc: 0.5900 - val_loss: 1.2213 - val_acc: 0.5294\n","Epoch 7/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1492 - acc: 0.6099 - val_loss: 1.2228 - val_acc: 0.5294\n","Epoch 8/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1727 - acc: 0.6197 - val_loss: 1.2150 - val_acc: 0.5294\n","Epoch 9/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1804 - acc: 0.5869 - val_loss: 1.2138 - val_acc: 0.5294\n","Epoch 10/100\n","24/24 [==============================] - 4s 163ms/step - loss: 1.1562 - acc: 0.6133 - val_loss: 1.2201 - val_acc: 0.5294\n","Epoch 11/100\n","24/24 [==============================] - 4s 165ms/step - loss: 1.0999 - acc: 0.6391 - val_loss: 1.2160 - val_acc: 0.5294\n","Epoch 12/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0908 - acc: 0.6492 - val_loss: 1.2132 - val_acc: 0.5294\n","Epoch 13/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1242 - acc: 0.6333 - val_loss: 1.2149 - val_acc: 0.5294\n","Epoch 14/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1050 - acc: 0.6432 - val_loss: 1.2108 - val_acc: 0.5294\n","Epoch 15/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0928 - acc: 0.6449 - val_loss: 1.2100 - val_acc: 0.5294\n","Epoch 16/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0975 - acc: 0.6316 - val_loss: 1.2040 - val_acc: 0.5294\n","Epoch 17/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1133 - acc: 0.6399 - val_loss: 1.1999 - val_acc: 0.5294\n","Epoch 18/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1267 - acc: 0.6174 - val_loss: 1.1954 - val_acc: 0.5294\n","Epoch 19/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.1083 - acc: 0.6202 - val_loss: 1.1893 - val_acc: 0.5294\n","Epoch 20/100\n","24/24 [==============================] - 4s 165ms/step - loss: 1.0626 - acc: 0.6470 - val_loss: 1.1855 - val_acc: 0.5294\n","Epoch 21/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0749 - acc: 0.6465 - val_loss: 1.1842 - val_acc: 0.5294\n","Epoch 22/100\n","24/24 [==============================] - 4s 165ms/step - loss: 1.0268 - acc: 0.6584 - val_loss: 1.1761 - val_acc: 0.5294\n","Epoch 23/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0671 - acc: 0.6403 - val_loss: 1.1757 - val_acc: 0.5294\n","Epoch 24/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0009 - acc: 0.6458 - val_loss: 1.2756 - val_acc: 0.5294\n","Epoch 25/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.9639 - acc: 0.6661 - val_loss: 1.1942 - val_acc: 0.5294\n","Epoch 26/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.9613 - acc: 0.6765 - val_loss: 1.1845 - val_acc: 0.5059\n","Epoch 27/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.9004 - acc: 0.6868 - val_loss: 1.2090 - val_acc: 0.5529\n","Epoch 28/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.8951 - acc: 0.6910 - val_loss: 1.1808 - val_acc: 0.5529\n","Epoch 29/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.8581 - acc: 0.6943 - val_loss: 1.8031 - val_acc: 0.5294\n","Epoch 30/100\n","24/24 [==============================] - 4s 164ms/step - loss: 1.0731 - acc: 0.5841 - val_loss: 1.2429 - val_acc: 0.5529\n","Epoch 31/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.7736 - acc: 0.7534 - val_loss: 1.2518 - val_acc: 0.4941\n","Epoch 32/100\n","24/24 [==============================] - 4s 165ms/step - loss: 0.8086 - acc: 0.7192 - val_loss: 1.4968 - val_acc: 0.5412\n","Epoch 33/100\n","24/24 [==============================] - 4s 164ms/step - loss: 0.7876 - acc: 0.7391 - val_loss: 1.3311 - val_acc: 0.5294\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZdeE-0xWGlN","executionInfo":{"status":"ok","timestamp":1621413312927,"user_tz":-480,"elapsed":29037,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"21e6afac-8d50-4028-e23c-bb48ef256591"},"source":["test(test_data)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 38ms/step - loss: 1.2222 - acc: 0.5602\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbe2fe12a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","test: 58.140\n","three class acc: 58.140, two class acc: 61.628\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6053    0.9388    0.7360        49\n","     class 1     0.4000    0.1538    0.2222        26\n","     class 2     0.0000    0.0000    0.0000        11\n","\n","    accuracy                         0.5814        86\n","   macro avg     0.3351    0.3642    0.3194        86\n","weighted avg     0.4658    0.5814    0.4865        86\n","\n","AUC:  0.6104913962056819\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6053    0.9388    0.7360        49\n","     class 1     0.7000    0.1892    0.2979        37\n","\n","    accuracy                         0.6163        86\n","   macro avg     0.6526    0.5640    0.5169        86\n","weighted avg     0.6460    0.6163    0.5475        86\n","\n","specificity: 0.9387755102040817\n","AUC:  0.6205184776613348\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"X70XqBemjGDD"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"xPBbaCfhe6XB","executionInfo":{"status":"ok","timestamp":1621412205119,"user_tz":-480,"elapsed":155022,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}}},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","def calculate_score(test, pred):\n","  new_pred = np.zeros((pred.shape[0], 2))\n","  new_pred[:, 0] = pred[:, 0]\n","  new_pred[:, 1] = pred[:, 1] + pred[: ,2]\n","  score = new_pred[:, 1]\n","  return score\n","\n","def test(test_dataset):\n","  # load model\n","  path = \"./BrainNet/mode2/epoch_30.h5\"\n","  model_1 = define_E2E()\n","  opt = optimizers.SGD(momentum=MOMENTUM,nesterov=True,lr=LR)\n","  model_1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['acc'])\n","  model_1.load_weights(path)\n","\n","  X_test, labels_test, code_test = test_dataset\n","  num_test = X_test.shape[0]\n","\n","  print(f\"\\nValidation Metrics of Discriminator:\")\n","  test_metrics = model_1.evaluate([X_test, code_test], labels_test, verbose=1)\n","  three_c_acc = 100 * test_metrics[1]\n","\n","  # two class accuracy\n","  temp_pred = model_1.predict([X_test, code_test])\n","  labels_pred = np.argmax(temp_pred, axis=1)\n","\n","  correct = np.sum(labels_pred==labels_test)\n","  acc = correct / num_test * 100\n","  print('test: %.3f' % acc)\n","\n","  labels_2_test, labels_2_pred = labels_test.copy(), labels_pred.copy()\n","  # classify 2 as 1\n","  labels_2_test[labels_2_test==2] = 1\n","  labels_2_pred[labels_2_pred==2] = 1\n","  # calculate the accuracy\n","  correct = np.sum(labels_2_test==labels_2_pred)\n","  two_c_acc = correct / num_test * 100\n","  print('three class acc: %.3f, two class acc: %.3f' % (three_c_acc, two_c_acc))\n","  print(\"=\"*100)\n","\n","  # three class confusion metrics\n","  target_names = ['class 0', 'class 1', 'class 2']\n","  print('three class:')\n","\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_test, labels_pred, target_names=target_names, digits=4))\n","\n","  # calculate AUC\n","  onehot = to_categorical(labels_test, num_classes=3)\n","  AUC = metrics.roc_auc_score(onehot, temp_pred, multi_class='ovr')\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)\n","\n","  # two class confusion metrics\n","  target_names = ['class 0', 'class 1']\n","  print('two class:')\n","  # calculate precision, recall, f1 score\n","  print(classification_report(labels_2_test, labels_2_pred, target_names=target_names, digits=4))\n","\n","  # calcuate specificity\n","  tn, fp, fn, tp = confusion_matrix(labels_2_test, labels_2_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print('specificity:', specificity)\n","\n","  # calculate AUC\n","  score = calculate_score(labels_2_test, temp_pred)\n","  AUC = metrics.roc_auc_score(labels_2_test, score)\n","  print('AUC: ', AUC)\n","  print(\"=\"*100)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DhuhxEeiX9X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621389635263,"user_tz":-480,"elapsed":2448,"user":{"displayName":"bin wu","photoUrl":"","userId":"03860176266725967165"}},"outputId":"7a946ea4-d325-472c-d87f-085622e4577b"},"source":["test(test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Validation Metrics of Discriminator:\n","3/3 [==============================] - 1s 28ms/step - loss: 1.2545 - acc: 0.5641\n","test: 58.140\n","three class acc: 58.140, two class acc: 63.953\n","====================================================================================================\n","three class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6250    0.9184    0.7438        49\n","     class 1     0.3571    0.1923    0.2500        26\n","     class 2     0.0000    0.0000    0.0000        11\n","\n","    accuracy                         0.5814        86\n","   macro avg     0.3274    0.3702    0.3313        86\n","weighted avg     0.4641    0.5814    0.4994        86\n","\n","AUC:  0.6893292293292292\n","====================================================================================================\n","two class:\n","              precision    recall  f1-score   support\n","\n","     class 0     0.6250    0.9184    0.7438        49\n","     class 1     0.7143    0.2703    0.3922        37\n","\n","    accuracy                         0.6395        86\n","   macro avg     0.6696    0.5943    0.5680        86\n","weighted avg     0.6634    0.6395    0.5925        86\n","\n","specificity: 0.9183673469387755\n","AUC:  0.6949806949806949\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}